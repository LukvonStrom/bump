[INFO] Scanning for projects...
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Build Order:
[INFO] 
[INFO] Conquery Parent                                                    [pom]
[INFO] backend                                                            [jar]
[INFO] executable                                                         [jar]
[INFO] autodoc                                                            [jar]
[INFO] 
[INFO] --------------------< com.bakdata.conquery:parent >---------------------
[INFO] Building Conquery Parent 0.0.0-SNAPSHOT                            [1/4]
[INFO] --------------------------------[ pom ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:3.1.0:clean (default-clean) @ parent ---
[INFO] 
[INFO] --------------------< com.bakdata.conquery:backend >--------------------
[INFO] Building backend 0.0.0-SNAPSHOT                                    [2/4]
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:3.1.0:clean (default-clean) @ backend ---
[INFO] Deleting /home/gabsko/breaking-updates/backend/target
[INFO] 
[INFO] --- maven-resources-plugin:3.2.0:resources (default-resources) @ backend ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Using 'UTF-8' encoding to copy filtered properties files.
[INFO] Copying 2 resources
[INFO] Copying 32 resources
[INFO] The encoding used to copy filtered properties files have not been set. This means that the same encoding will be used to copy filtered properties files as when copying other filtered resources. This might not be what you want! Run your build with --debug to see which files might be affected. Read more at https://maven.apache.org/plugins/maven-resources-plugin/examples/filtering-properties-files.html
[INFO] 
[INFO] --- maven-compiler-plugin:3.8.1:compile (default-compile) @ backend ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 822 source files to /home/gabsko/breaking-updates/backend/target/classes
[INFO] /home/gabsko/breaking-updates/backend/src/main/java/com/bakdata/conquery/models/common/Range.java: Some input files use or override a deprecated API.
[INFO] /home/gabsko/breaking-updates/backend/src/main/java/com/bakdata/conquery/models/common/Range.java: Recompile with -Xlint:deprecation for details.
[INFO] /home/gabsko/breaking-updates/backend/src/main/java/com/bakdata/conquery/models/common/Range.java: Some input files use unchecked or unsafe operations.
[INFO] /home/gabsko/breaking-updates/backend/src/main/java/com/bakdata/conquery/models/common/Range.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-resources-plugin:3.2.0:testResources (default-testResources) @ backend ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Using 'UTF-8' encoding to copy filtered properties files.
[INFO] Copying 467 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.8.1:testCompile (default-testCompile) @ backend ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 128 source files to /home/gabsko/breaking-updates/backend/target/test-classes
[INFO] /home/gabsko/breaking-updates/backend/src/test/java/com/bakdata/conquery/tasks/PermissionCleanupTaskTest.java: Some input files use or override a deprecated API.
[INFO] /home/gabsko/breaking-updates/backend/src/test/java/com/bakdata/conquery/tasks/PermissionCleanupTaskTest.java: Recompile with -Xlint:deprecation for details.
[INFO] /home/gabsko/breaking-updates/backend/src/test/java/com/bakdata/conquery/integration/tests/ReusedQueryTest.java: Some input files use unchecked or unsafe operations.
[INFO] /home/gabsko/breaking-updates/backend/src/test/java/com/bakdata/conquery/integration/tests/ReusedQueryTest.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.22.2:test (default-test) @ backend ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running com.bakdata.conquery.models.forms.DateContextTest
[INFO] Tests run: 15, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.11 s - in com.bakdata.conquery.models.forms.DateContextTest
[INFO] Running com.bakdata.conquery.models.execution.DefaultLabelTest
[INFO] [TEST] [2023-01-26 18:07:42]	c.b.c.i.c.CPSTypeIdResolver		Scanning Classpath
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver		Scanned: 1096 classes in classpath
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver			Base Class CredentialType
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				PASSWORD	->	PasswordCredential
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver			Base Class Mode
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				ABSOLUTE	->	AbsoluteMode
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				RELATIVE	->	RelativeMode
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				ENTITY_DATE	->	EntityDateMode
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver			Base Class CQElement
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				SAVED_QUERY	->	CQReusedQuery
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				AND	->	CQAnd
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				NEGATION	->	CQNegation
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				DAYS_BEFORE	->	CQDaysBeforeTemporalQuery
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				BEFORE_OR_SAME	->	CQBeforeOrSameTemporalQuery
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				RESULT_INFO_DECORATOR	->	ResultInfoDecorator
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				EXTERNAL	->	CQExternal
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				OR	->	CQOr
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				DAYS_OR_NO_EVENT_BEFORE	->	CQDaysBeforeOrNeverTemporalQuery
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				BEFORE	->	CQBeforeTemporalQuery
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				CONCEPT	->	CQConcept
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				SAME	->	CQSameTemporalQuery
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				DATE_RESTRICTION	->	CQDateRestriction
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver			Base Class QueryDescription
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				SECONDARY_ID_QUERY	->	SecondaryIdQuery
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				ENTITY_DATE_QUERY	->	EntityDateQuery
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				TABLE_EXPORT	->	TableExportQuery
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				CONCEPT_QUERY	->	ConceptQuery
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				FULL_EXPORT_FORM	->	FullExportForm
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				EXPORT_FORM	->	ExportForm
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				ABSOLUTE_FORM_QUERY	->	AbsoluteFormQuery
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				RELATIVE_FORM_QUERY	->	RelativeFormQuery
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				ARRAY_CONCEPT_QUERY	->	ArrayConceptQuery
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver			Base Class FilterValue
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				REAL_RANGE	->	CQRealRangeFilter
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				STRING	->	CQStringFilter
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				INTEGER_RANGE	->	CQIntegerRangeFilter
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				MONEY_RANGE	->	CQMoneyRangeFilter
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				BIG_MULTI_SELECT	->	CQBigMultiSelectFilter
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				SELECT	->	CQSelectFilter
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				MULTI_SELECT	->	CQMultiSelectFilter
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver			Base Class ConqueryTestSpec
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				FILTER_TEST	->	FilterTest
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				QUERY_TEST	->	QueryTest
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				FORM_TEST	->	FormTest
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver			Base Class ResultRendererProvider
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				XLSX	->	XlsxResultProvider
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				ARROW_STREAM	->	ArrowStreamResultProvider
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				ARROW_FILE	->	ArrowFileResultProvider
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				CSV	->	CsvResultRendererProvider
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver			Base Class ConqueryPermission
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				WILDCARD_PERMISSION	->	WildcardPermission
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver			Base Class StringPermissionBuilder
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				FORM_CONFIG	->	FormConfigPermission
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				ADMIN	->	AdminPermission
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				FORM_TYPE	->	FormPermission
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				DATASET	->	DatasetPermission
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				SUPER	->	SuperPermission
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				CONCEPT	->	ConceptPermission
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				EXECUTION	->	ExecutionPermission
[WARN] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver			Base Class interface com.bakdata.conquery.models.config.PluginConfig:	No registered types
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver			Base Class StoreFactory
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				NON_PERSISTENT	->	NonPersistentStoreFactory
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				XODUS	->	XodusStoreFactory
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver			Base Class AuthenticationRealmFactory
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				DEVELOPMENT	->	DevAuthConfig
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				API_TOKEN	->	ApiTokenRealmFactory
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				JWT_PKCE_REALM	->	JwtPkceVerifyingRealmFactory
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				LOCAL_AUTHENTICATION	->	LocalAuthenticationConfig
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				OIDC_AUTHORIZATION_CODE_FLOW	->	OIDCAuthorizationCodeFlowRealmFactory
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				OIDC_RESOURCE_OWNER_PASSWORD_CREDENTIAL_AUTHENTICATION	->	OIDCResourceOwnerPasswordCredentialRealmFactory
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver			Base Class AuthorizationConfig
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				DEVELOPMENT	->	DevelopmentAuthorizationConfig
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				DEFAULT	->	DefaultAuthorizationConfig
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver			Base Class Concept
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				TREE	->	TreeConcept
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver			Base Class CTCondition
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				EQUAL	->	EqualCondition
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				OR	->	OrCondition
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				GROOVY	->	GroovyCondition
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				PREFIX_LIST	->	PrefixCondition
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				AND	->	AndCondition
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				PREFIX_RANGE	->	PrefixRangeCondition
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				PRESENT	->	IsPresentCondition
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				COLUMN_EQUAL	->	ColumnEqualCondition
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				NOT	->	NotCondition
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver			Base Class Filter
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				COUNT	->	CountFilter
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				COUNT_QUARTERS	->	CountQuartersFilter
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				PREFIX_TEXT	->	PrefixTextFilter
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				NUMBER	->	NumberFilter
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				BIG_MULTI_SELECT	->	BigMultiSelectFilter
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				DATE_DISTANCE	->	DateDistanceFilter
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				SELECT	->	MultiSelectFilter
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				DURATION_SUM	->	DurationSumFilter
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				QUARTERS_IN_YEAR	->	QuartersInYearFilter
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				SINGLE_SELECT	->	SelectFilter
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				SUM	->	SumFilter
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver			Base Class Select
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				QUARTER	->	QuarterSelect
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				COUNT_QUARTERS	->	CountQuartersSelect
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				EXISTS	->	ExistsSelect
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				QUARTERS_IN_YEAR	->	QuartersInYearSelect
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				FIRST	->	FirstValueSelect
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				DATE_UNION	->	DateUnionSelect
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				DURATION_SUM	->	DurationSumSelect
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				COUNT	->	CountSelect
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				EVENT_DURATION_SUM	->	EventDurationSumSelect
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				PREFIX	->	PrefixSelect
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				DISTINCT	->	DistinctSelect
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				RANDOM	->	RandomValueSelect
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				COUNT_OCCURENCES	->	CountOccurencesSelect
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				LAST	->	LastValueSelect
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				EVENT_DATE_UNION	->	EventDateUnionSelect
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				DATE_DISTANCE	->	DateDistanceSelect
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				SUM	->	SumSelect
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver			Base Class Dictionary
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				MAP_DICTIONARY	->	MapDictionary
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				SUCCINCT_TRIE	->	SuccinctTrie
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver			Base Class ConqueryError
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				CQ_EXECUTION_CREATION_PLAN	->	ExecutionCreationPlanError
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				CQ_EXECUTION_JOB	->	ExecutionJobErrorWrapper
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				CQ_EXECUTION_NO_SECONDARY_ID	->	NoSecondaryIdSelectedError
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				CQ_EXECUTION_PROCESSING	->	ExecutionProcessingError
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				CQ_EXECUTION_CREATION_RESOLVE_EXTERNAL	->	ExternalResolveError
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				CQ_EXECUTION_CREATION_RESOLVE_EXTERNAL_FORMAT	->	ExternalResolveFormatError
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				CQ_EXECUTION_CREATION	->	ExecutionCreationErrorUnspecified
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				CQ_EXECUTION_PROCESSING_TIMEOUT	->	ExecutionProcessingTimeoutError
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				CQ_UNKNOWN_ERROR	->	UnknownError
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				CQ_EXECUTION_CREATION_RESOLVE	->	ExecutionCreationResolveError
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				CQ_EXECUTION_CREATION_CREATION_PLAN_DATECONTEXT_MISMATCH	->	ExecutionCreationPlanDateContextError
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				CQ_EXECUTION_CREATION_RESOLVE_EXTERNAL_EMPTY	->	ExternalResolveEmptyError
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver			Base Class ColumnStore
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				BOOLEANS	->	BitSetStore
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				STRING_NUMBER	->	StringTypeNumber
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				BYTES	->	ByteArrayStore
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				LONGS	->	LongArrayStore
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				SHORTS	->	ShortArrayStore
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				STRING_PREFIX	->	StringTypePrefixSuffix
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				EMPTY	->	EmptyStore
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				INTEGERS	->	IntArrayStore
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				DATES	->	IntegerDateStore
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				REBASE	->	RebasingStore
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				MONEY_VARINT	->	MoneyIntStore
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				DATE_RANGE_COMPOUND	->	DateRangeTypeCompound
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				STRING_DICTIONARY	->	StringTypeDictionary
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				DECIMALS	->	DecimalArrayStore
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				DATE_RANGE_DATE_RANGE	->	DateRangeTypeDateRange
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				DOUBLES	->	DoubleArrayStore
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				FLOATS	->	FloatArrayStore
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				STRING_SINGLETON	->	StringTypeSingleton
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				DECIMAL_SCALED	->	DecimalTypeScaled
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				DATE_RANGE_QUARTER	->	DateRangeTypeQuarter
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				STRING_ENCODED	->	StringTypeEncoded
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver			Base Class ManagedExecution
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				MANAGED_QUERY	->	ManagedQuery
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				INTERNAL_FORM	->	ManagedInternalForm
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				MANAGED_FORM	->	ManagedForm
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver			Base Class ResultType
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				INTEGER	->	IntegerT
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				MONEY	->	MoneyT
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				RESOLUTION	->	ResolutionT
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				DATE	->	DateT
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				STRING	->	StringT
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				ID	->	IdT
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				DATE_RANGE	->	DateRangeT
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				BOOLEAN	->	BooleanT
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				LIST	->	ListT
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				NUMERIC	->	NumericT
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				CATEGORICAL	->	CategoricalT
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver			Base Class NamespacedMessage
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				REMOVE_SECONDARYID	->	RemoveSecondaryId
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				IMPORT_BIT	->	ImportBucket
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				REMOVE_IMPORT	->	RemoveImportJob
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				REMOVE_TABLE	->	RemoveTable
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				REMOVE_CONCEPT	->	RemoveConcept
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				SHUTDOWN_WORKER	->	ShutdownWorkerStorage
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				UPDATE_SHARD_WORKER_IDENTITY	->	UpdateWorkerBucket
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				EXECUTE_FORM	->	ExecuteForm
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				CANCEL_QUERY	->	CancelQuery
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				UPDATE_METADATA	->	UpdateElementMatchingStats
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				REQUEST_CONSISTENCY	->	RequestConsistency
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				UPDATE_DATASET	->	UpdateDataset
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				UPDATE_DICTIONARY	->	UpdateDictionary
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				UPDATE_CONCEPT	->	UpdateConcept
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				UPDATE_MATCHING_STATS	->	UpdateMatchingStatsMessage
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				ADD_IMPORT	->	AddImport
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				REPORT_CONSISTENCY	->	ReportConsistency
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				UPDATE_TABLE	->	UpdateTable
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				COLLECT_QUERY_RESULT	->	CollectQueryResult
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				EXECUTE_QUERY	->	ExecuteQuery
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				UPDATE_SECONDARYID	->	UpdateSecondaryId
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver			Base Class NetworkMessage
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				FORWARD_TO_WORKER	->	ForwardToWorker
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				UPDATE_JOB_MANAGER_STATUS	->	UpdateJobManagerStatus
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				CANCEL_JOB	->	CancelJobMessage
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				FORWARD_TO_NAMESPACE	->	ForwardToNamespace
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				REMOVE_SHARD_NODE	->	RemoveShardNode
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				REMOVE_WORKER	->	RemoveWorker
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				ADD_SHARD_NODE	->	AddShardNode
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				REGISTER_SHARD_WORKER_IDENTITY	->	RegisterWorker
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				ADD_WORKER	->	AddWorker
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver			Base Class OutputDescription
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				COMPOUND_DATE_RANGE	->	CompoundDateRangeOutput
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				COPY	->	CopyOutput
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				LINE	->	LineOutput
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				DATE_RANGE	->	DateRangeOutput
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				EPOCH_DATE_RANGE	->	EpochDateRangeOutput
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				EPOCH	->	EpochOutput
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				NULL	->	NullOutput
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver			Base Class EntityResult
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				SINGLE_LINE	->	SinglelineEntityResult
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				MULTI_LINE	->	MultilineEntityResult
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver			Base Class ShardResult
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				FORM_SHARD_RESULT	->	FormShardResult
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				SHARD_RESULT	->	ShardResult
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver			Base Class ResourcesProvider
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				ApiV1	->	ApiV1
[INFO] [TEST] [2023-01-26 18:07:43]	c.b.c.i.c.CPSTypeIdResolver				FORM_RESOURCES	->	FormResourceProvider
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.515 s - in com.bakdata.conquery.models.execution.DefaultLabelTest
[INFO] Running com.bakdata.conquery.models.events.stores.primitive.BooleanStoreTest
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.139 s - in com.bakdata.conquery.models.events.stores.primitive.BooleanStoreTest
[INFO] Running com.bakdata.conquery.models.events.stores.primitive.IntArrayStoreTest
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 s - in com.bakdata.conquery.models.events.stores.primitive.IntArrayStoreTest
[INFO] Running com.bakdata.conquery.models.events.stores.types.ColumnStoreSerializationTests
ERROR StatusLogger Log4j2 could not find a logging implementation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...
[INFO] Tests run: 21, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.977 s - in com.bakdata.conquery.models.events.stores.types.ColumnStoreSerializationTests
[INFO] Running com.bakdata.conquery.models.events.stores.types.MajorTypesTest
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.011 s - in com.bakdata.conquery.models.events.stores.types.MajorTypesTest
[INFO] Running com.bakdata.conquery.models.events.stores.types.StringEncodingTest
[INFO] Tests run: 101, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.055 s - in com.bakdata.conquery.models.events.stores.types.StringEncodingTest
[INFO] Running com.bakdata.conquery.models.events.CBlockTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.087 s - in com.bakdata.conquery.models.events.CBlockTest
[INFO] Running com.bakdata.conquery.models.error.ConqueryErrorTest
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.024 s - in com.bakdata.conquery.models.error.ConqueryErrorTest
[INFO] Running com.bakdata.conquery.models.query.UniqueNameTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.008 s - in com.bakdata.conquery.models.query.UniqueNameTest
[INFO] Running com.bakdata.conquery.models.query.DefaultColumnNameTest
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.113 s - in com.bakdata.conquery.models.query.DefaultColumnNameTest
[INFO] Running com.bakdata.conquery.models.SerializationTests
[INFO] [TEST] [2023-01-26 18:07:45]	c.b.c.m.SerializationTests		Beware, this test will print an ERROR message.
[ERROR] [TEST] [2023-01-26 18:07:45]	c.b.c.m.e.ConqueryError$UnknownError		Encountered unknown Error[181a2bd4-09a6-41d3-9bc0-fa4a7f9cbd81]
[INFO] Tests run: 18, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.871 s - in com.bakdata.conquery.models.SerializationTests
[INFO] Running com.bakdata.conquery.models.auth.ApiTokenTest
[INFO] [TEST] [2023-01-26 18:07:45]	c.b.c.m.a.ApiTokenTest		Testing token: cq_44TZxFytw2tnEbJTa0OpX9gmBZENIzOWE2l47
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 s - in com.bakdata.conquery.models.auth.ApiTokenTest
[INFO] Running com.bakdata.conquery.models.auth.LocalAuthRealmTest
[INFO] [TEST] [2023-01-26 18:07:46]	c.b.c.m.a.b.PasswordHasher		Using the following settings to generate password hashes:
	Algorithm: PBKDF2WithHmacSHA1
	Iterations: 10000
	Key length: 256
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.682 s - in com.bakdata.conquery.models.auth.LocalAuthRealmTest
[INFO] Running com.bakdata.conquery.models.auth.CopyUserTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.003 s - in com.bakdata.conquery.models.auth.CopyUserTest
[INFO] Running com.bakdata.conquery.models.auth.InstancePermissionImplificationTest
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 s - in com.bakdata.conquery.models.auth.InstancePermissionImplificationTest
[INFO] Running com.bakdata.conquery.models.auth.IdpDelegatingAccessTokenCreatorTest
Loading JavaScript to validate ECMA262 regular expression in JsonSchema because java.util.regex package in Java does not match ECMA262
Warning: Nashorn engine is planned to be removed from a future JDK release
[INFO] [TEST] [2023-01-26 18:07:47]	c.b.c.m.a.IdpDelegatingAccessTokenCreatorTest		This test will print an Error below.
[ERROR] [TEST] [2023-01-26 18:07:47]	c.b.c.m.a.o.p.IdpDelegatingAccessTokenCreator		Received the following error from the auth server while validating username and password:
	Path: http://localhost:1080/realms/test_relam/protocol/openid-connect/token
	Status code: 403
	Status message: null
	Content: {"error":null}
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.498 s - in com.bakdata.conquery.models.auth.IdpDelegatingAccessTokenCreatorTest
[INFO] Running com.bakdata.conquery.models.auth.PermissionCreationTest
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 s - in com.bakdata.conquery.models.auth.PermissionCreationTest
[INFO] Running com.bakdata.conquery.models.auth.oidc.JwtPkceVerifyingRealmTest
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.751 s - in com.bakdata.conquery.models.auth.oidc.JwtPkceVerifyingRealmTest
[INFO] Running com.bakdata.conquery.models.auth.IntrospectionDelegatingRealmTest
[INFO] [TEST] [2023-01-26 18:07:52]	c.b.c.m.a.o.IntrospectionDelegatingRealm		Created new group: Group[group.group2]
[INFO] [TEST] [2023-01-26 18:07:52]	c.b.c.m.a.o.IntrospectionDelegatingRealm		Created new user: User[user.test_name1]
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.455 s - in com.bakdata.conquery.models.auth.IntrospectionDelegatingRealmTest
[INFO] Running com.bakdata.conquery.models.common.CQuarterTest
[INFO] Tests run: 616, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.166 s - in com.bakdata.conquery.models.common.CQuarterTest
[INFO] Running com.bakdata.conquery.models.common.daterange.CDateRangeTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 s - in com.bakdata.conquery.models.common.daterange.CDateRangeTest
[INFO] Running com.bakdata.conquery.models.common.RangeTest
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 s - in com.bakdata.conquery.models.common.RangeTest
[INFO] Running com.bakdata.conquery.models.common.QuarterUtilsTest
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 s - in com.bakdata.conquery.models.common.QuarterUtilsTest
[INFO] Running com.bakdata.conquery.models.externalservice.ResultTypeTest
[INFO] Tests run: 62, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.04 s - in com.bakdata.conquery.models.externalservice.ResultTypeTest
[INFO] Running com.bakdata.conquery.models.datasets.concepts.frontend.FEValueTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 s - in com.bakdata.conquery.models.datasets.concepts.frontend.FEValueTest
[INFO] Running com.bakdata.conquery.models.datasets.concepts.temporal.TemporalSamplerTest
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 s - in com.bakdata.conquery.models.datasets.concepts.temporal.TemporalSamplerTest
[INFO] Running com.bakdata.conquery.models.datasets.concepts.tree.GroovyIndexedTest
[INFO] Tests run: 51, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.131 s - in com.bakdata.conquery.models.datasets.concepts.tree.GroovyIndexedTest
[INFO] Running com.bakdata.conquery.models.datasets.concepts.tree.MatchingStatsTests
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 s - in com.bakdata.conquery.models.datasets.concepts.tree.MatchingStatsTests
[INFO] Running com.bakdata.conquery.models.identifiable.ids.IdTests
[INFO] Tests run: 57, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.072 s - in com.bakdata.conquery.models.identifiable.ids.IdTests
[INFO] Running com.bakdata.conquery.models.identifiable.mapping.PseudomizationTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.002 s - in com.bakdata.conquery.models.identifiable.mapping.PseudomizationTest
[INFO] Running com.bakdata.conquery.models.identifiable.IdMapTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.002 s - in com.bakdata.conquery.models.identifiable.IdMapTest
[INFO] Running com.bakdata.conquery.models.preproc.PreprocessorTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.004 s - in com.bakdata.conquery.models.preproc.PreprocessorTest
[INFO] Running com.bakdata.conquery.models.preproc.parser.specific.IntegerParserTest
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.008 s - in com.bakdata.conquery.models.preproc.parser.specific.IntegerParserTest
[INFO] Running com.bakdata.conquery.models.preproc.parser.specific.DateRangeParserTest
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 s - in com.bakdata.conquery.models.preproc.parser.specific.DateRangeParserTest
[INFO] Running com.bakdata.conquery.models.preproc.parser.specific.DecimalParserTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 s - in com.bakdata.conquery.models.preproc.parser.specific.DecimalParserTest
[INFO] Running com.bakdata.conquery.models.preproc.parser.specific.RealParserTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 s - in com.bakdata.conquery.models.preproc.parser.specific.RealParserTest
[INFO] Running com.bakdata.conquery.models.dictionary.MapDictionaryTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.013 s - in com.bakdata.conquery.models.dictionary.MapDictionaryTest
[INFO] Running com.bakdata.conquery.api.StoredQueriesProcessorTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.044 s - in com.bakdata.conquery.api.StoredQueriesProcessorTest
[INFO] Running com.bakdata.conquery.api.form.config.FormConfigTest
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.091 s - in com.bakdata.conquery.api.form.config.FormConfigTest
[INFO] Running com.bakdata.conquery.util.dict.SuccinctTrieTest
[INFO] [TEST] [2023-01-26 18:07:55]	c.b.c.u.d.SuccinctTrieTest		structure build
[INFO] [TEST] [2023-01-26 18:07:55]	c.b.c.u.d.SuccinctTrieTest		trie compressed
[INFO] [TEST] [2023-01-26 18:07:55]	c.b.c.u.d.SuccinctTrieTest		forward lookup done
[INFO] [TEST] [2023-01-26 18:07:55]	c.b.c.u.d.SuccinctTrieTest		reverse lookup done
[INFO] [TEST] [2023-01-26 18:07:55]	c.b.c.u.d.SuccinctTrieTest		structure build
[INFO] [TEST] [2023-01-26 18:07:55]	c.b.c.u.d.SuccinctTrieTest		trie compressed
[INFO] [TEST] [2023-01-26 18:07:55]	c.b.c.u.d.SuccinctTrieTest		forward lookup done
[INFO] [TEST] [2023-01-26 18:07:55]	c.b.c.u.d.SuccinctTrieTest		reverse lookup done
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.398 s - in com.bakdata.conquery.util.dict.SuccinctTrieTest
[INFO] Running com.bakdata.conquery.util.dict.TernaryTreeBalancerTest
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.251 s - in com.bakdata.conquery.util.dict.TernaryTreeBalancerTest
[INFO] Running com.bakdata.conquery.util.ConqueryEscapeTest
[INFO] Tests run: 22, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.007 s - in com.bakdata.conquery.util.ConqueryEscapeTest
[INFO] Running com.bakdata.conquery.util.progressreporter.ProgressReporterTest
[INFO] [TEST] [2023-01-26 18:07:58]	c.b.c.u.p.ProgressReporterTest		waited 00h 00m 00s  -   0% - est. 00h 00m 09s 
[INFO] [TEST] [2023-01-26 18:07:58]	c.b.c.u.p.ProgressReporterTest		waited 00h 00m 00s  -   0% - est. 00h 00m 09s 
[INFO] [TEST] [2023-01-26 18:07:58]	c.b.c.u.p.ProgressReporterTest		
[INFO] [TEST] [2023-01-26 18:07:58]	c.b.c.u.p.ProgressReporterTest		waited 00h 00m 00s  -   0% - est. 00h 00m 10s 
[INFO] [TEST] [2023-01-26 18:07:58]	c.b.c.u.p.ProgressReporterTest		waited 00h 00m 00s  -   0% - est. 00h 00m 20s 
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.309 s - in com.bakdata.conquery.util.progressreporter.ProgressReporterTest
[INFO] Running com.bakdata.conquery.util.progressreporter.ProgressReporterUtilTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 s - in com.bakdata.conquery.util.progressreporter.ProgressReporterUtilTest
[INFO] Running com.bakdata.conquery.util.search.QuickSearchTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 s - in com.bakdata.conquery.util.search.QuickSearchTest
[INFO] Running com.bakdata.conquery.integration.common.CDateSetTest
[INFO] Tests run: 22, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.008 s - in com.bakdata.conquery.integration.common.CDateSetTest
[INFO] Running com.bakdata.conquery.integration.ConqueryIntegrationTests
[INFO] [TEST] [2023-01-26 18:07:58]	c.b.c.u.s.TestConquery		Working in temporary directory /tmp/conqueryIntegrationTest12910953884258704183
[DEBUG] [2023-01-26 18:07:59]	c.b.c.c.StandaloneCommand	ManagerNode	Starting ManagerNode
[WARN] [2023-01-26 18:07:59]	c.b.c.m.c.XodusStoreFactory	ManagerNode	Had to create Storage Dir at `/tmp/conqueryIntegrationTest12910953884258704183/manager`
[INFO] [2023-01-26 18:07:59]	c.b.c.m.c.XodusStoreFactory	ManagerNode	All WorkerStores loaded: []
[INFO] [2023-01-26 18:07:59]	c.b.c.c.ManagerNode	ManagerNode	Opening MetaStorage
[INFO] [2023-01-26 18:07:59]	c.b.c.c.ManagerNode	ManagerNode	Loading MetaStorage
[DEBUG] [2023-01-26 18:07:59]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store AUTH_USER:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:07:59]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/users:AUTH_USER}): 0 entries, 0 B within 4.910 ms
[DEBUG] [2023-01-26 18:07:59]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store AUTH_ROLE:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:07:59]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/roles:AUTH_ROLE}): 0 entries, 0 B within 378.4 μs
[DEBUG] [2023-01-26 18:07:59]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store AUTH_GROUP:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:07:59]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/groups:AUTH_GROUP}): 0 entries, 0 B within 288.9 μs
[DEBUG] [2023-01-26 18:07:59]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store EXECUTIONS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:07:59]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/executions:EXECUTIONS}): 0 entries, 0 B within 265.4 μs
[DEBUG] [2023-01-26 18:07:59]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store FORM_CONFIG:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:07:59]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/formConfigs:FORM_CONFIG}): 0 entries, 0 B within 291.7 μs
[INFO] [2023-01-26 18:07:59]	c.b.c.c.ManagerNode	ManagerNode	MetaStorage loaded com.bakdata.conquery.io.storage.MetaStorage@4ce7d75e
[DEBUG] [2023-01-26 18:07:59]	c.b.c.m.a.AuthorizationController	ManagerNode	Security manager registered
[WARN] [2023-01-26 18:07:59]	c.b.c.m.a.d.DefaultInitialUserRealm	ManagerNode	
           §§
          §  §
         §    §
        §      §
       §  §§§§  §       You instantiated and are probably using a Shiro realm
      §   §§§§   §      that does not do any permission checks or authentication.
     §     §§     §     Access to all resources is granted to everyone.
    §      §§      §    DO NOT USE THIS REALM IN PRODUCTION
   $                §
  §        §§        §
 §                    §
 §§§§§§§§§§§§§§§§§§§§§§
[INFO] [2023-01-26 18:07:59]	c.b.c.m.a.AuthorizationController	ManagerNode	Registering the following realms to Shiro:
	com.bakdata.conquery.models.auth.conquerytoken.ConqueryTokenRealm_8
	com.bakdata.conquery.models.auth.ConqueryAuthorizationRealm_9
	com.bakdata.conquery.models.auth.develop.DefaultInitialUserRealm_10
[INFO] [2023-01-26 18:07:59]	c.b.c.c.ManagerNode	ManagerNode	Registering ResourcesProvider
[INFO] [2023-01-26 18:07:59]	c.b.c.m.f.f.FormScanner	ManagerNode	Form[EXPORT_FORM] from `Resource com/bakdata/conquery/frontend/forms/export_form.frontend_conf.json` of Type[com.bakdata.conquery.apiv1.forms.export_form.ExportForm]
[INFO] [2023-01-26 18:07:59]	c.b.c.m.f.f.FormScanner	ManagerNode	Form[FULL_EXPORT_FORM] from `Resource com/bakdata/conquery/frontend/forms/table_export_form.frontend_conf.json` of Type[com.bakdata.conquery.apiv1.forms.export_form.FullExportForm]
[DEBUG] [2023-01-26 18:07:59]	c.b.c.c.StandaloneCommand	ManagerNode	Waiting for ShardNodes to start
[WARN] [2023-01-26 18:07:59]	c.b.c.m.c.XodusStoreFactory	shard-node1	Had to create Storage Dir at `/tmp/conqueryIntegrationTest12910953884258704183/shard-node1`
[WARN] [2023-01-26 18:07:59]	c.b.c.m.c.XodusStoreFactory	shard-node0	Had to create Storage Dir at `/tmp/conqueryIntegrationTest12910953884258704183/shard-node0`
[INFO] [2023-01-26 18:07:59]	c.b.c.m.c.XodusStoreFactory	shard-node1	All WorkerStores loaded: []
[INFO] [2023-01-26 18:07:59]	c.b.c.c.ShardNode	shard-node1	All Worker Storages loaded: 0
[INFO] [2023-01-26 18:07:59]	c.b.c.m.c.XodusStoreFactory	shard-node0	All WorkerStores loaded: []
[INFO] [2023-01-26 18:07:59]	c.b.c.c.ShardNode	shard-node0	All Worker Storages loaded: 0
[DEBUG] [2023-01-26 18:07:59]	c.b.c.c.StandaloneCommand	ManagerNode	Starting REST Server
[INFO] [2023-01-26 18:07:59]	c.b.c.c.ManagerNode		Started ManagerNode @ /0:0:0:0:0:0:0:0:34233
[INFO] [2023-01-26 18:07:59]	c.b.c.c.ShardNode		Trying to connect to /127.0.0.1:34233
[INFO] [2023-01-26 18:07:59]	c.b.c.c.ManagerNode	ManagerNode[/127.0.0.1:34233]	New client /127.0.0.1:47326 connected, waiting for identity
[INFO] [2023-01-26 18:07:59]	c.b.c.c.ShardNode	/127.0.0.1:47326	Connected to ManagerNode @ /127.0.0.1:34233
[INFO] [2023-01-26 18:07:59]	c.b.c.c.ShardNode		Trying to connect to /127.0.0.1:34233
[INFO] [2023-01-26 18:07:59]	c.b.c.c.ManagerNode	ManagerNode[/127.0.0.1:34233]	New client /127.0.0.1:47328 connected, waiting for identity
[INFO] [2023-01-26 18:07:59]	c.b.c.c.ShardNode	/127.0.0.1:47328	Connected to ManagerNode @ /127.0.0.1:34233
[INFO] [2023-01-26 18:07:59]	c.b.c.m.m.n.s.AddShardNode	Job Manager fast ManagerNode	ShardNode `/127.0.0.1:47328` registered.
[INFO] [2023-01-26 18:07:59]	c.b.c.m.m.n.s.AddShardNode	Job Manager fast ManagerNode	ShardNode `/127.0.0.1:47326` registered.
[WARN] [2023-01-26 18:08:00]	o.g.j.i.Errors		The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.filters.Filter<?> from public void com.bakdata.conquery.resources.hierarchies.HFilters.setFilter(com.bakdata.conquery.models.datasets.concepts.filters.Filter<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public com.bakdata.conquery.apiv1.FullExecutionStatus com.bakdata.conquery.resources.api.QueryResource.getStatus(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) throws java.lang.InterruptedException is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public com.bakdata.conquery.apiv1.FullExecutionStatus com.bakdata.conquery.resources.api.QueryResource.patchQuery(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>,com.bakdata.conquery.apiv1.MetaDataPatch) throws com.bakdata.conquery.models.exceptions.JSONException is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public void com.bakdata.conquery.resources.api.QueryResource.deleteQuery(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>) is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public void com.bakdata.conquery.resources.api.QueryResource.cancel(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>) is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public com.bakdata.conquery.apiv1.FullExecutionStatus com.bakdata.conquery.resources.api.QueryResource.reexecute(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultExcelResource.get(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.identifiable.ids.specific.DatasetId,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultArrowStreamResource.get(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.datasets.Dataset,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultCsvResource.getAsCsv(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.datasets.Dataset,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.lang.String,java.lang.String,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultArrowFileResource.get(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.datasets.Dataset,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.filters.Filter<?> from public void com.bakdata.conquery.resources.hierarchies.HFilters.setFilter(com.bakdata.conquery.models.datasets.concepts.filters.Filter<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.

[WARN] [2023-01-26 18:08:00]	i.d.s.AdminEnvironment		
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!    THIS APPLICATION HAS NO HEALTHCHECKS. THIS MEANS YOU WILL NEVER KNOW      !
!     IF IT DIES IN PRODUCTION, WHICH MEANS YOU WILL NEVER KNOW IF YOU'RE      !
!    LETTING YOUR USERS DOWN. YOU SHOULD ADD A HEALTHCHECK FOR EACH OF YOUR    !
!         APPLICATION'S DEPENDENCIES WHICH FULLY (BUT LIGHTLY) TESTS IT.       !
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
[WARN] [2023-01-26 18:08:00]	o.g.j.i.Errors		The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.auth.entities.PermissionOwner<?> from public void com.bakdata.conquery.resources.hierarchies.HPermissions.setOwner(com.bakdata.conquery.models.auth.entities.PermissionOwner<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.auth.entities.PermissionOwner<?> from public void com.bakdata.conquery.resources.hierarchies.HPermissions.setOwner(com.bakdata.conquery.models.auth.entities.PermissionOwner<?>) is not resolvable to a concrete type.

[WARN] [2023-01-26 18:08:00]	o.g.j.i.Errors		The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter concept of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from protected com.bakdata.conquery.models.datasets.concepts.Concept<?> com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.concept is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter concept of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from protected com.bakdata.conquery.models.datasets.concepts.Concept<?> com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.concept is not resolvable to a concrete type.

[INFO] [2023-01-26 18:08:00]	c.b.c.i.IntegrationTest$Wrapper	DownloadLinkGeneration	STARTING integration test DownloadLinkGeneration
[INFO] [2023-01-26 18:08:00]	c.b.c.u.s.TestConquery	DownloadLinkGeneration	Setting up dataset
[DEBUG] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.SerializingStore	DownloadLinkGeneration	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.CachedStore	DownloadLinkGeneration		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DownloadLinkGeneration:DATASET}): 0 entries, 0 B within 506.7 μs
[DEBUG] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.SerializingStore	DownloadLinkGeneration	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.CachedStore	DownloadLinkGeneration		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DownloadLinkGeneration:SECONDARY_IDS}): 0 entries, 0 B within 378.3 μs
[DEBUG] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.SerializingStore	DownloadLinkGeneration	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.CachedStore	DownloadLinkGeneration		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DownloadLinkGeneration:TABLES}): 0 entries, 0 B within 338.7 μs
[DEBUG] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.SerializingStore	DownloadLinkGeneration	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.CachedStore	DownloadLinkGeneration		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 1.109 ms
[DEBUG] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.SerializingStore	DownloadLinkGeneration	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.CachedStore	DownloadLinkGeneration		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DownloadLinkGeneration:IMPORTS}): 0 entries, 0 B within 326.6 μs
[DEBUG] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.SerializingStore	DownloadLinkGeneration	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.CachedStore	DownloadLinkGeneration		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DownloadLinkGeneration:CONCEPTS}): 0 entries, 0 B within 367.6 μs
[INFO] [2023-01-26 18:08:00]	c.b.c.i.s.NamespacedStorage	DownloadLinkGeneration	Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
[DEBUG] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.SerializingStore	DownloadLinkGeneration	While processing store ID_MAPPING_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.CachedStore	DownloadLinkGeneration		loaded store cached big ID_MAPPING(EntityIdMap): 0 entries, 0 B within 192.7 μs
[DEBUG] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.SerializingStore	DownloadLinkGeneration	While processing store STRUCTURE:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.CachedStore	DownloadLinkGeneration		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DownloadLinkGeneration:STRUCTURE}): 0 entries, 0 B within 174.7 μs
[DEBUG] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.SerializingStore	DownloadLinkGeneration	While processing store WORKER_TO_BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.CachedStore	DownloadLinkGeneration		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DownloadLinkGeneration:WORKER_TO_BUCKETS}): 0 entries, 0 B within 172.5 μs
[DEBUG] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.SerializingStore	DownloadLinkGeneration	While processing store PRIMARY_DICTIONARY:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.CachedStore	DownloadLinkGeneration		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DownloadLinkGeneration:PRIMARY_DICTIONARY}): 0 entries, 0 B within 160.7 μs
[INFO] [2023-01-26 18:08:00]	c.b.c.m.m.n.s.AddWorker	Job Manager slow shard-node0	creating a new worker for Dataset[label=DownloadLinkGeneration, name=DownloadLinkGeneration]
[INFO] [2023-01-26 18:08:00]	c.b.c.m.m.n.s.AddWorker	Job Manager slow shard-node1	creating a new worker for Dataset[label=DownloadLinkGeneration, name=DownloadLinkGeneration]
[DEBUG] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DownloadLinkGeneration_4a82fcc9-9d08-4eac-81ca-9769083bee99:DATASET}): 0 entries, 0 B within 240.9 μs
[DEBUG] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DownloadLinkGeneration_4a82fcc9-9d08-4eac-81ca-9769083bee99:SECONDARY_IDS}): 0 entries, 0 B within 137.2 μs
[DEBUG] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[DEBUG] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DownloadLinkGeneration_04618efc-d37a-4435-bed5-0e9639c93e5e:DATASET}): 0 entries, 0 B within 249.2 μs
[INFO] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DownloadLinkGeneration_4a82fcc9-9d08-4eac-81ca-9769083bee99:TABLES}): 0 entries, 0 B within 132.3 μs
[DEBUG] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[DEBUG] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DownloadLinkGeneration_04618efc-d37a-4435-bed5-0e9639c93e5e:SECONDARY_IDS}): 0 entries, 0 B within 170.8 μs
[INFO] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 172.8 μs
[DEBUG] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DownloadLinkGeneration_04618efc-d37a-4435-bed5-0e9639c93e5e:TABLES}): 0 entries, 0 B within 153.3 μs
[DEBUG] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[DEBUG] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DownloadLinkGeneration_4a82fcc9-9d08-4eac-81ca-9769083bee99:IMPORTS}): 0 entries, 0 B within 312.9 μs
[INFO] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 160.3 μs
[DEBUG] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[DEBUG] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DownloadLinkGeneration_4a82fcc9-9d08-4eac-81ca-9769083bee99:CONCEPTS}): 0 entries, 0 B within 198.8 μs
[INFO] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DownloadLinkGeneration_04618efc-d37a-4435-bed5-0e9639c93e5e:IMPORTS}): 0 entries, 0 B within 202.0 μs
[INFO] [2023-01-26 18:08:00]	c.b.c.i.s.NamespacedStorage	Job Manager slow shard-node1	Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[DEBUG] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store WORKER:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DownloadLinkGeneration_04618efc-d37a-4435-bed5-0e9639c93e5e:CONCEPTS}): 0 entries, 0 B within 154.2 μs
[INFO] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DownloadLinkGeneration_4a82fcc9-9d08-4eac-81ca-9769083bee99:WORKER}): 0 entries, 0 B within 164.9 μs
[INFO] [2023-01-26 18:08:00]	c.b.c.i.s.NamespacedStorage	Job Manager slow shard-node0	Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store WORKER:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[DEBUG] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DownloadLinkGeneration_04618efc-d37a-4435-bed5-0e9639c93e5e:WORKER}): 0 entries, 0 B within 164.7 μs
[INFO] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DownloadLinkGeneration_4a82fcc9-9d08-4eac-81ca-9769083bee99:BUCKETS}): 0 entries, 0 B within 178.9 μs
[DEBUG] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[DEBUG] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DownloadLinkGeneration_04618efc-d37a-4435-bed5-0e9639c93e5e:BUCKETS}): 0 entries, 0 B within 149.6 μs
[INFO] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DownloadLinkGeneration_4a82fcc9-9d08-4eac-81ca-9769083bee99:C_BLOCKS}): 0 entries, 0 B within 140.4 μs
[DEBUG] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:00]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DownloadLinkGeneration_04618efc-d37a-4435-bed5-0e9639c93e5e:C_BLOCKS}): 0 entries, 0 B within 133.3 μs
[INFO] [2023-01-26 18:08:01]	c.b.c.u.s.TestConquery	DownloadLinkGeneration	Waiting for jobs to finish
[INFO] [2023-01-26 18:08:01]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=DownloadLinkGeneration]	Imports of worker DownloadLinkGeneration.worker_DownloadLinkGeneration_4a82fcc9-9d08-4eac-81ca-9769083bee99 are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:01]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=DownloadLinkGeneration]	Buckets of worker DownloadLinkGeneration.worker_DownloadLinkGeneration_4a82fcc9-9d08-4eac-81ca-9769083bee99 are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:01]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=DownloadLinkGeneration]	Consistency check was successful
[INFO] [2023-01-26 18:08:01]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=DownloadLinkGeneration]	Imports of worker DownloadLinkGeneration.worker_DownloadLinkGeneration_04618efc-d37a-4435-bed5-0e9639c93e5e are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:01]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=DownloadLinkGeneration]	Buckets of worker DownloadLinkGeneration.worker_DownloadLinkGeneration_04618efc-d37a-4435-bed5-0e9639c93e5e are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:01]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=DownloadLinkGeneration]	Consistency check was successful
[DEBUG] [2023-01-26 18:08:01]	c.b.c.m.a.AuthorizationController	DownloadLinkGeneration	Security manager registered
[INFO] [2023-01-26 18:08:01]	c.b.c.u.s.TestConquery	DownloadLinkGeneration	Waiting for jobs to finish
[INFO] [2023-01-26 18:08:01]	c.b.c.u.s.TestConquery	DownloadLinkGeneration	Waiting for jobs to finish
[INFO] [2023-01-26 18:08:01]	c.b.c.m.m.n.s.UpdateTable	Worker[DownloadLinkGeneration.worker_DownloadLinkGeneration_04618efc-d37a-4435-bed5-0e9639c93e5e, /127.0.0.1:47326]	Received update of Table DownloadLinkGeneration.test_table
[INFO] [2023-01-26 18:08:01]	c.b.c.m.m.n.s.UpdateTable	Worker[DownloadLinkGeneration.worker_DownloadLinkGeneration_4a82fcc9-9d08-4eac-81ca-9769083bee99, /127.0.0.1:47328]	Received update of Table DownloadLinkGeneration.test_table
[INFO] [2023-01-26 18:08:01]	c.b.c.u.s.TestConquery	DownloadLinkGeneration	Waiting for jobs to finish
[DEBUG] [2023-01-26 18:08:01]	c.b.c.i.s.WorkerStorage	Worker[DownloadLinkGeneration.worker_DownloadLinkGeneration_04618efc-d37a-4435-bed5-0e9639c93e5e, /127.0.0.1:47326]	Updating Concept[DownloadLinkGeneration.test_tree]
[DEBUG] [2023-01-26 18:08:01]	c.b.c.i.s.WorkerStorage	Worker[DownloadLinkGeneration.worker_DownloadLinkGeneration_4a82fcc9-9d08-4eac-81ca-9769083bee99, /127.0.0.1:47328]	Updating Concept[DownloadLinkGeneration.test_tree]
[INFO] [2023-01-26 18:08:01]	c.b.c.c.PreprocessorCommand	DownloadLinkGeneration	Preprocessing from command line config.
[INFO] [2023-01-26 18:08:01]	c.b.c.c.PreprocessorCommand	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_DownloadLinkGeneration/test_table.import.json, tag=Optional.empty)	DOES NOT EXIST
[INFO] [2023-01-26 18:08:01]	c.b.c.c.PreprocessorCommand	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_DownloadLinkGeneration/test_table.import.json, tag=Optional.empty)	Required to preprocess 94 B in total
[INFO] [2023-01-26 18:08:01]	c.b.c.m.p.Preprocessor	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_DownloadLinkGeneration/test_table.import.json, tag=Optional.empty)	PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_DownloadLinkGeneration/test_table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000637338s[INFO] [2023-01-26 18:08:01]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content.csv]	Statistics = IntSummaryStatistics{count=4, sum=4, min=1, average=1.000000, max=1}
[INFO] [2023-01-26 18:08:01]	c.b.c.m.p.PPColumn		Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=4, nullLines=0), subType=IntegerParser(super=Parser(lines=4, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@5c7a2c19)
[DEBUG] [2023-01-26 18:08:01]	c.b.c.m.p.PPColumn			datum: DateParser(super=Parser(lines=4, nullLines=0), subType=IntegerParser(super=Parser(lines=4, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@5c7a2c19) -> IntegerDateStore(store=ShortArrayStore())
[INFO] [2023-01-26 18:08:01]	c.b.c.m.p.PPColumn	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content.csv]	Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=4, nullLines=0), encoding=null, prefix=, suffix=)
[DEBUG] [2023-01-26 18:08:01]	c.b.c.m.p.p.s.StringParser	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content.csv]		Chosen encoding is Base16UpperCase
[DEBUG] [2023-01-26 18:08:01]	c.b.c.m.p.p.s.StringParser	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content.csv]		Using com.bakdata.conquery.models.preproc.parser.specific.string.TrieTypeGuesser@43539b3b(est. 64 B)
[DEBUG] [2023-01-26 18:08:01]	c.b.c.m.p.PPColumn	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content.csv]		test_column: StringParser(super=Parser(lines=4, nullLines=0), encoding=Base16UpperCase, prefix=, suffix=) -> StringTypeEncoded(encoding=Base16UpperCase, subType=StringTypeDictionary(dictionary=SuccinctTrie[size=2], numberType=ByteArrayStore()))
[DEBUG] [2023-01-26 18:08:01]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content.csv]	Encode primary Dictionary
[DEBUG] [2023-01-26 18:08:01]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content.csv]	Writing Headers
[DEBUG] [2023-01-26 18:08:01]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content.csv]	Writing header
[DEBUG] [2023-01-26 18:08:01]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content.csv]	Writing Dictionaries
[DEBUG] [2023-01-26 18:08:01]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content.csv]	Writing data
[INFO] [2023-01-26 18:08:01]	c.b.c.m.p.Preprocessor	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content.csv]	PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_DownloadLinkGeneration/test_table.import.json, tag=Optional.empty)
[INFO] [2023-01-26 18:08:01]	c.b.c.c.PreprocessorCommand		Successfully Preprocess 1 Jobs:
[INFO] [2023-01-26 18:08:01]	c.b.c.c.PreprocessorCommand			Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_DownloadLinkGeneration/test_table.import.json, tag=Optional.empty)
[DEBUG] [2023-01-26 18:08:01]	c.b.c.m.j.ImportJob	user.SUPERUSER@SUPERUSER	Done reading data. Contains 4 Entities.
[INFO] [2023-01-26 18:08:01]	c.b.c.m.j.ImportJob	user.SUPERUSER@SUPERUSER	Importing test_table into DownloadLinkGeneration.test_table
[DEBUG] [2023-01-26 18:08:01]	c.b.c.m.j.ImportJob	Job Manager slow DownloadLinkGeneration	Mapped 4 new ids
[DEBUG] [2023-01-26 18:08:01]	c.b.c.m.j.ImportJob	Job Manager slow DownloadLinkGeneration	Updating bucket assignments.
127.0.0.1 - - [26/Jan/2023:18:08:01 +0000] "POST /admin/datasets/DownloadLinkGeneration/imports?file=%2Ftmp%2FconqueryIntegrationTest12910953884258704183%2Ftmp_DownloadLinkGeneration%2Ftest_table.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 91
[INFO] [2023-01-26 18:08:01]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[DEBUG] [2023-01-26 18:08:01]	c.b.c.m.w.Namespace	Job Manager slow DownloadLinkGeneration	Assigning Bucket[0] to Worker[DownloadLinkGeneration.worker_DownloadLinkGeneration_4a82fcc9-9d08-4eac-81ca-9769083bee99]
[DEBUG] [2023-01-26 18:08:01]	c.b.c.m.w.Namespace	Job Manager slow DownloadLinkGeneration	Assigning Bucket[1] to Worker[DownloadLinkGeneration.worker_DownloadLinkGeneration_04618efc-d37a-4435-bed5-0e9639c93e5e]
[INFO] [2023-01-26 18:08:01]	c.b.c.m.j.ImportJob	Job Manager slow DownloadLinkGeneration	Importing Dictionaries
[DEBUG] [2023-01-26 18:08:01]	c.b.c.m.m.n.s.UpdateWorkerBucket	Worker[DownloadLinkGeneration.worker_DownloadLinkGeneration_04618efc-d37a-4435-bed5-0e9639c93e5e, /127.0.0.1:47326]	Received new WorkerInformation(size = 1,dataset = DownloadLinkGeneration)
[DEBUG] [2023-01-26 18:08:01]	c.b.c.m.m.n.s.UpdateWorkerBucket	Worker[DownloadLinkGeneration.worker_DownloadLinkGeneration_4a82fcc9-9d08-4eac-81ca-9769083bee99, /127.0.0.1:47328]	Received new WorkerInformation(size = 1,dataset = DownloadLinkGeneration)
[INFO] [2023-01-26 18:08:01]	c.b.c.m.j.ImportJob	Job Manager slow DownloadLinkGeneration	Remapping Dictionaries []
[WARN] [2023-01-26 18:08:01]	c.b.c.u.p.ProgressReporterImpl	Job Manager slow DownloadLinkGeneration	Max cannot be decreased.
[DEBUG] [2023-01-26 18:08:01]	c.b.c.m.m.n.s.UpdateDictionary	Worker[DownloadLinkGeneration.worker_DownloadLinkGeneration_4a82fcc9-9d08-4eac-81ca-9769083bee99, /127.0.0.1:47328]	Received Dictionary[DownloadLinkGeneration.test_table#DownloadLinkGeneration$2etest_table$2etest_column] of size 2.
[DEBUG] [2023-01-26 18:08:01]	c.b.c.m.m.n.s.UpdateDictionary	Worker[DownloadLinkGeneration.worker_DownloadLinkGeneration_04618efc-d37a-4435-bed5-0e9639c93e5e, /127.0.0.1:47326]	Received Dictionary[DownloadLinkGeneration.test_table#DownloadLinkGeneration$2etest_table$2etest_column] of size 2.
[INFO] [2023-01-26 18:08:01]	c.b.c.m.j.ImportJob	Job Manager slow DownloadLinkGeneration	Start sending 2 Buckets
[INFO] [2023-01-26 18:08:01]	c.b.c.m.m.n.s.AddImport	Worker[DownloadLinkGeneration.worker_DownloadLinkGeneration_4a82fcc9-9d08-4eac-81ca-9769083bee99, /127.0.0.1:47328]	Received Import[DownloadLinkGeneration.test_table.test_table], containing 4 entries.
[INFO] [2023-01-26 18:08:01]	c.b.c.m.m.n.s.AddImport	Worker[DownloadLinkGeneration.worker_DownloadLinkGeneration_04618efc-d37a-4435-bed5-0e9639c93e5e, /127.0.0.1:47326]	Received Import[DownloadLinkGeneration.test_table.test_table], containing 4 entries.
[WARN] [2023-01-26 18:08:01]	c.b.c.u.p.ProgressReporterImpl	Job Manager slow DownloadLinkGeneration	One or more Children are not done yet
[INFO] [2023-01-26 18:08:01]	c.b.c.m.m.n.s.ImportBucket	Worker[DownloadLinkGeneration.worker_DownloadLinkGeneration_4a82fcc9-9d08-4eac-81ca-9769083bee99, /127.0.0.1:47328]	Received DownloadLinkGeneration.test_table.test_table.0
[INFO] [2023-01-26 18:08:01]	c.b.c.m.m.n.s.ImportBucket	Worker[DownloadLinkGeneration.worker_DownloadLinkGeneration_04618efc-d37a-4435-bed5-0e9639c93e5e, /127.0.0.1:47326]	Received DownloadLinkGeneration.test_table.test_table.1
[DEBUG] [2023-01-26 18:08:01]	c.b.c.i.s.WorkerStorage	Worker[DownloadLinkGeneration.worker_DownloadLinkGeneration_4a82fcc9-9d08-4eac-81ca-9769083bee99, /127.0.0.1:47328]	Adding Bucket[DownloadLinkGeneration.test_table.test_table.0]
[DEBUG] [2023-01-26 18:08:01]	c.b.c.i.s.WorkerStorage	Worker[DownloadLinkGeneration.worker_DownloadLinkGeneration_04618efc-d37a-4435-bed5-0e9639c93e5e, /127.0.0.1:47326]	Adding Bucket[DownloadLinkGeneration.test_table.test_table.1]
[DEBUG] [2023-01-26 18:08:01]	c.b.c.i.s.WorkerStorage		Adding CBlock[DownloadLinkGeneration.test_table.test_table.1.DownloadLinkGeneration.test_tree.test_column]
[DEBUG] [2023-01-26 18:08:01]	c.b.c.i.s.WorkerStorage		Adding CBlock[DownloadLinkGeneration.test_table.test_table.0.DownloadLinkGeneration.test_tree.test_column]
[INFO] [2023-01-26 18:08:02]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[INFO] [2023-01-26 18:08:02]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:08:02 +0000] "GET /api/datasets/DownloadLinkGeneration/queries/DownloadLinkGeneration.45648560-9347-4366-9ac8-ee793fb99280 HTTP/1.1" 200 754 "-" "Conquery (test client)" 73
127.0.0.1 - - [26/Jan/2023:18:08:02 +0000] "GET /api/datasets/DownloadLinkGeneration/queries/DownloadLinkGeneration.45648560-9347-4366-9ac8-ee793fb99280 HTTP/1.1" 200 755 "-" "Conquery (test client)" 6
127.0.0.1 - - [26/Jan/2023:18:08:02 +0000] "GET /api/datasets/DownloadLinkGeneration/queries/DownloadLinkGeneration.45648560-9347-4366-9ac8-ee793fb99280 HTTP/1.1" 200 1019 "-" "Conquery (test client)" 4
[INFO] [2023-01-26 18:08:02]	c.b.c.m.j.JobExecutor		Closing Job Manager fast DownloadLinkGeneration
[INFO] [2023-01-26 18:08:02]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node0	removing worker for Dataset[label=DownloadLinkGeneration, name=DownloadLinkGeneration]
[INFO] [2023-01-26 18:08:02]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node1	removing worker for Dataset[label=DownloadLinkGeneration, name=DownloadLinkGeneration]
[INFO] [2023-01-26 18:08:02]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager fast worker_DownloadLinkGeneration_04618efc-d37a-4435-bed5-0e9639c93e5e
[INFO] [2023-01-26 18:08:02]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager fast worker_DownloadLinkGeneration_4a82fcc9-9d08-4eac-81ca-9769083bee99
[INFO] [2023-01-26 18:08:02]	c.b.c.m.j.JobExecutor		Closing Job Manager slow DownloadLinkGeneration
[INFO] [2023-01-26 18:08:02]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager slow worker_DownloadLinkGeneration_04618efc-d37a-4435-bed5-0e9639c93e5e
[INFO] [2023-01-26 18:08:02]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager slow worker_DownloadLinkGeneration_4a82fcc9-9d08-4eac-81ca-9769083bee99
[INFO] [2023-01-26 18:08:02]	c.b.c.m.w.Namespace		Removing namespace storage of DownloadLinkGeneration
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore		Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DownloadLinkGeneration
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore		Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DownloadLinkGeneration
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore		Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DownloadLinkGeneration
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore		Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DownloadLinkGeneration
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore		Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DownloadLinkGeneration
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore		Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DownloadLinkGeneration
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore		Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DownloadLinkGeneration
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore		Deleting store ID_MAPPING_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DownloadLinkGeneration
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore		Deleting store ID_MAPPING_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DownloadLinkGeneration
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore		Deleting store STRUCTURE from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DownloadLinkGeneration
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore		Deleting store WORKER_TO_BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DownloadLinkGeneration
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore		Deleting store PRIMARY_DICTIONARY from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DownloadLinkGeneration
[INFO] [2023-01-26 18:08:02]	c.b.c.m.c.XodusStoreFactory		Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DownloadLinkGeneration
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DownloadLinkGeneration_04618efc-d37a-4435-bed5-0e9639c93e5e
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DownloadLinkGeneration_4a82fcc9-9d08-4eac-81ca-9769083bee99
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DownloadLinkGeneration_04618efc-d37a-4435-bed5-0e9639c93e5e
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DownloadLinkGeneration_4a82fcc9-9d08-4eac-81ca-9769083bee99
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DownloadLinkGeneration_04618efc-d37a-4435-bed5-0e9639c93e5e
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DownloadLinkGeneration_4a82fcc9-9d08-4eac-81ca-9769083bee99
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DownloadLinkGeneration_04618efc-d37a-4435-bed5-0e9639c93e5e
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DownloadLinkGeneration_4a82fcc9-9d08-4eac-81ca-9769083bee99
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DownloadLinkGeneration_04618efc-d37a-4435-bed5-0e9639c93e5e
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DownloadLinkGeneration_4a82fcc9-9d08-4eac-81ca-9769083bee99
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DownloadLinkGeneration_04618efc-d37a-4435-bed5-0e9639c93e5e
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DownloadLinkGeneration_04618efc-d37a-4435-bed5-0e9639c93e5e
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DownloadLinkGeneration_4a82fcc9-9d08-4eac-81ca-9769083bee99
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DownloadLinkGeneration_04618efc-d37a-4435-bed5-0e9639c93e5e
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DownloadLinkGeneration_4a82fcc9-9d08-4eac-81ca-9769083bee99
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DownloadLinkGeneration_04618efc-d37a-4435-bed5-0e9639c93e5e
[INFO] [2023-01-26 18:08:02]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DownloadLinkGeneration_04618efc-d37a-4435-bed5-0e9639c93e5e
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DownloadLinkGeneration_4a82fcc9-9d08-4eac-81ca-9769083bee99
[INFO] [2023-01-26 18:08:02]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node0	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DownloadLinkGeneration_04618efc-d37a-4435-bed5-0e9639c93e5e
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DownloadLinkGeneration_4a82fcc9-9d08-4eac-81ca-9769083bee99
[DEBUG] [2023-01-26 18:08:02]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DownloadLinkGeneration_4a82fcc9-9d08-4eac-81ca-9769083bee99
[INFO] [2023-01-26 18:08:02]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node1	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DownloadLinkGeneration_4a82fcc9-9d08-4eac-81ca-9769083bee99
[INFO] [2023-01-26 18:08:02]	c.b.c.i.IntegrationTest$Wrapper	DownloadLinkGeneration	SUCCESS integration test DownloadLinkGeneration
[INFO] [2023-01-26 18:08:02]	c.b.c.i.IntegrationTest$Wrapper	AdminEndpointTest	STARTING integration test AdminEndpointTest
[WARN] [2023-01-26 18:08:02]	o.g.j.i.Errors	AdminEndpointTest	The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.auth.entities.PermissionOwner<?> from public void com.bakdata.conquery.resources.hierarchies.HPermissions.setOwner(com.bakdata.conquery.models.auth.entities.PermissionOwner<?>) is not resolvable to a concrete type.

[WARN] [2023-01-26 18:08:02]	o.g.j.i.Errors	AdminEndpointTest	The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.auth.entities.PermissionOwner<?> from public void com.bakdata.conquery.resources.hierarchies.HPermissions.setOwner(com.bakdata.conquery.models.auth.entities.PermissionOwner<?>) is not resolvable to a concrete type.

[INFO] [2023-01-26 18:08:02]	c.b.c.u.s.TestConquery	AdminEndpointTest	Waiting for jobs to finish
[INFO] [2023-01-26 18:08:02]	c.b.c.i.IntegrationTest$Wrapper	AdminEndpointTest	SUCCESS integration test AdminEndpointTest
[INFO] [2023-01-26 18:08:02]	c.b.c.i.IntegrationTest$Wrapper	AdminUIEndpointTest	STARTING integration test AdminUIEndpointTest
[WARN] [2023-01-26 18:08:02]	o.g.j.i.Errors	AdminUIEndpointTest	The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter concept of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from protected com.bakdata.conquery.models.datasets.concepts.Concept<?> com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.concept is not resolvable to a concrete type.

[WARN] [2023-01-26 18:08:02]	o.g.j.i.Errors	AdminUIEndpointTest	The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter concept of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from protected com.bakdata.conquery.models.datasets.concepts.Concept<?> com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.concept is not resolvable to a concrete type.

[INFO] [2023-01-26 18:08:02]	c.b.c.u.s.TestConquery	AdminUIEndpointTest	Waiting for jobs to finish
[INFO] [2023-01-26 18:08:02]	c.b.c.i.IntegrationTest$Wrapper	AdminUIEndpointTest	SUCCESS integration test AdminUIEndpointTest
[INFO] [2023-01-26 18:08:02]	c.b.c.i.IntegrationTest$Wrapper	ApiEndpointTest	STARTING integration test ApiEndpointTest
[WARN] [2023-01-26 18:08:02]	o.g.j.i.Errors	ApiEndpointTest	The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.

[WARN] [2023-01-26 18:08:02]	o.g.j.i.Errors	ApiEndpointTest	The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.filters.Filter<?> from public void com.bakdata.conquery.resources.hierarchies.HFilters.setFilter(com.bakdata.conquery.models.datasets.concepts.filters.Filter<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.

[WARN] [2023-01-26 18:08:02]	o.g.j.i.Errors	ApiEndpointTest	The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.

[WARN] [2023-01-26 18:08:02]	o.g.j.i.Errors	ApiEndpointTest	The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.filters.Filter<?> from public void com.bakdata.conquery.resources.hierarchies.HFilters.setFilter(com.bakdata.conquery.models.datasets.concepts.filters.Filter<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.

[INFO] [2023-01-26 18:08:02]	c.b.c.u.s.TestConquery	ApiEndpointTest	Waiting for jobs to finish
[INFO] [2023-01-26 18:08:02]	c.b.c.i.IntegrationTest$Wrapper	ApiEndpointTest	SUCCESS integration test ApiEndpointTest
[INFO] [2023-01-26 18:08:02]	c.b.c.u.s.TestConquery	ApiEndpointTest	Working in temporary directory /tmp/conqueryIntegrationTest12910953884258704183
INFO  [2023-01-26 18:08:02,736] io.dropwizard.server.DefaultServerFactory: Registering jersey handler with root path prefix: /
INFO  [2023-01-26 18:08:02,736] io.dropwizard.server.DefaultServerFactory: Registering admin handler with root path prefix: /
WARN  [2023-01-26 18:08:02,742] com.bakdata.conquery.models.config.XodusStoreFactory: Had to create Storage Dir at `/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/manager`
INFO  [2023-01-26 18:08:02,743] com.bakdata.conquery.models.config.XodusStoreFactory: All WorkerStores loaded: []
INFO  [2023-01-26 18:08:02,743] com.bakdata.conquery.commands.ManagerNode: Opening MetaStorage
INFO  [2023-01-26 18:08:02,765] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/manager/meta/users
INFO  [2023-01-26 18:08:02,790] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/manager/meta/roles
INFO  [2023-01-26 18:08:02,810] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/manager/meta/groups
INFO  [2023-01-26 18:08:02,829] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/manager/meta/executions
INFO  [2023-01-26 18:08:02,851] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/manager/meta/formConfigs
INFO  [2023-01-26 18:08:02,855] com.bakdata.conquery.commands.ManagerNode: Loading MetaStorage
INFO  [2023-01-26 18:08:02,855] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/manager/meta/users:AUTH_USER}): 0 entries, 0 B within 244.8 μs
INFO  [2023-01-26 18:08:02,856] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/manager/meta/roles:AUTH_ROLE}): 0 entries, 0 B within 212.6 μs
INFO  [2023-01-26 18:08:02,856] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/manager/meta/groups:AUTH_GROUP}): 0 entries, 0 B within 188.1 μs
INFO  [2023-01-26 18:08:02,856] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/manager/meta/executions:EXECUTIONS}): 0 entries, 0 B within 182.7 μs
INFO  [2023-01-26 18:08:02,857] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/manager/meta/formConfigs:FORM_CONFIG}): 0 entries, 0 B within 165.8 μs
INFO  [2023-01-26 18:08:02,857] com.bakdata.conquery.commands.ManagerNode: MetaStorage loaded com.bakdata.conquery.io.storage.MetaStorage@68baca
WARN  [2023-01-26 18:08:02,863] com.bakdata.conquery.models.auth.develop.DefaultInitialUserRealm: 
           §§
          §  §
         §    §
        §      §
       §  §§§§  §       You instantiated and are probably using a Shiro realm
      §   §§§§   §      that does not do any permission checks or authentication.
     §     §§     §     Access to all resources is granted to everyone.
    §      §§      §    DO NOT USE THIS REALM IN PRODUCTION
   $                §
  §        §§        §
 §                    §
 §§§§§§§§§§§§§§§§§§§§§§
INFO  [2023-01-26 18:08:02,866] com.bakdata.conquery.models.auth.AuthorizationController: Registering the following realms to Shiro:
	com.bakdata.conquery.models.auth.conquerytoken.ConqueryTokenRealm_11
	com.bakdata.conquery.models.auth.ConqueryAuthorizationRealm_12
	com.bakdata.conquery.models.auth.develop.DefaultInitialUserRealm_13
	com.bakdata.conquery.models.auth.apitoken.ApiTokenRealm_14
INFO  [2023-01-26 18:08:02,867] com.bakdata.conquery.commands.ManagerNode: Registering ResourcesProvider
INFO  [2023-01-26 18:08:02,877] com.bakdata.conquery.models.forms.frontendconfiguration.FormScanner: Form[EXPORT_FORM] from `Resource com/bakdata/conquery/frontend/forms/export_form.frontend_conf.json` of Type[com.bakdata.conquery.apiv1.forms.export_form.ExportForm]
INFO  [2023-01-26 18:08:02,877] com.bakdata.conquery.models.forms.frontendconfiguration.FormScanner: Form[FULL_EXPORT_FORM] from `Resource com/bakdata/conquery/frontend/forms/table_export_form.frontend_conf.json` of Type[com.bakdata.conquery.apiv1.forms.export_form.FullExportForm]
WARN  [2023-01-26 18:08:02,918] com.bakdata.conquery.models.config.XodusStoreFactory: Had to create Storage Dir at `/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/shard-node1`
INFO  [2023-01-26 18:08:02,918] com.bakdata.conquery.models.config.XodusStoreFactory: All WorkerStores loaded: []
INFO  [2023-01-26 18:08:02,918] com.bakdata.conquery.commands.ShardNode: All Worker Storages loaded: 0
WARN  [2023-01-26 18:08:02,920] com.bakdata.conquery.models.config.XodusStoreFactory: Had to create Storage Dir at `/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/shard-node0`
INFO  [2023-01-26 18:08:02,920] com.bakdata.conquery.models.config.XodusStoreFactory: All WorkerStores loaded: []
INFO  [2023-01-26 18:08:02,920] com.bakdata.conquery.commands.ShardNode: All Worker Storages loaded: 0
INFO  [2023-01-26 18:08:02,921] io.dropwizard.server.ServerFactory: Starting Conquery


 ▄████████  ▄██████▄  ███▄▄▄▄   ████████▄   ███    █▄     ▄████████    ▄████████ ▄██   ▄   
███    ███ ███    ███ ███▀▀▀██▄ ███    ███  ███    ███   ███    ███   ███    ███ ███   ██▄ 
███    █▀  ███    ███ ███   ███ ███    ███  ███    ███   ███    █▀    ███    ███ ███▄▄▄███ 
███        ███    ███ ███   ███ ███    ███  ███    ███  ▄███▄▄▄      ▄███▄▄▄▄██▀ ▀▀▀▀▀▀███ 
███        ███    ███ ███   ███ ███    ███  ███    ███ ▀▀███▀▀▀     ▀▀███▀▀▀▀▀   ▄██   ███ 
███    █▄  ███    ███ ███   ███ ███    ███  ███    ███   ███    █▄  ▀███████████ ███   ███ 
███    ███ ███    ███ ███   ███ ███  ▀ ███  ███    ███   ███    ███   ███    ███ ███   ███ 
████████▀   ▀██████▀   ▀█   █▀   ▀██████▀▄█ ████████▀    ██████████   ███    ███  ▀█████▀  
                                                                      ███    ███           
Version: 0.0.0-SNAPSHOT(${git.commit.id.describe})

           
INFO  [2023-01-26 18:08:02,934] org.eclipse.jetty.setuid.SetUIDListener: Opened application@57d52a0e{HTTP/1.1, (http/1.1)}{0.0.0.0:44991}
INFO  [2023-01-26 18:08:02,934] org.eclipse.jetty.setuid.SetUIDListener: Opened admin@7a1d627e{HTTP/1.1, (http/1.1)}{0.0.0.0:45301}
INFO  [2023-01-26 18:08:02,935] org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.17+8-post-Ubuntu-1ubuntu218.04
INFO  [2023-01-26 18:08:02,938] com.bakdata.conquery.commands.ManagerNode: Started ManagerNode @ /0:0:0:0:0:0:0:0:45413
INFO  [2023-01-26 18:08:02,960] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/api-token
INFO  [2023-01-26 18:08:02,979] com.bakdata.conquery.commands.ShardNode: Trying to connect to /127.0.0.1:45413
INFO  [2023-01-26 18:08:02,980] com.bakdata.conquery.commands.ManagerNode: New client /127.0.0.1:35226 connected, waiting for identity
INFO  [2023-01-26 18:08:02,980] com.bakdata.conquery.commands.ShardNode: Connected to ManagerNode @ /127.0.0.1:45413
INFO  [2023-01-26 18:08:02,982] com.bakdata.conquery.commands.ShardNode: Trying to connect to /127.0.0.1:45413
INFO  [2023-01-26 18:08:02,982] com.bakdata.conquery.commands.ManagerNode: New client /127.0.0.1:35228 connected, waiting for identity
INFO  [2023-01-26 18:08:02,983] com.bakdata.conquery.commands.ShardNode: Connected to ManagerNode @ /127.0.0.1:45413
INFO  [2023-01-26 18:08:02,991] com.bakdata.conquery.models.messages.network.specific.AddShardNode: ShardNode `/127.0.0.1:35226` registered.
INFO  [2023-01-26 18:08:02,994] com.bakdata.conquery.models.messages.network.specific.AddShardNode: ShardNode `/127.0.0.1:35228` registered.
INFO  [2023-01-26 18:08:03,077] io.dropwizard.jersey.DropwizardResourceConfig: The following paths were found for the configured resources:

    GET     /api/config/frontend (com.bakdata.conquery.resources.api.ConfigResource)
    GET     /api/datasets (com.bakdata.conquery.resources.api.DatasetsResource)
    GET     /api/datasets/{dataset}/concepts (com.bakdata.conquery.resources.api.DatasetResource)
    GET     /api/datasets/{dataset}/concepts/{concept} (com.bakdata.conquery.resources.api.ConceptResource)
    POST    /api/datasets/{dataset}/concepts/{concept}/resolve (com.bakdata.conquery.resources.api.ConceptResource)
    POST    /api/datasets/{dataset}/concepts/{concept}/tables/{table}/filters/{filter}/autocomplete (com.bakdata.conquery.resources.api.FilterResource)
    POST    /api/datasets/{dataset}/concepts/{concept}/tables/{table}/filters/{filter}/resolve (com.bakdata.conquery.resources.api.FilterResource)
    GET     /api/datasets/{dataset}/form-configs (com.bakdata.conquery.resources.api.FormConfigResource)
    POST    /api/datasets/{dataset}/form-configs (com.bakdata.conquery.resources.api.FormConfigResource)
    DELETE  /api/datasets/{dataset}/form-configs/{form-config} (com.bakdata.conquery.resources.api.FormConfigResource)
    GET     /api/datasets/{dataset}/form-configs/{form-config} (com.bakdata.conquery.resources.api.FormConfigResource)
    PATCH   /api/datasets/{dataset}/form-configs/{form-config} (com.bakdata.conquery.resources.api.FormConfigResource)
    GET     /api/datasets/{dataset}/form-queries (com.bakdata.conquery.resources.api.FormResource)
    GET     /api/datasets/{dataset}/queries (com.bakdata.conquery.resources.api.QueryResource)
    POST    /api/datasets/{dataset}/queries (com.bakdata.conquery.resources.api.QueryResource)
    POST    /api/datasets/{dataset}/queries/upload (com.bakdata.conquery.resources.api.QueryResource)
    DELETE  /api/datasets/{dataset}/queries/{query} (com.bakdata.conquery.resources.api.QueryResource)
    GET     /api/datasets/{dataset}/queries/{query} (com.bakdata.conquery.resources.api.QueryResource)
    PATCH   /api/datasets/{dataset}/queries/{query} (com.bakdata.conquery.resources.api.QueryResource)
    POST    /api/datasets/{dataset}/queries/{query}/cancel (com.bakdata.conquery.resources.api.QueryResource)
    POST    /api/datasets/{dataset}/queries/{query}/reexecute (com.bakdata.conquery.resources.api.QueryResource)
    GET     /api/datasets/{dataset}/result/{query}.arrf (com.bakdata.conquery.resources.api.ResultArrowFileResource)
    GET     /api/datasets/{dataset}/result/{query}.arrs (com.bakdata.conquery.resources.api.ResultArrowStreamResource)
    GET     /api/datasets/{dataset}/result/{query}.csv (com.bakdata.conquery.resources.api.ResultCsvResource)
    GET     /api/datasets/{dataset}/result/{query}.xlsx (com.bakdata.conquery.resources.api.ResultExcelResource)
    GET     /api/me (com.bakdata.conquery.resources.api.MeResource)
    GET     /api/token (com.bakdata.conquery.resources.api.ApiTokenResource)
    POST    /api/token (com.bakdata.conquery.resources.api.ApiTokenResource)
    DELETE  /api/token/{token} (com.bakdata.conquery.resources.api.ApiTokenResource)

WARN  [2023-01-26 18:08:03,077] org.glassfish.jersey.internal.Errors: The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.filters.Filter<?> from public void com.bakdata.conquery.resources.hierarchies.HFilters.setFilter(com.bakdata.conquery.models.datasets.concepts.filters.Filter<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public com.bakdata.conquery.apiv1.FullExecutionStatus com.bakdata.conquery.resources.api.QueryResource.getStatus(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) throws java.lang.InterruptedException is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public com.bakdata.conquery.apiv1.FullExecutionStatus com.bakdata.conquery.resources.api.QueryResource.patchQuery(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>,com.bakdata.conquery.apiv1.MetaDataPatch) throws com.bakdata.conquery.models.exceptions.JSONException is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public void com.bakdata.conquery.resources.api.QueryResource.deleteQuery(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>) is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public void com.bakdata.conquery.resources.api.QueryResource.cancel(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>) is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public com.bakdata.conquery.apiv1.FullExecutionStatus com.bakdata.conquery.resources.api.QueryResource.reexecute(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultExcelResource.get(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.identifiable.ids.specific.DatasetId,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultArrowStreamResource.get(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.datasets.Dataset,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultCsvResource.getAsCsv(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.datasets.Dataset,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.lang.String,java.lang.String,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultArrowFileResource.get(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.datasets.Dataset,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.filters.Filter<?> from public void com.bakdata.conquery.resources.hierarchies.HFilters.setFilter(com.bakdata.conquery.models.datasets.concepts.filters.Filter<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.

INFO  [2023-01-26 18:08:03,111] io.dropwizard.jersey.DropwizardResourceConfig: The following paths were found for the configured resources:

    NONE

INFO  [2023-01-26 18:08:03,111] org.eclipse.jetty.server.handler.ContextHandler: Started i.d.j.MutableServletContextHandler@1873e5f9{/,null,AVAILABLE}
INFO  [2023-01-26 18:08:03,111] io.dropwizard.setup.AdminEnvironment: tasks = 

    POST    /tasks/permission-cleanup (com.bakdata.conquery.tasks.PermissionCleanupTask)
    POST    /tasks/report-consistency (com.bakdata.conquery.tasks.ReportConsistencyTask)
    POST    /tasks/log-level (io.dropwizard.servlets.tasks.LogConfigurationTask)
    POST    /tasks/form-scanner (com.bakdata.conquery.models.forms.frontendconfiguration.FormScanner)
    POST    /tasks/clear-filter-source-search (com.bakdata.conquery.tasks.ClearFilterSourceSearch)
    POST    /tasks/gc (io.dropwizard.servlets.tasks.GarbageCollectionTask)
    POST    /tasks/query-cleanup (com.bakdata.conquery.tasks.QueryCleanupTask)
    POST    /tasks/shutdown (com.bakdata.conquery.resources.admin.ShutdownTask)

WARN  [2023-01-26 18:08:03,112] io.dropwizard.setup.AdminEnvironment: 
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!    THIS APPLICATION HAS NO HEALTHCHECKS. THIS MEANS YOU WILL NEVER KNOW      !
!     IF IT DIES IN PRODUCTION, WHICH MEANS YOU WILL NEVER KNOW IF YOU'RE      !
!    LETTING YOUR USERS DOWN. YOU SHOULD ADD A HEALTHCHECK FOR EACH OF YOUR    !
!         APPLICATION'S DEPENDENCIES WHICH FULLY (BUT LIGHTLY) TESTS IT.       !
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
INFO  [2023-01-26 18:08:03,206] io.dropwizard.jersey.DropwizardResourceConfig: The following paths were found for the configured resources:

    GET     /admin/auth-overview/csv (com.bakdata.conquery.resources.admin.rest.AuthOverviewResource)
    GET     /admin/auth-overview/csv/group/{groupId} (com.bakdata.conquery.resources.admin.rest.AuthOverviewResource)
    GET     /admin/datasets (com.bakdata.conquery.resources.admin.rest.AdminDatasetsResource)
    POST    /admin/datasets (com.bakdata.conquery.resources.admin.rest.AdminDatasetsResource)
    DELETE  /admin/datasets/{dataset} (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    GET     /admin/datasets/{dataset} (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    GET     /admin/datasets/{dataset}/concepts (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    POST    /admin/datasets/{dataset}/concepts (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    PUT     /admin/datasets/{dataset}/concepts (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    DELETE  /admin/datasets/{dataset}/concepts/{concept} (com.bakdata.conquery.resources.admin.rest.AdminConceptsResource)
    GET     /admin/datasets/{dataset}/concepts/{concept} (com.bakdata.conquery.resources.admin.rest.AdminConceptsResource)
    POST    /admin/datasets/{dataset}/cqpp (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    PUT     /admin/datasets/{dataset}/cqpp (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    POST    /admin/datasets/{dataset}/imports (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    PUT     /admin/datasets/{dataset}/imports (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    POST    /admin/datasets/{dataset}/label (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    GET     /admin/datasets/{dataset}/mapping (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    POST    /admin/datasets/{dataset}/mapping (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    POST    /admin/datasets/{dataset}/secondaryId (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    DELETE  /admin/datasets/{dataset}/secondaryId/{secondaryId} (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    POST    /admin/datasets/{dataset}/structure (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    GET     /admin/datasets/{dataset}/tables (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    POST    /admin/datasets/{dataset}/tables (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    DELETE  /admin/datasets/{dataset}/tables/{table} (com.bakdata.conquery.resources.admin.rest.AdminTablesResource)
    GET     /admin/datasets/{dataset}/tables/{table} (com.bakdata.conquery.resources.admin.rest.AdminTablesResource)
    GET     /admin/datasets/{dataset}/tables/{table}/imports (com.bakdata.conquery.resources.admin.rest.AdminTablesResource)
    DELETE  /admin/datasets/{dataset}/tables/{table}/imports/{importId} (com.bakdata.conquery.resources.admin.rest.AdminTablesResource)
    GET     /admin/datasets/{dataset}/tables/{table}/imports/{importId} (com.bakdata.conquery.resources.admin.rest.AdminTablesResource)
    POST    /admin/datasets/{dataset}/update-matching-stats (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    POST    /admin/datasets/{dataset}/weight (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    GET     /admin/groups (com.bakdata.conquery.resources.admin.rest.GroupResource)
    POST    /admin/groups (com.bakdata.conquery.resources.admin.rest.GroupResource)
    DELETE  /admin/groups/{groupId} (com.bakdata.conquery.resources.admin.rest.GroupResource)
    GET     /admin/groups/{groupId} (com.bakdata.conquery.resources.admin.rest.GroupResource)
    DELETE  /admin/groups/{groupId}/roles/{roleId} (com.bakdata.conquery.resources.admin.rest.GroupResource)
    POST    /admin/groups/{groupId}/roles/{roleId} (com.bakdata.conquery.resources.admin.rest.GroupResource)
    DELETE  /admin/groups/{groupId}/users/{userId} (com.bakdata.conquery.resources.admin.rest.GroupResource)
    POST    /admin/groups/{groupId}/users/{userId} (com.bakdata.conquery.resources.admin.rest.GroupResource)
    GET     /admin/jobs (com.bakdata.conquery.resources.admin.rest.AdminResource)
    POST    /admin/jobs/{jobId}/cancel (com.bakdata.conquery.resources.admin.rest.AdminResource)
    GET     /admin/logout (com.bakdata.conquery.resources.admin.rest.AdminResource)
    DELETE  /admin/permissions/{ownerId} (com.bakdata.conquery.resources.admin.rest.PermissionResource)
    POST    /admin/permissions/{ownerId} (com.bakdata.conquery.resources.admin.rest.PermissionResource)
    GET     /admin/queries (com.bakdata.conquery.resources.admin.rest.AdminResource)
    GET     /admin/roles (com.bakdata.conquery.resources.admin.rest.RoleResource)
    POST    /admin/roles (com.bakdata.conquery.resources.admin.rest.RoleResource)
    DELETE  /admin/roles/{roleId} (com.bakdata.conquery.resources.admin.rest.RoleResource)
    GET     /admin/roles/{roleId} (com.bakdata.conquery.resources.admin.rest.RoleResource)
    POST    /admin/script (com.bakdata.conquery.resources.admin.rest.AdminResource)
    GET     /admin/users (com.bakdata.conquery.resources.admin.rest.UserResource)
    POST    /admin/users (com.bakdata.conquery.resources.admin.rest.UserResource)
    POST    /admin/users/upload (com.bakdata.conquery.resources.admin.rest.UserResource)
    DELETE  /admin/users/{userId} (com.bakdata.conquery.resources.admin.rest.UserResource)
    GET     /admin/users/{userId} (com.bakdata.conquery.resources.admin.rest.UserResource)
    DELETE  /admin/users/{userId}/roles/{roleId} (com.bakdata.conquery.resources.admin.rest.UserResource)
    POST    /admin/users/{userId}/roles/{roleId} (com.bakdata.conquery.resources.admin.rest.UserResource)

WARN  [2023-01-26 18:08:03,207] org.glassfish.jersey.internal.Errors: The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.auth.entities.PermissionOwner<?> from public void com.bakdata.conquery.resources.hierarchies.HPermissions.setOwner(com.bakdata.conquery.models.auth.entities.PermissionOwner<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.auth.entities.PermissionOwner<?> from public void com.bakdata.conquery.resources.hierarchies.HPermissions.setOwner(com.bakdata.conquery.models.auth.entities.PermissionOwner<?>) is not resolvable to a concrete type.

INFO  [2023-01-26 18:08:03,262] io.dropwizard.jersey.DropwizardResourceConfig: The following paths were found for the configured resources:

    GET     /admin-ui/ (com.bakdata.conquery.resources.admin.ui.AdminUIResource)
    GET     /admin-ui/auth-overview (com.bakdata.conquery.resources.admin.ui.AuthOverviewUIResource)
    GET     /admin-ui/datasets (com.bakdata.conquery.resources.admin.ui.DatasetsUIResource)
    GET     /admin-ui/datasets/{dataset} (com.bakdata.conquery.resources.admin.ui.DatasetsUIResource)
    GET     /admin-ui/datasets/{dataset}/concepts/{concept} (com.bakdata.conquery.resources.admin.ui.ConceptsUIResource)
    GET     /admin-ui/datasets/{dataset}/mapping (com.bakdata.conquery.resources.admin.ui.DatasetsUIResource)
    GET     /admin-ui/datasets/{dataset}/tables/{table} (com.bakdata.conquery.resources.admin.ui.TablesUIResource)
    GET     /admin-ui/datasets/{dataset}/tables/{table}/import/{importId} (com.bakdata.conquery.resources.admin.ui.TablesUIResource)
    GET     /admin-ui/groups (com.bakdata.conquery.resources.admin.ui.GroupUIResource)
    GET     /admin-ui/groups/{groupId} (com.bakdata.conquery.resources.admin.ui.GroupUIResource)
    GET     /admin-ui/jobs (com.bakdata.conquery.resources.admin.ui.AdminUIResource)
    GET     /admin-ui/queries (com.bakdata.conquery.resources.admin.ui.AdminUIResource)
    GET     /admin-ui/roles (com.bakdata.conquery.resources.admin.ui.RoleUIResource)
    GET     /admin-ui/roles/{roleId} (com.bakdata.conquery.resources.admin.ui.RoleUIResource)
    GET     /admin-ui/script (com.bakdata.conquery.resources.admin.ui.AdminUIResource)
    GET     /admin-ui/users (com.bakdata.conquery.resources.admin.ui.UserUIResource)
    GET     /admin-ui/users/{userId} (com.bakdata.conquery.resources.admin.ui.UserUIResource)

WARN  [2023-01-26 18:08:03,262] org.glassfish.jersey.internal.Errors: The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter concept of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from protected com.bakdata.conquery.models.datasets.concepts.Concept<?> com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.concept is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter concept of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from protected com.bakdata.conquery.models.datasets.concepts.Concept<?> com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.concept is not resolvable to a concrete type.

INFO  [2023-01-26 18:08:03,297] io.dropwizard.jersey.DropwizardResourceConfig: The following paths were found for the configured resources:

    NONE

INFO  [2023-01-26 18:08:03,297] org.eclipse.jetty.server.handler.ContextHandler: Started i.d.j.MutableServletContextHandler@186ab4fa{/,null,AVAILABLE}
INFO  [2023-01-26 18:08:03,313] org.eclipse.jetty.server.AbstractConnector: Started application@57d52a0e{HTTP/1.1, (http/1.1)}{0.0.0.0:44991}
INFO  [2023-01-26 18:08:03,314] org.eclipse.jetty.server.AbstractConnector: Started admin@7a1d627e{HTTP/1.1, (http/1.1)}{0.0.0.0:45301}
INFO  [2023-01-26 18:08:03,315] org.eclipse.jetty.server.Server: Started @22854ms
INFO  [2023-01-26 18:08:03,319] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test ApiTokenRealmTest
INFO  [2023-01-26 18:08:03,321] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:03,341] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/manager/dataset_ApiTokenRealmTest
INFO  [2023-01-26 18:08:03,358] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/manager/dataset_ApiTokenRealmTest:DATASET}): 0 entries, 0 B within 159.6 μs
INFO  [2023-01-26 18:08:03,359] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/manager/dataset_ApiTokenRealmTest:SECONDARY_IDS}): 0 entries, 0 B within 100.7 μs
INFO  [2023-01-26 18:08:03,359] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/manager/dataset_ApiTokenRealmTest:TABLES}): 0 entries, 0 B within 89.43 μs
INFO  [2023-01-26 18:08:03,359] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 88.92 μs
INFO  [2023-01-26 18:08:03,359] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/manager/dataset_ApiTokenRealmTest:IMPORTS}): 0 entries, 0 B within 116.0 μs
INFO  [2023-01-26 18:08:03,359] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/manager/dataset_ApiTokenRealmTest:CONCEPTS}): 0 entries, 0 B within 100.7 μs
INFO  [2023-01-26 18:08:03,360] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:03,360] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big ID_MAPPING(EntityIdMap): 0 entries, 0 B within 95.90 μs
INFO  [2023-01-26 18:08:03,360] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/manager/dataset_ApiTokenRealmTest:STRUCTURE}): 0 entries, 0 B within 80.30 μs
INFO  [2023-01-26 18:08:03,360] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/manager/dataset_ApiTokenRealmTest:WORKER_TO_BUCKETS}): 0 entries, 0 B within 82.07 μs
INFO  [2023-01-26 18:08:03,360] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/manager/dataset_ApiTokenRealmTest:PRIMARY_DICTIONARY}): 0 entries, 0 B within 77.08 μs
INFO  [2023-01-26 18:08:03,375] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=ApiTokenRealmTest, name=ApiTokenRealmTest]
INFO  [2023-01-26 18:08:03,376] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=ApiTokenRealmTest, name=ApiTokenRealmTest]
INFO  [2023-01-26 18:08:03,407] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/shard-node1/worker_worker_ApiTokenRealmTest_08ad0d4a-6e27-4820-bebe-132d2fdc2950
INFO  [2023-01-26 18:08:03,412] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/shard-node0/worker_worker_ApiTokenRealmTest_a2b8e90a-44fe-486a-be5d-f8b2c229ed6b
INFO  [2023-01-26 18:08:03,438] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/shard-node1/worker_worker_ApiTokenRealmTest_08ad0d4a-6e27-4820-bebe-132d2fdc2950:DATASET}): 0 entries, 0 B within 207.5 μs
INFO  [2023-01-26 18:08:03,439] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/shard-node1/worker_worker_ApiTokenRealmTest_08ad0d4a-6e27-4820-bebe-132d2fdc2950:SECONDARY_IDS}): 0 entries, 0 B within 113.1 μs
INFO  [2023-01-26 18:08:03,439] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/shard-node1/worker_worker_ApiTokenRealmTest_08ad0d4a-6e27-4820-bebe-132d2fdc2950:TABLES}): 0 entries, 0 B within 89.96 μs
INFO  [2023-01-26 18:08:03,439] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 94.26 μs
INFO  [2023-01-26 18:08:03,439] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/shard-node1/worker_worker_ApiTokenRealmTest_08ad0d4a-6e27-4820-bebe-132d2fdc2950:IMPORTS}): 0 entries, 0 B within 83.02 μs
INFO  [2023-01-26 18:08:03,440] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/shard-node1/worker_worker_ApiTokenRealmTest_08ad0d4a-6e27-4820-bebe-132d2fdc2950:CONCEPTS}): 0 entries, 0 B within 212.3 μs
INFO  [2023-01-26 18:08:03,440] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:03,440] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/shard-node1/worker_worker_ApiTokenRealmTest_08ad0d4a-6e27-4820-bebe-132d2fdc2950:WORKER}): 0 entries, 0 B within 121.2 μs
INFO  [2023-01-26 18:08:03,440] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/shard-node1/worker_worker_ApiTokenRealmTest_08ad0d4a-6e27-4820-bebe-132d2fdc2950:BUCKETS}): 0 entries, 0 B within 100.8 μs
INFO  [2023-01-26 18:08:03,440] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/shard-node1/worker_worker_ApiTokenRealmTest_08ad0d4a-6e27-4820-bebe-132d2fdc2950:C_BLOCKS}): 0 entries, 0 B within 101.4 μs
INFO  [2023-01-26 18:08:03,454] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/shard-node0/worker_worker_ApiTokenRealmTest_a2b8e90a-44fe-486a-be5d-f8b2c229ed6b:DATASET}): 0 entries, 0 B within 222.5 μs
INFO  [2023-01-26 18:08:03,455] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/shard-node0/worker_worker_ApiTokenRealmTest_a2b8e90a-44fe-486a-be5d-f8b2c229ed6b:SECONDARY_IDS}): 0 entries, 0 B within 139.7 μs
INFO  [2023-01-26 18:08:03,455] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/shard-node0/worker_worker_ApiTokenRealmTest_a2b8e90a-44fe-486a-be5d-f8b2c229ed6b:TABLES}): 0 entries, 0 B within 159.9 μs
INFO  [2023-01-26 18:08:03,455] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 150.5 μs
INFO  [2023-01-26 18:08:03,456] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/shard-node0/worker_worker_ApiTokenRealmTest_a2b8e90a-44fe-486a-be5d-f8b2c229ed6b:IMPORTS}): 0 entries, 0 B within 118.4 μs
INFO  [2023-01-26 18:08:03,456] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/shard-node0/worker_worker_ApiTokenRealmTest_a2b8e90a-44fe-486a-be5d-f8b2c229ed6b:CONCEPTS}): 0 entries, 0 B within 114.3 μs
INFO  [2023-01-26 18:08:03,456] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:03,456] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/shard-node0/worker_worker_ApiTokenRealmTest_a2b8e90a-44fe-486a-be5d-f8b2c229ed6b:WORKER}): 0 entries, 0 B within 127.4 μs
INFO  [2023-01-26 18:08:03,456] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/shard-node0/worker_worker_ApiTokenRealmTest_a2b8e90a-44fe-486a-be5d-f8b2c229ed6b:BUCKETS}): 0 entries, 0 B within 115.6 μs
INFO  [2023-01-26 18:08:03,456] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/shard-node0/worker_worker_ApiTokenRealmTest_a2b8e90a-44fe-486a-be5d-f8b2c229ed6b:C_BLOCKS}): 0 entries, 0 B within 121.7 μs
INFO  [2023-01-26 18:08:03,459] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker ApiTokenRealmTest.worker_ApiTokenRealmTest_08ad0d4a-6e27-4820-bebe-132d2fdc2950 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:03,460] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker ApiTokenRealmTest.worker_ApiTokenRealmTest_08ad0d4a-6e27-4820-bebe-132d2fdc2950 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:03,460] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:03,476] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:03,479] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker ApiTokenRealmTest.worker_ApiTokenRealmTest_a2b8e90a-44fe-486a-be5d-f8b2c229ed6b are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:03,479] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker ApiTokenRealmTest.worker_ApiTokenRealmTest_a2b8e90a-44fe-486a-be5d-f8b2c229ed6b are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:03,479] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:03,632] com.bakdata.conquery.models.auth.apitoken.ApiTokenRealm: Creating new api token data for user user.SUPERUSER@SUPERUSER with id: dffb2824-efb7-413e-8ed7-3801b9162243
127.0.0.1 - - [26/Jan/2023:18:08:03 +0000] "POST /api/token HTTP/1.1" 200 96 "-" "Conquery (test client)" 76
127.0.0.1 - - [26/Jan/2023:18:08:03 +0000] "GET /api/token HTTP/1.1" 200 178 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:08:03,747] com.bakdata.conquery.models.auth.apitoken.ApiTokenRealm: Creating new api token data for user user.SUPERUSER@SUPERUSER with id: 2a3c807e-9630-4a24-a0bb-1eca66d88151
127.0.0.1 - - [26/Jan/2023:18:08:03 +0000] "POST /api/token HTTP/1.1" 200 96 "-" "Conquery (test client)" 25
127.0.0.1 - - [26/Jan/2023:18:08:03 +0000] "GET /api/token HTTP/1.1" 200 353 "-" "Conquery (test client)" 3
127.0.0.1 - - [26/Jan/2023:18:08:03 +0000] "GET /api/datasets HTTP/1.1" 200 56 "-" "Conquery (test client)" 31
127.0.0.1 - - [26/Jan/2023:18:08:03 +0000] "GET /api/datasets HTTP/1.1" 200 2 "-" "Conquery (test client)" 46
127.0.0.1 - - [26/Jan/2023:18:08:03 +0000] "GET /admin/datasets HTTP/1.1" 200 21 "-" "Conquery (test client)" 33
127.0.0.1 - - [26/Jan/2023:18:08:03 +0000] "DELETE /api/token/2a3c807e-9630-4a24-a0bb-1eca66d88151 HTTP/1.1" 403 63 "-" "Conquery (test client)" 31
127.0.0.1 - - [26/Jan/2023:18:08:04 +0000] "DELETE /api/token/2a3c807e-9630-4a24-a0bb-1eca66d88151 HTTP/1.1" 200 0 "-" "Conquery (test client)" 3
WARN  [2023-01-26 18:08:04,061] com.bakdata.conquery.models.auth.web.DefaultAuthFilter: Non of the configured realms was able to successfully authenticate the extracted token(s).
127.0.0.1 - - [26/Jan/2023:18:08:04 +0000] "GET /admin/datasets HTTP/1.1" 401 46 "-" "Conquery (test client)" 29
WARN  [2023-01-26 18:08:04,082] com.bakdata.conquery.models.auth.web.AuthorizationExceptionMapper: Shiro failed to authorize the request. Reason: Subject does not have permission [admin]
127.0.0.1 - - [26/Jan/2023:18:08:04 +0000] "DELETE /api/token/dffb2824-efb7-413e-8ed7-3801b9162243 HTTP/1.1" 403 86 "-" "Conquery (test client)" 3
127.0.0.1 - - [26/Jan/2023:18:08:04 +0000] "POST /api/token HTTP/1.1" 422 27 "-" "Conquery (test client)" 32
INFO  [2023-01-26 18:08:04,152] com.bakdata.conquery.models.auth.apitoken.ApiTokenRealm: Creating new api token data for user user.TestUser2 with id: bb8a4eff-92f6-499d-8a56-05eadccae359
INFO  [2023-01-26 18:08:04,198] com.bakdata.conquery.models.auth.apitoken.ApiTokenRealm: Supplied token expired on: 2023-01-25
WARN  [2023-01-26 18:08:04,198] com.bakdata.conquery.models.auth.web.DefaultAuthFilter: Non of the configured realms was able to successfully authenticate the extracted token(s).
127.0.0.1 - - [26/Jan/2023:18:08:04 +0000] "GET /api/datasets HTTP/1.1" 401 46 "-" "Conquery (test client)" 27
INFO  [2023-01-26 18:08:04,201] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast ApiTokenRealmTest
INFO  [2023-01-26 18:08:04,202] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=ApiTokenRealmTest, name=ApiTokenRealmTest]
INFO  [2023-01-26 18:08:04,203] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_ApiTokenRealmTest_08ad0d4a-6e27-4820-bebe-132d2fdc2950
INFO  [2023-01-26 18:08:04,203] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=ApiTokenRealmTest, name=ApiTokenRealmTest]
INFO  [2023-01-26 18:08:04,203] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_ApiTokenRealmTest_a2b8e90a-44fe-486a-be5d-f8b2c229ed6b
INFO  [2023-01-26 18:08:04,266] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_ApiTokenRealmTest_08ad0d4a-6e27-4820-bebe-132d2fdc2950
INFO  [2023-01-26 18:08:04,270] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow ApiTokenRealmTest
INFO  [2023-01-26 18:08:04,270] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_ApiTokenRealmTest_a2b8e90a-44fe-486a-be5d-f8b2c229ed6b
INFO  [2023-01-26 18:08:04,369] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/shard-node0/worker_worker_ApiTokenRealmTest_a2b8e90a-44fe-486a-be5d-f8b2c229ed6b
INFO  [2023-01-26 18:08:04,369] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/shard-node1/worker_worker_ApiTokenRealmTest_08ad0d4a-6e27-4820-bebe-132d2fdc2950
INFO  [2023-01-26 18:08:04,370] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of ApiTokenRealmTest
INFO  [2023-01-26 18:08:04,372] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/manager/dataset_ApiTokenRealmTest
INFO  [2023-01-26 18:08:04,388] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:04,487] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test ApiTokenRealmTest
INFO  [2023-01-26 18:08:04,490] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test ConceptPermissionTest
INFO  [2023-01-26 18:08:04,491] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:04,512] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptPermissionTest
INFO  [2023-01-26 18:08:04,537] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptPermissionTest:DATASET}): 0 entries, 0 B within 201.0 μs
INFO  [2023-01-26 18:08:04,538] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptPermissionTest:SECONDARY_IDS}): 0 entries, 0 B within 142.6 μs
INFO  [2023-01-26 18:08:04,538] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptPermissionTest:TABLES}): 0 entries, 0 B within 112.3 μs
INFO  [2023-01-26 18:08:04,538] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 119.6 μs
INFO  [2023-01-26 18:08:04,538] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptPermissionTest:IMPORTS}): 0 entries, 0 B within 109.7 μs
INFO  [2023-01-26 18:08:04,539] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptPermissionTest:CONCEPTS}): 0 entries, 0 B within 106.8 μs
INFO  [2023-01-26 18:08:04,539] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:04,539] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big ID_MAPPING(EntityIdMap): 0 entries, 0 B within 103.6 μs
INFO  [2023-01-26 18:08:04,539] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptPermissionTest:STRUCTURE}): 0 entries, 0 B within 91.45 μs
INFO  [2023-01-26 18:08:04,539] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptPermissionTest:WORKER_TO_BUCKETS}): 0 entries, 0 B within 101.6 μs
INFO  [2023-01-26 18:08:04,539] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptPermissionTest:PRIMARY_DICTIONARY}): 0 entries, 0 B within 97.90 μs
INFO  [2023-01-26 18:08:04,550] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=ConceptPermissionTest, name=ConceptPermissionTest]
INFO  [2023-01-26 18:08:04,550] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=ConceptPermissionTest, name=ConceptPermissionTest]
INFO  [2023-01-26 18:08:04,570] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptPermissionTest_b13cf729-0d72-4f28-be1f-af98a6879eea
INFO  [2023-01-26 18:08:04,570] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptPermissionTest_ab6f6905-8e69-4e6d-a980-f22e806ad718
INFO  [2023-01-26 18:08:04,597] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptPermissionTest_ab6f6905-8e69-4e6d-a980-f22e806ad718:DATASET}): 0 entries, 0 B within 155.2 μs
INFO  [2023-01-26 18:08:04,597] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptPermissionTest_ab6f6905-8e69-4e6d-a980-f22e806ad718:SECONDARY_IDS}): 0 entries, 0 B within 73.92 μs
INFO  [2023-01-26 18:08:04,597] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptPermissionTest_ab6f6905-8e69-4e6d-a980-f22e806ad718:TABLES}): 0 entries, 0 B within 71.59 μs
INFO  [2023-01-26 18:08:04,598] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 75.57 μs
INFO  [2023-01-26 18:08:04,598] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptPermissionTest_ab6f6905-8e69-4e6d-a980-f22e806ad718:IMPORTS}): 0 entries, 0 B within 139.7 μs
INFO  [2023-01-26 18:08:04,598] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptPermissionTest_ab6f6905-8e69-4e6d-a980-f22e806ad718:CONCEPTS}): 0 entries, 0 B within 71.29 μs
INFO  [2023-01-26 18:08:04,598] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:04,598] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptPermissionTest_ab6f6905-8e69-4e6d-a980-f22e806ad718:WORKER}): 0 entries, 0 B within 114.2 μs
INFO  [2023-01-26 18:08:04,598] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptPermissionTest_ab6f6905-8e69-4e6d-a980-f22e806ad718:BUCKETS}): 0 entries, 0 B within 59.58 μs
INFO  [2023-01-26 18:08:04,598] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptPermissionTest_ab6f6905-8e69-4e6d-a980-f22e806ad718:C_BLOCKS}): 0 entries, 0 B within 57.58 μs
INFO  [2023-01-26 18:08:04,600] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptPermissionTest_b13cf729-0d72-4f28-be1f-af98a6879eea:DATASET}): 0 entries, 0 B within 180.2 μs
INFO  [2023-01-26 18:08:04,601] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptPermissionTest_b13cf729-0d72-4f28-be1f-af98a6879eea:SECONDARY_IDS}): 0 entries, 0 B within 163.6 μs
INFO  [2023-01-26 18:08:04,601] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptPermissionTest_b13cf729-0d72-4f28-be1f-af98a6879eea:TABLES}): 0 entries, 0 B within 122.8 μs
INFO  [2023-01-26 18:08:04,601] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 103.1 μs
INFO  [2023-01-26 18:08:04,602] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptPermissionTest_b13cf729-0d72-4f28-be1f-af98a6879eea:IMPORTS}): 0 entries, 0 B within 94.40 μs
INFO  [2023-01-26 18:08:04,602] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptPermissionTest_b13cf729-0d72-4f28-be1f-af98a6879eea:CONCEPTS}): 0 entries, 0 B within 74.31 μs
INFO  [2023-01-26 18:08:04,602] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:04,602] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptPermissionTest_b13cf729-0d72-4f28-be1f-af98a6879eea:WORKER}): 0 entries, 0 B within 85.63 μs
INFO  [2023-01-26 18:08:04,602] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptPermissionTest_b13cf729-0d72-4f28-be1f-af98a6879eea:BUCKETS}): 0 entries, 0 B within 84.71 μs
INFO  [2023-01-26 18:08:04,602] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptPermissionTest_b13cf729-0d72-4f28-be1f-af98a6879eea:C_BLOCKS}): 0 entries, 0 B within 114.6 μs
INFO  [2023-01-26 18:08:04,609] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker ConceptPermissionTest.worker_ConceptPermissionTest_ab6f6905-8e69-4e6d-a980-f22e806ad718 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:04,609] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker ConceptPermissionTest.worker_ConceptPermissionTest_ab6f6905-8e69-4e6d-a980-f22e806ad718 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:04,609] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:04,611] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker ConceptPermissionTest.worker_ConceptPermissionTest_b13cf729-0d72-4f28-be1f-af98a6879eea are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:04,611] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker ConceptPermissionTest.worker_ConceptPermissionTest_b13cf729-0d72-4f28-be1f-af98a6879eea are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:04,611] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:04,614] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:04,716] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:04,729] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:04,729] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ConceptPermissionTest.test_table
INFO  [2023-01-26 18:08:04,729] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ConceptPermissionTest.test_table
INFO  [2023-01-26 18:08:04,854] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:04,965] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:04,965] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:04,966] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 94 B in total
INFO  [2023-01-26 18:08:04,966] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ConceptPermissionTest/test_table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000178793sINFO  [2023-01-26 18:08:04,984] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=4, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:08:04,984] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=4, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:08:04,984] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=4, nullLines=0), subType=IntegerParser(super=Parser(lines=4, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@5fb68064)
INFO  [2023-01-26 18:08:04,988] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ConceptPermissionTest/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:04,988] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:04,988] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ConceptPermissionTest/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:05,010] com.bakdata.conquery.models.jobs.ImportJob: Importing test_table into ConceptPermissionTest.test_table
127.0.0.1 - - [26/Jan/2023:18:08:05 +0000] "POST /admin/datasets/ConceptPermissionTest/imports?file=%2Ftmp%2FconqueryIntegrationTest12910953884258704183%2Ftmp_ConceptPermissionTest%2Ftest_table.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 11
INFO  [2023-01-26 18:08:05,018] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:05,020] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:05,029] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:05,029] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:05,071] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ConceptPermissionTest.test_table.test_table], containing 4 entries.
INFO  [2023-01-26 18:08:05,071] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ConceptPermissionTest.test_table.test_table], containing 4 entries.
INFO  [2023-01-26 18:08:05,071] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
WARN  [2023-01-26 18:08:05,074] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:05,074] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ConceptPermissionTest.test_table.test_table.1
INFO  [2023-01-26 18:08:05,075] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ConceptPermissionTest.test_table.test_table.0
INFO  [2023-01-26 18:08:05,220] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[ConceptPermissionTest] by User[{user.testUser].
WARN  [2023-01-26 18:08:05,224] com.bakdata.conquery.models.auth.web.AuthorizationExceptionMapper: Shiro failed to authorize the request. Reason: Subject does not have permission [concepts:read:conceptpermissiontest.test_tree]
127.0.0.1 - - [26/Jan/2023:18:08:05 +0000] "POST /api/datasets/ConceptPermissionTest/queries HTTP/1.1" 403 126 "-" "Conquery (test client)" 15
INFO  [2023-01-26 18:08:05,225] com.bakdata.conquery.integration.tests.ConceptPermissionTest: Adding the Permission[concepts:read:conceptpermissiontest.test_tree] to User[User[user.testUser]]
INFO  [2023-01-26 18:08:05,244] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[ConceptPermissionTest] by User[{user.testUser].
INFO  [2023-01-26 18:08:05,246] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[4f285018-c04d-40b7-8d66-b98d16ce8f47] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_ConceptPermissionTest))]]
127.0.0.1 - - [26/Jan/2023:18:08:05 +0000] "POST /api/datasets/ConceptPermissionTest/queries HTTP/1.1" 201 1121 "-" "Conquery (test client)" 13
INFO  [2023-01-26 18:08:05,258] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery ConceptPermissionTest.4f285018-c04d-40b7-8d66-b98d16ce8f47
INFO  [2023-01-26 18:08:05,259] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery ConceptPermissionTest.4f285018-c04d-40b7-8d66-b98d16ce8f47
INFO  [2023-01-26 18:08:05,277] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[ConceptPermissionTest.4f285018-c04d-40b7-8d66-b98d16ce8f47] with 0 results within PT0.017356S
INFO  [2023-01-26 18:08:05,278] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[ConceptPermissionTest.4f285018-c04d-40b7-8d66-b98d16ce8f47] with 2 results within PT0.019658S
INFO  [2023-01-26 18:08:05,284] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=ConceptPermissionTest.4f285018-c04d-40b7-8d66-b98d16ce8f47, workerId=ConceptPermissionTest.worker_ConceptPermissionTest_ab6f6905-8e69-4e6d-a980-f22e806ad718, startTime=2023-01-26T18:08:05.259756, finishTime=2023-01-26T18:08:05.277112) of size 0
INFO  [2023-01-26 18:08:05,285] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=ConceptPermissionTest.4f285018-c04d-40b7-8d66-b98d16ce8f47, workerId=ConceptPermissionTest.worker_ConceptPermissionTest_b13cf729-0d72-4f28-be1f-af98a6879eea, startTime=2023-01-26T18:08:05.258978, finishTime=2023-01-26T18:08:05.278636) of size 2
INFO  [2023-01-26 18:08:05,287] com.bakdata.conquery.models.execution.ManagedExecution: DONE 4f285018-c04d-40b7-8d66-b98d16ce8f47 ManagedQuery within PT0.03921S
127.0.0.1 - - [26/Jan/2023:18:08:05 +0000] "GET /api/datasets/ConceptPermissionTest/queries/ConceptPermissionTest.4f285018-c04d-40b7-8d66-b98d16ce8f47 HTTP/1.1" 200 1137 "-" "Conquery (test client)" 16
INFO  [2023-01-26 18:08:05,290] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:05,392] com.bakdata.conquery.io.storage.MetaStorage: Remove User = user.testUser
INFO  [2023-01-26 18:08:05,393] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast ConceptPermissionTest
INFO  [2023-01-26 18:08:05,394] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=ConceptPermissionTest, name=ConceptPermissionTest]
INFO  [2023-01-26 18:08:05,394] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=ConceptPermissionTest, name=ConceptPermissionTest]
INFO  [2023-01-26 18:08:05,394] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_ConceptPermissionTest_ab6f6905-8e69-4e6d-a980-f22e806ad718
INFO  [2023-01-26 18:08:05,394] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_ConceptPermissionTest_b13cf729-0d72-4f28-be1f-af98a6879eea
INFO  [2023-01-26 18:08:05,427] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_ConceptPermissionTest_ab6f6905-8e69-4e6d-a980-f22e806ad718
INFO  [2023-01-26 18:08:05,427] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_ConceptPermissionTest_b13cf729-0d72-4f28-be1f-af98a6879eea
INFO  [2023-01-26 18:08:05,472] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow ConceptPermissionTest
INFO  [2023-01-26 18:08:05,474] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of ConceptPermissionTest
INFO  [2023-01-26 18:08:05,476] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptPermissionTest
INFO  [2023-01-26 18:08:05,522] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:05,527] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptPermissionTest_ab6f6905-8e69-4e6d-a980-f22e806ad718
INFO  [2023-01-26 18:08:05,530] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptPermissionTest_b13cf729-0d72-4f28-be1f-af98a6879eea
INFO  [2023-01-26 18:08:05,648] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test ConceptPermissionTest
INFO  [2023-01-26 18:08:05,653] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test ConceptResolutionTest
INFO  [2023-01-26 18:08:05,654] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:05,677] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptResolutionTest
INFO  [2023-01-26 18:08:05,693] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptResolutionTest:DATASET}): 0 entries, 0 B within 175.0 μs
INFO  [2023-01-26 18:08:05,693] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptResolutionTest:SECONDARY_IDS}): 0 entries, 0 B within 77.51 μs
INFO  [2023-01-26 18:08:05,694] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptResolutionTest:TABLES}): 0 entries, 0 B within 68.86 μs
INFO  [2023-01-26 18:08:05,694] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 77.44 μs
INFO  [2023-01-26 18:08:05,694] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptResolutionTest:IMPORTS}): 0 entries, 0 B within 58.97 μs
INFO  [2023-01-26 18:08:05,694] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptResolutionTest:CONCEPTS}): 0 entries, 0 B within 68.55 μs
INFO  [2023-01-26 18:08:05,694] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:05,694] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big ID_MAPPING(EntityIdMap): 0 entries, 0 B within 59.24 μs
INFO  [2023-01-26 18:08:05,694] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptResolutionTest:STRUCTURE}): 0 entries, 0 B within 58.41 μs
INFO  [2023-01-26 18:08:05,694] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptResolutionTest:WORKER_TO_BUCKETS}): 0 entries, 0 B within 64.28 μs
INFO  [2023-01-26 18:08:05,694] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptResolutionTest:PRIMARY_DICTIONARY}): 0 entries, 0 B within 70.84 μs
INFO  [2023-01-26 18:08:05,702] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=ConceptResolutionTest, name=ConceptResolutionTest]
INFO  [2023-01-26 18:08:05,702] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=ConceptResolutionTest, name=ConceptResolutionTest]
INFO  [2023-01-26 18:08:05,725] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptResolutionTest_586f516a-672c-42d6-a2f0-3e018a863873
INFO  [2023-01-26 18:08:05,730] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptResolutionTest_04b991d3-872e-4aeb-b973-91d797551a9a
INFO  [2023-01-26 18:08:05,747] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptResolutionTest_586f516a-672c-42d6-a2f0-3e018a863873:DATASET}): 0 entries, 0 B within 162.0 μs
INFO  [2023-01-26 18:08:05,747] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptResolutionTest_586f516a-672c-42d6-a2f0-3e018a863873:SECONDARY_IDS}): 0 entries, 0 B within 100.3 μs
INFO  [2023-01-26 18:08:05,748] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptResolutionTest_586f516a-672c-42d6-a2f0-3e018a863873:TABLES}): 0 entries, 0 B within 63.49 μs
INFO  [2023-01-26 18:08:05,748] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 88.72 μs
INFO  [2023-01-26 18:08:05,748] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptResolutionTest_586f516a-672c-42d6-a2f0-3e018a863873:IMPORTS}): 0 entries, 0 B within 72.12 μs
INFO  [2023-01-26 18:08:05,748] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptResolutionTest_586f516a-672c-42d6-a2f0-3e018a863873:CONCEPTS}): 0 entries, 0 B within 53.05 μs
INFO  [2023-01-26 18:08:05,748] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:05,748] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptResolutionTest_586f516a-672c-42d6-a2f0-3e018a863873:WORKER}): 0 entries, 0 B within 53.79 μs
INFO  [2023-01-26 18:08:05,748] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptResolutionTest_586f516a-672c-42d6-a2f0-3e018a863873:BUCKETS}): 0 entries, 0 B within 59.74 μs
INFO  [2023-01-26 18:08:05,748] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptResolutionTest_586f516a-672c-42d6-a2f0-3e018a863873:C_BLOCKS}): 0 entries, 0 B within 60.77 μs
INFO  [2023-01-26 18:08:05,753] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker ConceptResolutionTest.worker_ConceptResolutionTest_586f516a-672c-42d6-a2f0-3e018a863873 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:05,753] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker ConceptResolutionTest.worker_ConceptResolutionTest_586f516a-672c-42d6-a2f0-3e018a863873 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:05,753] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:05,766] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptResolutionTest_04b991d3-872e-4aeb-b973-91d797551a9a:DATASET}): 0 entries, 0 B within 156.5 μs
INFO  [2023-01-26 18:08:05,767] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptResolutionTest_04b991d3-872e-4aeb-b973-91d797551a9a:SECONDARY_IDS}): 0 entries, 0 B within 85.21 μs
INFO  [2023-01-26 18:08:05,767] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptResolutionTest_04b991d3-872e-4aeb-b973-91d797551a9a:TABLES}): 0 entries, 0 B within 62.34 μs
INFO  [2023-01-26 18:08:05,767] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 76.50 μs
INFO  [2023-01-26 18:08:05,767] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptResolutionTest_04b991d3-872e-4aeb-b973-91d797551a9a:IMPORTS}): 0 entries, 0 B within 61.31 μs
INFO  [2023-01-26 18:08:05,767] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptResolutionTest_04b991d3-872e-4aeb-b973-91d797551a9a:CONCEPTS}): 0 entries, 0 B within 114.2 μs
INFO  [2023-01-26 18:08:05,767] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:05,767] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptResolutionTest_04b991d3-872e-4aeb-b973-91d797551a9a:WORKER}): 0 entries, 0 B within 81.03 μs
INFO  [2023-01-26 18:08:05,767] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptResolutionTest_04b991d3-872e-4aeb-b973-91d797551a9a:BUCKETS}): 0 entries, 0 B within 78.79 μs
INFO  [2023-01-26 18:08:05,768] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptResolutionTest_04b991d3-872e-4aeb-b973-91d797551a9a:C_BLOCKS}): 0 entries, 0 B within 66.10 μs
INFO  [2023-01-26 18:08:05,777] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker ConceptResolutionTest.worker_ConceptResolutionTest_04b991d3-872e-4aeb-b973-91d797551a9a are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:05,777] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker ConceptResolutionTest.worker_ConceptResolutionTest_04b991d3-872e-4aeb-b973-91d797551a9a are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:05,777] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:05,780] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:05,881] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:05,889] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:05,890] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ConceptResolutionTest.test_table
INFO  [2023-01-26 18:08:05,890] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ConceptResolutionTest.test_table
INFO  [2023-01-26 18:08:06,008] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:06,123] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:06,123] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:06,123] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 94 B in total
INFO  [2023-01-26 18:08:06,123] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ConceptResolutionTest/test_table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000194662sINFO  [2023-01-26 18:08:06,143] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=4, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:08:06,143] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=4, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:08:06,143] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=4, nullLines=0), subType=IntegerParser(super=Parser(lines=4, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@12f9d721)
INFO  [2023-01-26 18:08:06,148] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ConceptResolutionTest/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:06,149] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:06,149] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ConceptResolutionTest/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:06,175] com.bakdata.conquery.models.jobs.ImportJob: Importing test_table into ConceptResolutionTest.test_table
127.0.0.1 - - [26/Jan/2023:18:08:06 +0000] "POST /admin/datasets/ConceptResolutionTest/imports?file=%2Ftmp%2FconqueryIntegrationTest12910953884258704183%2Ftmp_ConceptResolutionTest%2Ftest_table.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 14
INFO  [2023-01-26 18:08:06,177] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:06,180] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:06,190] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:06,190] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:06,230] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ConceptResolutionTest.test_table.test_table], containing 4 entries.
INFO  [2023-01-26 18:08:06,230] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ConceptResolutionTest.test_table.test_table], containing 4 entries.
INFO  [2023-01-26 18:08:06,231] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
WARN  [2023-01-26 18:08:06,234] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:06,234] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ConceptResolutionTest.test_table.test_table.0
INFO  [2023-01-26 18:08:06,234] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ConceptResolutionTest.test_table.test_table.1
INFO  [2023-01-26 18:08:06,342] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:06,347] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:06,363] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:06,370] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast ConceptResolutionTest
INFO  [2023-01-26 18:08:06,371] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=ConceptResolutionTest, name=ConceptResolutionTest]
INFO  [2023-01-26 18:08:06,371] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=ConceptResolutionTest, name=ConceptResolutionTest]
INFO  [2023-01-26 18:08:06,371] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_ConceptResolutionTest_586f516a-672c-42d6-a2f0-3e018a863873
INFO  [2023-01-26 18:08:06,371] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_ConceptResolutionTest_04b991d3-872e-4aeb-b973-91d797551a9a
INFO  [2023-01-26 18:08:06,376] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_ConceptResolutionTest_04b991d3-872e-4aeb-b973-91d797551a9a
INFO  [2023-01-26 18:08:06,428] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow ConceptResolutionTest
INFO  [2023-01-26 18:08:06,434] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of ConceptResolutionTest
INFO  [2023-01-26 18:08:06,435] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptResolutionTest
INFO  [2023-01-26 18:08:06,440] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptResolutionTest_04b991d3-872e-4aeb-b973-91d797551a9a
INFO  [2023-01-26 18:08:06,445] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:06,449] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_ConceptResolutionTest_586f516a-672c-42d6-a2f0-3e018a863873
INFO  [2023-01-26 18:08:06,556] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptResolutionTest_586f516a-672c-42d6-a2f0-3e018a863873
INFO  [2023-01-26 18:08:06,668] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test ConceptResolutionTest
INFO  [2023-01-26 18:08:06,671] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test FilterResolutionContainsTest
INFO  [2023-01-26 18:08:06,671] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:06,694] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_FilterResolutionContainsTest
INFO  [2023-01-26 18:08:06,708] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_FilterResolutionContainsTest:DATASET}): 0 entries, 0 B within 177.1 μs
INFO  [2023-01-26 18:08:06,708] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_FilterResolutionContainsTest:SECONDARY_IDS}): 0 entries, 0 B within 89.18 μs
INFO  [2023-01-26 18:08:06,708] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_FilterResolutionContainsTest:TABLES}): 0 entries, 0 B within 73.79 μs
INFO  [2023-01-26 18:08:06,708] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 73.62 μs
INFO  [2023-01-26 18:08:06,709] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_FilterResolutionContainsTest:IMPORTS}): 0 entries, 0 B within 75.86 μs
INFO  [2023-01-26 18:08:06,709] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_FilterResolutionContainsTest:CONCEPTS}): 0 entries, 0 B within 86.45 μs
INFO  [2023-01-26 18:08:06,709] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:06,709] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big ID_MAPPING(EntityIdMap): 0 entries, 0 B within 57.35 μs
INFO  [2023-01-26 18:08:06,709] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_FilterResolutionContainsTest:STRUCTURE}): 0 entries, 0 B within 47.56 μs
INFO  [2023-01-26 18:08:06,709] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_FilterResolutionContainsTest:WORKER_TO_BUCKETS}): 0 entries, 0 B within 48.77 μs
INFO  [2023-01-26 18:08:06,709] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_FilterResolutionContainsTest:PRIMARY_DICTIONARY}): 0 entries, 0 B within 51.00 μs
INFO  [2023-01-26 18:08:06,717] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=FilterResolutionContainsTest, name=FilterResolutionContainsTest]
INFO  [2023-01-26 18:08:06,717] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=FilterResolutionContainsTest, name=FilterResolutionContainsTest]
INFO  [2023-01-26 18:08:06,735] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_FilterResolutionContainsTest_e02e2975-c593-4fb2-a2c3-362f866848e4
INFO  [2023-01-26 18:08:06,735] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_FilterResolutionContainsTest_e5234829-1f47-40e7-94dd-17076edcd4f8
INFO  [2023-01-26 18:08:06,755] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_FilterResolutionContainsTest_e02e2975-c593-4fb2-a2c3-362f866848e4:DATASET}): 0 entries, 0 B within 130.1 μs
INFO  [2023-01-26 18:08:06,755] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_FilterResolutionContainsTest_e02e2975-c593-4fb2-a2c3-362f866848e4:SECONDARY_IDS}): 0 entries, 0 B within 73.11 μs
INFO  [2023-01-26 18:08:06,755] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_FilterResolutionContainsTest_e02e2975-c593-4fb2-a2c3-362f866848e4:TABLES}): 0 entries, 0 B within 53.23 μs
INFO  [2023-01-26 18:08:06,755] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 52.14 μs
INFO  [2023-01-26 18:08:06,755] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_FilterResolutionContainsTest_e02e2975-c593-4fb2-a2c3-362f866848e4:IMPORTS}): 0 entries, 0 B within 50.77 μs
INFO  [2023-01-26 18:08:06,756] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_FilterResolutionContainsTest_e02e2975-c593-4fb2-a2c3-362f866848e4:CONCEPTS}): 0 entries, 0 B within 47.62 μs
INFO  [2023-01-26 18:08:06,756] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:06,756] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_FilterResolutionContainsTest_e02e2975-c593-4fb2-a2c3-362f866848e4:WORKER}): 0 entries, 0 B within 45.70 μs
INFO  [2023-01-26 18:08:06,756] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_FilterResolutionContainsTest_e02e2975-c593-4fb2-a2c3-362f866848e4:BUCKETS}): 0 entries, 0 B within 62.12 μs
INFO  [2023-01-26 18:08:06,756] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_FilterResolutionContainsTest_e02e2975-c593-4fb2-a2c3-362f866848e4:C_BLOCKS}): 0 entries, 0 B within 73.40 μs
INFO  [2023-01-26 18:08:06,758] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_FilterResolutionContainsTest_e5234829-1f47-40e7-94dd-17076edcd4f8:DATASET}): 0 entries, 0 B within 83.18 μs
INFO  [2023-01-26 18:08:06,758] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_FilterResolutionContainsTest_e5234829-1f47-40e7-94dd-17076edcd4f8:SECONDARY_IDS}): 0 entries, 0 B within 46.69 μs
INFO  [2023-01-26 18:08:06,758] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_FilterResolutionContainsTest_e5234829-1f47-40e7-94dd-17076edcd4f8:TABLES}): 0 entries, 0 B within 41.01 μs
INFO  [2023-01-26 18:08:06,758] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 42.96 μs
INFO  [2023-01-26 18:08:06,758] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_FilterResolutionContainsTest_e5234829-1f47-40e7-94dd-17076edcd4f8:IMPORTS}): 0 entries, 0 B within 45.76 μs
INFO  [2023-01-26 18:08:06,758] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_FilterResolutionContainsTest_e5234829-1f47-40e7-94dd-17076edcd4f8:CONCEPTS}): 0 entries, 0 B within 37.10 μs
INFO  [2023-01-26 18:08:06,758] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:06,758] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_FilterResolutionContainsTest_e5234829-1f47-40e7-94dd-17076edcd4f8:WORKER}): 0 entries, 0 B within 37.92 μs
INFO  [2023-01-26 18:08:06,758] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_FilterResolutionContainsTest_e5234829-1f47-40e7-94dd-17076edcd4f8:BUCKETS}): 0 entries, 0 B within 36.63 μs
INFO  [2023-01-26 18:08:06,758] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_FilterResolutionContainsTest_e5234829-1f47-40e7-94dd-17076edcd4f8:C_BLOCKS}): 0 entries, 0 B within 37.30 μs
INFO  [2023-01-26 18:08:06,760] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker FilterResolutionContainsTest.worker_FilterResolutionContainsTest_e02e2975-c593-4fb2-a2c3-362f866848e4 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:06,760] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker FilterResolutionContainsTest.worker_FilterResolutionContainsTest_e02e2975-c593-4fb2-a2c3-362f866848e4 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:06,760] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:06,761] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker FilterResolutionContainsTest.worker_FilterResolutionContainsTest_e5234829-1f47-40e7-94dd-17076edcd4f8 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:06,761] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker FilterResolutionContainsTest.worker_FilterResolutionContainsTest_e5234829-1f47-40e7-94dd-17076edcd4f8 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:06,761] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:06,764] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:06,865] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:06,873] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:06,874] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table FilterResolutionContainsTest.table1
INFO  [2023-01-26 18:08:06,874] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table FilterResolutionContainsTest.table1
INFO  [2023-01-26 18:08:07,032] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:07,156] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:07,156] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:07,157] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 158 B in total
INFO  [2023-01-26 18:08:07,157] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_FilterResolutionContainsTest/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000185028sINFO  [2023-01-26 18:08:07,176] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=8, sum=8, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:08:07,176] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=8, nullLines=2), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:08:07,176] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=8, nullLines=0), subType=IntegerParser(super=Parser(lines=8, nullLines=0), minValue=13828, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@419c8581)
INFO  [2023-01-26 18:08:07,182] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_FilterResolutionContainsTest/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:07,182] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:07,182] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_FilterResolutionContainsTest/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:07,211] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into FilterResolutionContainsTest.table1
127.0.0.1 - - [26/Jan/2023:18:08:07 +0000] "POST /admin/datasets/FilterResolutionContainsTest/imports?file=%2Ftmp%2FconqueryIntegrationTest12910953884258704183%2Ftmp_FilterResolutionContainsTest%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 14
INFO  [2023-01-26 18:08:07,213] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:07,215] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:07,228] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:07,228] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:07,236] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[FilterResolutionContainsTest.table1.table1], containing 8 entries.
INFO  [2023-01-26 18:08:07,236] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[FilterResolutionContainsTest.table1.table1], containing 8 entries.
INFO  [2023-01-26 18:08:07,236] com.bakdata.conquery.models.jobs.ImportJob: Start sending 3 Buckets
INFO  [2023-01-26 18:08:07,239] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received FilterResolutionContainsTest.table1.table1.0
INFO  [2023-01-26 18:08:07,239] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received FilterResolutionContainsTest.table1.table1.1
WARN  [2023-01-26 18:08:07,240] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:07,240] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received FilterResolutionContainsTest.table1.table1.2
INFO  [2023-01-26 18:08:07,346] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:07,351] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:07,375] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:07,384] com.bakdata.conquery.apiv1.FilterSearch: Processing reference list '/tmp/conquery_search2696094778972345143.csv' ...
INFO  [2023-01-26 18:08:07,408] com.bakdata.conquery.apiv1.FilterSearch: Processed reference list '/tmp/conquery_search2696094778972345143.csv' in 24 ms (5 Items in 6 Lines)
INFO  [2023-01-26 18:08:07,413] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast FilterResolutionContainsTest
INFO  [2023-01-26 18:08:07,414] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=FilterResolutionContainsTest, name=FilterResolutionContainsTest]
INFO  [2023-01-26 18:08:07,414] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=FilterResolutionContainsTest, name=FilterResolutionContainsTest]
INFO  [2023-01-26 18:08:07,414] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_FilterResolutionContainsTest_e5234829-1f47-40e7-94dd-17076edcd4f8
INFO  [2023-01-26 18:08:07,414] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_FilterResolutionContainsTest_e02e2975-c593-4fb2-a2c3-362f866848e4
INFO  [2023-01-26 18:08:07,426] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow FilterResolutionContainsTest
INFO  [2023-01-26 18:08:07,440] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of FilterResolutionContainsTest
INFO  [2023-01-26 18:08:07,441] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_FilterResolutionContainsTest
INFO  [2023-01-26 18:08:07,454] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:07,457] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_FilterResolutionContainsTest_e02e2975-c593-4fb2-a2c3-362f866848e4
INFO  [2023-01-26 18:08:07,459] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_FilterResolutionContainsTest_e5234829-1f47-40e7-94dd-17076edcd4f8
INFO  [2023-01-26 18:08:07,556] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_FilterResolutionContainsTest_e5234829-1f47-40e7-94dd-17076edcd4f8
INFO  [2023-01-26 18:08:07,556] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_FilterResolutionContainsTest_e02e2975-c593-4fb2-a2c3-362f866848e4
INFO  [2023-01-26 18:08:07,673] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test FilterResolutionContainsTest
INFO  [2023-01-26 18:08:07,677] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test FilterResolutionExactTest
INFO  [2023-01-26 18:08:07,678] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:07,697] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_FilterResolutionExactTest
INFO  [2023-01-26 18:08:07,706] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_FilterResolutionExactTest:DATASET}): 0 entries, 0 B within 124.2 μs
INFO  [2023-01-26 18:08:07,706] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_FilterResolutionExactTest:SECONDARY_IDS}): 0 entries, 0 B within 65.18 μs
INFO  [2023-01-26 18:08:07,706] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_FilterResolutionExactTest:TABLES}): 0 entries, 0 B within 48.18 μs
INFO  [2023-01-26 18:08:07,706] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 57.65 μs
INFO  [2023-01-26 18:08:07,706] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_FilterResolutionExactTest:IMPORTS}): 0 entries, 0 B within 46.79 μs
INFO  [2023-01-26 18:08:07,707] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_FilterResolutionExactTest:CONCEPTS}): 0 entries, 0 B within 49.27 μs
INFO  [2023-01-26 18:08:07,707] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:07,707] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big ID_MAPPING(EntityIdMap): 0 entries, 0 B within 49.12 μs
INFO  [2023-01-26 18:08:07,707] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_FilterResolutionExactTest:STRUCTURE}): 0 entries, 0 B within 44.91 μs
INFO  [2023-01-26 18:08:07,707] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_FilterResolutionExactTest:WORKER_TO_BUCKETS}): 0 entries, 0 B within 54.32 μs
INFO  [2023-01-26 18:08:07,707] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_FilterResolutionExactTest:PRIMARY_DICTIONARY}): 0 entries, 0 B within 50.52 μs
INFO  [2023-01-26 18:08:07,713] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=FilterResolutionExactTest, name=FilterResolutionExactTest]
INFO  [2023-01-26 18:08:07,713] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=FilterResolutionExactTest, name=FilterResolutionExactTest]
INFO  [2023-01-26 18:08:07,732] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_FilterResolutionExactTest_c60ab8dd-213a-40d2-b9d3-9f7813f35945
INFO  [2023-01-26 18:08:07,732] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_FilterResolutionExactTest_d85a5fa4-123f-46c2-9027-5c6db143a18a
INFO  [2023-01-26 18:08:07,754] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_FilterResolutionExactTest_d85a5fa4-123f-46c2-9027-5c6db143a18a:DATASET}): 0 entries, 0 B within 184.5 μs
INFO  [2023-01-26 18:08:07,755] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_FilterResolutionExactTest_d85a5fa4-123f-46c2-9027-5c6db143a18a:SECONDARY_IDS}): 0 entries, 0 B within 92.81 μs
INFO  [2023-01-26 18:08:07,755] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_FilterResolutionExactTest_d85a5fa4-123f-46c2-9027-5c6db143a18a:TABLES}): 0 entries, 0 B within 70.02 μs
INFO  [2023-01-26 18:08:07,755] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 72.05 μs
INFO  [2023-01-26 18:08:07,755] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_FilterResolutionExactTest_d85a5fa4-123f-46c2-9027-5c6db143a18a:IMPORTS}): 0 entries, 0 B within 66.48 μs
INFO  [2023-01-26 18:08:07,755] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_FilterResolutionExactTest_d85a5fa4-123f-46c2-9027-5c6db143a18a:CONCEPTS}): 0 entries, 0 B within 75.23 μs
INFO  [2023-01-26 18:08:07,755] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:07,755] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_FilterResolutionExactTest_d85a5fa4-123f-46c2-9027-5c6db143a18a:WORKER}): 0 entries, 0 B within 67.91 μs
INFO  [2023-01-26 18:08:07,755] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_FilterResolutionExactTest_d85a5fa4-123f-46c2-9027-5c6db143a18a:BUCKETS}): 0 entries, 0 B within 66.25 μs
INFO  [2023-01-26 18:08:07,756] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_FilterResolutionExactTest_d85a5fa4-123f-46c2-9027-5c6db143a18a:C_BLOCKS}): 0 entries, 0 B within 82.40 μs
INFO  [2023-01-26 18:08:07,760] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker FilterResolutionExactTest.worker_FilterResolutionExactTest_d85a5fa4-123f-46c2-9027-5c6db143a18a are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:07,760] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker FilterResolutionExactTest.worker_FilterResolutionExactTest_d85a5fa4-123f-46c2-9027-5c6db143a18a are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:07,760] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:07,769] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_FilterResolutionExactTest_c60ab8dd-213a-40d2-b9d3-9f7813f35945:DATASET}): 0 entries, 0 B within 127.6 μs
INFO  [2023-01-26 18:08:07,769] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_FilterResolutionExactTest_c60ab8dd-213a-40d2-b9d3-9f7813f35945:SECONDARY_IDS}): 0 entries, 0 B within 62.26 μs
INFO  [2023-01-26 18:08:07,769] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_FilterResolutionExactTest_c60ab8dd-213a-40d2-b9d3-9f7813f35945:TABLES}): 0 entries, 0 B within 40.28 μs
INFO  [2023-01-26 18:08:07,769] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 50.33 μs
INFO  [2023-01-26 18:08:07,770] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_FilterResolutionExactTest_c60ab8dd-213a-40d2-b9d3-9f7813f35945:IMPORTS}): 0 entries, 0 B within 38.78 μs
INFO  [2023-01-26 18:08:07,770] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_FilterResolutionExactTest_c60ab8dd-213a-40d2-b9d3-9f7813f35945:CONCEPTS}): 0 entries, 0 B within 36.65 μs
INFO  [2023-01-26 18:08:07,770] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:07,770] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_FilterResolutionExactTest_c60ab8dd-213a-40d2-b9d3-9f7813f35945:WORKER}): 0 entries, 0 B within 43.05 μs
INFO  [2023-01-26 18:08:07,770] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_FilterResolutionExactTest_c60ab8dd-213a-40d2-b9d3-9f7813f35945:BUCKETS}): 0 entries, 0 B within 35.65 μs
INFO  [2023-01-26 18:08:07,770] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_FilterResolutionExactTest_c60ab8dd-213a-40d2-b9d3-9f7813f35945:C_BLOCKS}): 0 entries, 0 B within 49.52 μs
INFO  [2023-01-26 18:08:07,773] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker FilterResolutionExactTest.worker_FilterResolutionExactTest_c60ab8dd-213a-40d2-b9d3-9f7813f35945 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:07,773] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker FilterResolutionExactTest.worker_FilterResolutionExactTest_c60ab8dd-213a-40d2-b9d3-9f7813f35945 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:07,773] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:07,776] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:07,877] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:07,885] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:07,885] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table FilterResolutionExactTest.table1
INFO  [2023-01-26 18:08:07,885] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table FilterResolutionExactTest.table1
INFO  [2023-01-26 18:08:08,025] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:08,139] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:08,141] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:08,141] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 158 B in total
INFO  [2023-01-26 18:08:08,141] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_FilterResolutionExactTest/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.00021075sINFO  [2023-01-26 18:08:08,163] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=8, sum=8, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:08:08,163] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=8, nullLines=2), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:08:08,163] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=8, nullLines=0), subType=IntegerParser(super=Parser(lines=8, nullLines=0), minValue=13828, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@4c0b634f)
INFO  [2023-01-26 18:08:08,167] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_FilterResolutionExactTest/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:08,167] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:08,167] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_FilterResolutionExactTest/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:08,193] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into FilterResolutionExactTest.table1
127.0.0.1 - - [26/Jan/2023:18:08:08 +0000] "POST /admin/datasets/FilterResolutionExactTest/imports?file=%2Ftmp%2FconqueryIntegrationTest12910953884258704183%2Ftmp_FilterResolutionExactTest%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 14
INFO  [2023-01-26 18:08:08,197] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:08,198] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:08,206] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:08,206] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:08,213] com.bakdata.conquery.models.jobs.ImportJob: Start sending 3 Buckets
INFO  [2023-01-26 18:08:08,214] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[FilterResolutionExactTest.table1.table1], containing 8 entries.
INFO  [2023-01-26 18:08:08,214] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[FilterResolutionExactTest.table1.table1], containing 8 entries.
WARN  [2023-01-26 18:08:08,215] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:08,216] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received FilterResolutionExactTest.table1.table1.1
INFO  [2023-01-26 18:08:08,216] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received FilterResolutionExactTest.table1.table1.0
INFO  [2023-01-26 18:08:08,218] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received FilterResolutionExactTest.table1.table1.2
INFO  [2023-01-26 18:08:08,324] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:08,329] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:08,342] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:08,348] com.bakdata.conquery.apiv1.FilterSearch: Processing reference list '/tmp/conquery_search9159298305187706179csv' ...
INFO  [2023-01-26 18:08:08,372] com.bakdata.conquery.apiv1.FilterSearch: Processed reference list '/tmp/conquery_search9159298305187706179csv' in 24 ms (4 Items in 5 Lines)
INFO  [2023-01-26 18:08:08,374] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast FilterResolutionExactTest
INFO  [2023-01-26 18:08:08,376] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=FilterResolutionExactTest, name=FilterResolutionExactTest]
INFO  [2023-01-26 18:08:08,376] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=FilterResolutionExactTest, name=FilterResolutionExactTest]
INFO  [2023-01-26 18:08:08,376] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_FilterResolutionExactTest_d85a5fa4-123f-46c2-9027-5c6db143a18a
INFO  [2023-01-26 18:08:08,376] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_FilterResolutionExactTest_c60ab8dd-213a-40d2-b9d3-9f7813f35945
INFO  [2023-01-26 18:08:08,410] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_FilterResolutionExactTest_c60ab8dd-213a-40d2-b9d3-9f7813f35945
INFO  [2023-01-26 18:08:08,413] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow FilterResolutionExactTest
INFO  [2023-01-26 18:08:08,416] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of FilterResolutionExactTest
INFO  [2023-01-26 18:08:08,417] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_FilterResolutionExactTest
INFO  [2023-01-26 18:08:08,423] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_FilterResolutionExactTest_c60ab8dd-213a-40d2-b9d3-9f7813f35945
INFO  [2023-01-26 18:08:08,424] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:08,457] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_FilterResolutionExactTest_d85a5fa4-123f-46c2-9027-5c6db143a18a
INFO  [2023-01-26 18:08:08,562] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_FilterResolutionExactTest_d85a5fa4-123f-46c2-9027-5c6db143a18a
INFO  [2023-01-26 18:08:08,675] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test FilterResolutionExactTest
INFO  [2023-01-26 18:08:08,679] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test FilterResolutionPrefixTest
INFO  [2023-01-26 18:08:08,680] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:08,698] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_FilterResolutionPrefixTest
INFO  [2023-01-26 18:08:08,711] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_FilterResolutionPrefixTest:DATASET}): 0 entries, 0 B within 208.9 μs
INFO  [2023-01-26 18:08:08,712] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_FilterResolutionPrefixTest:SECONDARY_IDS}): 0 entries, 0 B within 95.27 μs
INFO  [2023-01-26 18:08:08,712] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_FilterResolutionPrefixTest:TABLES}): 0 entries, 0 B within 72.94 μs
INFO  [2023-01-26 18:08:08,712] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 74.68 μs
INFO  [2023-01-26 18:08:08,712] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_FilterResolutionPrefixTest:IMPORTS}): 0 entries, 0 B within 69.07 μs
INFO  [2023-01-26 18:08:08,712] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_FilterResolutionPrefixTest:CONCEPTS}): 0 entries, 0 B within 68.88 μs
INFO  [2023-01-26 18:08:08,712] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:08,712] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big ID_MAPPING(EntityIdMap): 0 entries, 0 B within 68.91 μs
INFO  [2023-01-26 18:08:08,712] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_FilterResolutionPrefixTest:STRUCTURE}): 0 entries, 0 B within 73.14 μs
INFO  [2023-01-26 18:08:08,713] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_FilterResolutionPrefixTest:WORKER_TO_BUCKETS}): 0 entries, 0 B within 74.80 μs
INFO  [2023-01-26 18:08:08,713] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_FilterResolutionPrefixTest:PRIMARY_DICTIONARY}): 0 entries, 0 B within 81.43 μs
INFO  [2023-01-26 18:08:08,724] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=FilterResolutionPrefixTest, name=FilterResolutionPrefixTest]
INFO  [2023-01-26 18:08:08,724] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=FilterResolutionPrefixTest, name=FilterResolutionPrefixTest]
INFO  [2023-01-26 18:08:08,752] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_FilterResolutionPrefixTest_56164ad6-8be2-4d01-957d-a1887d8d7d3c
INFO  [2023-01-26 18:08:08,757] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_FilterResolutionPrefixTest_b3d7261e-0dce-44a0-afb1-2ca4c612500d
INFO  [2023-01-26 18:08:08,778] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_FilterResolutionPrefixTest_b3d7261e-0dce-44a0-afb1-2ca4c612500d:DATASET}): 0 entries, 0 B within 128.6 μs
INFO  [2023-01-26 18:08:08,778] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_FilterResolutionPrefixTest_b3d7261e-0dce-44a0-afb1-2ca4c612500d:SECONDARY_IDS}): 0 entries, 0 B within 67.84 μs
INFO  [2023-01-26 18:08:08,778] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_FilterResolutionPrefixTest_b3d7261e-0dce-44a0-afb1-2ca4c612500d:TABLES}): 0 entries, 0 B within 52.69 μs
INFO  [2023-01-26 18:08:08,779] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 53.57 μs
INFO  [2023-01-26 18:08:08,779] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_FilterResolutionPrefixTest_b3d7261e-0dce-44a0-afb1-2ca4c612500d:IMPORTS}): 0 entries, 0 B within 63.99 μs
INFO  [2023-01-26 18:08:08,779] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_FilterResolutionPrefixTest_b3d7261e-0dce-44a0-afb1-2ca4c612500d:CONCEPTS}): 0 entries, 0 B within 50.60 μs
INFO  [2023-01-26 18:08:08,779] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:08,779] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_FilterResolutionPrefixTest_b3d7261e-0dce-44a0-afb1-2ca4c612500d:WORKER}): 0 entries, 0 B within 50.95 μs
INFO  [2023-01-26 18:08:08,779] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_FilterResolutionPrefixTest_b3d7261e-0dce-44a0-afb1-2ca4c612500d:BUCKETS}): 0 entries, 0 B within 52.32 μs
INFO  [2023-01-26 18:08:08,779] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_FilterResolutionPrefixTest_b3d7261e-0dce-44a0-afb1-2ca4c612500d:C_BLOCKS}): 0 entries, 0 B within 76.66 μs
INFO  [2023-01-26 18:08:08,779] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_FilterResolutionPrefixTest_56164ad6-8be2-4d01-957d-a1887d8d7d3c:DATASET}): 0 entries, 0 B within 91.26 μs
INFO  [2023-01-26 18:08:08,779] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_FilterResolutionPrefixTest_56164ad6-8be2-4d01-957d-a1887d8d7d3c:SECONDARY_IDS}): 0 entries, 0 B within 58.13 μs
INFO  [2023-01-26 18:08:08,780] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_FilterResolutionPrefixTest_56164ad6-8be2-4d01-957d-a1887d8d7d3c:TABLES}): 0 entries, 0 B within 94.82 μs
INFO  [2023-01-26 18:08:08,780] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 68.36 μs
INFO  [2023-01-26 18:08:08,780] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_FilterResolutionPrefixTest_56164ad6-8be2-4d01-957d-a1887d8d7d3c:IMPORTS}): 0 entries, 0 B within 62.36 μs
INFO  [2023-01-26 18:08:08,780] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_FilterResolutionPrefixTest_56164ad6-8be2-4d01-957d-a1887d8d7d3c:CONCEPTS}): 0 entries, 0 B within 43.68 μs
INFO  [2023-01-26 18:08:08,780] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:08,780] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_FilterResolutionPrefixTest_56164ad6-8be2-4d01-957d-a1887d8d7d3c:WORKER}): 0 entries, 0 B within 35.34 μs
INFO  [2023-01-26 18:08:08,780] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_FilterResolutionPrefixTest_56164ad6-8be2-4d01-957d-a1887d8d7d3c:BUCKETS}): 0 entries, 0 B within 49.77 μs
INFO  [2023-01-26 18:08:08,780] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_FilterResolutionPrefixTest_56164ad6-8be2-4d01-957d-a1887d8d7d3c:C_BLOCKS}): 0 entries, 0 B within 36.60 μs
INFO  [2023-01-26 18:08:08,792] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker FilterResolutionPrefixTest.worker_FilterResolutionPrefixTest_b3d7261e-0dce-44a0-afb1-2ca4c612500d are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:08,792] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker FilterResolutionPrefixTest.worker_FilterResolutionPrefixTest_b3d7261e-0dce-44a0-afb1-2ca4c612500d are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:08,792] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:08,795] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker FilterResolutionPrefixTest.worker_FilterResolutionPrefixTest_56164ad6-8be2-4d01-957d-a1887d8d7d3c are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:08,795] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker FilterResolutionPrefixTest.worker_FilterResolutionPrefixTest_56164ad6-8be2-4d01-957d-a1887d8d7d3c are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:08,795] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:08,797] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:08,900] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:08,908] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:08,908] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table FilterResolutionPrefixTest.table1
INFO  [2023-01-26 18:08:08,908] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table FilterResolutionPrefixTest.table1
INFO  [2023-01-26 18:08:09,034] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:09,149] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:09,150] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:09,150] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 158 B in total
INFO  [2023-01-26 18:08:09,150] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_FilterResolutionPrefixTest/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000189515sINFO  [2023-01-26 18:08:09,170] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=8, sum=8, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:08:09,170] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=8, nullLines=2), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:08:09,170] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=8, nullLines=0), subType=IntegerParser(super=Parser(lines=8, nullLines=0), minValue=13828, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@27d57f0a)
INFO  [2023-01-26 18:08:09,174] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_FilterResolutionPrefixTest/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:09,175] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:09,175] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_FilterResolutionPrefixTest/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:09,199] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into FilterResolutionPrefixTest.table1
127.0.0.1 - - [26/Jan/2023:18:08:09 +0000] "POST /admin/datasets/FilterResolutionPrefixTest/imports?file=%2Ftmp%2FconqueryIntegrationTest12910953884258704183%2Ftmp_FilterResolutionPrefixTest%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 12
INFO  [2023-01-26 18:08:09,200] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:09,203] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:09,216] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:09,216] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:09,221] com.bakdata.conquery.models.jobs.ImportJob: Start sending 3 Buckets
WARN  [2023-01-26 18:08:09,223] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:09,225] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[FilterResolutionPrefixTest.table1.table1], containing 8 entries.
INFO  [2023-01-26 18:08:09,226] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[FilterResolutionPrefixTest.table1.table1], containing 8 entries.
INFO  [2023-01-26 18:08:09,226] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received FilterResolutionPrefixTest.table1.table1.1
INFO  [2023-01-26 18:08:09,229] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received FilterResolutionPrefixTest.table1.table1.0
INFO  [2023-01-26 18:08:09,231] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received FilterResolutionPrefixTest.table1.table1.2
INFO  [2023-01-26 18:08:09,337] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:09,342] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:09,355] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:09,361] com.bakdata.conquery.apiv1.FilterSearch: Processing reference list '/tmp/conquery_search10019355969671351839csv' ...
INFO  [2023-01-26 18:08:09,381] com.bakdata.conquery.apiv1.FilterSearch: Processed reference list '/tmp/conquery_search10019355969671351839csv' in 20 ms (4 Items in 5 Lines)
INFO  [2023-01-26 18:08:09,383] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast FilterResolutionPrefixTest
INFO  [2023-01-26 18:08:09,383] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=FilterResolutionPrefixTest, name=FilterResolutionPrefixTest]
INFO  [2023-01-26 18:08:09,383] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=FilterResolutionPrefixTest, name=FilterResolutionPrefixTest]
INFO  [2023-01-26 18:08:09,383] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_FilterResolutionPrefixTest_56164ad6-8be2-4d01-957d-a1887d8d7d3c
INFO  [2023-01-26 18:08:09,383] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_FilterResolutionPrefixTest_b3d7261e-0dce-44a0-afb1-2ca4c612500d
INFO  [2023-01-26 18:08:09,424] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow FilterResolutionPrefixTest
INFO  [2023-01-26 18:08:09,424] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_FilterResolutionPrefixTest_56164ad6-8be2-4d01-957d-a1887d8d7d3c
INFO  [2023-01-26 18:08:09,436] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_FilterResolutionPrefixTest_56164ad6-8be2-4d01-957d-a1887d8d7d3c
INFO  [2023-01-26 18:08:09,482] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_FilterResolutionPrefixTest_b3d7261e-0dce-44a0-afb1-2ca4c612500d
INFO  [2023-01-26 18:08:09,524] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of FilterResolutionPrefixTest
INFO  [2023-01-26 18:08:09,525] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_FilterResolutionPrefixTest
INFO  [2023-01-26 18:08:09,530] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_FilterResolutionPrefixTest_b3d7261e-0dce-44a0-afb1-2ca4c612500d
INFO  [2023-01-26 18:08:09,545] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:09,644] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test FilterResolutionPrefixTest
INFO  [2023-01-26 18:08:09,646] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test GroupHandlingTest
INFO  [2023-01-26 18:08:09,647] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:09,666] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_GroupHandlingTest
INFO  [2023-01-26 18:08:09,678] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_GroupHandlingTest:DATASET}): 0 entries, 0 B within 158.6 μs
INFO  [2023-01-26 18:08:09,678] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_GroupHandlingTest:SECONDARY_IDS}): 0 entries, 0 B within 89.16 μs
INFO  [2023-01-26 18:08:09,678] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_GroupHandlingTest:TABLES}): 0 entries, 0 B within 62.07 μs
INFO  [2023-01-26 18:08:09,678] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 62.72 μs
INFO  [2023-01-26 18:08:09,679] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_GroupHandlingTest:IMPORTS}): 0 entries, 0 B within 58.90 μs
INFO  [2023-01-26 18:08:09,679] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_GroupHandlingTest:CONCEPTS}): 0 entries, 0 B within 57.96 μs
INFO  [2023-01-26 18:08:09,679] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:09,679] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big ID_MAPPING(EntityIdMap): 0 entries, 0 B within 60.75 μs
INFO  [2023-01-26 18:08:09,679] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_GroupHandlingTest:STRUCTURE}): 0 entries, 0 B within 70.71 μs
INFO  [2023-01-26 18:08:09,679] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_GroupHandlingTest:WORKER_TO_BUCKETS}): 0 entries, 0 B within 60.09 μs
INFO  [2023-01-26 18:08:09,679] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_GroupHandlingTest:PRIMARY_DICTIONARY}): 0 entries, 0 B within 81.22 μs
INFO  [2023-01-26 18:08:09,687] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=GroupHandlingTest, name=GroupHandlingTest]
INFO  [2023-01-26 18:08:09,687] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=GroupHandlingTest, name=GroupHandlingTest]
INFO  [2023-01-26 18:08:09,717] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_GroupHandlingTest_35966581-354c-4215-b6b5-6806000ae031
INFO  [2023-01-26 18:08:09,722] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_GroupHandlingTest_2de851e9-7682-426e-898d-e03e167f2d6b
INFO  [2023-01-26 18:08:09,737] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_GroupHandlingTest_35966581-354c-4215-b6b5-6806000ae031:DATASET}): 0 entries, 0 B within 123.7 μs
INFO  [2023-01-26 18:08:09,737] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_GroupHandlingTest_35966581-354c-4215-b6b5-6806000ae031:SECONDARY_IDS}): 0 entries, 0 B within 57.14 μs
INFO  [2023-01-26 18:08:09,738] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_GroupHandlingTest_35966581-354c-4215-b6b5-6806000ae031:TABLES}): 0 entries, 0 B within 43.02 μs
INFO  [2023-01-26 18:08:09,738] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 51.67 μs
INFO  [2023-01-26 18:08:09,738] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_GroupHandlingTest_35966581-354c-4215-b6b5-6806000ae031:IMPORTS}): 0 entries, 0 B within 37.23 μs
INFO  [2023-01-26 18:08:09,738] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_GroupHandlingTest_35966581-354c-4215-b6b5-6806000ae031:CONCEPTS}): 0 entries, 0 B within 40.42 μs
INFO  [2023-01-26 18:08:09,738] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:09,738] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_GroupHandlingTest_35966581-354c-4215-b6b5-6806000ae031:WORKER}): 0 entries, 0 B within 37.75 μs
INFO  [2023-01-26 18:08:09,738] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_GroupHandlingTest_35966581-354c-4215-b6b5-6806000ae031:BUCKETS}): 0 entries, 0 B within 35.33 μs
INFO  [2023-01-26 18:08:09,738] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_GroupHandlingTest_35966581-354c-4215-b6b5-6806000ae031:C_BLOCKS}): 0 entries, 0 B within 35.78 μs
INFO  [2023-01-26 18:08:09,742] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker GroupHandlingTest.worker_GroupHandlingTest_35966581-354c-4215-b6b5-6806000ae031 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:09,742] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker GroupHandlingTest.worker_GroupHandlingTest_35966581-354c-4215-b6b5-6806000ae031 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:09,742] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:09,747] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_GroupHandlingTest_2de851e9-7682-426e-898d-e03e167f2d6b:DATASET}): 0 entries, 0 B within 184.9 μs
INFO  [2023-01-26 18:08:09,747] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_GroupHandlingTest_2de851e9-7682-426e-898d-e03e167f2d6b:SECONDARY_IDS}): 0 entries, 0 B within 79.96 μs
INFO  [2023-01-26 18:08:09,747] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_GroupHandlingTest_2de851e9-7682-426e-898d-e03e167f2d6b:TABLES}): 0 entries, 0 B within 58.32 μs
INFO  [2023-01-26 18:08:09,747] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 57.59 μs
INFO  [2023-01-26 18:08:09,747] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_GroupHandlingTest_2de851e9-7682-426e-898d-e03e167f2d6b:IMPORTS}): 0 entries, 0 B within 50.97 μs
INFO  [2023-01-26 18:08:09,748] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_GroupHandlingTest_2de851e9-7682-426e-898d-e03e167f2d6b:CONCEPTS}): 0 entries, 0 B within 53.41 μs
INFO  [2023-01-26 18:08:09,748] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:09,748] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_GroupHandlingTest_2de851e9-7682-426e-898d-e03e167f2d6b:WORKER}): 0 entries, 0 B within 59.47 μs
INFO  [2023-01-26 18:08:09,748] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_GroupHandlingTest_2de851e9-7682-426e-898d-e03e167f2d6b:BUCKETS}): 0 entries, 0 B within 56.48 μs
INFO  [2023-01-26 18:08:09,748] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_GroupHandlingTest_2de851e9-7682-426e-898d-e03e167f2d6b:C_BLOCKS}): 0 entries, 0 B within 54.17 μs
INFO  [2023-01-26 18:08:09,751] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker GroupHandlingTest.worker_GroupHandlingTest_2de851e9-7682-426e-898d-e03e167f2d6b are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:09,751] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker GroupHandlingTest.worker_GroupHandlingTest_2de851e9-7682-426e-898d-e03e167f2d6b are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:09,751] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:09,752] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:09,862] com.bakdata.conquery.io.storage.MetaStorage: Remove User = user.user
INFO  [2023-01-26 18:08:09,862] com.bakdata.conquery.io.storage.MetaStorage: Remove User = user.user2
INFO  [2023-01-26 18:08:09,863] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast GroupHandlingTest
INFO  [2023-01-26 18:08:09,863] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=GroupHandlingTest, name=GroupHandlingTest]
INFO  [2023-01-26 18:08:09,863] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_GroupHandlingTest_2de851e9-7682-426e-898d-e03e167f2d6b
INFO  [2023-01-26 18:08:09,864] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=GroupHandlingTest, name=GroupHandlingTest]
INFO  [2023-01-26 18:08:09,864] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_GroupHandlingTest_35966581-354c-4215-b6b5-6806000ae031
INFO  [2023-01-26 18:08:09,887] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow GroupHandlingTest
INFO  [2023-01-26 18:08:09,939] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_GroupHandlingTest_35966581-354c-4215-b6b5-6806000ae031
INFO  [2023-01-26 18:08:09,949] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_GroupHandlingTest_2de851e9-7682-426e-898d-e03e167f2d6b
INFO  [2023-01-26 18:08:09,986] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of GroupHandlingTest
INFO  [2023-01-26 18:08:09,987] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_GroupHandlingTest
INFO  [2023-01-26 18:08:09,994] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:10,040] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_GroupHandlingTest_35966581-354c-4215-b6b5-6806000ae031
INFO  [2023-01-26 18:08:10,049] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_GroupHandlingTest_2de851e9-7682-426e-898d-e03e167f2d6b
INFO  [2023-01-26 18:08:10,162] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test GroupHandlingTest
INFO  [2023-01-26 18:08:10,164] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test ImportUpdateTest
INFO  [2023-01-26 18:08:10,165] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:10,185] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportUpdateTest
INFO  [2023-01-26 18:08:10,198] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportUpdateTest:DATASET}): 0 entries, 0 B within 122.4 μs
INFO  [2023-01-26 18:08:10,198] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportUpdateTest:SECONDARY_IDS}): 0 entries, 0 B within 90.36 μs
INFO  [2023-01-26 18:08:10,198] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportUpdateTest:TABLES}): 0 entries, 0 B within 69.36 μs
INFO  [2023-01-26 18:08:10,198] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 59.96 μs
INFO  [2023-01-26 18:08:10,198] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportUpdateTest:IMPORTS}): 0 entries, 0 B within 62.17 μs
INFO  [2023-01-26 18:08:10,199] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportUpdateTest:CONCEPTS}): 0 entries, 0 B within 59.44 μs
INFO  [2023-01-26 18:08:10,199] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:10,199] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big ID_MAPPING(EntityIdMap): 0 entries, 0 B within 65.01 μs
INFO  [2023-01-26 18:08:10,199] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportUpdateTest:STRUCTURE}): 0 entries, 0 B within 49.27 μs
INFO  [2023-01-26 18:08:10,199] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportUpdateTest:WORKER_TO_BUCKETS}): 0 entries, 0 B within 69.23 μs
INFO  [2023-01-26 18:08:10,199] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportUpdateTest:PRIMARY_DICTIONARY}): 0 entries, 0 B within 122.7 μs
INFO  [2023-01-26 18:08:10,206] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=ImportUpdateTest, name=ImportUpdateTest]
INFO  [2023-01-26 18:08:10,206] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=ImportUpdateTest, name=ImportUpdateTest]
INFO  [2023-01-26 18:08:10,225] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportUpdateTest_ce6e9144-3730-47d8-9deb-3aaaf51d9afc
INFO  [2023-01-26 18:08:10,225] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportUpdateTest_0b33edb8-623f-476c-8017-2515a12e9409
INFO  [2023-01-26 18:08:10,253] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportUpdateTest_0b33edb8-623f-476c-8017-2515a12e9409:DATASET}): 0 entries, 0 B within 232.3 μs
INFO  [2023-01-26 18:08:10,253] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportUpdateTest_0b33edb8-623f-476c-8017-2515a12e9409:SECONDARY_IDS}): 0 entries, 0 B within 79.95 μs
INFO  [2023-01-26 18:08:10,253] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportUpdateTest_0b33edb8-623f-476c-8017-2515a12e9409:TABLES}): 0 entries, 0 B within 32.40 μs
INFO  [2023-01-26 18:08:10,253] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 29.45 μs
INFO  [2023-01-26 18:08:10,253] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportUpdateTest_0b33edb8-623f-476c-8017-2515a12e9409:IMPORTS}): 0 entries, 0 B within 25.35 μs
INFO  [2023-01-26 18:08:10,253] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportUpdateTest_0b33edb8-623f-476c-8017-2515a12e9409:CONCEPTS}): 0 entries, 0 B within 56.16 μs
INFO  [2023-01-26 18:08:10,253] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:10,253] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportUpdateTest_0b33edb8-623f-476c-8017-2515a12e9409:WORKER}): 0 entries, 0 B within 82.60 μs
INFO  [2023-01-26 18:08:10,254] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportUpdateTest_0b33edb8-623f-476c-8017-2515a12e9409:BUCKETS}): 0 entries, 0 B within 37.09 μs
INFO  [2023-01-26 18:08:10,254] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportUpdateTest_0b33edb8-623f-476c-8017-2515a12e9409:C_BLOCKS}): 0 entries, 0 B within 27.04 μs
INFO  [2023-01-26 18:08:10,256] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportUpdateTest_ce6e9144-3730-47d8-9deb-3aaaf51d9afc:DATASET}): 0 entries, 0 B within 94.65 μs
INFO  [2023-01-26 18:08:10,256] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportUpdateTest_ce6e9144-3730-47d8-9deb-3aaaf51d9afc:SECONDARY_IDS}): 0 entries, 0 B within 78.45 μs
INFO  [2023-01-26 18:08:10,256] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportUpdateTest_ce6e9144-3730-47d8-9deb-3aaaf51d9afc:TABLES}): 0 entries, 0 B within 70.29 μs
INFO  [2023-01-26 18:08:10,257] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker ImportUpdateTest.worker_ImportUpdateTest_0b33edb8-623f-476c-8017-2515a12e9409 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:10,257] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker ImportUpdateTest.worker_ImportUpdateTest_0b33edb8-623f-476c-8017-2515a12e9409 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:10,257] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:10,257] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 95.55 μs
INFO  [2023-01-26 18:08:10,257] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportUpdateTest_ce6e9144-3730-47d8-9deb-3aaaf51d9afc:IMPORTS}): 0 entries, 0 B within 53.42 μs
INFO  [2023-01-26 18:08:10,257] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportUpdateTest_ce6e9144-3730-47d8-9deb-3aaaf51d9afc:CONCEPTS}): 0 entries, 0 B within 35.34 μs
INFO  [2023-01-26 18:08:10,257] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:10,258] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportUpdateTest_ce6e9144-3730-47d8-9deb-3aaaf51d9afc:WORKER}): 0 entries, 0 B within 30.58 μs
INFO  [2023-01-26 18:08:10,258] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportUpdateTest_ce6e9144-3730-47d8-9deb-3aaaf51d9afc:BUCKETS}): 0 entries, 0 B within 26.68 μs
INFO  [2023-01-26 18:08:10,258] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportUpdateTest_ce6e9144-3730-47d8-9deb-3aaaf51d9afc:C_BLOCKS}): 0 entries, 0 B within 27.23 μs
INFO  [2023-01-26 18:08:10,261] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker ImportUpdateTest.worker_ImportUpdateTest_ce6e9144-3730-47d8-9deb-3aaaf51d9afc are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:10,261] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker ImportUpdateTest.worker_ImportUpdateTest_ce6e9144-3730-47d8-9deb-3aaaf51d9afc are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:10,261] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:10,263] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:10,366] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:10,377] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ImportUpdateTest.table1
INFO  [2023-01-26 18:08:10,377] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ImportUpdateTest.table1
INFO  [2023-01-26 18:08:10,377] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:10,378] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ImportUpdateTest.table2
INFO  [2023-01-26 18:08:10,378] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ImportUpdateTest.table2
INFO  [2023-01-26 18:08:10,498] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:10,610] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:10,610] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:10,610] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:10,610] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 151 B in total
INFO  [2023-01-26 18:08:10,611] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ImportUpdateTest/table1.import.json, tag=Optional.empty)
███████████████████████████████                   ▌  62%	est. time remaining: 0.045185206sINFO  [2023-01-26 18:08:10,684] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=4, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:08:10,684] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=4, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:08:10,684] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=4, nullLines=0), subType=IntegerParser(super=Parser(lines=4, nullLines=0), minValue=15655, maxValue=16021), dateReader=com.bakdata.conquery.util.DateReader@7b49e40e)
INFO  [2023-01-26 18:08:10,688] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ImportUpdateTest/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:10,688] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ImportUpdateTest/table2.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000958216sINFO  [2023-01-26 18:08:10,707] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=2, sum=2, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:08:10,708] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=2, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:08:10,708] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=2, nullLines=0), subType=IntegerParser(super=Parser(lines=2, nullLines=0), minValue=14805, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@5edcc66b)
INFO  [2023-01-26 18:08:10,711] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ImportUpdateTest/table2.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:10,711] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 2 Jobs:
INFO  [2023-01-26 18:08:10,711] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ImportUpdateTest/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:10,711] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ImportUpdateTest/table2.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:10,711] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:10,734] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into ImportUpdateTest.table1
127.0.0.1 - - [26/Jan/2023:18:08:10 +0000] "POST /admin/datasets/ImportUpdateTest/imports?file=%2Ftmp%2FconqueryIntegrationTest12910953884258704183%2Ftmp_ImportUpdateTest%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:08:10,734] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:10,737] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:10,753] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:10,753] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:10,759] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:08:10,761] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ImportUpdateTest.table1.table1], containing 4 entries.
WARN  [2023-01-26 18:08:10,762] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:10,763] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ImportUpdateTest.table1.table1.0
INFO  [2023-01-26 18:08:10,766] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ImportUpdateTest.table1.table1], containing 4 entries.
INFO  [2023-01-26 18:08:10,769] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ImportUpdateTest.table1.table1.1
INFO  [2023-01-26 18:08:10,885] com.bakdata.conquery.integration.tests.ImportUpdateTest: Checking state before update
INFO  [2023-01-26 18:08:10,907] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[ImportUpdateTest] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:08:10,915] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[8ded335d-3b9e-4581-9e02-3b7e120cd608] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_ImportUpdateTest))]]
INFO  [2023-01-26 18:08:10,918] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery ImportUpdateTest.8ded335d-3b9e-4581-9e02-3b7e120cd608
INFO  [2023-01-26 18:08:10,918] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery ImportUpdateTest.8ded335d-3b9e-4581-9e02-3b7e120cd608
INFO  [2023-01-26 18:08:10,919] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[ImportUpdateTest.8ded335d-3b9e-4581-9e02-3b7e120cd608] with 0 results within PT0.000773S
INFO  [2023-01-26 18:08:10,920] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[ImportUpdateTest.8ded335d-3b9e-4581-9e02-3b7e120cd608] with 2 results within PT0.001474S
INFO  [2023-01-26 18:08:10,920] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=ImportUpdateTest.8ded335d-3b9e-4581-9e02-3b7e120cd608, workerId=ImportUpdateTest.worker_ImportUpdateTest_ce6e9144-3730-47d8-9deb-3aaaf51d9afc, startTime=2023-01-26T18:08:10.918877, finishTime=2023-01-26T18:08:10.919650) of size 0
127.0.0.1 - - [26/Jan/2023:18:08:10 +0000] "POST /api/datasets/ImportUpdateTest/queries HTTP/1.1" 201 1166 "-" "Conquery (test client)" 16
INFO  [2023-01-26 18:08:10,922] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=ImportUpdateTest.8ded335d-3b9e-4581-9e02-3b7e120cd608, workerId=ImportUpdateTest.worker_ImportUpdateTest_0b33edb8-623f-476c-8017-2515a12e9409, startTime=2023-01-26T18:08:10.918727, finishTime=2023-01-26T18:08:10.920201) of size 2
INFO  [2023-01-26 18:08:10,923] com.bakdata.conquery.models.execution.ManagedExecution: DONE 8ded335d-3b9e-4581-9e02-3b7e120cd608 ManagedQuery within PT0.007164S
127.0.0.1 - - [26/Jan/2023:18:08:10 +0000] "GET /api/datasets/ImportUpdateTest/queries/ImportUpdateTest.8ded335d-3b9e-4581-9e02-3b7e120cd608 HTTP/1.1" 200 1421 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:08:10,966] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:08:10 +0000] "PUT /admin/datasets/ImportUpdateTest/imports?file=%2Ftmp%2FconqueryIntegrationTest12910953884258704183%2Ftmp_ImportUpdateTest%2Ftable2.cqpp HTTP/1.1" 404 79 "-" "Conquery (test client)" 12
INFO  [2023-01-26 18:08:11,028] com.bakdata.conquery.integration.tests.ImportUpdateTest: Manually loading new data for import
INFO  [2023-01-26 18:08:11,029] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:11,030] com.bakdata.conquery.commands.PreprocessorCommand: EXISTS ALREADY
INFO  [2023-01-26 18:08:11,030] com.bakdata.conquery.commands.PreprocessorCommand: 	HASH OUTDATED
INFO  [2023-01-26 18:08:11,031] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 124 B in total
INFO  [2023-01-26 18:08:11,031] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ImportUpdateTest/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000216255sINFO  [2023-01-26 18:08:11,053] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=5, sum=5, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:08:11,053] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=5, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:08:11,053] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=5, nullLines=0), subType=IntegerParser(super=Parser(lines=5, nullLines=0), minValue=14805, maxValue=15929), dateReader=com.bakdata.conquery.util.DateReader@49dad7e4)
INFO  [2023-01-26 18:08:11,057] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ImportUpdateTest/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:11,057] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:11,057] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ImportUpdateTest/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:11,057] com.bakdata.conquery.integration.tests.ImportUpdateTest: updating import
INFO  [2023-01-26 18:08:11,073] com.bakdata.conquery.models.messages.namespaces.specific.RemoveImportJob: Deleting Import[NamedImpl(name=table1)]
INFO  [2023-01-26 18:08:11,075] com.bakdata.conquery.models.messages.namespaces.specific.RemoveImportJob: Deleting Import[NamedImpl(name=table1)]
INFO  [2023-01-26 18:08:11,079] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into ImportUpdateTest.table1
127.0.0.1 - - [26/Jan/2023:18:08:11 +0000] "PUT /admin/datasets/ImportUpdateTest/imports?file=%2Ftmp%2FconqueryIntegrationTest12910953884258704183%2Ftmp_ImportUpdateTest%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 14
INFO  [2023-01-26 18:08:11,080] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:11,080] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:11,090] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:11,090] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:11,141] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:08:11,146] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ImportUpdateTest.table1.table1], containing 5 entries.
INFO  [2023-01-26 18:08:11,146] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ImportUpdateTest.table1.table1], containing 5 entries.
WARN  [2023-01-26 18:08:11,151] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:11,151] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ImportUpdateTest.table1.table1.2
INFO  [2023-01-26 18:08:11,151] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ImportUpdateTest.table1.table1.1
INFO  [2023-01-26 18:08:11,257] com.bakdata.conquery.integration.tests.ImportUpdateTest: Checking state after update
INFO  [2023-01-26 18:08:11,279] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[ImportUpdateTest] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:08:11,281] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[54a1b89c-6f77-4c67-ab1d-4139d43973a8] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_ImportUpdateTest))]]
INFO  [2023-01-26 18:08:11,283] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery ImportUpdateTest.54a1b89c-6f77-4c67-ab1d-4139d43973a8
INFO  [2023-01-26 18:08:11,283] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery ImportUpdateTest.54a1b89c-6f77-4c67-ab1d-4139d43973a8
INFO  [2023-01-26 18:08:11,285] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[ImportUpdateTest.54a1b89c-6f77-4c67-ab1d-4139d43973a8] with 2 results within PT0.002172S
INFO  [2023-01-26 18:08:11,286] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[ImportUpdateTest.54a1b89c-6f77-4c67-ab1d-4139d43973a8] with 2 results within PT0.003003S
INFO  [2023-01-26 18:08:11,287] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=ImportUpdateTest.54a1b89c-6f77-4c67-ab1d-4139d43973a8, workerId=ImportUpdateTest.worker_ImportUpdateTest_ce6e9144-3730-47d8-9deb-3aaaf51d9afc, startTime=2023-01-26T18:08:11.283679, finishTime=2023-01-26T18:08:11.285851) of size 2
INFO  [2023-01-26 18:08:11,288] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=ImportUpdateTest.54a1b89c-6f77-4c67-ab1d-4139d43973a8, workerId=ImportUpdateTest.worker_ImportUpdateTest_0b33edb8-623f-476c-8017-2515a12e9409, startTime=2023-01-26T18:08:11.283679, finishTime=2023-01-26T18:08:11.286682) of size 2
INFO  [2023-01-26 18:08:11,289] com.bakdata.conquery.models.execution.ManagedExecution: DONE 54a1b89c-6f77-4c67-ab1d-4139d43973a8 ManagedQuery within PT0.007223S
127.0.0.1 - - [26/Jan/2023:18:08:11 +0000] "POST /api/datasets/ImportUpdateTest/queries HTTP/1.1" 201 1166 "-" "Conquery (test client)" 13
127.0.0.1 - - [26/Jan/2023:18:08:11 +0000] "GET /api/datasets/ImportUpdateTest/queries/ImportUpdateTest.54a1b89c-6f77-4c67-ab1d-4139d43973a8 HTTP/1.1" 200 1421 "-" "Conquery (test client)" 5
INFO  [2023-01-26 18:08:11,306] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast ImportUpdateTest
INFO  [2023-01-26 18:08:11,307] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=ImportUpdateTest, name=ImportUpdateTest]
INFO  [2023-01-26 18:08:11,307] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=ImportUpdateTest, name=ImportUpdateTest]
INFO  [2023-01-26 18:08:11,307] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_ImportUpdateTest_ce6e9144-3730-47d8-9deb-3aaaf51d9afc
INFO  [2023-01-26 18:08:11,307] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_ImportUpdateTest_0b33edb8-623f-476c-8017-2515a12e9409
INFO  [2023-01-26 18:08:11,329] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow ImportUpdateTest
INFO  [2023-01-26 18:08:11,351] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of ImportUpdateTest
INFO  [2023-01-26 18:08:11,353] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportUpdateTest
INFO  [2023-01-26 18:08:11,362] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:11,375] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_ImportUpdateTest_ce6e9144-3730-47d8-9deb-3aaaf51d9afc
INFO  [2023-01-26 18:08:11,375] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_ImportUpdateTest_0b33edb8-623f-476c-8017-2515a12e9409
INFO  [2023-01-26 18:08:11,456] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportUpdateTest_0b33edb8-623f-476c-8017-2515a12e9409
INFO  [2023-01-26 18:08:11,456] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportUpdateTest_ce6e9144-3730-47d8-9deb-3aaaf51d9afc
INFO  [2023-01-26 18:08:11,569] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test ImportUpdateTest
INFO  [2023-01-26 18:08:11,573] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test MetadataCollectionTest
INFO  [2023-01-26 18:08:11,573] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:11,592] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_MetadataCollectionTest
INFO  [2023-01-26 18:08:11,613] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_MetadataCollectionTest:DATASET}): 0 entries, 0 B within 249.8 μs
INFO  [2023-01-26 18:08:11,613] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_MetadataCollectionTest:SECONDARY_IDS}): 0 entries, 0 B within 89.93 μs
INFO  [2023-01-26 18:08:11,613] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_MetadataCollectionTest:TABLES}): 0 entries, 0 B within 90.38 μs
INFO  [2023-01-26 18:08:11,613] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 86.81 μs
INFO  [2023-01-26 18:08:11,614] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_MetadataCollectionTest:IMPORTS}): 0 entries, 0 B within 96.12 μs
INFO  [2023-01-26 18:08:11,614] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_MetadataCollectionTest:CONCEPTS}): 0 entries, 0 B within 105.8 μs
INFO  [2023-01-26 18:08:11,614] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:11,614] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big ID_MAPPING(EntityIdMap): 0 entries, 0 B within 74.69 μs
INFO  [2023-01-26 18:08:11,614] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_MetadataCollectionTest:STRUCTURE}): 0 entries, 0 B within 79.23 μs
INFO  [2023-01-26 18:08:11,614] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_MetadataCollectionTest:WORKER_TO_BUCKETS}): 0 entries, 0 B within 66.48 μs
INFO  [2023-01-26 18:08:11,615] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_MetadataCollectionTest:PRIMARY_DICTIONARY}): 0 entries, 0 B within 58.71 μs
INFO  [2023-01-26 18:08:11,624] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=MetadataCollectionTest, name=MetadataCollectionTest]
INFO  [2023-01-26 18:08:11,624] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=MetadataCollectionTest, name=MetadataCollectionTest]
INFO  [2023-01-26 18:08:11,654] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_MetadataCollectionTest_08b81ef1-8698-4b51-ab18-593b990d1352
INFO  [2023-01-26 18:08:11,659] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_MetadataCollectionTest_7a4bb379-d24b-4a15-bea8-611386aac213
INFO  [2023-01-26 18:08:11,685] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_MetadataCollectionTest_08b81ef1-8698-4b51-ab18-593b990d1352:DATASET}): 0 entries, 0 B within 91.30 μs
INFO  [2023-01-26 18:08:11,685] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_MetadataCollectionTest_08b81ef1-8698-4b51-ab18-593b990d1352:SECONDARY_IDS}): 0 entries, 0 B within 42.20 μs
INFO  [2023-01-26 18:08:11,685] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_MetadataCollectionTest_08b81ef1-8698-4b51-ab18-593b990d1352:TABLES}): 0 entries, 0 B within 29.57 μs
INFO  [2023-01-26 18:08:11,685] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 32.43 μs
INFO  [2023-01-26 18:08:11,685] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_MetadataCollectionTest_08b81ef1-8698-4b51-ab18-593b990d1352:IMPORTS}): 0 entries, 0 B within 28.44 μs
INFO  [2023-01-26 18:08:11,685] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_MetadataCollectionTest_08b81ef1-8698-4b51-ab18-593b990d1352:CONCEPTS}): 0 entries, 0 B within 28.43 μs
INFO  [2023-01-26 18:08:11,685] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:11,685] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_MetadataCollectionTest_08b81ef1-8698-4b51-ab18-593b990d1352:WORKER}): 0 entries, 0 B within 29.56 μs
INFO  [2023-01-26 18:08:11,685] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_MetadataCollectionTest_08b81ef1-8698-4b51-ab18-593b990d1352:BUCKETS}): 0 entries, 0 B within 27.83 μs
INFO  [2023-01-26 18:08:11,685] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_MetadataCollectionTest_08b81ef1-8698-4b51-ab18-593b990d1352:C_BLOCKS}): 0 entries, 0 B within 33.24 μs
INFO  [2023-01-26 18:08:11,690] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker MetadataCollectionTest.worker_MetadataCollectionTest_08b81ef1-8698-4b51-ab18-593b990d1352 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:11,690] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker MetadataCollectionTest.worker_MetadataCollectionTest_08b81ef1-8698-4b51-ab18-593b990d1352 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:11,690] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:11,692] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_MetadataCollectionTest_7a4bb379-d24b-4a15-bea8-611386aac213:DATASET}): 0 entries, 0 B within 101.3 μs
INFO  [2023-01-26 18:08:11,692] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_MetadataCollectionTest_7a4bb379-d24b-4a15-bea8-611386aac213:SECONDARY_IDS}): 0 entries, 0 B within 56.37 μs
INFO  [2023-01-26 18:08:11,692] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_MetadataCollectionTest_7a4bb379-d24b-4a15-bea8-611386aac213:TABLES}): 0 entries, 0 B within 44.71 μs
INFO  [2023-01-26 18:08:11,693] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 48.85 μs
INFO  [2023-01-26 18:08:11,693] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_MetadataCollectionTest_7a4bb379-d24b-4a15-bea8-611386aac213:IMPORTS}): 0 entries, 0 B within 43.10 μs
INFO  [2023-01-26 18:08:11,693] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_MetadataCollectionTest_7a4bb379-d24b-4a15-bea8-611386aac213:CONCEPTS}): 0 entries, 0 B within 42.02 μs
INFO  [2023-01-26 18:08:11,693] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:11,693] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_MetadataCollectionTest_7a4bb379-d24b-4a15-bea8-611386aac213:WORKER}): 0 entries, 0 B within 42.02 μs
INFO  [2023-01-26 18:08:11,693] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_MetadataCollectionTest_7a4bb379-d24b-4a15-bea8-611386aac213:BUCKETS}): 0 entries, 0 B within 53.26 μs
INFO  [2023-01-26 18:08:11,693] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_MetadataCollectionTest_7a4bb379-d24b-4a15-bea8-611386aac213:C_BLOCKS}): 0 entries, 0 B within 44.69 μs
INFO  [2023-01-26 18:08:11,696] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker MetadataCollectionTest.worker_MetadataCollectionTest_7a4bb379-d24b-4a15-bea8-611386aac213 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:11,696] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker MetadataCollectionTest.worker_MetadataCollectionTest_7a4bb379-d24b-4a15-bea8-611386aac213 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:11,696] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:11,698] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:11,800] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:11,810] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:11,810] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table MetadataCollectionTest.test_table
INFO  [2023-01-26 18:08:11,810] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table MetadataCollectionTest.test_table
INFO  [2023-01-26 18:08:11,923] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:12,034] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:12,035] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:12,035] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 94 B in total
INFO  [2023-01-26 18:08:12,035] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_MetadataCollectionTest/test_table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000369391sINFO  [2023-01-26 18:08:12,087] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=4, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:08:12,087] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=4, nullLines=0), subType=IntegerParser(super=Parser(lines=4, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@457bccfa)
INFO  [2023-01-26 18:08:12,087] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=4, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:08:12,092] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_MetadataCollectionTest/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:12,092] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:12,092] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_MetadataCollectionTest/test_table.import.json, tag=Optional.empty)
127.0.0.1 - - [26/Jan/2023:18:08:12 +0000] "POST /admin/datasets/MetadataCollectionTest/imports?file=%2Ftmp%2FconqueryIntegrationTest12910953884258704183%2Ftmp_MetadataCollectionTest%2Ftest_table.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 12
INFO  [2023-01-26 18:08:12,141] com.bakdata.conquery.models.jobs.ImportJob: Importing test_table into MetadataCollectionTest.test_table
INFO  [2023-01-26 18:08:12,142] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:12,151] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:12,168] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:12,168] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:12,175] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[MetadataCollectionTest.test_table.test_table], containing 4 entries.
INFO  [2023-01-26 18:08:12,175] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[MetadataCollectionTest.test_table.test_table], containing 4 entries.
INFO  [2023-01-26 18:08:12,176] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
WARN  [2023-01-26 18:08:12,184] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:12,184] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MetadataCollectionTest.test_table.test_table.1
INFO  [2023-01-26 18:08:12,187] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MetadataCollectionTest.test_table.test_table.0
INFO  [2023-01-26 18:08:12,294] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:12,299] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:12,319] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:08:12,322] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:12,324] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:08:12,453] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast MetadataCollectionTest
INFO  [2023-01-26 18:08:12,453] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=MetadataCollectionTest, name=MetadataCollectionTest]
INFO  [2023-01-26 18:08:12,453] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=MetadataCollectionTest, name=MetadataCollectionTest]
INFO  [2023-01-26 18:08:12,453] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_MetadataCollectionTest_7a4bb379-d24b-4a15-bea8-611386aac213
INFO  [2023-01-26 18:08:12,453] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_MetadataCollectionTest_08b81ef1-8698-4b51-ab18-593b990d1352
INFO  [2023-01-26 18:08:12,544] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow MetadataCollectionTest
INFO  [2023-01-26 18:08:12,544] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_MetadataCollectionTest_08b81ef1-8698-4b51-ab18-593b990d1352
INFO  [2023-01-26 18:08:12,545] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of MetadataCollectionTest
INFO  [2023-01-26 18:08:12,545] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_MetadataCollectionTest_7a4bb379-d24b-4a15-bea8-611386aac213
INFO  [2023-01-26 18:08:12,545] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_MetadataCollectionTest
INFO  [2023-01-26 18:08:12,555] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:12,645] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_MetadataCollectionTest_7a4bb379-d24b-4a15-bea8-611386aac213
INFO  [2023-01-26 18:08:12,645] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_MetadataCollectionTest_08b81ef1-8698-4b51-ab18-593b990d1352
INFO  [2023-01-26 18:08:12,757] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test MetadataCollectionTest
INFO  [2023-01-26 18:08:12,760] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test PermissionGroupHandlingTest
INFO  [2023-01-26 18:08:12,761] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:12,780] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_PermissionGroupHandlingTest
INFO  [2023-01-26 18:08:12,792] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_PermissionGroupHandlingTest:DATASET}): 0 entries, 0 B within 83.28 μs
INFO  [2023-01-26 18:08:12,792] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_PermissionGroupHandlingTest:SECONDARY_IDS}): 0 entries, 0 B within 40.98 μs
INFO  [2023-01-26 18:08:12,792] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_PermissionGroupHandlingTest:TABLES}): 0 entries, 0 B within 35.73 μs
INFO  [2023-01-26 18:08:12,792] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 61.60 μs
INFO  [2023-01-26 18:08:12,792] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_PermissionGroupHandlingTest:IMPORTS}): 0 entries, 0 B within 32.98 μs
INFO  [2023-01-26 18:08:12,792] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_PermissionGroupHandlingTest:CONCEPTS}): 0 entries, 0 B within 30.82 μs
INFO  [2023-01-26 18:08:12,793] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:12,793] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big ID_MAPPING(EntityIdMap): 0 entries, 0 B within 42.07 μs
INFO  [2023-01-26 18:08:12,793] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_PermissionGroupHandlingTest:STRUCTURE}): 0 entries, 0 B within 38.81 μs
INFO  [2023-01-26 18:08:12,793] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_PermissionGroupHandlingTest:WORKER_TO_BUCKETS}): 0 entries, 0 B within 35.16 μs
INFO  [2023-01-26 18:08:12,793] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_PermissionGroupHandlingTest:PRIMARY_DICTIONARY}): 0 entries, 0 B within 30.68 μs
INFO  [2023-01-26 18:08:12,800] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=PermissionGroupHandlingTest, name=PermissionGroupHandlingTest]
INFO  [2023-01-26 18:08:12,800] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=PermissionGroupHandlingTest, name=PermissionGroupHandlingTest]
INFO  [2023-01-26 18:08:12,819] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_PermissionGroupHandlingTest_7dd63d2e-4392-409b-9700-f0be5055a806
INFO  [2023-01-26 18:08:12,819] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_PermissionGroupHandlingTest_4bc383ef-5186-4d2f-a0aa-8e028319e35a
INFO  [2023-01-26 18:08:12,840] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_PermissionGroupHandlingTest_4bc383ef-5186-4d2f-a0aa-8e028319e35a:DATASET}): 0 entries, 0 B within 86.06 μs
INFO  [2023-01-26 18:08:12,840] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_PermissionGroupHandlingTest_4bc383ef-5186-4d2f-a0aa-8e028319e35a:SECONDARY_IDS}): 0 entries, 0 B within 37.91 μs
INFO  [2023-01-26 18:08:12,840] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_PermissionGroupHandlingTest_4bc383ef-5186-4d2f-a0aa-8e028319e35a:TABLES}): 0 entries, 0 B within 24.38 μs
INFO  [2023-01-26 18:08:12,840] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 36.83 μs
INFO  [2023-01-26 18:08:12,840] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_PermissionGroupHandlingTest_4bc383ef-5186-4d2f-a0aa-8e028319e35a:IMPORTS}): 0 entries, 0 B within 43.53 μs
INFO  [2023-01-26 18:08:12,841] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_PermissionGroupHandlingTest_4bc383ef-5186-4d2f-a0aa-8e028319e35a:CONCEPTS}): 0 entries, 0 B within 34.16 μs
INFO  [2023-01-26 18:08:12,841] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:12,841] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_PermissionGroupHandlingTest_4bc383ef-5186-4d2f-a0aa-8e028319e35a:WORKER}): 0 entries, 0 B within 37.50 μs
INFO  [2023-01-26 18:08:12,841] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_PermissionGroupHandlingTest_4bc383ef-5186-4d2f-a0aa-8e028319e35a:BUCKETS}): 0 entries, 0 B within 43.21 μs
INFO  [2023-01-26 18:08:12,841] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_PermissionGroupHandlingTest_4bc383ef-5186-4d2f-a0aa-8e028319e35a:C_BLOCKS}): 0 entries, 0 B within 39.09 μs
INFO  [2023-01-26 18:08:12,842] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_PermissionGroupHandlingTest_7dd63d2e-4392-409b-9700-f0be5055a806:DATASET}): 0 entries, 0 B within 55.94 μs
INFO  [2023-01-26 18:08:12,842] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_PermissionGroupHandlingTest_7dd63d2e-4392-409b-9700-f0be5055a806:SECONDARY_IDS}): 0 entries, 0 B within 28.29 μs
INFO  [2023-01-26 18:08:12,842] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_PermissionGroupHandlingTest_7dd63d2e-4392-409b-9700-f0be5055a806:TABLES}): 0 entries, 0 B within 25.03 μs
INFO  [2023-01-26 18:08:12,842] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 24.54 μs
INFO  [2023-01-26 18:08:12,842] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_PermissionGroupHandlingTest_7dd63d2e-4392-409b-9700-f0be5055a806:IMPORTS}): 0 entries, 0 B within 22.65 μs
INFO  [2023-01-26 18:08:12,843] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_PermissionGroupHandlingTest_7dd63d2e-4392-409b-9700-f0be5055a806:CONCEPTS}): 0 entries, 0 B within 21.37 μs
INFO  [2023-01-26 18:08:12,843] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:12,843] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_PermissionGroupHandlingTest_7dd63d2e-4392-409b-9700-f0be5055a806:WORKER}): 0 entries, 0 B within 21.65 μs
INFO  [2023-01-26 18:08:12,843] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_PermissionGroupHandlingTest_7dd63d2e-4392-409b-9700-f0be5055a806:BUCKETS}): 0 entries, 0 B within 20.84 μs
INFO  [2023-01-26 18:08:12,843] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_PermissionGroupHandlingTest_7dd63d2e-4392-409b-9700-f0be5055a806:C_BLOCKS}): 0 entries, 0 B within 20.09 μs
INFO  [2023-01-26 18:08:12,845] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker PermissionGroupHandlingTest.worker_PermissionGroupHandlingTest_4bc383ef-5186-4d2f-a0aa-8e028319e35a are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:12,845] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker PermissionGroupHandlingTest.worker_PermissionGroupHandlingTest_4bc383ef-5186-4d2f-a0aa-8e028319e35a are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:12,845] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:12,846] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker PermissionGroupHandlingTest.worker_PermissionGroupHandlingTest_7dd63d2e-4392-409b-9700-f0be5055a806 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:12,846] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker PermissionGroupHandlingTest.worker_PermissionGroupHandlingTest_7dd63d2e-4392-409b-9700-f0be5055a806 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:12,846] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:12,847] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:12,963] com.bakdata.conquery.io.storage.MetaStorage: Remove User = user.user
INFO  [2023-01-26 18:08:12,964] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast PermissionGroupHandlingTest
INFO  [2023-01-26 18:08:12,964] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=PermissionGroupHandlingTest, name=PermissionGroupHandlingTest]
INFO  [2023-01-26 18:08:12,964] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=PermissionGroupHandlingTest, name=PermissionGroupHandlingTest]
INFO  [2023-01-26 18:08:12,964] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_PermissionGroupHandlingTest_7dd63d2e-4392-409b-9700-f0be5055a806
INFO  [2023-01-26 18:08:12,964] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_PermissionGroupHandlingTest_4bc383ef-5186-4d2f-a0aa-8e028319e35a
INFO  [2023-01-26 18:08:13,000] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow PermissionGroupHandlingTest
INFO  [2023-01-26 18:08:13,050] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_PermissionGroupHandlingTest_4bc383ef-5186-4d2f-a0aa-8e028319e35a
INFO  [2023-01-26 18:08:13,050] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_PermissionGroupHandlingTest_7dd63d2e-4392-409b-9700-f0be5055a806
INFO  [2023-01-26 18:08:13,100] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of PermissionGroupHandlingTest
INFO  [2023-01-26 18:08:13,101] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_PermissionGroupHandlingTest
INFO  [2023-01-26 18:08:13,109] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:13,151] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_PermissionGroupHandlingTest_7dd63d2e-4392-409b-9700-f0be5055a806
INFO  [2023-01-26 18:08:13,151] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_PermissionGroupHandlingTest_4bc383ef-5186-4d2f-a0aa-8e028319e35a
INFO  [2023-01-26 18:08:13,268] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test PermissionGroupHandlingTest
INFO  [2023-01-26 18:08:13,271] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test PermissionRoleHandlingTest
INFO  [2023-01-26 18:08:13,271] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:13,290] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_PermissionRoleHandlingTest
INFO  [2023-01-26 18:08:13,301] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_PermissionRoleHandlingTest:DATASET}): 0 entries, 0 B within 89.70 μs
INFO  [2023-01-26 18:08:13,301] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_PermissionRoleHandlingTest:SECONDARY_IDS}): 0 entries, 0 B within 44.62 μs
INFO  [2023-01-26 18:08:13,301] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_PermissionRoleHandlingTest:TABLES}): 0 entries, 0 B within 35.84 μs
INFO  [2023-01-26 18:08:13,301] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 42.18 μs
INFO  [2023-01-26 18:08:13,302] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_PermissionRoleHandlingTest:IMPORTS}): 0 entries, 0 B within 33.63 μs
INFO  [2023-01-26 18:08:13,302] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_PermissionRoleHandlingTest:CONCEPTS}): 0 entries, 0 B within 33.73 μs
INFO  [2023-01-26 18:08:13,302] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:13,302] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big ID_MAPPING(EntityIdMap): 0 entries, 0 B within 36.88 μs
INFO  [2023-01-26 18:08:13,302] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_PermissionRoleHandlingTest:STRUCTURE}): 0 entries, 0 B within 33.06 μs
INFO  [2023-01-26 18:08:13,302] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_PermissionRoleHandlingTest:WORKER_TO_BUCKETS}): 0 entries, 0 B within 43.94 μs
INFO  [2023-01-26 18:08:13,302] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_PermissionRoleHandlingTest:PRIMARY_DICTIONARY}): 0 entries, 0 B within 32.32 μs
INFO  [2023-01-26 18:08:13,316] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=PermissionRoleHandlingTest, name=PermissionRoleHandlingTest]
INFO  [2023-01-26 18:08:13,316] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=PermissionRoleHandlingTest, name=PermissionRoleHandlingTest]
INFO  [2023-01-26 18:08:13,335] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_PermissionRoleHandlingTest_1113c800-5362-482d-80be-d3bd5c1d1265
INFO  [2023-01-26 18:08:13,335] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_PermissionRoleHandlingTest_72b02e7e-6cdb-41d5-bff3-8196fb1d05ec
INFO  [2023-01-26 18:08:13,357] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_PermissionRoleHandlingTest_1113c800-5362-482d-80be-d3bd5c1d1265:DATASET}): 0 entries, 0 B within 106.2 μs
INFO  [2023-01-26 18:08:13,357] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_PermissionRoleHandlingTest_1113c800-5362-482d-80be-d3bd5c1d1265:SECONDARY_IDS}): 0 entries, 0 B within 70.01 μs
INFO  [2023-01-26 18:08:13,357] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_PermissionRoleHandlingTest_1113c800-5362-482d-80be-d3bd5c1d1265:TABLES}): 0 entries, 0 B within 43.40 μs
INFO  [2023-01-26 18:08:13,357] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 43.45 μs
INFO  [2023-01-26 18:08:13,357] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_PermissionRoleHandlingTest_1113c800-5362-482d-80be-d3bd5c1d1265:IMPORTS}): 0 entries, 0 B within 29.42 μs
INFO  [2023-01-26 18:08:13,357] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_PermissionRoleHandlingTest_1113c800-5362-482d-80be-d3bd5c1d1265:CONCEPTS}): 0 entries, 0 B within 28.37 μs
INFO  [2023-01-26 18:08:13,357] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:13,357] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_PermissionRoleHandlingTest_1113c800-5362-482d-80be-d3bd5c1d1265:WORKER}): 0 entries, 0 B within 28.56 μs
INFO  [2023-01-26 18:08:13,357] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_PermissionRoleHandlingTest_1113c800-5362-482d-80be-d3bd5c1d1265:BUCKETS}): 0 entries, 0 B within 27.56 μs
INFO  [2023-01-26 18:08:13,357] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_PermissionRoleHandlingTest_1113c800-5362-482d-80be-d3bd5c1d1265:C_BLOCKS}): 0 entries, 0 B within 26.81 μs
INFO  [2023-01-26 18:08:13,360] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_PermissionRoleHandlingTest_72b02e7e-6cdb-41d5-bff3-8196fb1d05ec:DATASET}): 0 entries, 0 B within 96.87 μs
INFO  [2023-01-26 18:08:13,360] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_PermissionRoleHandlingTest_72b02e7e-6cdb-41d5-bff3-8196fb1d05ec:SECONDARY_IDS}): 0 entries, 0 B within 38.38 μs
INFO  [2023-01-26 18:08:13,360] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_PermissionRoleHandlingTest_72b02e7e-6cdb-41d5-bff3-8196fb1d05ec:TABLES}): 0 entries, 0 B within 29.27 μs
INFO  [2023-01-26 18:08:13,360] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 32.11 μs
INFO  [2023-01-26 18:08:13,360] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_PermissionRoleHandlingTest_72b02e7e-6cdb-41d5-bff3-8196fb1d05ec:IMPORTS}): 0 entries, 0 B within 28.99 μs
INFO  [2023-01-26 18:08:13,360] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_PermissionRoleHandlingTest_72b02e7e-6cdb-41d5-bff3-8196fb1d05ec:CONCEPTS}): 0 entries, 0 B within 22.61 μs
INFO  [2023-01-26 18:08:13,360] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:13,360] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_PermissionRoleHandlingTest_72b02e7e-6cdb-41d5-bff3-8196fb1d05ec:WORKER}): 0 entries, 0 B within 22.17 μs
INFO  [2023-01-26 18:08:13,360] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_PermissionRoleHandlingTest_72b02e7e-6cdb-41d5-bff3-8196fb1d05ec:BUCKETS}): 0 entries, 0 B within 20.88 μs
INFO  [2023-01-26 18:08:13,360] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_PermissionRoleHandlingTest_72b02e7e-6cdb-41d5-bff3-8196fb1d05ec:C_BLOCKS}): 0 entries, 0 B within 20.36 μs
INFO  [2023-01-26 18:08:13,368] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker PermissionRoleHandlingTest.worker_PermissionRoleHandlingTest_72b02e7e-6cdb-41d5-bff3-8196fb1d05ec are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:13,368] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker PermissionRoleHandlingTest.worker_PermissionRoleHandlingTest_72b02e7e-6cdb-41d5-bff3-8196fb1d05ec are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:13,368] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:13,368] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker PermissionRoleHandlingTest.worker_PermissionRoleHandlingTest_1113c800-5362-482d-80be-d3bd5c1d1265 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:13,368] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker PermissionRoleHandlingTest.worker_PermissionRoleHandlingTest_1113c800-5362-482d-80be-d3bd5c1d1265 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:13,368] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:13,368] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:13,473] com.bakdata.conquery.io.storage.MetaStorage: Remove User = user.user
INFO  [2023-01-26 18:08:13,473] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast PermissionRoleHandlingTest
INFO  [2023-01-26 18:08:13,474] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=PermissionRoleHandlingTest, name=PermissionRoleHandlingTest]
INFO  [2023-01-26 18:08:13,474] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_PermissionRoleHandlingTest_72b02e7e-6cdb-41d5-bff3-8196fb1d05ec
INFO  [2023-01-26 18:08:13,474] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=PermissionRoleHandlingTest, name=PermissionRoleHandlingTest]
INFO  [2023-01-26 18:08:13,474] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_PermissionRoleHandlingTest_1113c800-5362-482d-80be-d3bd5c1d1265
INFO  [2023-01-26 18:08:13,518] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow PermissionRoleHandlingTest
INFO  [2023-01-26 18:08:13,563] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_PermissionRoleHandlingTest_1113c800-5362-482d-80be-d3bd5c1d1265
INFO  [2023-01-26 18:08:13,563] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_PermissionRoleHandlingTest_72b02e7e-6cdb-41d5-bff3-8196fb1d05ec
INFO  [2023-01-26 18:08:13,619] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of PermissionRoleHandlingTest
INFO  [2023-01-26 18:08:13,619] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_PermissionRoleHandlingTest
INFO  [2023-01-26 18:08:13,628] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:13,661] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_PermissionRoleHandlingTest_1113c800-5362-482d-80be-d3bd5c1d1265
INFO  [2023-01-26 18:08:13,664] com.bakdata.conquery.models.config.XodusStoreFactory: Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_PermissionRoleHandlingTest_72b02e7e-6cdb-41d5-bff3-8196fb1d05ec
INFO  [2023-01-26 18:08:13,781] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test PermissionRoleHandlingTest
INFO  [2023-01-26 18:08:13,787] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test RestartTest
INFO  [2023-01-26 18:08:13,793] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:13,813] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest
INFO  [2023-01-26 18:08:13,827] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest:DATASET}): 0 entries, 0 B within 163.4 μs
INFO  [2023-01-26 18:08:13,827] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest:SECONDARY_IDS}): 0 entries, 0 B within 91.93 μs
INFO  [2023-01-26 18:08:13,828] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest:TABLES}): 0 entries, 0 B within 129.6 μs
INFO  [2023-01-26 18:08:13,828] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 94.96 μs
INFO  [2023-01-26 18:08:13,828] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest:IMPORTS}): 0 entries, 0 B within 76.08 μs
INFO  [2023-01-26 18:08:13,828] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest:CONCEPTS}): 0 entries, 0 B within 75.73 μs
INFO  [2023-01-26 18:08:13,828] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:13,828] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big ID_MAPPING(EntityIdMap): 0 entries, 0 B within 87.59 μs
INFO  [2023-01-26 18:08:13,829] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest:STRUCTURE}): 0 entries, 0 B within 49.71 μs
INFO  [2023-01-26 18:08:13,829] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest:WORKER_TO_BUCKETS}): 0 entries, 0 B within 51.18 μs
INFO  [2023-01-26 18:08:13,829] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest:PRIMARY_DICTIONARY}): 0 entries, 0 B within 90.16 μs
INFO  [2023-01-26 18:08:13,837] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=RestartTest, name=RestartTest]
INFO  [2023-01-26 18:08:13,837] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=RestartTest, name=RestartTest]
INFO  [2023-01-26 18:08:13,867] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea
INFO  [2023-01-26 18:08:13,872] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33
INFO  [2023-01-26 18:08:13,890] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea:DATASET}): 0 entries, 0 B within 81.71 μs
INFO  [2023-01-26 18:08:13,890] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea:SECONDARY_IDS}): 0 entries, 0 B within 32.58 μs
INFO  [2023-01-26 18:08:13,890] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea:TABLES}): 0 entries, 0 B within 23.40 μs
INFO  [2023-01-26 18:08:13,890] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 25.41 μs
INFO  [2023-01-26 18:08:13,890] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea:IMPORTS}): 0 entries, 0 B within 19.40 μs
INFO  [2023-01-26 18:08:13,890] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea:CONCEPTS}): 0 entries, 0 B within 18.54 μs
INFO  [2023-01-26 18:08:13,890] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:13,890] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea:WORKER}): 0 entries, 0 B within 19.12 μs
INFO  [2023-01-26 18:08:13,890] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea:BUCKETS}): 0 entries, 0 B within 21.02 μs
INFO  [2023-01-26 18:08:13,890] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea:C_BLOCKS}): 0 entries, 0 B within 20.19 μs
INFO  [2023-01-26 18:08:13,895] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker RestartTest.worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:13,895] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker RestartTest.worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:13,895] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:13,901] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33:DATASET}): 0 entries, 0 B within 81.87 μs
INFO  [2023-01-26 18:08:13,901] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33:SECONDARY_IDS}): 0 entries, 0 B within 36.26 μs
INFO  [2023-01-26 18:08:13,901] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33:TABLES}): 0 entries, 0 B within 27.87 μs
INFO  [2023-01-26 18:08:13,901] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 30.57 μs
INFO  [2023-01-26 18:08:13,901] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33:IMPORTS}): 0 entries, 0 B within 25.74 μs
INFO  [2023-01-26 18:08:13,901] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33:CONCEPTS}): 0 entries, 0 B within 23.72 μs
INFO  [2023-01-26 18:08:13,901] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:13,901] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33:WORKER}): 0 entries, 0 B within 23.37 μs
INFO  [2023-01-26 18:08:13,901] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33:BUCKETS}): 0 entries, 0 B within 23.03 μs
INFO  [2023-01-26 18:08:13,901] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33:C_BLOCKS}): 0 entries, 0 B within 22.36 μs
INFO  [2023-01-26 18:08:13,904] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker RestartTest.worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:13,904] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker RestartTest.worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:13,904] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:13,905] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:14,035] com.bakdata.conquery.resources.admin.rest.AdminDatasetProcessor: Received new SecondaryId[RestartTest.secondary]
INFO  [2023-01-26 18:08:14,038] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:14,039] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId RestartTest.secondary
INFO  [2023-01-26 18:08:14,039] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId RestartTest.secondary
INFO  [2023-01-26 18:08:14,147] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:14,147] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table RestartTest.test_table
INFO  [2023-01-26 18:08:14,147] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table RestartTest.test_table
INFO  [2023-01-26 18:08:14,268] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:14,381] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:14,382] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:14,382] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 94 B in total
INFO  [2023-01-26 18:08:14,382] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_RestartTest/test_table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.00025565sINFO  [2023-01-26 18:08:14,408] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=4, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:08:14,408] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=4, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:08:14,408] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=4, nullLines=0), subType=IntegerParser(super=Parser(lines=4, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@71a639cf)
INFO  [2023-01-26 18:08:14,411] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_RestartTest/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:14,411] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:14,411] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_RestartTest/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:14,437] com.bakdata.conquery.models.jobs.ImportJob: Importing test_table into RestartTest.test_table
127.0.0.1 - - [26/Jan/2023:18:08:14 +0000] "POST /admin/datasets/RestartTest/imports?file=%2Ftmp%2FconqueryIntegrationTest12910953884258704183%2Ftmp_RestartTest%2Ftest_table.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 15
INFO  [2023-01-26 18:08:14,438] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:14,441] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:14,455] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:14,455] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:14,462] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[RestartTest.test_table.test_table], containing 4 entries.
INFO  [2023-01-26 18:08:14,462] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[RestartTest.test_table.test_table], containing 4 entries.
INFO  [2023-01-26 18:08:14,463] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:08:14,464] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received RestartTest.test_table.test_table.0
WARN  [2023-01-26 18:08:14,465] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:14,465] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received RestartTest.test_table.test_table.1
INFO  [2023-01-26 18:08:14,588] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:14,593] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:14,605] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: SIMPLE_TREECONCEPT_QUERY Test QUERY INIT
INFO  [2023-01-26 18:08:14,620] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[RestartTest] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:08:14,621] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[9f47db6b-4ad1-45f3-a0fd-113f5d0a4c1f] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_RestartTest))]]
INFO  [2023-01-26 18:08:14,623] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery RestartTest.9f47db6b-4ad1-45f3-a0fd-113f5d0a4c1f
INFO  [2023-01-26 18:08:14,623] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery RestartTest.9f47db6b-4ad1-45f3-a0fd-113f5d0a4c1f
INFO  [2023-01-26 18:08:14,624] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[RestartTest.9f47db6b-4ad1-45f3-a0fd-113f5d0a4c1f] with 0 results within PT0.000591S
INFO  [2023-01-26 18:08:14,625] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[RestartTest.9f47db6b-4ad1-45f3-a0fd-113f5d0a4c1f] with 2 results within PT0.001265S
INFO  [2023-01-26 18:08:14,625] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=RestartTest.9f47db6b-4ad1-45f3-a0fd-113f5d0a4c1f, workerId=RestartTest.worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33, startTime=2023-01-26T18:08:14.623878, finishTime=2023-01-26T18:08:14.624469) of size 0
INFO  [2023-01-26 18:08:14,625] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=RestartTest.9f47db6b-4ad1-45f3-a0fd-113f5d0a4c1f, workerId=RestartTest.worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea, startTime=2023-01-26T18:08:14.623908, finishTime=2023-01-26T18:08:14.625173) of size 2
127.0.0.1 - - [26/Jan/2023:18:08:14 +0000] "POST /api/datasets/RestartTest/queries HTTP/1.1" 201 1119 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:08:14,627] com.bakdata.conquery.models.execution.ManagedExecution: DONE 9f47db6b-4ad1-45f3-a0fd-113f5d0a4c1f ManagedQuery within PT0.004942S
127.0.0.1 - - [26/Jan/2023:18:08:14 +0000] "GET /api/datasets/RestartTest/queries/RestartTest.9f47db6b-4ad1-45f3-a0fd-113f5d0a4c1f HTTP/1.1" 200 1354 "-" "Conquery (test client)" 4
INFO  [2023-01-26 18:08:14,668] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=RestartTest], queryId=9f47db6b-4ad1-45f3-a0fd-113f5d0a4c1f, label=test_tree---test_child1	@§$, creationTime=2023-01-26T18:08:14.620838, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@7ef9cb76[Count = 0], startTime=2023-01-26T18:08:14.621389, finishTime=2023-01-26T18:08:14.626331, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@48c97141), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_RestartTest)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@3c1bfc47], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@53855f66], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=null, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@224ae08c, com.bakdata.conquery.models.query.ColumnDescriptor@5d0d8896]) download on dataset Dataset[label=null, name=RestartTest] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:08:14,690] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=RestartTest], queryId=9f47db6b-4ad1-45f3-a0fd-113f5d0a4c1f, label=test_tree---test_child1	@§$, creationTime=2023-01-26T18:08:14.620838, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@7ef9cb76[Count = 0], startTime=2023-01-26T18:08:14.621389, finishTime=2023-01-26T18:08:14.626331, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@48c97141), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_RestartTest)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@3c1bfc47], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@53855f66], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=null, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@224ae08c, com.bakdata.conquery.models.query.ColumnDescriptor@5d0d8896]) on dataset Dataset[label=null, name=RestartTest]
127.0.0.1 - - [26/Jan/2023:18:08:14 +0000] "GET /api/datasets/RestartTest/result/RestartTest.9f47db6b-4ad1-45f3-a0fd-113f5d0a4c1f.csv?pretty=false HTTP/1.1" 200 65 "-" "Conquery (test client)" 41
INFO  [2023-01-26 18:08:14,703] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest SIMPLE_TREECONCEPT_QUERY Test on 3 rows
INFO  [2023-01-26 18:08:14,730] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1
INFO  [2023-01-26 18:08:14,738] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1:DATASET}): 0 entries, 0 B within 97.52 μs
INFO  [2023-01-26 18:08:14,738] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1:SECONDARY_IDS}): 0 entries, 0 B within 57.21 μs
INFO  [2023-01-26 18:08:14,738] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1:TABLES}): 0 entries, 0 B within 43.30 μs
INFO  [2023-01-26 18:08:14,739] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 38.09 μs
INFO  [2023-01-26 18:08:14,739] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1:IMPORTS}): 0 entries, 0 B within 39.38 μs
INFO  [2023-01-26 18:08:14,739] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1:CONCEPTS}): 0 entries, 0 B within 31.50 μs
INFO  [2023-01-26 18:08:14,739] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:14,739] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big ID_MAPPING(EntityIdMap): 0 entries, 0 B within 35.09 μs
INFO  [2023-01-26 18:08:14,739] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1:STRUCTURE}): 0 entries, 0 B within 36.93 μs
INFO  [2023-01-26 18:08:14,739] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1:WORKER_TO_BUCKETS}): 0 entries, 0 B within 34.25 μs
INFO  [2023-01-26 18:08:14,739] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1:PRIMARY_DICTIONARY}): 0 entries, 0 B within 238.8 μs
INFO  [2023-01-26 18:08:14,746] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=testDataset1, name=testDataset1]
INFO  [2023-01-26 18:08:14,746] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=testDataset1, name=testDataset1]
INFO  [2023-01-26 18:08:14,773] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2
INFO  [2023-01-26 18:08:14,779] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd
INFO  [2023-01-26 18:08:14,779] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f
INFO  [2023-01-26 18:08:14,786] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2:DATASET}): 0 entries, 0 B within 277.9 μs
INFO  [2023-01-26 18:08:14,786] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2:SECONDARY_IDS}): 0 entries, 0 B within 79.14 μs
INFO  [2023-01-26 18:08:14,786] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2:TABLES}): 0 entries, 0 B within 66.02 μs
INFO  [2023-01-26 18:08:14,786] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 91.86 μs
INFO  [2023-01-26 18:08:14,786] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2:IMPORTS}): 0 entries, 0 B within 60.13 μs
INFO  [2023-01-26 18:08:14,787] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2:CONCEPTS}): 0 entries, 0 B within 56.47 μs
INFO  [2023-01-26 18:08:14,787] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:14,787] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big ID_MAPPING(EntityIdMap): 0 entries, 0 B within 67.83 μs
INFO  [2023-01-26 18:08:14,787] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2:STRUCTURE}): 0 entries, 0 B within 55.58 μs
INFO  [2023-01-26 18:08:14,787] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2:WORKER_TO_BUCKETS}): 0 entries, 0 B within 54.61 μs
INFO  [2023-01-26 18:08:14,787] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2:PRIMARY_DICTIONARY}): 0 entries, 0 B within 83.78 μs
INFO  [2023-01-26 18:08:14,798] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd:DATASET}): 0 entries, 0 B within 84.37 μs
INFO  [2023-01-26 18:08:14,799] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd:SECONDARY_IDS}): 0 entries, 0 B within 40.80 μs
INFO  [2023-01-26 18:08:14,799] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd:TABLES}): 0 entries, 0 B within 41.70 μs
INFO  [2023-01-26 18:08:14,799] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 41.44 μs
INFO  [2023-01-26 18:08:14,799] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd:IMPORTS}): 0 entries, 0 B within 32.13 μs
INFO  [2023-01-26 18:08:14,799] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd:CONCEPTS}): 0 entries, 0 B within 30.29 μs
INFO  [2023-01-26 18:08:14,799] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:14,799] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd:WORKER}): 0 entries, 0 B within 30.29 μs
INFO  [2023-01-26 18:08:14,799] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd:BUCKETS}): 0 entries, 0 B within 28.74 μs
INFO  [2023-01-26 18:08:14,799] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd:C_BLOCKS}): 0 entries, 0 B within 30.11 μs
INFO  [2023-01-26 18:08:14,802] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=testDataset2, name=testDataset2]
INFO  [2023-01-26 18:08:14,805] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker testDataset1.worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:14,805] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker testDataset1.worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:14,805] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:14,805] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f:DATASET}): 0 entries, 0 B within 99.04 μs
INFO  [2023-01-26 18:08:14,806] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f:SECONDARY_IDS}): 0 entries, 0 B within 53.51 μs
INFO  [2023-01-26 18:08:14,806] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f:TABLES}): 0 entries, 0 B within 42.63 μs
INFO  [2023-01-26 18:08:14,806] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 39.62 μs
INFO  [2023-01-26 18:08:14,806] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f:IMPORTS}): 0 entries, 0 B within 31.60 μs
INFO  [2023-01-26 18:08:14,806] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f:CONCEPTS}): 0 entries, 0 B within 31.38 μs
INFO  [2023-01-26 18:08:14,806] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:14,806] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f:WORKER}): 0 entries, 0 B within 30.57 μs
INFO  [2023-01-26 18:08:14,806] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f:BUCKETS}): 0 entries, 0 B within 29.88 μs
INFO  [2023-01-26 18:08:14,806] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f:C_BLOCKS}): 0 entries, 0 B within 29.49 μs
INFO  [2023-01-26 18:08:14,811] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=testDataset2, name=testDataset2]
INFO  [2023-01-26 18:08:14,813] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker testDataset1.worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:14,813] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker testDataset1.worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:14,813] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:14,819] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3
INFO  [2023-01-26 18:08:14,830] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3:DATASET}): 0 entries, 0 B within 98.74 μs
INFO  [2023-01-26 18:08:14,830] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3:SECONDARY_IDS}): 0 entries, 0 B within 65.50 μs
INFO  [2023-01-26 18:08:14,830] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3:TABLES}): 0 entries, 0 B within 46.64 μs
INFO  [2023-01-26 18:08:14,831] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 50.50 μs
INFO  [2023-01-26 18:08:14,831] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3:IMPORTS}): 0 entries, 0 B within 49.29 μs
INFO  [2023-01-26 18:08:14,831] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3:CONCEPTS}): 0 entries, 0 B within 44.39 μs
INFO  [2023-01-26 18:08:14,831] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:14,831] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big ID_MAPPING(EntityIdMap): 0 entries, 0 B within 48.62 μs
INFO  [2023-01-26 18:08:14,831] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3:STRUCTURE}): 0 entries, 0 B within 45.29 μs
INFO  [2023-01-26 18:08:14,831] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3:WORKER_TO_BUCKETS}): 0 entries, 0 B within 49.03 μs
INFO  [2023-01-26 18:08:14,831] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3:PRIMARY_DICTIONARY}): 0 entries, 0 B within 38.10 μs
INFO  [2023-01-26 18:08:14,835] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8
INFO  [2023-01-26 18:08:14,840] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f
INFO  [2023-01-26 18:08:14,851] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8:DATASET}): 0 entries, 0 B within 72.16 μs
INFO  [2023-01-26 18:08:14,851] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8:SECONDARY_IDS}): 0 entries, 0 B within 25.17 μs
INFO  [2023-01-26 18:08:14,851] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8:TABLES}): 0 entries, 0 B within 19.83 μs
INFO  [2023-01-26 18:08:14,851] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 21.39 μs
INFO  [2023-01-26 18:08:14,851] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8:IMPORTS}): 0 entries, 0 B within 26.00 μs
INFO  [2023-01-26 18:08:14,851] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8:CONCEPTS}): 0 entries, 0 B within 47.37 μs
INFO  [2023-01-26 18:08:14,851] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:14,851] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8:WORKER}): 0 entries, 0 B within 24.46 μs
INFO  [2023-01-26 18:08:14,851] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8:BUCKETS}): 0 entries, 0 B within 23.36 μs
INFO  [2023-01-26 18:08:14,851] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8:C_BLOCKS}): 0 entries, 0 B within 25.38 μs
INFO  [2023-01-26 18:08:14,852] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=testDataset3, name=testDataset3]
INFO  [2023-01-26 18:08:14,855] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker testDataset2.worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:14,855] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker testDataset2.worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:14,855] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:14,857] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4
INFO  [2023-01-26 18:08:14,860] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f:DATASET}): 0 entries, 0 B within 84.85 μs
INFO  [2023-01-26 18:08:14,860] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f:SECONDARY_IDS}): 0 entries, 0 B within 40.75 μs
INFO  [2023-01-26 18:08:14,860] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f:TABLES}): 0 entries, 0 B within 37.84 μs
INFO  [2023-01-26 18:08:14,860] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 35.21 μs
INFO  [2023-01-26 18:08:14,860] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f:IMPORTS}): 0 entries, 0 B within 29.31 μs
INFO  [2023-01-26 18:08:14,860] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f:CONCEPTS}): 0 entries, 0 B within 32.75 μs
INFO  [2023-01-26 18:08:14,860] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:14,860] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f:WORKER}): 0 entries, 0 B within 31.17 μs
INFO  [2023-01-26 18:08:14,860] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f:BUCKETS}): 0 entries, 0 B within 29.32 μs
INFO  [2023-01-26 18:08:14,860] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f:C_BLOCKS}): 0 entries, 0 B within 30.03 μs
INFO  [2023-01-26 18:08:14,867] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=testDataset3, name=testDataset3]
INFO  [2023-01-26 18:08:14,867] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4:DATASET}): 0 entries, 0 B within 96.03 μs
INFO  [2023-01-26 18:08:14,867] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4:SECONDARY_IDS}): 0 entries, 0 B within 49.04 μs
INFO  [2023-01-26 18:08:14,867] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4:TABLES}): 0 entries, 0 B within 44.23 μs
INFO  [2023-01-26 18:08:14,867] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 69.24 μs
INFO  [2023-01-26 18:08:14,867] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4:IMPORTS}): 0 entries, 0 B within 42.54 μs
INFO  [2023-01-26 18:08:14,867] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4:CONCEPTS}): 0 entries, 0 B within 42.66 μs
INFO  [2023-01-26 18:08:14,867] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:14,867] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big ID_MAPPING(EntityIdMap): 0 entries, 0 B within 47.77 μs
INFO  [2023-01-26 18:08:14,868] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4:STRUCTURE}): 0 entries, 0 B within 49.72 μs
INFO  [2023-01-26 18:08:14,868] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4:WORKER_TO_BUCKETS}): 0 entries, 0 B within 49.63 μs
INFO  [2023-01-26 18:08:14,868] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4:PRIMARY_DICTIONARY}): 0 entries, 0 B within 37.03 μs
INFO  [2023-01-26 18:08:14,868] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker testDataset2.worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:14,868] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker testDataset2.worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:14,868] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:14,873] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac
INFO  [2023-01-26 18:08:14,891] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac:DATASET}): 0 entries, 0 B within 86.66 μs
INFO  [2023-01-26 18:08:14,891] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac:SECONDARY_IDS}): 0 entries, 0 B within 25.45 μs
INFO  [2023-01-26 18:08:14,891] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac:TABLES}): 0 entries, 0 B within 18.54 μs
INFO  [2023-01-26 18:08:14,891] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 21.76 μs
INFO  [2023-01-26 18:08:14,891] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac:IMPORTS}): 0 entries, 0 B within 18.18 μs
INFO  [2023-01-26 18:08:14,891] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac:CONCEPTS}): 0 entries, 0 B within 17.29 μs
INFO  [2023-01-26 18:08:14,891] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:14,891] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac:WORKER}): 0 entries, 0 B within 18.51 μs
INFO  [2023-01-26 18:08:14,892] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac:BUCKETS}): 0 entries, 0 B within 17.10 μs
INFO  [2023-01-26 18:08:14,892] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac:C_BLOCKS}): 0 entries, 0 B within 17.16 μs
INFO  [2023-01-26 18:08:14,892] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=testDataset4, name=testDataset4]
INFO  [2023-01-26 18:08:14,895] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker testDataset3.worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:14,895] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker testDataset3.worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:14,895] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:14,901] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a
INFO  [2023-01-26 18:08:14,906] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5
INFO  [2023-01-26 18:08:14,915] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5:DATASET}): 0 entries, 0 B within 108.1 μs
INFO  [2023-01-26 18:08:14,915] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5:SECONDARY_IDS}): 0 entries, 0 B within 62.79 μs
INFO  [2023-01-26 18:08:14,915] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5:TABLES}): 0 entries, 0 B within 45.90 μs
INFO  [2023-01-26 18:08:14,916] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 47.71 μs
INFO  [2023-01-26 18:08:14,916] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5:IMPORTS}): 0 entries, 0 B within 48.20 μs
INFO  [2023-01-26 18:08:14,916] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5:CONCEPTS}): 0 entries, 0 B within 48.84 μs
INFO  [2023-01-26 18:08:14,916] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:14,916] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big ID_MAPPING(EntityIdMap): 0 entries, 0 B within 62.41 μs
INFO  [2023-01-26 18:08:14,916] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5:STRUCTURE}): 0 entries, 0 B within 41.52 μs
INFO  [2023-01-26 18:08:14,916] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5:WORKER_TO_BUCKETS}): 0 entries, 0 B within 38.94 μs
INFO  [2023-01-26 18:08:14,916] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5:PRIMARY_DICTIONARY}): 0 entries, 0 B within 37.77 μs
INFO  [2023-01-26 18:08:14,942] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0
INFO  [2023-01-26 18:08:14,952] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a:DATASET}): 0 entries, 0 B within 86.02 μs
INFO  [2023-01-26 18:08:14,953] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a:SECONDARY_IDS}): 0 entries, 0 B within 34.98 μs
INFO  [2023-01-26 18:08:14,953] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a:TABLES}): 0 entries, 0 B within 28.28 μs
INFO  [2023-01-26 18:08:14,953] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 47.91 μs
INFO  [2023-01-26 18:08:14,953] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a:IMPORTS}): 0 entries, 0 B within 35.21 μs
INFO  [2023-01-26 18:08:14,953] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a:CONCEPTS}): 0 entries, 0 B within 23.62 μs
INFO  [2023-01-26 18:08:14,953] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:14,953] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a:WORKER}): 0 entries, 0 B within 24.86 μs
INFO  [2023-01-26 18:08:14,953] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a:BUCKETS}): 0 entries, 0 B within 21.96 μs
INFO  [2023-01-26 18:08:14,953] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a:C_BLOCKS}): 0 entries, 0 B within 23.39 μs
INFO  [2023-01-26 18:08:14,954] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=testDataset4, name=testDataset4]
INFO  [2023-01-26 18:08:14,955] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker testDataset3.worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:14,955] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker testDataset3.worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:14,955] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:14,970] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0:DATASET}): 0 entries, 0 B within 99.01 μs
INFO  [2023-01-26 18:08:14,970] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0:SECONDARY_IDS}): 0 entries, 0 B within 36.91 μs
INFO  [2023-01-26 18:08:14,970] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0:TABLES}): 0 entries, 0 B within 27.21 μs
INFO  [2023-01-26 18:08:14,970] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 33.22 μs
INFO  [2023-01-26 18:08:14,970] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0:IMPORTS}): 0 entries, 0 B within 25.02 μs
INFO  [2023-01-26 18:08:14,970] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0:CONCEPTS}): 0 entries, 0 B within 32.66 μs
INFO  [2023-01-26 18:08:14,970] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:14,970] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0:WORKER}): 0 entries, 0 B within 22.54 μs
INFO  [2023-01-26 18:08:14,970] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0:BUCKETS}): 0 entries, 0 B within 21.37 μs
INFO  [2023-01-26 18:08:14,970] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0:C_BLOCKS}): 0 entries, 0 B within 20.71 μs
INFO  [2023-01-26 18:08:14,971] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=testDataset5, name=testDataset5]
INFO  [2023-01-26 18:08:14,974] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker testDataset4.worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:14,974] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker testDataset4.worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:14,974] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:14,978] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6
INFO  [2023-01-26 18:08:14,983] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e
INFO  [2023-01-26 18:08:14,989] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6:DATASET}): 0 entries, 0 B within 74.80 μs
INFO  [2023-01-26 18:08:15,005] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e
INFO  [2023-01-26 18:08:15,005] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6:SECONDARY_IDS}): 0 entries, 0 B within 107.8 μs
INFO  [2023-01-26 18:08:15,005] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6:TABLES}): 0 entries, 0 B within 50.07 μs
INFO  [2023-01-26 18:08:15,006] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 52.40 μs
INFO  [2023-01-26 18:08:15,006] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6:IMPORTS}): 0 entries, 0 B within 48.23 μs
INFO  [2023-01-26 18:08:15,006] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6:CONCEPTS}): 0 entries, 0 B within 43.43 μs
INFO  [2023-01-26 18:08:15,006] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:15,006] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big ID_MAPPING(EntityIdMap): 0 entries, 0 B within 48.10 μs
INFO  [2023-01-26 18:08:15,006] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6:STRUCTURE}): 0 entries, 0 B within 49.56 μs
INFO  [2023-01-26 18:08:15,006] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6:WORKER_TO_BUCKETS}): 0 entries, 0 B within 39.05 μs
INFO  [2023-01-26 18:08:15,006] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6:PRIMARY_DICTIONARY}): 0 entries, 0 B within 37.54 μs
INFO  [2023-01-26 18:08:15,024] com.bakdata.conquery.io.storage.MetaStorage: Remove User = user.userDelete@test$2eemail
INFO  [2023-01-26 18:08:15,025] com.bakdata.conquery.resources.admin.rest.AdminProcessor: Deleting Role[role.roleDelete]
INFO  [2023-01-26 18:08:15,025] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e:DATASET}): 0 entries, 0 B within 94.39 μs
INFO  [2023-01-26 18:08:15,025] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e:SECONDARY_IDS}): 0 entries, 0 B within 38.53 μs
INFO  [2023-01-26 18:08:15,025] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e:TABLES}): 0 entries, 0 B within 29.95 μs
INFO  [2023-01-26 18:08:15,026] com.bakdata.conquery.integration.tests.RestartTest: Shutting down for restart
INFO  [2023-01-26 18:08:15,026] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 35.21 μs
INFO  [2023-01-26 18:08:15,026] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e:IMPORTS}): 0 entries, 0 B within 28.05 μs
INFO  [2023-01-26 18:08:15,026] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e:CONCEPTS}): 0 entries, 0 B within 26.66 μs
INFO  [2023-01-26 18:08:15,026] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:15,026] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e:WORKER}): 0 entries, 0 B within 28.31 μs
INFO  [2023-01-26 18:08:15,026] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e:BUCKETS}): 0 entries, 0 B within 26.93 μs
INFO  [2023-01-26 18:08:15,026] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e:C_BLOCKS}): 0 entries, 0 B within 29.68 μs
INFO  [2023-01-26 18:08:15,027] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=testDataset5, name=testDataset5]
INFO  [2023-01-26 18:08:15,029] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker testDataset4.worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:15,029] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker testDataset4.worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:15,029] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:15,030] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e:DATASET}): 0 entries, 0 B within 71.12 μs
INFO  [2023-01-26 18:08:15,030] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e:SECONDARY_IDS}): 0 entries, 0 B within 42.04 μs
INFO  [2023-01-26 18:08:15,030] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e:TABLES}): 0 entries, 0 B within 33.57 μs
INFO  [2023-01-26 18:08:15,030] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 38.21 μs
INFO  [2023-01-26 18:08:15,030] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e:IMPORTS}): 0 entries, 0 B within 33.50 μs
INFO  [2023-01-26 18:08:15,030] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e:CONCEPTS}): 0 entries, 0 B within 29.52 μs
INFO  [2023-01-26 18:08:15,030] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:15,030] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e:WORKER}): 0 entries, 0 B within 23.59 μs
INFO  [2023-01-26 18:08:15,030] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e:BUCKETS}): 0 entries, 0 B within 17.73 μs
INFO  [2023-01-26 18:08:15,030] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e:C_BLOCKS}): 0 entries, 0 B within 17.23 μs
INFO  [2023-01-26 18:08:15,031] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=testDataset6, name=testDataset6]
INFO  [2023-01-26 18:08:15,032] org.eclipse.jetty.server.AbstractConnector: Stopped application@48fd156e{HTTP/1.1, (http/1.1)}{0.0.0.0:39407}
INFO  [2023-01-26 18:08:15,032] org.eclipse.jetty.server.AbstractConnector: Stopped admin@15c2ea37{HTTP/1.1, (http/1.1)}{0.0.0.0:41661}
INFO  [2023-01-26 18:08:15,037] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker testDataset5.worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:15,038] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker testDataset5.worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:15,038] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:15,042] org.eclipse.jetty.server.handler.ContextHandler: Stopped i.d.j.MutableServletContextHandler@76c38ecc{/,null,STOPPED}
INFO  [2023-01-26 18:08:15,044] org.eclipse.jetty.server.handler.ContextHandler: Stopped i.d.j.MutableServletContextHandler@35b4f63a{/,null,STOPPED}
INFO  [2023-01-26 18:08:15,044] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast shard-node1
INFO  [2023-01-26 18:08:15,055] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced
INFO  [2023-01-26 18:08:15,061] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a
INFO  [2023-01-26 18:08:15,077] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a:DATASET}): 0 entries, 0 B within 62.60 μs
INFO  [2023-01-26 18:08:15,077] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a:SECONDARY_IDS}): 0 entries, 0 B within 36.03 μs
INFO  [2023-01-26 18:08:15,077] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a:TABLES}): 0 entries, 0 B within 33.28 μs
INFO  [2023-01-26 18:08:15,077] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 34.69 μs
INFO  [2023-01-26 18:08:15,077] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced:DATASET}): 0 entries, 0 B within 69.95 μs
INFO  [2023-01-26 18:08:15,077] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a:IMPORTS}): 0 entries, 0 B within 33.88 μs
INFO  [2023-01-26 18:08:15,077] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced:SECONDARY_IDS}): 0 entries, 0 B within 55.90 μs
INFO  [2023-01-26 18:08:15,077] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a:CONCEPTS}): 0 entries, 0 B within 28.74 μs
INFO  [2023-01-26 18:08:15,077] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:15,077] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced:TABLES}): 0 entries, 0 B within 38.05 μs
INFO  [2023-01-26 18:08:15,077] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a:WORKER}): 0 entries, 0 B within 26.50 μs
INFO  [2023-01-26 18:08:15,077] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a:BUCKETS}): 0 entries, 0 B within 31.29 μs
INFO  [2023-01-26 18:08:15,077] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 58.83 μs
INFO  [2023-01-26 18:08:15,077] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a:C_BLOCKS}): 0 entries, 0 B within 25.94 μs
INFO  [2023-01-26 18:08:15,078] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced:IMPORTS}): 0 entries, 0 B within 39.79 μs
INFO  [2023-01-26 18:08:15,078] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced:CONCEPTS}): 0 entries, 0 B within 35.66 μs
INFO  [2023-01-26 18:08:15,078] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:15,078] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced:WORKER}): 0 entries, 0 B within 34.73 μs
INFO  [2023-01-26 18:08:15,078] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced:BUCKETS}): 0 entries, 0 B within 32.24 μs
INFO  [2023-01-26 18:08:15,078] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced:C_BLOCKS}): 0 entries, 0 B within 30.16 μs
INFO  [2023-01-26 18:08:15,078] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=testDataset6, name=testDataset6]
WARN  [2023-01-26 18:08:15,079] com.bakdata.conquery.models.jobs.JobExecutor: Tried to add a job to a closed JobManager: reacting to ForwardToWorker(workerId=testDataset6.worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a, text=RequestConsistency)
INFO  [2023-01-26 18:08:15,080] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker testDataset5.worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:15,080] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker testDataset5.worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:15,080] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:15,098] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7
INFO  [2023-01-26 18:08:15,114] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7:DATASET}): 0 entries, 0 B within 69.18 μs
INFO  [2023-01-26 18:08:15,114] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7:SECONDARY_IDS}): 0 entries, 0 B within 30.63 μs
INFO  [2023-01-26 18:08:15,114] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7:TABLES}): 0 entries, 0 B within 19.24 μs
INFO  [2023-01-26 18:08:15,114] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 23.96 μs
INFO  [2023-01-26 18:08:15,114] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7:IMPORTS}): 0 entries, 0 B within 18.46 μs
INFO  [2023-01-26 18:08:15,114] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7:CONCEPTS}): 0 entries, 0 B within 20.18 μs
INFO  [2023-01-26 18:08:15,114] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:15,114] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7:WORKER}): 0 entries, 0 B within 18.69 μs
INFO  [2023-01-26 18:08:15,114] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7:BUCKETS}): 0 entries, 0 B within 18.22 μs
INFO  [2023-01-26 18:08:15,115] com.bakdata.conquery.io.storage.xodus.stores.CachedStore: 	loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7:C_BLOCKS}): 0 entries, 0 B within 17.16 μs
INFO  [2023-01-26 18:08:15,117] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker testDataset6.worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:15,117] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker testDataset6.worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:15,117] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:15,132] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow shard-node1
INFO  [2023-01-26 18:08:15,179] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea
INFO  [2023-01-26 18:08:15,205] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea
INFO  [2023-01-26 18:08:15,285] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea:DATASET}
INFO  [2023-01-26 18:08:15,285] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea:SECONDARY_IDS}
INFO  [2023-01-26 18:08:15,285] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea:TABLES}
INFO  [2023-01-26 18:08:15,285] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea:DICTIONARIES_META}
INFO  [2023-01-26 18:08:15,285] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea:DICTIONARIES_DATA}
INFO  [2023-01-26 18:08:15,285] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea:IMPORTS}
INFO  [2023-01-26 18:08:15,285] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea:CONCEPTS}
INFO  [2023-01-26 18:08:15,285] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea:WORKER}
INFO  [2023-01-26 18:08:15,285] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea:BUCKETS}
INFO  [2023-01-26 18:08:15,285] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea:C_BLOCKS}
INFO  [2023-01-26 18:08:15,285] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea
INFO  [2023-01-26 18:08:15,294] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a
INFO  [2023-01-26 18:08:15,378] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a
INFO  [2023-01-26 18:08:15,478] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a:DATASET}
INFO  [2023-01-26 18:08:15,478] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a:SECONDARY_IDS}
INFO  [2023-01-26 18:08:15,478] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a:TABLES}
INFO  [2023-01-26 18:08:15,478] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a:DICTIONARIES_META}
INFO  [2023-01-26 18:08:15,478] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a:DICTIONARIES_DATA}
INFO  [2023-01-26 18:08:15,479] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a:IMPORTS}
INFO  [2023-01-26 18:08:15,479] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a:CONCEPTS}
INFO  [2023-01-26 18:08:15,479] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a:WORKER}
INFO  [2023-01-26 18:08:15,479] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a:BUCKETS}
INFO  [2023-01-26 18:08:15,479] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a:C_BLOCKS}
INFO  [2023-01-26 18:08:15,479] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a
INFO  [2023-01-26 18:08:15,486] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd
INFO  [2023-01-26 18:08:15,510] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd
INFO  [2023-01-26 18:08:15,610] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd:DATASET}
INFO  [2023-01-26 18:08:15,610] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd:SECONDARY_IDS}
INFO  [2023-01-26 18:08:15,610] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd:TABLES}
INFO  [2023-01-26 18:08:15,610] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd:DICTIONARIES_META}
INFO  [2023-01-26 18:08:15,610] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd:DICTIONARIES_DATA}
INFO  [2023-01-26 18:08:15,610] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd:IMPORTS}
INFO  [2023-01-26 18:08:15,610] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd:CONCEPTS}
INFO  [2023-01-26 18:08:15,610] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd:WORKER}
INFO  [2023-01-26 18:08:15,610] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd:BUCKETS}
INFO  [2023-01-26 18:08:15,610] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd:C_BLOCKS}
INFO  [2023-01-26 18:08:15,610] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd
INFO  [2023-01-26 18:08:15,616] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0
INFO  [2023-01-26 18:08:15,672] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0
INFO  [2023-01-26 18:08:15,772] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0:DATASET}
INFO  [2023-01-26 18:08:15,772] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0:SECONDARY_IDS}
INFO  [2023-01-26 18:08:15,772] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0:TABLES}
INFO  [2023-01-26 18:08:15,772] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0:DICTIONARIES_META}
INFO  [2023-01-26 18:08:15,772] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0:DICTIONARIES_DATA}
INFO  [2023-01-26 18:08:15,772] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0:IMPORTS}
INFO  [2023-01-26 18:08:15,772] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0:CONCEPTS}
INFO  [2023-01-26 18:08:15,772] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0:WORKER}
INFO  [2023-01-26 18:08:15,772] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0:BUCKETS}
INFO  [2023-01-26 18:08:15,772] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0:C_BLOCKS}
INFO  [2023-01-26 18:08:15,772] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0
INFO  [2023-01-26 18:08:15,783] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac
INFO  [2023-01-26 18:08:15,810] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac
INFO  [2023-01-26 18:08:15,910] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac:DATASET}
INFO  [2023-01-26 18:08:15,910] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac:SECONDARY_IDS}
INFO  [2023-01-26 18:08:15,910] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac:TABLES}
INFO  [2023-01-26 18:08:15,910] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac:DICTIONARIES_META}
INFO  [2023-01-26 18:08:15,910] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac:DICTIONARIES_DATA}
INFO  [2023-01-26 18:08:15,910] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac:IMPORTS}
INFO  [2023-01-26 18:08:15,910] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac:CONCEPTS}
INFO  [2023-01-26 18:08:15,910] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac:WORKER}
INFO  [2023-01-26 18:08:15,910] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac:BUCKETS}
INFO  [2023-01-26 18:08:15,910] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac:C_BLOCKS}
INFO  [2023-01-26 18:08:15,910] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac
INFO  [2023-01-26 18:08:15,917] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e
INFO  [2023-01-26 18:08:15,931] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e
INFO  [2023-01-26 18:08:16,031] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e:DATASET}
INFO  [2023-01-26 18:08:16,031] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e:SECONDARY_IDS}
INFO  [2023-01-26 18:08:16,031] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e:TABLES}
INFO  [2023-01-26 18:08:16,031] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e:DICTIONARIES_META}
INFO  [2023-01-26 18:08:16,032] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e:DICTIONARIES_DATA}
INFO  [2023-01-26 18:08:16,032] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e:IMPORTS}
INFO  [2023-01-26 18:08:16,032] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e:CONCEPTS}
INFO  [2023-01-26 18:08:16,032] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e:WORKER}
INFO  [2023-01-26 18:08:16,032] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e:BUCKETS}
INFO  [2023-01-26 18:08:16,032] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e:C_BLOCKS}
INFO  [2023-01-26 18:08:16,032] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e
INFO  [2023-01-26 18:08:16,042] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8
INFO  [2023-01-26 18:08:16,053] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8
INFO  [2023-01-26 18:08:16,054] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8:DATASET}
INFO  [2023-01-26 18:08:16,054] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8:SECONDARY_IDS}
INFO  [2023-01-26 18:08:16,054] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8:TABLES}
INFO  [2023-01-26 18:08:16,054] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8:DICTIONARIES_META}
INFO  [2023-01-26 18:08:16,054] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8:DICTIONARIES_DATA}
INFO  [2023-01-26 18:08:16,054] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8:IMPORTS}
INFO  [2023-01-26 18:08:16,054] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8:CONCEPTS}
INFO  [2023-01-26 18:08:16,054] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8:WORKER}
INFO  [2023-01-26 18:08:16,054] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8:BUCKETS}
INFO  [2023-01-26 18:08:16,054] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8:C_BLOCKS}
INFO  [2023-01-26 18:08:16,054] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8
INFO  [2023-01-26 18:08:16,061] com.bakdata.conquery.commands.ShardNode: Connection was closed by ManagerNode
INFO  [2023-01-26 18:08:16,061] com.bakdata.conquery.commands.ShardNode: Disconnected from ManagerNode
INFO  [2023-01-26 18:08:16,062] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast shard-node0
INFO  [2023-01-26 18:08:16,062] com.bakdata.conquery.commands.ManagerNode: Client 'null' disconnected 
INFO  [2023-01-26 18:08:16,117] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow shard-node0
INFO  [2023-01-26 18:08:16,218] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a
INFO  [2023-01-26 18:08:16,255] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a
INFO  [2023-01-26 18:08:16,355] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a:DATASET}
INFO  [2023-01-26 18:08:16,355] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a:SECONDARY_IDS}
INFO  [2023-01-26 18:08:16,355] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a:TABLES}
INFO  [2023-01-26 18:08:16,355] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a:DICTIONARIES_META}
INFO  [2023-01-26 18:08:16,355] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a:DICTIONARIES_DATA}
INFO  [2023-01-26 18:08:16,355] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a:IMPORTS}
INFO  [2023-01-26 18:08:16,355] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a:CONCEPTS}
INFO  [2023-01-26 18:08:16,355] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a:WORKER}
INFO  [2023-01-26 18:08:16,355] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a:BUCKETS}
INFO  [2023-01-26 18:08:16,355] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a:C_BLOCKS}
INFO  [2023-01-26 18:08:16,355] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a
INFO  [2023-01-26 18:08:16,364] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f
INFO  [2023-01-26 18:08:16,413] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f
INFO  [2023-01-26 18:08:16,414] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f:DATASET}
INFO  [2023-01-26 18:08:16,414] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f:SECONDARY_IDS}
INFO  [2023-01-26 18:08:16,414] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f:TABLES}
INFO  [2023-01-26 18:08:16,414] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f:DICTIONARIES_META}
INFO  [2023-01-26 18:08:16,414] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f:DICTIONARIES_DATA}
INFO  [2023-01-26 18:08:16,414] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f:IMPORTS}
INFO  [2023-01-26 18:08:16,414] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f:CONCEPTS}
INFO  [2023-01-26 18:08:16,414] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f:WORKER}
INFO  [2023-01-26 18:08:16,414] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f:BUCKETS}
INFO  [2023-01-26 18:08:16,414] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f:C_BLOCKS}
INFO  [2023-01-26 18:08:16,414] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f
INFO  [2023-01-26 18:08:16,421] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f
INFO  [2023-01-26 18:08:16,468] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f
INFO  [2023-01-26 18:08:16,562] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f:DATASET}
INFO  [2023-01-26 18:08:16,562] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f:SECONDARY_IDS}
INFO  [2023-01-26 18:08:16,562] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f:TABLES}
INFO  [2023-01-26 18:08:16,562] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f:DICTIONARIES_META}
INFO  [2023-01-26 18:08:16,562] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f:DICTIONARIES_DATA}
INFO  [2023-01-26 18:08:16,562] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f:IMPORTS}
INFO  [2023-01-26 18:08:16,562] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f:CONCEPTS}
INFO  [2023-01-26 18:08:16,562] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f:WORKER}
INFO  [2023-01-26 18:08:16,562] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f:BUCKETS}
INFO  [2023-01-26 18:08:16,562] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f:C_BLOCKS}
INFO  [2023-01-26 18:08:16,562] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f
INFO  [2023-01-26 18:08:16,569] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced
INFO  [2023-01-26 18:08:16,584] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced
INFO  [2023-01-26 18:08:16,684] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced:DATASET}
INFO  [2023-01-26 18:08:16,684] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced:SECONDARY_IDS}
INFO  [2023-01-26 18:08:16,684] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced:TABLES}
INFO  [2023-01-26 18:08:16,684] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced:DICTIONARIES_META}
INFO  [2023-01-26 18:08:16,684] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced:DICTIONARIES_DATA}
INFO  [2023-01-26 18:08:16,684] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced:IMPORTS}
INFO  [2023-01-26 18:08:16,684] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced:CONCEPTS}
INFO  [2023-01-26 18:08:16,684] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced:WORKER}
INFO  [2023-01-26 18:08:16,684] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced:BUCKETS}
INFO  [2023-01-26 18:08:16,684] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced:C_BLOCKS}
INFO  [2023-01-26 18:08:16,684] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced
INFO  [2023-01-26 18:08:16,691] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33
INFO  [2023-01-26 18:08:16,739] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33
INFO  [2023-01-26 18:08:16,785] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33:DATASET}
INFO  [2023-01-26 18:08:16,786] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33:SECONDARY_IDS}
INFO  [2023-01-26 18:08:16,786] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33:TABLES}
INFO  [2023-01-26 18:08:16,786] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33:DICTIONARIES_META}
INFO  [2023-01-26 18:08:16,786] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33:DICTIONARIES_DATA}
INFO  [2023-01-26 18:08:16,786] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33:IMPORTS}
INFO  [2023-01-26 18:08:16,786] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33:CONCEPTS}
INFO  [2023-01-26 18:08:16,786] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33:WORKER}
INFO  [2023-01-26 18:08:16,786] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33:BUCKETS}
INFO  [2023-01-26 18:08:16,786] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33:C_BLOCKS}
INFO  [2023-01-26 18:08:16,786] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33
INFO  [2023-01-26 18:08:16,792] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7
INFO  [2023-01-26 18:08:16,817] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7
INFO  [2023-01-26 18:08:16,917] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7:DATASET}
INFO  [2023-01-26 18:08:16,917] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7:SECONDARY_IDS}
INFO  [2023-01-26 18:08:16,917] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7:TABLES}
INFO  [2023-01-26 18:08:16,917] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7:DICTIONARIES_META}
INFO  [2023-01-26 18:08:16,917] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7:DICTIONARIES_DATA}
INFO  [2023-01-26 18:08:16,917] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7:IMPORTS}
INFO  [2023-01-26 18:08:16,917] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7:CONCEPTS}
INFO  [2023-01-26 18:08:16,917] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7:WORKER}
INFO  [2023-01-26 18:08:16,917] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7:BUCKETS}
INFO  [2023-01-26 18:08:16,917] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7:C_BLOCKS}
INFO  [2023-01-26 18:08:16,917] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7
INFO  [2023-01-26 18:08:16,924] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e
INFO  [2023-01-26 18:08:16,929] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e
INFO  [2023-01-26 18:08:17,029] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e:DATASET}
INFO  [2023-01-26 18:08:17,029] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e:SECONDARY_IDS}
INFO  [2023-01-26 18:08:17,029] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e:TABLES}
INFO  [2023-01-26 18:08:17,029] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e:DICTIONARIES_META}
INFO  [2023-01-26 18:08:17,029] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e:DICTIONARIES_DATA}
INFO  [2023-01-26 18:08:17,029] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e:IMPORTS}
INFO  [2023-01-26 18:08:17,029] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e:CONCEPTS}
INFO  [2023-01-26 18:08:17,029] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e:WORKER}
INFO  [2023-01-26 18:08:17,029] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e:BUCKETS}
INFO  [2023-01-26 18:08:17,029] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e:C_BLOCKS}
INFO  [2023-01-26 18:08:17,029] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e
INFO  [2023-01-26 18:08:17,036] com.bakdata.conquery.commands.ShardNode: Connection was closed by ManagerNode
INFO  [2023-01-26 18:08:17,036] com.bakdata.conquery.commands.ShardNode: Disconnected from ManagerNode
INFO  [2023-01-26 18:08:17,036] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast ManagerNode
INFO  [2023-01-26 18:08:17,036] com.bakdata.conquery.commands.ManagerNode: Client 'null' disconnected 
INFO  [2023-01-26 18:08:17,118] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow ManagerNode
INFO  [2023-01-26 18:08:17,139] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast testDataset1
INFO  [2023-01-26 18:08:17,150] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow testDataset1
INFO  [2023-01-26 18:08:17,249] com.bakdata.conquery.models.worker.Namespace: Closing namespace storage of testDataset1
INFO  [2023-01-26 18:08:17,250] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1:DATASET}
INFO  [2023-01-26 18:08:17,250] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1:SECONDARY_IDS}
INFO  [2023-01-26 18:08:17,250] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1:TABLES}
INFO  [2023-01-26 18:08:17,250] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1:DICTIONARIES_META}
INFO  [2023-01-26 18:08:17,250] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1:DICTIONARIES_DATA}
INFO  [2023-01-26 18:08:17,250] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1:IMPORTS}
INFO  [2023-01-26 18:08:17,250] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1:CONCEPTS}
INFO  [2023-01-26 18:08:17,250] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1:ID_MAPPING_META}
INFO  [2023-01-26 18:08:17,250] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1:ID_MAPPING_DATA}
INFO  [2023-01-26 18:08:17,250] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1:STRUCTURE}
INFO  [2023-01-26 18:08:17,250] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1:WORKER_TO_BUCKETS}
INFO  [2023-01-26 18:08:17,250] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1:PRIMARY_DICTIONARY}
INFO  [2023-01-26 18:08:17,250] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1
INFO  [2023-01-26 18:08:17,257] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast testDataset2
INFO  [2023-01-26 18:08:17,312] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow testDataset2
INFO  [2023-01-26 18:08:17,412] com.bakdata.conquery.models.worker.Namespace: Closing namespace storage of testDataset2
INFO  [2023-01-26 18:08:17,412] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2:DATASET}
INFO  [2023-01-26 18:08:17,412] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2:SECONDARY_IDS}
INFO  [2023-01-26 18:08:17,412] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2:TABLES}
INFO  [2023-01-26 18:08:17,412] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2:DICTIONARIES_META}
INFO  [2023-01-26 18:08:17,412] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2:DICTIONARIES_DATA}
INFO  [2023-01-26 18:08:17,412] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2:IMPORTS}
INFO  [2023-01-26 18:08:17,412] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2:CONCEPTS}
INFO  [2023-01-26 18:08:17,412] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2:ID_MAPPING_META}
INFO  [2023-01-26 18:08:17,412] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2:ID_MAPPING_DATA}
INFO  [2023-01-26 18:08:17,412] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2:STRUCTURE}
INFO  [2023-01-26 18:08:17,412] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2:WORKER_TO_BUCKETS}
INFO  [2023-01-26 18:08:17,412] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2:PRIMARY_DICTIONARY}
INFO  [2023-01-26 18:08:17,412] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2
INFO  [2023-01-26 18:08:17,419] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast RestartTest
INFO  [2023-01-26 18:08:17,444] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow RestartTest
INFO  [2023-01-26 18:08:17,486] com.bakdata.conquery.models.worker.Namespace: Closing namespace storage of RestartTest
INFO  [2023-01-26 18:08:17,486] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest:DATASET}
INFO  [2023-01-26 18:08:17,486] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest:SECONDARY_IDS}
INFO  [2023-01-26 18:08:17,486] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest:TABLES}
INFO  [2023-01-26 18:08:17,486] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest:DICTIONARIES_META}
INFO  [2023-01-26 18:08:17,486] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest:DICTIONARIES_DATA}
INFO  [2023-01-26 18:08:17,486] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest:IMPORTS}
INFO  [2023-01-26 18:08:17,486] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest:CONCEPTS}
INFO  [2023-01-26 18:08:17,486] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest:ID_MAPPING_META}
INFO  [2023-01-26 18:08:17,486] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest:ID_MAPPING_DATA}
INFO  [2023-01-26 18:08:17,486] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest:STRUCTURE}
INFO  [2023-01-26 18:08:17,486] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest:WORKER_TO_BUCKETS}
INFO  [2023-01-26 18:08:17,486] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest:PRIMARY_DICTIONARY}
INFO  [2023-01-26 18:08:17,486] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest
INFO  [2023-01-26 18:08:17,492] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast testDataset3
INFO  [2023-01-26 18:08:17,543] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow testDataset3
INFO  [2023-01-26 18:08:17,644] com.bakdata.conquery.models.worker.Namespace: Closing namespace storage of testDataset3
INFO  [2023-01-26 18:08:17,644] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3:DATASET}
INFO  [2023-01-26 18:08:17,644] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3:SECONDARY_IDS}
INFO  [2023-01-26 18:08:17,644] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3:TABLES}
INFO  [2023-01-26 18:08:17,644] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3:DICTIONARIES_META}
INFO  [2023-01-26 18:08:17,644] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3:DICTIONARIES_DATA}
INFO  [2023-01-26 18:08:17,644] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3:IMPORTS}
INFO  [2023-01-26 18:08:17,644] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3:CONCEPTS}
INFO  [2023-01-26 18:08:17,644] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3:ID_MAPPING_META}
INFO  [2023-01-26 18:08:17,644] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3:ID_MAPPING_DATA}
INFO  [2023-01-26 18:08:17,644] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3:STRUCTURE}
INFO  [2023-01-26 18:08:17,644] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3:WORKER_TO_BUCKETS}
INFO  [2023-01-26 18:08:17,644] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3:PRIMARY_DICTIONARY}
INFO  [2023-01-26 18:08:17,644] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3
INFO  [2023-01-26 18:08:17,651] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast testDataset4
INFO  [2023-01-26 18:08:17,685] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow testDataset4
INFO  [2023-01-26 18:08:17,785] com.bakdata.conquery.models.worker.Namespace: Closing namespace storage of testDataset4
INFO  [2023-01-26 18:08:17,785] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4:DATASET}
INFO  [2023-01-26 18:08:17,785] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4:SECONDARY_IDS}
INFO  [2023-01-26 18:08:17,785] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4:TABLES}
INFO  [2023-01-26 18:08:17,785] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4:DICTIONARIES_META}
INFO  [2023-01-26 18:08:17,785] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4:DICTIONARIES_DATA}
INFO  [2023-01-26 18:08:17,785] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4:IMPORTS}
INFO  [2023-01-26 18:08:17,785] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4:CONCEPTS}
INFO  [2023-01-26 18:08:17,785] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4:ID_MAPPING_META}
INFO  [2023-01-26 18:08:17,785] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4:ID_MAPPING_DATA}
INFO  [2023-01-26 18:08:17,785] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4:STRUCTURE}
INFO  [2023-01-26 18:08:17,785] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4:WORKER_TO_BUCKETS}
INFO  [2023-01-26 18:08:17,785] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4:PRIMARY_DICTIONARY}
INFO  [2023-01-26 18:08:17,785] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4
INFO  [2023-01-26 18:08:17,792] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast testDataset5
INFO  [2023-01-26 18:08:17,850] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow testDataset5
INFO  [2023-01-26 18:08:17,945] com.bakdata.conquery.models.worker.Namespace: Closing namespace storage of testDataset5
INFO  [2023-01-26 18:08:17,945] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5:DATASET}
INFO  [2023-01-26 18:08:17,945] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5:SECONDARY_IDS}
INFO  [2023-01-26 18:08:17,945] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5:TABLES}
INFO  [2023-01-26 18:08:17,945] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5:DICTIONARIES_META}
INFO  [2023-01-26 18:08:17,945] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5:DICTIONARIES_DATA}
INFO  [2023-01-26 18:08:17,945] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5:IMPORTS}
INFO  [2023-01-26 18:08:17,946] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5:CONCEPTS}
INFO  [2023-01-26 18:08:17,946] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5:ID_MAPPING_META}
INFO  [2023-01-26 18:08:17,946] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5:ID_MAPPING_DATA}
INFO  [2023-01-26 18:08:17,946] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5:STRUCTURE}
INFO  [2023-01-26 18:08:17,946] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5:WORKER_TO_BUCKETS}
INFO  [2023-01-26 18:08:17,946] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5:PRIMARY_DICTIONARY}
INFO  [2023-01-26 18:08:17,946] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5
INFO  [2023-01-26 18:08:17,953] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast testDataset6
INFO  [2023-01-26 18:08:18,016] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow testDataset6
INFO  [2023-01-26 18:08:18,116] com.bakdata.conquery.models.worker.Namespace: Closing namespace storage of testDataset6
INFO  [2023-01-26 18:08:18,116] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6:DATASET}
INFO  [2023-01-26 18:08:18,116] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6:SECONDARY_IDS}
INFO  [2023-01-26 18:08:18,116] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6:TABLES}
INFO  [2023-01-26 18:08:18,116] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6:DICTIONARIES_META}
INFO  [2023-01-26 18:08:18,116] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6:DICTIONARIES_DATA}
INFO  [2023-01-26 18:08:18,116] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6:IMPORTS}
INFO  [2023-01-26 18:08:18,116] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6:CONCEPTS}
INFO  [2023-01-26 18:08:18,116] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6:ID_MAPPING_META}
INFO  [2023-01-26 18:08:18,116] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6:ID_MAPPING_DATA}
INFO  [2023-01-26 18:08:18,116] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6:STRUCTURE}
INFO  [2023-01-26 18:08:18,116] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6:WORKER_TO_BUCKETS}
INFO  [2023-01-26 18:08:18,116] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6:PRIMARY_DICTIONARY}
INFO  [2023-01-26 18:08:18,116] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6
INFO  [2023-01-26 18:08:18,131] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/executions:EXECUTIONS}
INFO  [2023-01-26 18:08:18,131] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/executions
INFO  [2023-01-26 18:08:18,138] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/formConfigs:FORM_CONFIG}
INFO  [2023-01-26 18:08:18,138] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/formConfigs
INFO  [2023-01-26 18:08:18,149] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/users:AUTH_USER}
INFO  [2023-01-26 18:08:18,149] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/users
INFO  [2023-01-26 18:08:18,155] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/roles:AUTH_ROLE}
INFO  [2023-01-26 18:08:18,155] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/roles
INFO  [2023-01-26 18:08:18,161] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/groups:AUTH_GROUP}
INFO  [2023-01-26 18:08:18,161] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/groups
INFO  [2023-01-26 18:08:18,170] com.bakdata.conquery.integration.tests.RestartTest: Restarting
INFO  [2023-01-26 18:08:18,170] com.bakdata.conquery.util.support.TestConquery: Working in temporary directory /tmp/conqueryIntegrationTest12910953884258704183
[DEBUG] [2023-01-26 18:08:18]	c.b.c.c.StandaloneCommand	ManagerNode	Starting ManagerNode
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1:DATASET}): 1 entries, 51 B within 1.101 ms
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1:SECONDARY_IDS}): 0 entries, 0 B within 64.93 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1:TABLES}): 0 entries, 0 B within 49.34 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 45.00 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1:IMPORTS}): 0 entries, 0 B within 44.37 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1:CONCEPTS}): 0 entries, 0 B within 38.52 μs
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1	Done reading Dataset[label=testDataset1, name=testDataset1] / com.bakdata.conquery.io.storage.NamespaceStorage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1	While processing store ID_MAPPING_META:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1		loaded store cached big ID_MAPPING(EntityIdMap): 1 entries, 43 B within 5.193 ms
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1	While processing store STRUCTURE:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1:STRUCTURE}): 0 entries, 0 B within 60.84 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1	While processing store WORKER_TO_BUCKETS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1:WORKER_TO_BUCKETS}): 1 entries, 12 B within 121.7 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1	While processing store PRIMARY_DICTIONARY:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1:PRIMARY_DICTIONARY}): 0 entries, 0 B within 39.23 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1	DONE reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4:DATASET}): 1 entries, 51 B within 248.9 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4:SECONDARY_IDS}): 0 entries, 0 B within 66.99 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4:TABLES}): 0 entries, 0 B within 49.27 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 50.44 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4:IMPORTS}): 0 entries, 0 B within 46.74 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4:CONCEPTS}): 0 entries, 0 B within 43.14 μs
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4	Done reading Dataset[label=testDataset4, name=testDataset4] / com.bakdata.conquery.io.storage.NamespaceStorage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4	While processing store ID_MAPPING_META:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4		loaded store cached big ID_MAPPING(EntityIdMap): 1 entries, 43 B within 352.8 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4	While processing store STRUCTURE:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4:STRUCTURE}): 0 entries, 0 B within 62.71 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4	While processing store WORKER_TO_BUCKETS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4:WORKER_TO_BUCKETS}): 1 entries, 12 B within 73.57 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4	While processing store PRIMARY_DICTIONARY:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4:PRIMARY_DICTIONARY}): 0 entries, 0 B within 27.83 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4	DONE reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest:DATASET}): 1 entries, 49 B within 191.9 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest	While processing store SECONDARY_IDS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest:SECONDARY_IDS}): 1 entries, 70 B within 199.5 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3:DATASET}): 1 entries, 51 B within 109.2 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3:SECONDARY_IDS}): 0 entries, 0 B within 38.33 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest	While processing store TABLES:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3:TABLES}): 0 entries, 0 B within 27.14 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest:TABLES}): 1 entries, 187 B within 257.9 μs
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 33.38 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3:IMPORTS}): 0 entries, 0 B within 24.79 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3:CONCEPTS}): 0 entries, 0 B within 22.88 μs
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3	Done reading Dataset[label=testDataset3, name=testDataset3] / com.bakdata.conquery.io.storage.NamespaceStorage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3	While processing store ID_MAPPING_META:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3		loaded store cached big ID_MAPPING(EntityIdMap): 1 entries, 43 B within 190.0 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3	While processing store STRUCTURE:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3:STRUCTURE}): 0 entries, 0 B within 25.15 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3	While processing store WORKER_TO_BUCKETS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3:WORKER_TO_BUCKETS}): 1 entries, 12 B within 71.35 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3	While processing store PRIMARY_DICTIONARY:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3:PRIMARY_DICTIONARY}): 0 entries, 0 B within 33.63 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3	DONE reading Storage
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5:DATASET}): 1 entries, 51 B within 134.9 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5:SECONDARY_IDS}): 0 entries, 0 B within 44.14 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5:TABLES}): 0 entries, 0 B within 27.37 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 26.92 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5:IMPORTS}): 0 entries, 0 B within 23.13 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5:CONCEPTS}): 0 entries, 0 B within 22.60 μs
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5	Done reading Dataset[label=testDataset5, name=testDataset5] / com.bakdata.conquery.io.storage.NamespaceStorage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest	While processing store DICTIONARIES_META:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest		loaded store cached big DICTIONARIES(Dictionary): 1 entries, 43 B within 929.3 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5	While processing store ID_MAPPING_META:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5		loaded store cached big ID_MAPPING(EntityIdMap): 1 entries, 43 B within 194.5 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5	While processing store STRUCTURE:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5:STRUCTURE}): 0 entries, 0 B within 23.33 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5	While processing store WORKER_TO_BUCKETS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5:WORKER_TO_BUCKETS}): 1 entries, 12 B within 51.98 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5	While processing store PRIMARY_DICTIONARY:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5:PRIMARY_DICTIONARY}): 0 entries, 0 B within 24.27 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5	DONE reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6:DATASET}): 1 entries, 51 B within 124.1 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6:SECONDARY_IDS}): 0 entries, 0 B within 38.75 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6:TABLES}): 0 entries, 0 B within 34.29 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 34.38 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6:IMPORTS}): 0 entries, 0 B within 31.60 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6:CONCEPTS}): 0 entries, 0 B within 34.94 μs
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6	Done reading Dataset[label=testDataset6, name=testDataset6] / com.bakdata.conquery.io.storage.NamespaceStorage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2:DATASET}): 1 entries, 51 B within 94.49 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2:SECONDARY_IDS}): 0 entries, 0 B within 32.64 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2:TABLES}): 0 entries, 0 B within 24.71 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 25.72 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6	While processing store ID_MAPPING_META:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6		loaded store cached big ID_MAPPING(EntityIdMap): 1 entries, 43 B within 266.8 μs
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2:IMPORTS}): 0 entries, 0 B within 30.15 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2:CONCEPTS}): 0 entries, 0 B within 32.39 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6	While processing store STRUCTURE:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2	Done reading Dataset[label=testDataset2, name=testDataset2] / com.bakdata.conquery.io.storage.NamespaceStorage
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6:STRUCTURE}): 0 entries, 0 B within 48.68 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6	While processing store WORKER_TO_BUCKETS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6:WORKER_TO_BUCKETS}): 1 entries, 12 B within 67.79 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6	While processing store PRIMARY_DICTIONARY:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2	While processing store ID_MAPPING_META:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6:PRIMARY_DICTIONARY}): 0 entries, 0 B within 36.51 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6	DONE reading Storage
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2		loaded store cached big ID_MAPPING(EntityIdMap): 1 entries, 43 B within 188.5 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2	While processing store STRUCTURE:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2:STRUCTURE}): 0 entries, 0 B within 33.01 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2	While processing store WORKER_TO_BUCKETS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2:WORKER_TO_BUCKETS}): 1 entries, 12 B within 56.46 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2	While processing store PRIMARY_DICTIONARY:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2:PRIMARY_DICTIONARY}): 0 entries, 0 B within 26.98 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2	DONE reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest	While processing store IMPORTS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest:IMPORTS}): 1 entries, 466 B within 3.339 ms
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest	While processing store CONCEPTS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest:CONCEPTS}): 1 entries, 452 B within 4.553 ms
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest	Done reading Dataset[label=RestartTest, name=RestartTest] / com.bakdata.conquery.io.storage.NamespaceStorage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest	While processing store ID_MAPPING_META:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest		loaded store cached big ID_MAPPING(EntityIdMap): 1 entries, 43 B within 323.3 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest	While processing store STRUCTURE:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest:STRUCTURE}): 0 entries, 0 B within 32.52 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest	While processing store WORKER_TO_BUCKETS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest:WORKER_TO_BUCKETS}): 1 entries, 226 B within 157.3 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest	While processing store PRIMARY_DICTIONARY:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest:PRIMARY_DICTIONARY}): 1 entries, 97 B within 774.7 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest	DONE reading Storage
[INFO] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	ManagerNode	All WorkerStores loaded: [NamespacedStorage(pathName=dataset_testDataset1), NamespacedStorage(pathName=dataset_testDataset4), NamespacedStorage(pathName=dataset_testDataset3), NamespacedStorage(pathName=dataset_testDataset5), NamespacedStorage(pathName=dataset_testDataset6), NamespacedStorage(pathName=dataset_testDataset2), NamespacedStorage(pathName=dataset_RestartTest)]
[INFO] [2023-01-26 18:08:18]	c.b.c.c.ManagerNode	ManagerNode	Opening MetaStorage
[INFO] [2023-01-26 18:08:18]	c.b.c.c.ManagerNode	ManagerNode	Loading MetaStorage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store AUTH_USER:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/users:AUTH_USER}): 2 entries, 328 B within 1.325 ms
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store AUTH_ROLE:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/roles:AUTH_ROLE}): 1 entries, 150 B within 363.9 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store AUTH_GROUP:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/groups:AUTH_GROUP}): 1 entries, 203 B within 298.0 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store EXECUTIONS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/executions:EXECUTIONS}): 1 entries, 525 B within 8.343 ms
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store FORM_CONFIG:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/formConfigs:FORM_CONFIG}): 0 entries, 0 B within 59.87 μs
[INFO] [2023-01-26 18:08:18]	c.b.c.c.ManagerNode	ManagerNode	MetaStorage loaded com.bakdata.conquery.io.storage.MetaStorage@599a7657
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.a.AuthorizationController	ManagerNode	Security manager registered
[WARN] [2023-01-26 18:08:18]	c.b.c.m.a.d.DefaultInitialUserRealm	ManagerNode	
           §§
          §  §
         §    §
        §      §
       §  §§§§  §       You instantiated and are probably using a Shiro realm
      §   §§§§   §      that does not do any permission checks or authentication.
     §     §§     §     Access to all resources is granted to everyone.
    §      §§      §    DO NOT USE THIS REALM IN PRODUCTION
   $                §
  §        §§        §
 §                    §
 §§§§§§§§§§§§§§§§§§§§§§
[INFO] [2023-01-26 18:08:18]	c.b.c.m.a.AuthorizationController	ManagerNode	Registering the following realms to Shiro:
	com.bakdata.conquery.models.auth.conquerytoken.ConqueryTokenRealm_15
	com.bakdata.conquery.models.auth.ConqueryAuthorizationRealm_16
	com.bakdata.conquery.models.auth.develop.DefaultInitialUserRealm_17
[INFO] [2023-01-26 18:08:18]	c.b.c.c.ManagerNode	ManagerNode	Registering ResourcesProvider
[INFO] [2023-01-26 18:08:18]	c.b.c.m.f.f.FormScanner	ManagerNode	Form[EXPORT_FORM] from `Resource com/bakdata/conquery/frontend/forms/export_form.frontend_conf.json` of Type[com.bakdata.conquery.apiv1.forms.export_form.ExportForm]
[INFO] [2023-01-26 18:08:18]	c.b.c.m.f.f.FormScanner	ManagerNode	Form[FULL_EXPORT_FORM] from `Resource com/bakdata/conquery/frontend/forms/table_export_form.frontend_conf.json` of Type[com.bakdata.conquery.apiv1.forms.export_form.FullExportForm]
[DEBUG] [2023-01-26 18:08:18]	c.b.c.c.StandaloneCommand	ManagerNode	Waiting for ShardNodes to start
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced:DATASET}): 1 entries, 51 B within 191.0 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced:SECONDARY_IDS}): 0 entries, 0 B within 49.17 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced:TABLES}): 0 entries, 0 B within 36.84 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 54.71 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced:IMPORTS}): 0 entries, 0 B within 30.63 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced:CONCEPTS}): 0 entries, 0 B within 29.60 μs
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced	Done reading Dataset[label=testDataset5, name=testDataset5] / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced	While processing store WORKER:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced:WORKER}): 1 entries, 125 B within 120.6 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced:BUCKETS}): 0 entries, 0 B within 31.39 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced:C_BLOCKS}): 0 entries, 0 B within 29.06 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced	DONE reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e:DATASET}): 1 entries, 51 B within 115.8 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e:SECONDARY_IDS}): 0 entries, 0 B within 30.51 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e:TABLES}): 0 entries, 0 B within 22.79 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 26.45 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e:IMPORTS}): 0 entries, 0 B within 30.17 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e:CONCEPTS}): 0 entries, 0 B within 21.00 μs
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e	Done reading Dataset[label=testDataset5, name=testDataset5] / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e	While processing store WORKER:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e:WORKER}): 1 entries, 125 B within 74.44 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e:BUCKETS}): 0 entries, 0 B within 23.65 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e:C_BLOCKS}): 0 entries, 0 B within 21.57 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e	DONE reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7:DATASET}): 1 entries, 51 B within 169.3 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7:SECONDARY_IDS}): 0 entries, 0 B within 39.36 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7:TABLES}): 0 entries, 0 B within 29.96 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 33.75 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7:IMPORTS}): 0 entries, 0 B within 28.44 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7:CONCEPTS}): 0 entries, 0 B within 27.16 μs
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7	Done reading Dataset[label=testDataset6, name=testDataset6] / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7	While processing store WORKER:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7:WORKER}): 1 entries, 125 B within 95.83 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7:BUCKETS}): 0 entries, 0 B within 24.82 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7:C_BLOCKS}): 0 entries, 0 B within 21.60 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7	DONE reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0:DATASET}): 1 entries, 51 B within 121.3 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0:SECONDARY_IDS}): 0 entries, 0 B within 42.47 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0:TABLES}): 0 entries, 0 B within 35.55 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 42.01 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0:IMPORTS}): 0 entries, 0 B within 41.04 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0:CONCEPTS}): 0 entries, 0 B within 28.02 μs
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0	Done reading Dataset[label=testDataset4, name=testDataset4] / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0	While processing store WORKER:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0:WORKER}): 1 entries, 125 B within 114.3 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0:BUCKETS}): 0 entries, 0 B within 34.34 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0:C_BLOCKS}): 0 entries, 0 B within 27.29 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0	DONE reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea:DATASET}): 1 entries, 49 B within 152.9 μs
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e:DATASET}): 1 entries, 51 B within 163.3 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e:SECONDARY_IDS}): 0 entries, 0 B within 52.44 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea	While processing store SECONDARY_IDS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e:TABLES}): 0 entries, 0 B within 38.49 μs
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea:SECONDARY_IDS}): 1 entries, 70 B within 139.8 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 40.19 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e:IMPORTS}): 0 entries, 0 B within 28.41 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e:CONCEPTS}): 0 entries, 0 B within 26.47 μs
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e	Done reading Dataset[label=testDataset4, name=testDataset4] / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea	While processing store TABLES:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea:TABLES}): 1 entries, 187 B within 190.4 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e	While processing store WORKER:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e:WORKER}): 1 entries, 125 B within 93.07 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e:BUCKETS}): 0 entries, 0 B within 29.35 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e:C_BLOCKS}): 0 entries, 0 B within 27.27 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e	DONE reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea	While processing store DICTIONARIES_META:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea		loaded store cached big DICTIONARIES(Dictionary): 1 entries, 43 B within 896.0 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea	While processing store IMPORTS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea:IMPORTS}): 1 entries, 466 B within 3.419 ms
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea	While processing store CONCEPTS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea:CONCEPTS}): 1 entries, 452 B within 5.440 ms
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea	Done reading Dataset[label=RestartTest, name=RestartTest] / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea	While processing store WORKER:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea:WORKER}): 1 entries, 124 B within 111.1 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f:DATASET}): 1 entries, 51 B within 156.8 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f:SECONDARY_IDS}): 0 entries, 0 B within 46.70 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f:TABLES}): 0 entries, 0 B within 46.68 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 39.59 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f:IMPORTS}): 0 entries, 0 B within 54.03 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f:CONCEPTS}): 0 entries, 0 B within 50.37 μs
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f	Done reading Dataset[label=testDataset2, name=testDataset2] / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f	While processing store WORKER:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f:WORKER}): 1 entries, 125 B within 118.4 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f:BUCKETS}): 0 entries, 0 B within 40.65 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f:C_BLOCKS}): 0 entries, 0 B within 34.31 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f	DONE reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea	While processing store BUCKETS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea:BUCKETS}): 1 entries, 358 B within 1.636 ms
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea	While processing store C_BLOCKS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea:C_BLOCKS}): 1 entries, 213 B within 296.3 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea	DONE reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd:DATASET}): 1 entries, 51 B within 193.2 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd:SECONDARY_IDS}): 0 entries, 0 B within 59.60 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd:TABLES}): 0 entries, 0 B within 43.82 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 54.05 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd:IMPORTS}): 0 entries, 0 B within 41.34 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd:CONCEPTS}): 0 entries, 0 B within 48.10 μs
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd	Done reading Dataset[label=testDataset1, name=testDataset1] / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd	While processing store WORKER:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd:WORKER}): 1 entries, 125 B within 149.2 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd:BUCKETS}): 0 entries, 0 B within 55.62 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd:C_BLOCKS}): 0 entries, 0 B within 38.76 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd	DONE reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f:DATASET}): 1 entries, 51 B within 155.4 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f:SECONDARY_IDS}): 0 entries, 0 B within 47.64 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f:TABLES}): 0 entries, 0 B within 37.07 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 37.66 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f:IMPORTS}): 0 entries, 0 B within 33.62 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f:CONCEPTS}): 0 entries, 0 B within 31.68 μs
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f	Done reading Dataset[label=testDataset1, name=testDataset1] / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f	While processing store WORKER:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f:WORKER}): 1 entries, 125 B within 108.2 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f:BUCKETS}): 0 entries, 0 B within 34.42 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f:C_BLOCKS}): 0 entries, 0 B within 32.65 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f	DONE reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8:DATASET}): 1 entries, 51 B within 165.0 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8:SECONDARY_IDS}): 0 entries, 0 B within 49.30 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8:TABLES}): 0 entries, 0 B within 39.54 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 45.94 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8:IMPORTS}): 0 entries, 0 B within 57.50 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8:CONCEPTS}): 0 entries, 0 B within 46.50 μs
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8	Done reading Dataset[label=testDataset2, name=testDataset2] / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8	While processing store WORKER:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8:WORKER}): 1 entries, 125 B within 146.7 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8:BUCKETS}): 0 entries, 0 B within 49.08 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8:C_BLOCKS}): 0 entries, 0 B within 45.86 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8	DONE reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33:DATASET}): 1 entries, 49 B within 116.4 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33	While processing store SECONDARY_IDS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33:SECONDARY_IDS}): 1 entries, 70 B within 116.2 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33	While processing store TABLES:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33:TABLES}): 1 entries, 187 B within 163.4 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33	While processing store DICTIONARIES_META:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33		loaded store cached big DICTIONARIES(Dictionary): 1 entries, 43 B within 822.6 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33	While processing store IMPORTS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33:IMPORTS}): 1 entries, 466 B within 3.908 ms
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a:DATASET}): 1 entries, 51 B within 173.9 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a:SECONDARY_IDS}): 0 entries, 0 B within 60.60 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a:TABLES}): 0 entries, 0 B within 32.49 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 34.19 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a:IMPORTS}): 0 entries, 0 B within 37.77 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a:CONCEPTS}): 0 entries, 0 B within 30.56 μs
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a	Done reading Dataset[label=testDataset6, name=testDataset6] / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a	While processing store WORKER:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a:WORKER}): 1 entries, 125 B within 120.3 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a:BUCKETS}): 0 entries, 0 B within 45.83 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a:C_BLOCKS}): 0 entries, 0 B within 43.16 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a	DONE reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a:DATASET}): 1 entries, 51 B within 117.1 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a:SECONDARY_IDS}): 0 entries, 0 B within 30.71 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a:TABLES}): 0 entries, 0 B within 22.82 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 33.38 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a:IMPORTS}): 0 entries, 0 B within 25.75 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a:CONCEPTS}): 0 entries, 0 B within 16.94 μs
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a	Done reading Dataset[label=testDataset3, name=testDataset3] / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a	While processing store WORKER:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a:WORKER}): 1 entries, 125 B within 82.01 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a:BUCKETS}): 0 entries, 0 B within 38.58 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a:C_BLOCKS}): 0 entries, 0 B within 36.57 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a	DONE reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33	While processing store CONCEPTS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33:CONCEPTS}): 1 entries, 452 B within 5.328 ms
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33	Done reading Dataset[label=RestartTest, name=RestartTest] / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33	While processing store WORKER:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33:WORKER}): 1 entries, 124 B within 103.8 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33	While processing store BUCKETS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33:BUCKETS}): 1 entries, 346 B within 1.847 ms
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33	While processing store C_BLOCKS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33:C_BLOCKS}): 1 entries, 213 B within 261.6 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33	DONE reading Storage
[INFO] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	shard-node0	All WorkerStores loaded: [WorkerStorage(worker=NamedImpl(name=worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced)), WorkerStorage(worker=NamedImpl(name=worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7)), WorkerStorage(worker=NamedImpl(name=worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e)), WorkerStorage(worker=NamedImpl(name=worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f)), WorkerStorage(worker=NamedImpl(name=worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f)), WorkerStorage(worker=NamedImpl(name=worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a)), WorkerStorage(worker=NamedImpl(name=worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33))]
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac:DATASET}): 1 entries, 51 B within 217.5 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac:SECONDARY_IDS}): 0 entries, 0 B within 56.58 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac:TABLES}): 0 entries, 0 B within 45.29 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 49.33 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac:IMPORTS}): 0 entries, 0 B within 43.28 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac:CONCEPTS}): 0 entries, 0 B within 49.05 μs
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac	Done reading Dataset[label=testDataset3, name=testDataset3] / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac	While processing store WORKER:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac:WORKER}): 1 entries, 125 B within 133.9 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac:BUCKETS}): 0 entries, 0 B within 45.31 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:18]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac:C_BLOCKS}): 0 entries, 0 B within 43.03 μs
[DEBUG] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac	DONE reading Storage
[INFO] [2023-01-26 18:08:18]	c.b.c.m.c.XodusStoreFactory	shard-node1	All WorkerStores loaded: [WorkerStorage(worker=NamedImpl(name=worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e)), WorkerStorage(worker=NamedImpl(name=worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0)), WorkerStorage(worker=NamedImpl(name=worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea)), WorkerStorage(worker=NamedImpl(name=worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd)), WorkerStorage(worker=NamedImpl(name=worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8)), WorkerStorage(worker=NamedImpl(name=worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a)), WorkerStorage(worker=NamedImpl(name=worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac))]
[INFO] [2023-01-26 18:08:18]	c.b.c.c.ShardNode	shard-node0	All Worker Storages loaded: 7
[INFO] [2023-01-26 18:08:18]	c.b.c.c.ShardNode	shard-node1	All Worker Storages loaded: 7
[DEBUG] [2023-01-26 18:08:18]	c.b.c.c.StandaloneCommand	ManagerNode	Starting REST Server
[INFO] [2023-01-26 18:08:18]	c.b.c.c.ManagerNode		Started ManagerNode @ /0:0:0:0:0:0:0:0:34233
[INFO] [2023-01-26 18:08:18]	c.b.c.c.ShardNode		Trying to connect to /127.0.0.1:34233
[INFO] [2023-01-26 18:08:18]	c.b.c.c.ManagerNode	ManagerNode[/127.0.0.1:34233]	New client /127.0.0.1:49088 connected, waiting for identity
[INFO] [2023-01-26 18:08:18]	c.b.c.c.ShardNode	/127.0.0.1:49088	Connected to ManagerNode @ /127.0.0.1:34233
[INFO] [2023-01-26 18:08:18]	c.b.c.c.ShardNode		Trying to connect to /127.0.0.1:34233
[INFO] [2023-01-26 18:08:18]	c.b.c.c.ShardNode	/127.0.0.1:49088	Sending worker identity 'worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a'
[INFO] [2023-01-26 18:08:18]	c.b.c.c.ManagerNode	ManagerNode[/127.0.0.1:34233]	New client /127.0.0.1:49092 connected, waiting for identity
[INFO] [2023-01-26 18:08:18]	c.b.c.c.ShardNode	/127.0.0.1:49092	Connected to ManagerNode @ /127.0.0.1:34233
[INFO] [2023-01-26 18:08:18]	c.b.c.c.ShardNode	/127.0.0.1:49092	Sending worker identity 'worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea'
[INFO] [2023-01-26 18:08:18]	c.b.c.c.ShardNode	/127.0.0.1:49088	Sending worker identity 'worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f'
[INFO] [2023-01-26 18:08:18]	c.b.c.c.ShardNode	/127.0.0.1:49088	Sending worker identity 'worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f'
[INFO] [2023-01-26 18:08:18]	c.b.c.c.ShardNode	/127.0.0.1:49088	Sending worker identity 'worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced'
[INFO] [2023-01-26 18:08:18]	c.b.c.c.ShardNode	/127.0.0.1:49088	Sending worker identity 'worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33'
[INFO] [2023-01-26 18:08:18]	c.b.c.c.ShardNode	/127.0.0.1:49088	Sending worker identity 'worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7'
[INFO] [2023-01-26 18:08:18]	c.b.c.c.ShardNode	/127.0.0.1:49092	Sending worker identity 'worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a'
[INFO] [2023-01-26 18:08:18]	c.b.c.c.ShardNode	/127.0.0.1:49088	Sending worker identity 'worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e'
[INFO] [2023-01-26 18:08:18]	c.b.c.c.ShardNode	/127.0.0.1:49092	Sending worker identity 'worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0'
[INFO] [2023-01-26 18:08:18]	c.b.c.c.ShardNode	/127.0.0.1:49092	Sending worker identity 'worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd'
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.AddShardNode	Job Manager fast ManagerNode	ShardNode `/127.0.0.1:49088` registered.
[INFO] [2023-01-26 18:08:18]	c.b.c.c.ShardNode	/127.0.0.1:49092	Sending worker identity 'worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac'
[INFO] [2023-01-26 18:08:18]	c.b.c.c.ShardNode	/127.0.0.1:49092	Sending worker identity 'worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e'
[INFO] [2023-01-26 18:08:18]	c.b.c.c.ShardNode	/127.0.0.1:49092	Sending worker identity 'worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8'
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.AddShardNode	Job Manager fast ManagerNode	ShardNode `/127.0.0.1:49092` registered.
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset3, name=testDataset3]	Imports of worker testDataset3.worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset3, name=testDataset3]	Buckets of worker testDataset3.worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset3, name=testDataset3]	Consistency check was successful
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset2, name=testDataset2]	Imports of worker testDataset2.worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset2, name=testDataset2]	Buckets of worker testDataset2.worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset2, name=testDataset2]	Consistency check was successful
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset1, name=testDataset1]	Imports of worker testDataset1.worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset1, name=testDataset1]	Buckets of worker testDataset1.worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset1, name=testDataset1]	Consistency check was successful
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset5, name=testDataset5]	Imports of worker testDataset5.worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset5, name=testDataset5]	Buckets of worker testDataset5.worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset5, name=testDataset5]	Consistency check was successful
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=RestartTest, name=RestartTest]	Imports of worker RestartTest.worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33 are consistent with the manager: 1 Imports
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=RestartTest, name=RestartTest]	Buckets of worker RestartTest.worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33 are consistent with the manager: 1 Buckets
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=RestartTest, name=RestartTest]	Consistency check was successful
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset6, name=testDataset6]	Imports of worker testDataset6.worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7 are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset6, name=testDataset6]	Buckets of worker testDataset6.worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7 are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset6, name=testDataset6]	Consistency check was successful
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset4, name=testDataset4]	Imports of worker testDataset4.worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset4, name=testDataset4]	Buckets of worker testDataset4.worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset4, name=testDataset4]	Consistency check was successful
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=RestartTest, name=RestartTest]	Imports of worker RestartTest.worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea are consistent with the manager: 1 Imports
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=RestartTest, name=RestartTest]	Buckets of worker RestartTest.worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea are consistent with the manager: 1 Buckets
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=RestartTest, name=RestartTest]	Consistency check was successful
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset6, name=testDataset6]	Imports of worker testDataset6.worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset6, name=testDataset6]	Buckets of worker testDataset6.worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset6, name=testDataset6]	Consistency check was successful
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset4, name=testDataset4]	Imports of worker testDataset4.worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0 are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset4, name=testDataset4]	Buckets of worker testDataset4.worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0 are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset4, name=testDataset4]	Consistency check was successful
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset1, name=testDataset1]	Imports of worker testDataset1.worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset1, name=testDataset1]	Buckets of worker testDataset1.worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset1, name=testDataset1]	Consistency check was successful
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset3, name=testDataset3]	Imports of worker testDataset3.worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset3, name=testDataset3]	Buckets of worker testDataset3.worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset3, name=testDataset3]	Consistency check was successful
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset5, name=testDataset5]	Imports of worker testDataset5.worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset5, name=testDataset5]	Buckets of worker testDataset5.worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset5, name=testDataset5]	Consistency check was successful
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset2, name=testDataset2]	Imports of worker testDataset2.worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8 are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset2, name=testDataset2]	Buckets of worker testDataset2.worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8 are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:18]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=testDataset2, name=testDataset2]	Consistency check was successful
[WARN] [2023-01-26 18:08:19]	o.g.j.i.Errors		The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.filters.Filter<?> from public void com.bakdata.conquery.resources.hierarchies.HFilters.setFilter(com.bakdata.conquery.models.datasets.concepts.filters.Filter<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public com.bakdata.conquery.apiv1.FullExecutionStatus com.bakdata.conquery.resources.api.QueryResource.getStatus(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) throws java.lang.InterruptedException is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public com.bakdata.conquery.apiv1.FullExecutionStatus com.bakdata.conquery.resources.api.QueryResource.patchQuery(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>,com.bakdata.conquery.apiv1.MetaDataPatch) throws com.bakdata.conquery.models.exceptions.JSONException is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public void com.bakdata.conquery.resources.api.QueryResource.deleteQuery(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>) is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public void com.bakdata.conquery.resources.api.QueryResource.cancel(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>) is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public com.bakdata.conquery.apiv1.FullExecutionStatus com.bakdata.conquery.resources.api.QueryResource.reexecute(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultExcelResource.get(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.identifiable.ids.specific.DatasetId,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultArrowStreamResource.get(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.datasets.Dataset,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultCsvResource.getAsCsv(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.datasets.Dataset,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.lang.String,java.lang.String,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultArrowFileResource.get(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.datasets.Dataset,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.filters.Filter<?> from public void com.bakdata.conquery.resources.hierarchies.HFilters.setFilter(com.bakdata.conquery.models.datasets.concepts.filters.Filter<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.

[WARN] [2023-01-26 18:08:19]	i.d.s.AdminEnvironment		
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!    THIS APPLICATION HAS NO HEALTHCHECKS. THIS MEANS YOU WILL NEVER KNOW      !
!     IF IT DIES IN PRODUCTION, WHICH MEANS YOU WILL NEVER KNOW IF YOU'RE      !
!    LETTING YOUR USERS DOWN. YOU SHOULD ADD A HEALTHCHECK FOR EACH OF YOUR    !
!         APPLICATION'S DEPENDENCIES WHICH FULLY (BUT LIGHTLY) TESTS IT.       !
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
[WARN] [2023-01-26 18:08:19]	o.g.j.i.Errors		The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.auth.entities.PermissionOwner<?> from public void com.bakdata.conquery.resources.hierarchies.HPermissions.setOwner(com.bakdata.conquery.models.auth.entities.PermissionOwner<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.auth.entities.PermissionOwner<?> from public void com.bakdata.conquery.resources.hierarchies.HPermissions.setOwner(com.bakdata.conquery.models.auth.entities.PermissionOwner<?>) is not resolvable to a concrete type.

[WARN] [2023-01-26 18:08:19]	o.g.j.i.Errors		The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter concept of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from protected com.bakdata.conquery.models.datasets.concepts.Concept<?> com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.concept is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter concept of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from protected com.bakdata.conquery.models.datasets.concepts.Concept<?> com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.concept is not resolvable to a concrete type.

[INFO] [2023-01-26 18:08:19]	c.b.c.u.s.TestConquery		loading dataset
[INFO] [2023-01-26 18:08:19]	c.b.c.u.s.TestConquery		Reusing existing folder /tmp/conqueryIntegrationTest12910953884258704183/tmp_RestartTest for Support
[INFO] [2023-01-26 18:08:19]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[INFO] [2023-01-26 18:08:19]	c.b.c.i.t.RestartTest		Restart complete
[INFO] [2023-01-26 18:08:19]	c.b.c.i.j.AbstractQueryEngineTest		SIMPLE_TREECONCEPT_QUERY Test QUERY INIT
[INFO] [2023-01-26 18:08:19]	c.b.c.a.QueryProcessor	user.SUPERUSER@SUPERUSER	Query posted on Dataset[RestartTest] by User[{user.SUPERUSER@SUPERUSER].
[INFO] [2023-01-26 18:08:19]	c.b.c.m.q.ExecutionManager	user.SUPERUSER@SUPERUSER	Executing Query[3523f1ae-34ef-434e-af65-aa4d7a718c99] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_RestartTest))]]
[INFO] [2023-01-26 18:08:19]	c.b.c.m.m.n.s.ExecuteQuery	Worker[RestartTest.worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea, /127.0.0.1:49092]	Started ConceptQuery RestartTest.3523f1ae-34ef-434e-af65-aa4d7a718c99
127.0.0.1 - - [26/Jan/2023:18:08:19 +0000] "POST /api/datasets/RestartTest/queries HTTP/1.1" 201 1119 "-" "Conquery (test client)" 19
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.c.IntegrationUtils		Trying to get Query result
[INFO] [2023-01-26 18:08:19]	c.b.c.m.m.n.s.ExecuteQuery	Worker[RestartTest.worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33, /127.0.0.1:49088]	Started ConceptQuery RestartTest.3523f1ae-34ef-434e-af65-aa4d7a718c99
[DEBUG] [2023-01-26 18:08:19]	c.b.c.m.q.QueryExecutor	Worker[RestartTest.worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea, /127.0.0.1:49092]	QueryPlan for Query[RestartTest.3523f1ae-34ef-434e-af65-aa4d7a718c99] = `ConceptQueryPlan(child=ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table, name=test_table]])])), validityDateColumn=Column(id = RestartTest.test_table.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=connector, name=connector], dateColumn=null), selectedSecondaryId=null), dateAggregator=DateAggregator(action=MERGE))`
[DEBUG] [2023-01-26 18:08:19]	c.b.c.m.q.QueryExecutor	Worker[RestartTest.worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33, /127.0.0.1:49088]	QueryPlan for Query[RestartTest.3523f1ae-34ef-434e-af65-aa4d7a718c99] = `ConceptQueryPlan(child=ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table, name=test_table]])])), validityDateColumn=Column(id = RestartTest.test_table.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=connector, name=connector], dateColumn=null), selectedSecondaryId=null), dateAggregator=DateAggregator(action=MERGE))`
[INFO] [2023-01-26 18:08:19]	c.b.c.m.q.r.ShardResult		FINISHED Query[RestartTest.3523f1ae-34ef-434e-af65-aa4d7a718c99] with 0 results within PT0.010058S
[INFO] [2023-01-26 18:08:19]	c.b.c.m.q.r.ShardResult		FINISHED Query[RestartTest.3523f1ae-34ef-434e-af65-aa4d7a718c99] with 2 results within PT0.013637S
[INFO] [2023-01-26 18:08:19]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=RestartTest, name=RestartTest]	Received ShardResult(queryId=RestartTest.3523f1ae-34ef-434e-af65-aa4d7a718c99, workerId=RestartTest.worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33, startTime=2023-01-26T18:08:19.290327, finishTime=2023-01-26T18:08:19.300385) of size 0
[DEBUG] [2023-01-26 18:08:19]	c.b.c.m.q.ManagedQuery	Dataset[label=RestartTest, name=RestartTest]	Received Result[size=0] for Query[RestartTest.3523f1ae-34ef-434e-af65-aa4d7a718c99]
[INFO] [2023-01-26 18:08:19]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=RestartTest, name=RestartTest]	Received ShardResult(queryId=RestartTest.3523f1ae-34ef-434e-af65-aa4d7a718c99, workerId=RestartTest.worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea, startTime=2023-01-26T18:08:19.286970, finishTime=2023-01-26T18:08:19.300607) of size 2
[DEBUG] [2023-01-26 18:08:19]	c.b.c.m.q.ManagedQuery	Dataset[label=RestartTest, name=RestartTest]	Received Result[size=2] for Query[RestartTest.3523f1ae-34ef-434e-af65-aa4d7a718c99]
[INFO] [2023-01-26 18:08:19]	c.b.c.m.e.ManagedExecution	Dataset[label=RestartTest, name=RestartTest]	DONE 3523f1ae-34ef-434e-af65-aa4d7a718c99 ManagedQuery within PT0.023175S
127.0.0.1 - - [26/Jan/2023:18:08:19 +0000] "GET /api/datasets/RestartTest/queries/RestartTest.3523f1ae-34ef-434e-af65-aa4d7a718c99 HTTP/1.1" 200 1355 "-" "Conquery (test client)" 5
[INFO] [2023-01-26 18:08:19]	c.b.c.r.a.ResultCsvResource	user.SUPERUSER@SUPERUSER	Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=RestartTest, name=RestartTest], queryId=3523f1ae-34ef-434e-af65-aa4d7a718c99, label=test_tree---test_child1	@§$, creationTime=2023-01-26T18:08:19.277686, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@6b401603[Count = 0], startTime=2023-01-26T18:08:19.280991, finishTime=2023-01-26T18:08:19.304166, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@213e8be5), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_RestartTest)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@39790740], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1bdf675a], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=null, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@70449a2c, com.bakdata.conquery.models.query.ColumnDescriptor@25705662]) download on dataset Dataset[label=RestartTest, name=RestartTest] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
[INFO] [2023-01-26 18:08:19]	c.b.c.i.r.c.ResultCsvProcessor	SUPERUSER@SUPERUSER	Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=RestartTest, name=RestartTest], queryId=3523f1ae-34ef-434e-af65-aa4d7a718c99, label=test_tree---test_child1	@§$, creationTime=2023-01-26T18:08:19.277686, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@6b401603[Count = 0], startTime=2023-01-26T18:08:19.280991, finishTime=2023-01-26T18:08:19.304166, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@213e8be5), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_RestartTest)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@39790740], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1bdf675a], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=null, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@70449a2c, com.bakdata.conquery.models.query.ColumnDescriptor@25705662]) on dataset Dataset[label=RestartTest, name=RestartTest]
127.0.0.1 - - [26/Jan/2023:18:08:19 +0000] "GET /api/datasets/RestartTest/result/RestartTest.3523f1ae-34ef-434e-af65-aa4d7a718c99.csv?pretty=false HTTP/1.1" 200 65 "-" "Conquery (test client)" 4
[INFO] [2023-01-26 18:08:19]	c.b.c.i.j.AbstractQueryEngineTest		INTEGRATION TEST SUCCESSFUL QueryTest SIMPLE_TREECONCEPT_QUERY Test on 3 rows
[INFO] [2023-01-26 18:08:19]	c.b.c.m.j.JobExecutor		Closing Job Manager fast testDataset1
[INFO] [2023-01-26 18:08:19]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node0	removing worker for Dataset[label=testDataset1, name=testDataset1]
[INFO] [2023-01-26 18:08:19]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager fast worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f
[INFO] [2023-01-26 18:08:19]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node1	removing worker for Dataset[label=testDataset1, name=testDataset1]
[INFO] [2023-01-26 18:08:19]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager fast worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd
[INFO] [2023-01-26 18:08:19]	c.b.c.m.j.JobExecutor		Closing Job Manager slow testDataset1
[INFO] [2023-01-26 18:08:19]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager slow worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd
[INFO] [2023-01-26 18:08:19]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager slow worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f
[INFO] [2023-01-26 18:08:19]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node0	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset1_7fb7aea4-c971-42b7-96de-49d63b7b305f
[INFO] [2023-01-26 18:08:19]	c.b.c.m.w.Namespace		Removing namespace storage of testDataset1
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store ID_MAPPING_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd
[INFO] [2023-01-26 18:08:19]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node1	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset1_76754a81-b920-4d75-9683-9acf81d52ebd
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store ID_MAPPING_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store STRUCTURE from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store WORKER_TO_BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store PRIMARY_DICTIONARY from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1
[INFO] [2023-01-26 18:08:19]	c.b.c.m.c.XodusStoreFactory		Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset1
[INFO] [2023-01-26 18:08:19]	c.b.c.m.j.JobExecutor		Closing Job Manager fast testDataset2
[INFO] [2023-01-26 18:08:19]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node0	removing worker for Dataset[label=testDataset2, name=testDataset2]
[INFO] [2023-01-26 18:08:19]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager fast worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f
[INFO] [2023-01-26 18:08:19]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node1	removing worker for Dataset[label=testDataset2, name=testDataset2]
[INFO] [2023-01-26 18:08:19]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager fast worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8
[INFO] [2023-01-26 18:08:19]	c.b.c.m.j.JobExecutor		Closing Job Manager slow testDataset2
[INFO] [2023-01-26 18:08:19]	c.b.c.m.w.Namespace		Removing namespace storage of testDataset2
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store ID_MAPPING_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store ID_MAPPING_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store STRUCTURE from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store WORKER_TO_BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store PRIMARY_DICTIONARY from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2
[INFO] [2023-01-26 18:08:19]	c.b.c.m.c.XodusStoreFactory		Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset2
[INFO] [2023-01-26 18:08:19]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager slow worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f
[INFO] [2023-01-26 18:08:19]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager slow worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8
[INFO] [2023-01-26 18:08:19]	c.b.c.m.j.JobExecutor		Closing Job Manager fast testDataset3
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f
[INFO] [2023-01-26 18:08:19]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node0	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset2_deedc823-12e2-462a-b714-45703bc5f85f
[INFO] [2023-01-26 18:08:19]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node0	removing worker for Dataset[label=testDataset3, name=testDataset3]
[INFO] [2023-01-26 18:08:19]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager fast worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a
[INFO] [2023-01-26 18:08:19]	c.b.c.m.j.JobExecutor		Closing Job Manager slow testDataset3
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8
[INFO] [2023-01-26 18:08:19]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node1	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset2_603fd766-580e-49d1-873d-36cf01799ad8
[INFO] [2023-01-26 18:08:19]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager slow worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a
[INFO] [2023-01-26 18:08:19]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node1	removing worker for Dataset[label=testDataset3, name=testDataset3]
[INFO] [2023-01-26 18:08:19]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager fast worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac
[INFO] [2023-01-26 18:08:19]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager slow worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a
[INFO] [2023-01-26 18:08:19]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node0	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset3_1d319a6b-94f9-47a3-a62e-069bfa79257a
[INFO] [2023-01-26 18:08:19]	c.b.c.m.w.Namespace		Removing namespace storage of testDataset3
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac
[INFO] [2023-01-26 18:08:19]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node1	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset3_11698573-ceed-4961-886e-08038ffad0ac
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store ID_MAPPING_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store ID_MAPPING_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store STRUCTURE from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store WORKER_TO_BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore		Deleting store PRIMARY_DICTIONARY from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3
[INFO] [2023-01-26 18:08:19]	c.b.c.m.c.XodusStoreFactory		Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset3
[INFO] [2023-01-26 18:08:19]	c.b.c.m.j.JobExecutor		Closing Job Manager fast testDataset4
[INFO] [2023-01-26 18:08:19]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node1	removing worker for Dataset[label=testDataset4, name=testDataset4]
[INFO] [2023-01-26 18:08:19]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node0	removing worker for Dataset[label=testDataset4, name=testDataset4]
[INFO] [2023-01-26 18:08:19]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager fast worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0
[INFO] [2023-01-26 18:08:19]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager fast worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e
[INFO] [2023-01-26 18:08:19]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager slow worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e
[INFO] [2023-01-26 18:08:19]	c.b.c.m.j.JobExecutor		Closing Job Manager slow testDataset4
[INFO] [2023-01-26 18:08:19]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager slow worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e
[DEBUG] [2023-01-26 18:08:19]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e
[INFO] [2023-01-26 18:08:19]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node0	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset4_2518d668-9d71-481f-a2ab-28979f06202e
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0
[INFO] [2023-01-26 18:08:19]	c.b.c.m.w.Namespace		Removing namespace storage of testDataset4
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4
[INFO] [2023-01-26 18:08:20]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node1	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset4_1b9982d7-10b3-437c-b7e6-d00aa4fbfbd0
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store ID_MAPPING_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store ID_MAPPING_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store STRUCTURE from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store WORKER_TO_BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store PRIMARY_DICTIONARY from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4
[INFO] [2023-01-26 18:08:20]	c.b.c.m.c.XodusStoreFactory		Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset4
[INFO] [2023-01-26 18:08:20]	c.b.c.m.j.JobExecutor		Closing Job Manager fast testDataset5
[INFO] [2023-01-26 18:08:20]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node1	removing worker for Dataset[label=testDataset5, name=testDataset5]
[INFO] [2023-01-26 18:08:20]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node0	removing worker for Dataset[label=testDataset5, name=testDataset5]
[INFO] [2023-01-26 18:08:20]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager fast worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e
[INFO] [2023-01-26 18:08:20]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager fast worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced
[INFO] [2023-01-26 18:08:20]	c.b.c.m.j.JobExecutor		Closing Job Manager slow testDataset5
[INFO] [2023-01-26 18:08:20]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager slow worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced
[INFO] [2023-01-26 18:08:20]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager slow worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced
[INFO] [2023-01-26 18:08:20]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node0	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset5_4c3d82b7-e8ed-48f8-95d5-01a93d3b1ced
[INFO] [2023-01-26 18:08:20]	c.b.c.m.w.Namespace		Removing namespace storage of testDataset5
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5
[INFO] [2023-01-26 18:08:20]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node1	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset5_44080f86-7ead-47b5-bb3e-fbc655a3792e
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store ID_MAPPING_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store ID_MAPPING_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store STRUCTURE from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store WORKER_TO_BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store PRIMARY_DICTIONARY from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5
[INFO] [2023-01-26 18:08:20]	c.b.c.m.c.XodusStoreFactory		Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset5
[INFO] [2023-01-26 18:08:20]	c.b.c.m.j.JobExecutor		Closing Job Manager fast testDataset6
[INFO] [2023-01-26 18:08:20]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node0	removing worker for Dataset[label=testDataset6, name=testDataset6]
[INFO] [2023-01-26 18:08:20]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager fast worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7
[INFO] [2023-01-26 18:08:20]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node1	removing worker for Dataset[label=testDataset6, name=testDataset6]
[INFO] [2023-01-26 18:08:20]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager fast worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a
[INFO] [2023-01-26 18:08:20]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager slow worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a
[INFO] [2023-01-26 18:08:20]	c.b.c.m.j.JobExecutor		Closing Job Manager slow testDataset6
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a
[INFO] [2023-01-26 18:08:20]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager slow worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a
[INFO] [2023-01-26 18:08:20]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node1	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_testDataset6_9169780d-b8e6-4dec-a9c1-e1892c4cfd8a
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7
[INFO] [2023-01-26 18:08:20]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node0	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_testDataset6_6cc3681c-b1f2-428f-bd67-81c7458efad7
[INFO] [2023-01-26 18:08:20]	c.b.c.m.w.Namespace		Removing namespace storage of testDataset6
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store ID_MAPPING_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store ID_MAPPING_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store STRUCTURE from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store WORKER_TO_BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store PRIMARY_DICTIONARY from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6
[INFO] [2023-01-26 18:08:20]	c.b.c.m.c.XodusStoreFactory		Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_testDataset6
[INFO] [2023-01-26 18:08:20]	c.b.c.m.j.JobExecutor		Closing Job Manager fast RestartTest
[INFO] [2023-01-26 18:08:20]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node1	removing worker for Dataset[label=RestartTest, name=RestartTest]
[INFO] [2023-01-26 18:08:20]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node0	removing worker for Dataset[label=RestartTest, name=RestartTest]
[INFO] [2023-01-26 18:08:20]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager fast worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33
[INFO] [2023-01-26 18:08:20]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager fast worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea
[INFO] [2023-01-26 18:08:20]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager slow worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33
[INFO] [2023-01-26 18:08:20]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node0	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RestartTest_611c10d0-6ed0-4d4e-ac2e-6d7cdb559f33
[INFO] [2023-01-26 18:08:20]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager slow worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea
[INFO] [2023-01-26 18:08:20]	c.b.c.m.j.JobExecutor		Closing Job Manager slow RestartTest
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea
[INFO] [2023-01-26 18:08:20]	c.b.c.m.w.Namespace		Removing namespace storage of RestartTest
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea
[INFO] [2023-01-26 18:08:20]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node1	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RestartTest_7314a026-22c9-4be8-9b0c-22e099ebd6ea
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store ID_MAPPING_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store ID_MAPPING_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store STRUCTURE from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store WORKER_TO_BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.XodusStore		Deleting store PRIMARY_DICTIONARY from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest
[INFO] [2023-01-26 18:08:20]	c.b.c.m.c.XodusStoreFactory		Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RestartTest
[INFO] [2023-01-26 18:08:20]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[INFO] [2023-01-26 18:08:20]	c.b.c.i.IntegrationTest$Wrapper	RestartTest	SUCCESS integration test RestartTest
[INFO] [2023-01-26 18:08:20]	c.b.c.i.IntegrationTest$Wrapper	ReusedQueryTest	STARTING integration test ReusedQueryTest
[INFO] [2023-01-26 18:08:20]	c.b.c.u.s.TestConquery	ReusedQueryTest	Setting up dataset
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.SerializingStore	ReusedQueryTest	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.CachedStore	ReusedQueryTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ReusedQueryTest:DATASET}): 0 entries, 0 B within 91.36 μs
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.SerializingStore	ReusedQueryTest	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.CachedStore	ReusedQueryTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ReusedQueryTest:SECONDARY_IDS}): 0 entries, 0 B within 36.44 μs
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.SerializingStore	ReusedQueryTest	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.CachedStore	ReusedQueryTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ReusedQueryTest:TABLES}): 0 entries, 0 B within 29.85 μs
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.SerializingStore	ReusedQueryTest	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.CachedStore	ReusedQueryTest		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 42.34 μs
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.SerializingStore	ReusedQueryTest	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.CachedStore	ReusedQueryTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ReusedQueryTest:IMPORTS}): 0 entries, 0 B within 31.27 μs
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.SerializingStore	ReusedQueryTest	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.CachedStore	ReusedQueryTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ReusedQueryTest:CONCEPTS}): 0 entries, 0 B within 47.40 μs
[INFO] [2023-01-26 18:08:20]	c.b.c.i.s.NamespacedStorage	ReusedQueryTest	Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.SerializingStore	ReusedQueryTest	While processing store ID_MAPPING_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.CachedStore	ReusedQueryTest		loaded store cached big ID_MAPPING(EntityIdMap): 0 entries, 0 B within 35.46 μs
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.SerializingStore	ReusedQueryTest	While processing store STRUCTURE:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.CachedStore	ReusedQueryTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ReusedQueryTest:STRUCTURE}): 0 entries, 0 B within 29.51 μs
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.SerializingStore	ReusedQueryTest	While processing store WORKER_TO_BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.CachedStore	ReusedQueryTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ReusedQueryTest:WORKER_TO_BUCKETS}): 0 entries, 0 B within 28.45 μs
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.SerializingStore	ReusedQueryTest	While processing store PRIMARY_DICTIONARY:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.CachedStore	ReusedQueryTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ReusedQueryTest:PRIMARY_DICTIONARY}): 0 entries, 0 B within 37.87 μs
[INFO] [2023-01-26 18:08:20]	c.b.c.m.m.n.s.AddWorker	Job Manager slow shard-node0	creating a new worker for Dataset[label=ReusedQueryTest, name=ReusedQueryTest]
[INFO] [2023-01-26 18:08:20]	c.b.c.m.m.n.s.AddWorker	Job Manager slow shard-node1	creating a new worker for Dataset[label=ReusedQueryTest, name=ReusedQueryTest]
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a:DATASET}): 0 entries, 0 B within 158.6 μs
[INFO] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada:DATASET}): 0 entries, 0 B within 156.8 μs
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada:SECONDARY_IDS}): 0 entries, 0 B within 61.19 μs
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a:SECONDARY_IDS}): 0 entries, 0 B within 118.0 μs
[INFO] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada:TABLES}): 0 entries, 0 B within 50.29 μs
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 50.58 μs
[INFO] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a:TABLES}): 0 entries, 0 B within 81.34 μs
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada:IMPORTS}): 0 entries, 0 B within 45.24 μs
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 47.67 μs
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada:CONCEPTS}): 0 entries, 0 B within 36.72 μs
[INFO] [2023-01-26 18:08:20]	c.b.c.i.s.NamespacedStorage	Job Manager slow shard-node0	Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a:IMPORTS}): 0 entries, 0 B within 32.55 μs
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store WORKER:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada:WORKER}): 0 entries, 0 B within 56.41 μs
[INFO] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a:CONCEPTS}): 0 entries, 0 B within 41.76 μs
[INFO] [2023-01-26 18:08:20]	c.b.c.i.s.NamespacedStorage	Job Manager slow shard-node1	Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store WORKER:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada:BUCKETS}): 0 entries, 0 B within 49.42 μs
[INFO] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a:WORKER}): 0 entries, 0 B within 53.33 μs
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada:C_BLOCKS}): 0 entries, 0 B within 55.15 μs
[INFO] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a:BUCKETS}): 0 entries, 0 B within 58.48 μs
[DEBUG] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:20]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a:C_BLOCKS}): 0 entries, 0 B within 19.84 μs
[INFO] [2023-01-26 18:08:20]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=ReusedQueryTest]	Imports of worker ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:20]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=ReusedQueryTest]	Buckets of worker ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:20]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=ReusedQueryTest]	Consistency check was successful
[INFO] [2023-01-26 18:08:20]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=ReusedQueryTest]	Imports of worker ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:20]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=ReusedQueryTest]	Buckets of worker ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:20]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=ReusedQueryTest]	Consistency check was successful
[INFO] [2023-01-26 18:08:20]	c.b.c.u.s.TestConquery	ReusedQueryTest	Waiting for jobs to finish
[INFO] [2023-01-26 18:08:20]	c.b.c.r.a.r.AdminDatasetProcessor	ReusedQueryTest	Received new SecondaryId[ReusedQueryTest.secondary]
[INFO] [2023-01-26 18:08:20]	c.b.c.r.a.r.AdminDatasetProcessor	ReusedQueryTest	Received new SecondaryId[ReusedQueryTest.ignored]
[INFO] [2023-01-26 18:08:20]	c.b.c.u.s.TestConquery	ReusedQueryTest	Waiting for jobs to finish
[INFO] [2023-01-26 18:08:20]	c.b.c.m.m.n.s.UpdateSecondaryId	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	Received update of SecondaryId ReusedQueryTest.secondary
[INFO] [2023-01-26 18:08:20]	c.b.c.m.m.n.s.UpdateSecondaryId	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	Received update of SecondaryId ReusedQueryTest.ignored
[INFO] [2023-01-26 18:08:20]	c.b.c.m.m.n.s.UpdateSecondaryId	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	Received update of SecondaryId ReusedQueryTest.secondary
[INFO] [2023-01-26 18:08:20]	c.b.c.m.m.n.s.UpdateSecondaryId	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	Received update of SecondaryId ReusedQueryTest.ignored
[INFO] [2023-01-26 18:08:21]	c.b.c.u.s.TestConquery	ReusedQueryTest	Waiting for jobs to finish
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.UpdateTable	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	Received update of Table ReusedQueryTest.table
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.UpdateTable	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	Received update of Table ReusedQueryTest.table2
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.UpdateTable	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	Received update of Table ReusedQueryTest.table
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.UpdateTable	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	Received update of Table ReusedQueryTest.table2
[INFO] [2023-01-26 18:08:21]	c.b.c.u.s.TestConquery	ReusedQueryTest	Waiting for jobs to finish
[DEBUG] [2023-01-26 18:08:21]	c.b.c.i.s.WorkerStorage	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	Updating Concept[ReusedQueryTest.concept]
[DEBUG] [2023-01-26 18:08:21]	c.b.c.i.s.WorkerStorage	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	Updating Concept[ReusedQueryTest.concept]
[INFO] [2023-01-26 18:08:21]	c.b.c.c.PreprocessorCommand	ReusedQueryTest	Preprocessing from command line config.
[INFO] [2023-01-26 18:08:21]	c.b.c.c.PreprocessorCommand	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ReusedQueryTest/table.import.json, tag=Optional.empty)	DOES NOT EXIST
[INFO] [2023-01-26 18:08:21]	c.b.c.c.PreprocessorCommand	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ReusedQueryTest/table2.import.json, tag=Optional.empty)	DOES NOT EXIST
[INFO] [2023-01-26 18:08:21]	c.b.c.c.PreprocessorCommand	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ReusedQueryTest/table2.import.json, tag=Optional.empty)	Required to preprocess 465 B in total
[INFO] [2023-01-26 18:08:21]	c.b.c.m.p.Preprocessor	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ReusedQueryTest/table.import.json, tag=Optional.empty)	PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ReusedQueryTest/table.import.json, tag=Optional.empty)
██████████████████████████▌                       ▌  53%	est. time remaining: 0.033788024s[INFO] [2023-01-26 18:08:21]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=table, name=table]:table[0/content.csv]	Statistics = IntSummaryStatistics{count=2, sum=6, min=1, average=3.000000, max=5}
[INFO] [2023-01-26 18:08:21]	c.b.c.m.p.PPColumn		Compute best Subtype for  Column[ignored] with StringParser(super=Parser(lines=6, nullLines=0), encoding=null, prefix=a, suffix=a)
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.p.PPColumn			ignored: StringParser(super=Parser(lines=6, nullLines=0), encoding=null, prefix=a, suffix=a) -> StringTypeSingleton(singleValue=a)
[INFO] [2023-01-26 18:08:21]	c.b.c.m.p.PPColumn		Compute best Subtype for  Column[sid] with StringParser(super=Parser(lines=6, nullLines=1), encoding=null, prefix=f_, suffix=)
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.p.p.s.StringParser		Reduced strings by the 'f_' prefix and '' suffix
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.p.p.s.StringParser			Chosen encoding is Base16LowerCase
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.p.p.s.StringParser			Using com.bakdata.conquery.models.preproc.parser.specific.string.TrieTypeGuesser@710718a5(est. 100 B)
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.p.PPColumn			sid: StringParser(super=Parser(lines=6, nullLines=1), encoding=Base16LowerCase, prefix=f_, suffix=) -> StringTypePrefixSuffix(subType=StringTypeEncoded(encoding=Base16LowerCase, subType=StringTypeDictionary(dictionary=SuccinctTrie[size=4], numberType=ByteArrayStore())), prefix=f_, suffix=)
[INFO] [2023-01-26 18:08:21]	c.b.c.m.p.PPColumn		Compute best Subtype for  Column[value] with RealParser(super=Parser(lines=6, nullLines=0), requiredPrecision=4.9E-324, floatULP=1.1920928955078125E-7)
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.p.p.s.RealParser		Max ULP = 1.1920928955078125E-7
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.p.PPColumn			value: RealParser(super=Parser(lines=6, nullLines=0), requiredPrecision=4.9E-324, floatULP=1.1920928955078125E-7) -> DoubleArrayStore()
[INFO] [2023-01-26 18:08:21]	c.b.c.m.p.PPColumn	ImportDescriptor [table=table, name=table]:table[0/content.csv]	Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=6, nullLines=0), minParser=DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=14790, maxValue=16982), dateReader=com.bakdata.conquery.util.DateReader@d4c326f), maxParser=DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=14790, maxValue=16982), dateReader=com.bakdata.conquery.util.DateReader@4a0ff6e6), dateReader=com.bakdata.conquery.util.DateReader@436b0899, onlyQuarters=false, maxValue=16982, minValue=14790, anyOpen=false)
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.p.PPColumn	ImportDescriptor [table=table, name=table]:table[0/content.csv]		datum: DateRangeParser(super=Parser(lines=6, nullLines=0), minParser=DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=14790, maxValue=16982), dateReader=com.bakdata.conquery.util.DateReader@d4c326f), maxParser=DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=14790, maxValue=16982), dateReader=com.bakdata.conquery.util.DateReader@4a0ff6e6), dateReader=com.bakdata.conquery.util.DateReader@436b0899, onlyQuarters=false, maxValue=16982, minValue=14790, anyOpen=false) -> DateRangeTypeDateRange(minStore=IntegerDateStore(store=ShortArrayStore()), maxStore=IntegerDateStore(store=ShortArrayStore()))
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=table, name=table]:table[0/content.csv]	Encode primary Dictionary
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=table, name=table]:table[0/content.csv]	Writing Headers
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=table, name=table]:table[0/content.csv]	Writing header
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=table, name=table]:table[0/content.csv]	Writing Dictionaries
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=table, name=table]:table[0/content.csv]	Writing data
[INFO] [2023-01-26 18:08:21]	c.b.c.m.p.Preprocessor	ImportDescriptor [table=table, name=table]:table[0/content.csv]	PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ReusedQueryTest/table.import.json, tag=Optional.empty)
[INFO] [2023-01-26 18:08:21]	c.b.c.m.p.Preprocessor	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ReusedQueryTest/table2.import.json, tag=Optional.empty)	PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ReusedQueryTest/table2.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000771684s[INFO] [2023-01-26 18:08:21]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=table2, name=table2]:table2[0/content2.csv]	Statistics = IntSummaryStatistics{count=2, sum=6, min=1, average=3.000000, max=5}
[INFO] [2023-01-26 18:08:21]	c.b.c.m.p.PPColumn	ImportDescriptor [table=table2, name=table2]:table2[0/content2.csv]	Compute best Subtype for  Column[value] with RealParser(super=Parser(lines=6, nullLines=0), requiredPrecision=4.9E-324, floatULP=9.5367431640625E-7)
[INFO] [2023-01-26 18:08:21]	c.b.c.m.p.PPColumn		Compute best Subtype for  Column[sid] with StringParser(super=Parser(lines=6, nullLines=1), encoding=null, prefix=f_, suffix=)
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.p.p.s.StringParser		Reduced strings by the 'f_' prefix and '' suffix
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.p.p.s.RealParser	ImportDescriptor [table=table2, name=table2]:table2[0/content2.csv]	Max ULP = 9.5367431640625E-7
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.p.PPColumn	ImportDescriptor [table=table2, name=table2]:table2[0/content2.csv]		value: RealParser(super=Parser(lines=6, nullLines=0), requiredPrecision=4.9E-324, floatULP=9.5367431640625E-7) -> DoubleArrayStore()
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.p.p.s.StringParser			Chosen encoding is Base16LowerCase
[INFO] [2023-01-26 18:08:21]	c.b.c.m.p.PPColumn		Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=6, nullLines=0), minParser=DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=18443, maxValue=20634), dateReader=com.bakdata.conquery.util.DateReader@46ccaf05), maxParser=DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=18443, maxValue=20634), dateReader=com.bakdata.conquery.util.DateReader@6d5374af), dateReader=com.bakdata.conquery.util.DateReader@47e4db91, onlyQuarters=false, maxValue=20634, minValue=18443, anyOpen=false)
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.p.PPColumn			datum: DateRangeParser(super=Parser(lines=6, nullLines=0), minParser=DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=18443, maxValue=20634), dateReader=com.bakdata.conquery.util.DateReader@46ccaf05), maxParser=DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=18443, maxValue=20634), dateReader=com.bakdata.conquery.util.DateReader@6d5374af), dateReader=com.bakdata.conquery.util.DateReader@47e4db91, onlyQuarters=false, maxValue=20634, minValue=18443, anyOpen=false) -> DateRangeTypeDateRange(minStore=IntegerDateStore(store=ShortArrayStore()), maxStore=IntegerDateStore(store=ShortArrayStore()))
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.p.p.s.StringParser			Using com.bakdata.conquery.models.preproc.parser.specific.string.TrieTypeGuesser@7fc0f8f5(est. 83 B)
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.p.PPColumn			sid: StringParser(super=Parser(lines=6, nullLines=1), encoding=Base16LowerCase, prefix=f_, suffix=) -> StringTypePrefixSuffix(subType=StringTypeEncoded(encoding=Base16LowerCase, subType=StringTypeDictionary(dictionary=SuccinctTrie[size=3], numberType=ByteArrayStore())), prefix=f_, suffix=)
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=table2, name=table2]:table2[0/content2.csv]	Encode primary Dictionary
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=table2, name=table2]:table2[0/content2.csv]	Writing Headers
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=table2, name=table2]:table2[0/content2.csv]	Writing header
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=table2, name=table2]:table2[0/content2.csv]	Writing Dictionaries
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=table2, name=table2]:table2[0/content2.csv]	Writing data
[INFO] [2023-01-26 18:08:21]	c.b.c.m.p.Preprocessor	ImportDescriptor [table=table2, name=table2]:table2[0/content2.csv]	PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ReusedQueryTest/table2.import.json, tag=Optional.empty)
[INFO] [2023-01-26 18:08:21]	c.b.c.c.PreprocessorCommand		Successfully Preprocess 2 Jobs:
[INFO] [2023-01-26 18:08:21]	c.b.c.c.PreprocessorCommand			Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ReusedQueryTest/table.import.json, tag=Optional.empty)
[INFO] [2023-01-26 18:08:21]	c.b.c.c.PreprocessorCommand			Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ReusedQueryTest/table2.import.json, tag=Optional.empty)
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.j.ImportJob	user.SUPERUSER@SUPERUSER	Done reading data. Contains 2 Entities.
[INFO] [2023-01-26 18:08:21]	c.b.c.m.j.ImportJob	user.SUPERUSER@SUPERUSER	Importing table into ReusedQueryTest.table
127.0.0.1 - - [26/Jan/2023:18:08:21 +0000] "POST /admin/datasets/ReusedQueryTest/imports?file=%2Ftmp%2FconqueryIntegrationTest12910953884258704183%2Ftmp_ReusedQueryTest%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 14
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.j.ImportJob	Job Manager slow ReusedQueryTest	Mapped 2 new ids
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.j.ImportJob	Job Manager slow ReusedQueryTest	Updating bucket assignments.
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.w.Namespace	Job Manager slow ReusedQueryTest	Assigning Bucket[0] to Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a]
[INFO] [2023-01-26 18:08:21]	c.b.c.m.j.ImportJob	Job Manager slow ReusedQueryTest	Importing Dictionaries
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.UpdateWorkerBucket	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	Received new WorkerInformation(size = 0,dataset = ReusedQueryTest)
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.UpdateWorkerBucket	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	Received new WorkerInformation(size = 1,dataset = ReusedQueryTest)
[INFO] [2023-01-26 18:08:21]	c.b.c.m.j.ImportJob	Job Manager slow ReusedQueryTest	Remapping Dictionaries []
[WARN] [2023-01-26 18:08:21]	c.b.c.u.p.ProgressReporterImpl	Job Manager slow ReusedQueryTest	Max cannot be decreased.
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.UpdateDictionary	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	Received Dictionary[ReusedQueryTest.table#ReusedQueryTest$2etable$2esid] of size 4.
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.UpdateDictionary	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	Received Dictionary[ReusedQueryTest.table#ReusedQueryTest$2etable$2esid] of size 4.
[INFO] [2023-01-26 18:08:21]	c.b.c.m.j.ImportJob	Job Manager slow ReusedQueryTest	Start sending 1 Buckets
[WARN] [2023-01-26 18:08:21]	c.b.c.u.p.ProgressReporterImpl	Job Manager slow ReusedQueryTest	One or more Children are not done yet
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.AddImport	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	Received Import[ReusedQueryTest.table.table], containing 6 entries.
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.AddImport	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	Received Import[ReusedQueryTest.table.table], containing 6 entries.
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.j.ImportJob	user.SUPERUSER@SUPERUSER	Done reading data. Contains 2 Entities.
[INFO] [2023-01-26 18:08:21]	c.b.c.m.j.ImportJob	user.SUPERUSER@SUPERUSER	Importing table2 into ReusedQueryTest.table2
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.j.ImportJob	Job Manager slow ReusedQueryTest	Mapped 0 new ids
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.j.ImportJob	Job Manager slow ReusedQueryTest	Updating bucket assignments.
[INFO] [2023-01-26 18:08:21]	c.b.c.m.j.ImportJob	Job Manager slow ReusedQueryTest	Importing Dictionaries
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.ImportBucket	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	Received ReusedQueryTest.table.table.0
[DEBUG] [2023-01-26 18:08:21]	c.b.c.i.s.WorkerStorage	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	Adding Bucket[ReusedQueryTest.table.table.0]
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.UpdateWorkerBucket	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	Received new WorkerInformation(size = 0,dataset = ReusedQueryTest)
[INFO] [2023-01-26 18:08:21]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:08:21 +0000] "POST /admin/datasets/ReusedQueryTest/imports?file=%2Ftmp%2FconqueryIntegrationTest12910953884258704183%2Ftmp_ReusedQueryTest%2Ftable2.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 11
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.UpdateWorkerBucket	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	Received new WorkerInformation(size = 1,dataset = ReusedQueryTest)
[DEBUG] [2023-01-26 18:08:21]	c.b.c.i.s.WorkerStorage		Adding CBlock[ReusedQueryTest.table.table.0.ReusedQueryTest.concept.connector1]
[INFO] [2023-01-26 18:08:21]	c.b.c.m.j.ImportJob	Job Manager slow ReusedQueryTest	Remapping Dictionaries []
[WARN] [2023-01-26 18:08:21]	c.b.c.u.p.ProgressReporterImpl	Job Manager slow ReusedQueryTest	Max cannot be decreased.
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.UpdateDictionary	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	Received Dictionary[ReusedQueryTest.table2#ReusedQueryTest$2etable2$2esid] of size 3.
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.UpdateDictionary	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	Received Dictionary[ReusedQueryTest.table2#ReusedQueryTest$2etable2$2esid] of size 3.
[INFO] [2023-01-26 18:08:21]	c.b.c.m.j.ImportJob	Job Manager slow ReusedQueryTest	Start sending 1 Buckets
[WARN] [2023-01-26 18:08:21]	c.b.c.u.p.ProgressReporterImpl	Job Manager slow ReusedQueryTest	One or more Children are not done yet
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.AddImport	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	Received Import[ReusedQueryTest.table2.table2], containing 6 entries.
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.AddImport	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	Received Import[ReusedQueryTest.table2.table2], containing 6 entries.
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.ImportBucket	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	Received ReusedQueryTest.table2.table2.0
[DEBUG] [2023-01-26 18:08:21]	c.b.c.i.s.WorkerStorage	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	Adding Bucket[ReusedQueryTest.table2.table2.0]
[DEBUG] [2023-01-26 18:08:21]	c.b.c.i.s.WorkerStorage		Adding CBlock[ReusedQueryTest.table2.table2.0.ReusedQueryTest.concept.connector2]
[INFO] [2023-01-26 18:08:21]	c.b.c.a.QueryProcessor	user.SUPERUSER@SUPERUSER	Query posted on Dataset[ReusedQueryTest] by User[{user.SUPERUSER@SUPERUSER].
[INFO] [2023-01-26 18:08:21]	c.b.c.m.q.ExecutionManager	user.SUPERUSER@SUPERUSER	Executing Query[008749db-0461-4909-be70-1dd993aed1a8] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_ReusedQueryTest))]]
127.0.0.1 - - [26/Jan/2023:18:08:21 +0000] "POST /api/datasets/ReusedQueryTest/queries HTTP/1.1" 201 1594 "-" "Conquery (test client)" 14
[DEBUG] [2023-01-26 18:08:21]	c.b.c.i.c.IntegrationUtils		Trying to get Query result
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	Started SecondaryIdQuery ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	Started SecondaryIdQuery ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8
[WARN] [2023-01-26 18:08:21]	c.b.c.m.q.QueryExecutor	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	Entities for query are empty
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.QueryExecutor	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	QueryPlan for Query[ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8] = `com.bakdata.conquery.models.query.queryplan.SecondaryIdQueryPlan@32ec636c`
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.QueryExecutor	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	QueryPlan for Query[ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8] = `com.bakdata.conquery.models.query.queryplan.SecondaryIdQueryPlan@5d992f06`
[INFO] [2023-01-26 18:08:21]	c.b.c.m.q.r.ShardResult	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	FINISHED Query[ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8] with 0 results within PT0.003092S
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=ReusedQueryTest]	Received ShardResult(queryId=ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8, workerId=ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, startTime=2023-01-26T18:08:21.682417, finishTime=2023-01-26T18:08:21.685509) of size 0
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=ReusedQueryTest]	Received Result[size=0] for Query[ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8]
[INFO] [2023-01-26 18:08:21]	c.b.c.m.q.r.ShardResult		FINISHED Query[ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8] with 2 results within PT0.008493S
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=ReusedQueryTest]	Received ShardResult(queryId=ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8, workerId=ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, startTime=2023-01-26T18:08:21.682426, finishTime=2023-01-26T18:08:21.690919) of size 2
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=ReusedQueryTest]	Received Result[size=2] for Query[ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8]
[INFO] [2023-01-26 18:08:21]	c.b.c.m.e.ManagedExecution	Dataset[label=null, name=ReusedQueryTest]	DONE 008749db-0461-4909-be70-1dd993aed1a8 ManagedQuery within PT0.025245S
127.0.0.1 - - [26/Jan/2023:18:08:21 +0000] "GET /api/datasets/ReusedQueryTest/queries/ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8 HTTP/1.1" 200 1846 "-" "Conquery (test client)" 6
[INFO] [2023-01-26 18:08:21]	c.b.c.a.QueryProcessor	user.SUPERUSER@SUPERUSER	Query posted on Dataset[ReusedQueryTest] by User[{user.SUPERUSER@SUPERUSER].
[INFO] [2023-01-26 18:08:21]	c.b.c.m.q.ExecutionManager	user.SUPERUSER@SUPERUSER	Executing Query[45b625e5-cbfb-4bb7-b027-ddedd543b45f] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_ReusedQueryTest))]]
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	Started ConceptQuery ReusedQueryTest.45b625e5-cbfb-4bb7-b027-ddedd543b45f
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	Started ConceptQuery ReusedQueryTest.45b625e5-cbfb-4bb7-b027-ddedd543b45f
[WARN] [2023-01-26 18:08:21]	c.b.c.m.q.QueryExecutor	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	Entities for query are empty
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.QueryExecutor	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	QueryPlan for Query[ReusedQueryTest.45b625e5-cbfb-4bb7-b027-ddedd543b45f] = `ConceptQueryPlan(child=QPParentNode(children=[ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[RealFilterNode(super=NumberFilterNode(super=FilterNode(filterValue=[1.0]), column=Column(id = ReusedQueryTest.table.value, type = REAL)))], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=table, name=table]])])), validityDateColumn=Column(id = ReusedQueryTest.table.datum, type = DATE_RANGE))), table=CQTable(filters=[FilterValue.CQRealRangeFilter(super=FilterValue(value=[1]))], selects=[], connector=ConceptTreeConnector[label=connector1, name=connector1], dateColumn=null), selectedSecondaryId=null), ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[RealFilterNode(super=NumberFilterNode(super=FilterNode(filterValue=[1.0]), column=Column(id = ReusedQueryTest.table2.value, type = REAL)))], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=table2, name=table2]])])), validityDateColumn=Column(id = ReusedQueryTest.table2.datum, type = DATE_RANGE))), table=CQTable(filters=[FilterValue.CQRealRangeFilter(super=FilterValue(value=[1]))], selects=[], connector=ConceptTreeConnector[label=connector2, name=connector2], dateColumn=null), selectedSecondaryId=null)]), dateAggregator=DateAggregator(action=MERGE))`
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.QueryExecutor	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	QueryPlan for Query[ReusedQueryTest.45b625e5-cbfb-4bb7-b027-ddedd543b45f] = `ConceptQueryPlan(child=QPParentNode(children=[ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[RealFilterNode(super=NumberFilterNode(super=FilterNode(filterValue=[1.0]), column=Column(id = ReusedQueryTest.table.value, type = REAL)))], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=table, name=table]])])), validityDateColumn=Column(id = ReusedQueryTest.table.datum, type = DATE_RANGE))), table=CQTable(filters=[FilterValue.CQRealRangeFilter(super=FilterValue(value=[1]))], selects=[], connector=ConceptTreeConnector[label=connector1, name=connector1], dateColumn=null), selectedSecondaryId=null), ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[RealFilterNode(super=NumberFilterNode(super=FilterNode(filterValue=[1.0]), column=Column(id = ReusedQueryTest.table2.value, type = REAL)))], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=table2, name=table2]])])), validityDateColumn=Column(id = ReusedQueryTest.table2.datum, type = DATE_RANGE))), table=CQTable(filters=[FilterValue.CQRealRangeFilter(super=FilterValue(value=[1]))], selects=[], connector=ConceptTreeConnector[label=connector2, name=connector2], dateColumn=null), selectedSecondaryId=null)]), dateAggregator=DateAggregator(action=MERGE))`
[INFO] [2023-01-26 18:08:21]	c.b.c.m.q.r.ShardResult	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	FINISHED Query[ReusedQueryTest.45b625e5-cbfb-4bb7-b027-ddedd543b45f] with 0 results within PT0.001273S
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=ReusedQueryTest]	Received ShardResult(queryId=ReusedQueryTest.45b625e5-cbfb-4bb7-b027-ddedd543b45f, workerId=ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, startTime=2023-01-26T18:08:21.739981, finishTime=2023-01-26T18:08:21.741254) of size 0
127.0.0.1 - - [26/Jan/2023:18:08:21 +0000] "POST /api/datasets/ReusedQueryTest/queries HTTP/1.1" 201 1014 "-" "Conquery (test client)" 19
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=ReusedQueryTest]	Received Result[size=0] for Query[ReusedQueryTest.45b625e5-cbfb-4bb7-b027-ddedd543b45f]
[DEBUG] [2023-01-26 18:08:21]	c.b.c.i.c.IntegrationUtils		Trying to get Query result
[INFO] [2023-01-26 18:08:21]	c.b.c.m.q.r.ShardResult		FINISHED Query[ReusedQueryTest.45b625e5-cbfb-4bb7-b027-ddedd543b45f] with 2 results within PT0.00317S
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=ReusedQueryTest]	Received ShardResult(queryId=ReusedQueryTest.45b625e5-cbfb-4bb7-b027-ddedd543b45f, workerId=ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, startTime=2023-01-26T18:08:21.739985, finishTime=2023-01-26T18:08:21.743155) of size 2
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=ReusedQueryTest]	Received Result[size=2] for Query[ReusedQueryTest.45b625e5-cbfb-4bb7-b027-ddedd543b45f]
[INFO] [2023-01-26 18:08:21]	c.b.c.m.e.ManagedExecution	Dataset[label=null, name=ReusedQueryTest]	DONE 45b625e5-cbfb-4bb7-b027-ddedd543b45f ManagedQuery within PT0.007378S
127.0.0.1 - - [26/Jan/2023:18:08:21 +0000] "GET /api/datasets/ReusedQueryTest/queries/ReusedQueryTest.45b625e5-cbfb-4bb7-b027-ddedd543b45f HTTP/1.1" 200 1265 "-" "Conquery (test client)" 4
[INFO] [2023-01-26 18:08:21]	c.b.c.a.QueryProcessor	user.SUPERUSER@SUPERUSER	User[user.SUPERUSER@SUPERUSER] reexecuted Query[ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=ReusedQueryTest], queryId=008749db-0461-4909-be70-1dd993aed1a8, label=concept	@§$, creationTime=2023-01-26T18:08:21.671911, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@31a561[Count = 0], startTime=2023-01-26T18:08:21.674409, finishTime=2023-01-26T18:08:21.699654, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@130b322d), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_ReusedQueryTest)), query=com.bakdata.conquery.apiv1.query.SecondaryIdQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@39790740], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1bdf675a], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=null, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@7833dd25, com.bakdata.conquery.models.query.ColumnDescriptor@42cceb80, com.bakdata.conquery.models.query.ColumnDescriptor@4f5b5415])]
[INFO] [2023-01-26 18:08:21]	c.b.c.m.q.ExecutionManager	user.SUPERUSER@SUPERUSER	Executing Query[008749db-0461-4909-be70-1dd993aed1a8] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_ReusedQueryTest))]]
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	Started SecondaryIdQuery ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	Started SecondaryIdQuery ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.QueryExecutor	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	QueryPlan for Query[ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8] = `com.bakdata.conquery.models.query.queryplan.SecondaryIdQueryPlan@2c8c9aef`
[WARN] [2023-01-26 18:08:21]	c.b.c.m.q.QueryExecutor	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	Entities for query are empty
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.QueryExecutor	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	QueryPlan for Query[ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8] = `com.bakdata.conquery.models.query.queryplan.SecondaryIdQueryPlan@764f22a1`
[INFO] [2023-01-26 18:08:21]	c.b.c.m.q.r.ShardResult	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	FINISHED Query[ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8] with 0 results within PT0.000518S
127.0.0.1 - - [26/Jan/2023:18:08:21 +0000] "POST /api/datasets/ReusedQueryTest/queries/ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8/reexecute HTTP/1.1" 200 1614 "-" "Conquery (test client)" 5
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=ReusedQueryTest]	Received ShardResult(queryId=ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8, workerId=ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, startTime=2023-01-26T18:08:21.777777, finishTime=2023-01-26T18:08:21.778295) of size 0
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=ReusedQueryTest]	Received Result[size=0] for Query[ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8]
[INFO] [2023-01-26 18:08:21]	c.b.c.m.q.r.ShardResult		FINISHED Query[ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8] with 2 results within PT0.003925S
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=ReusedQueryTest]	Received ShardResult(queryId=ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8, workerId=ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, startTime=2023-01-26T18:08:21.777560, finishTime=2023-01-26T18:08:21.781485) of size 2
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=ReusedQueryTest]	Received Result[size=2] for Query[ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8]
[INFO] [2023-01-26 18:08:21]	c.b.c.m.e.ManagedExecution	Dataset[label=null, name=ReusedQueryTest]	DONE 008749db-0461-4909-be70-1dd993aed1a8 ManagedQuery within PT0.010301S
[INFO] [2023-01-26 18:08:21]	c.b.c.a.QueryProcessor	user.SUPERUSER@SUPERUSER	Query posted on Dataset[ReusedQueryTest] by User[{user.SUPERUSER@SUPERUSER].
[INFO] [2023-01-26 18:08:21]	c.b.c.m.q.ExecutionManager	user.SUPERUSER@SUPERUSER	Executing Query[008749db-0461-4909-be70-1dd993aed1a8] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_ReusedQueryTest))]]
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	Started SecondaryIdQuery ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	Started SecondaryIdQuery ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.QueryExecutor	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	QueryPlan for Query[ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8] = `com.bakdata.conquery.models.query.queryplan.SecondaryIdQueryPlan@4d7a08c5`
[WARN] [2023-01-26 18:08:21]	c.b.c.m.q.QueryExecutor	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	Entities for query are empty
127.0.0.1 - - [26/Jan/2023:18:08:21 +0000] "POST /api/datasets/ReusedQueryTest/queries HTTP/1.1" 201 1614 "-" "Conquery (test client)" 5
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.QueryExecutor	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	QueryPlan for Query[ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8] = `com.bakdata.conquery.models.query.queryplan.SecondaryIdQueryPlan@752516b7`
[INFO] [2023-01-26 18:08:21]	c.b.c.m.q.r.ShardResult	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	FINISHED Query[ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8] with 0 results within PT0.000517S
[DEBUG] [2023-01-26 18:08:21]	c.b.c.i.c.IntegrationUtils		Trying to get Query result
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=ReusedQueryTest]	Received ShardResult(queryId=ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8, workerId=ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, startTime=2023-01-26T18:08:21.822798, finishTime=2023-01-26T18:08:21.823315) of size 0
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=ReusedQueryTest]	Received Result[size=0] for Query[ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8]
[INFO] [2023-01-26 18:08:21]	c.b.c.m.q.r.ShardResult		FINISHED Query[ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8] with 2 results within PT0.002119S
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=ReusedQueryTest]	Received ShardResult(queryId=ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8, workerId=ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, startTime=2023-01-26T18:08:21.822561, finishTime=2023-01-26T18:08:21.824680) of size 2
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=ReusedQueryTest]	Received Result[size=2] for Query[ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8]
[INFO] [2023-01-26 18:08:21]	c.b.c.m.e.ManagedExecution	Dataset[label=null, name=ReusedQueryTest]	DONE 008749db-0461-4909-be70-1dd993aed1a8 ManagedQuery within PT0.004372S
127.0.0.1 - - [26/Jan/2023:18:08:21 +0000] "GET /api/datasets/ReusedQueryTest/queries/ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8 HTTP/1.1" 200 1845 "-" "Conquery (test client)" 4
[INFO] [2023-01-26 18:08:21]	c.b.c.a.QueryProcessor	user.SUPERUSER@SUPERUSER	Query posted on Dataset[ReusedQueryTest] by User[{user.SUPERUSER@SUPERUSER].
[INFO] [2023-01-26 18:08:21]	c.b.c.m.q.ExecutionManager	user.SUPERUSER@SUPERUSER	Executing Query[f789c7a5-f34d-4010-99be-2c77cdf5796e] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_ReusedQueryTest))]]
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	Started SecondaryIdQuery ReusedQueryTest.f789c7a5-f34d-4010-99be-2c77cdf5796e
127.0.0.1 - - [26/Jan/2023:18:08:21 +0000] "POST /api/datasets/ReusedQueryTest/queries HTTP/1.1" 201 1608 "-" "Conquery (test client)" 12
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	Started SecondaryIdQuery ReusedQueryTest.f789c7a5-f34d-4010-99be-2c77cdf5796e
[DEBUG] [2023-01-26 18:08:21]	c.b.c.i.c.IntegrationUtils		Trying to get Query result
[WARN] [2023-01-26 18:08:21]	c.b.c.m.q.QueryExecutor	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	Entities for query are empty
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.QueryExecutor	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	QueryPlan for Query[ReusedQueryTest.f789c7a5-f34d-4010-99be-2c77cdf5796e] = `com.bakdata.conquery.models.query.queryplan.SecondaryIdQueryPlan@4dd44afb`
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.QueryExecutor	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	QueryPlan for Query[ReusedQueryTest.f789c7a5-f34d-4010-99be-2c77cdf5796e] = `com.bakdata.conquery.models.query.queryplan.SecondaryIdQueryPlan@32d90f6`
[INFO] [2023-01-26 18:08:21]	c.b.c.m.q.r.ShardResult	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	FINISHED Query[ReusedQueryTest.f789c7a5-f34d-4010-99be-2c77cdf5796e] with 0 results within PT0.002155S
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=ReusedQueryTest]	Received ShardResult(queryId=ReusedQueryTest.f789c7a5-f34d-4010-99be-2c77cdf5796e, workerId=ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, startTime=2023-01-26T18:08:21.869363, finishTime=2023-01-26T18:08:21.871518) of size 0
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=ReusedQueryTest]	Received Result[size=0] for Query[ReusedQueryTest.f789c7a5-f34d-4010-99be-2c77cdf5796e]
[INFO] [2023-01-26 18:08:21]	c.b.c.m.q.r.ShardResult		FINISHED Query[ReusedQueryTest.f789c7a5-f34d-4010-99be-2c77cdf5796e] with 1 results within PT0.002769S
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=ReusedQueryTest]	Received ShardResult(queryId=ReusedQueryTest.f789c7a5-f34d-4010-99be-2c77cdf5796e, workerId=ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, startTime=2023-01-26T18:08:21.869834, finishTime=2023-01-26T18:08:21.872603) of size 1
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=ReusedQueryTest]	Received Result[size=1] for Query[ReusedQueryTest.f789c7a5-f34d-4010-99be-2c77cdf5796e]
[INFO] [2023-01-26 18:08:21]	c.b.c.m.e.ManagedExecution	Dataset[label=null, name=ReusedQueryTest]	DONE f789c7a5-f34d-4010-99be-2c77cdf5796e ManagedQuery within PT0.009207S
127.0.0.1 - - [26/Jan/2023:18:08:21 +0000] "GET /api/datasets/ReusedQueryTest/queries/ReusedQueryTest.f789c7a5-f34d-4010-99be-2c77cdf5796e HTTP/1.1" 200 1859 "-" "Conquery (test client)" 6
[INFO] [2023-01-26 18:08:21]	c.b.c.a.QueryProcessor	user.SUPERUSER@SUPERUSER	Query posted on Dataset[ReusedQueryTest] by User[{user.SUPERUSER@SUPERUSER].
[INFO] [2023-01-26 18:08:21]	c.b.c.m.q.ExecutionManager	user.SUPERUSER@SUPERUSER	Executing Query[008749db-0461-4909-be70-1dd993aed1a8] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_ReusedQueryTest))]]
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	Started SecondaryIdQuery ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	Started SecondaryIdQuery ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.QueryExecutor	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	QueryPlan for Query[ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8] = `com.bakdata.conquery.models.query.queryplan.SecondaryIdQueryPlan@e77a2bb`
[WARN] [2023-01-26 18:08:21]	c.b.c.m.q.QueryExecutor	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	Entities for query are empty
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.QueryExecutor	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	QueryPlan for Query[ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8] = `com.bakdata.conquery.models.query.queryplan.SecondaryIdQueryPlan@5eeb9f6e`
[INFO] [2023-01-26 18:08:21]	c.b.c.m.q.r.ShardResult	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	FINISHED Query[ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8] with 0 results within PT0.000473S
127.0.0.1 - - [26/Jan/2023:18:08:21 +0000] "POST /api/datasets/ReusedQueryTest/queries HTTP/1.1" 201 1614 "-" "Conquery (test client)" 5
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=ReusedQueryTest]	Received ShardResult(queryId=ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8, workerId=ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, startTime=2023-01-26T18:08:21.905685, finishTime=2023-01-26T18:08:21.906158) of size 0
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=ReusedQueryTest]	Received Result[size=0] for Query[ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8]
[DEBUG] [2023-01-26 18:08:21]	c.b.c.i.c.IntegrationUtils		Trying to get Query result
[INFO] [2023-01-26 18:08:21]	c.b.c.m.q.r.ShardResult		FINISHED Query[ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8] with 2 results within PT0.002326S
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=ReusedQueryTest]	Received ShardResult(queryId=ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8, workerId=ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, startTime=2023-01-26T18:08:21.905396, finishTime=2023-01-26T18:08:21.907722) of size 2
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=ReusedQueryTest]	Received Result[size=2] for Query[ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8]
[INFO] [2023-01-26 18:08:21]	c.b.c.m.e.ManagedExecution	Dataset[label=null, name=ReusedQueryTest]	DONE 008749db-0461-4909-be70-1dd993aed1a8 ManagedQuery within PT0.004274S
127.0.0.1 - - [26/Jan/2023:18:08:21 +0000] "GET /api/datasets/ReusedQueryTest/queries/ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8 HTTP/1.1" 200 1845 "-" "Conquery (test client)" 3
[INFO] [2023-01-26 18:08:21]	c.b.c.a.QueryProcessor	user.SUPERUSER@SUPERUSER	Query posted on Dataset[ReusedQueryTest] by User[{user.SUPERUSER@SUPERUSER].
[INFO] [2023-01-26 18:08:21]	c.b.c.m.q.ExecutionManager	user.SUPERUSER@SUPERUSER	Executing Query[008749db-0461-4909-be70-1dd993aed1a8] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_ReusedQueryTest))]]
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	Started SecondaryIdQuery ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	Started SecondaryIdQuery ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.QueryExecutor	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	QueryPlan for Query[ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8] = `com.bakdata.conquery.models.query.queryplan.SecondaryIdQueryPlan@7d0a5e5a`
[WARN] [2023-01-26 18:08:21]	c.b.c.m.q.QueryExecutor	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	Entities for query are empty
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.QueryExecutor	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	QueryPlan for Query[ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8] = `com.bakdata.conquery.models.query.queryplan.SecondaryIdQueryPlan@5cc3b87d`
[INFO] [2023-01-26 18:08:21]	c.b.c.m.q.r.ShardResult	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	FINISHED Query[ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8] with 0 results within PT0.000407S
127.0.0.1 - - [26/Jan/2023:18:08:21 +0000] "POST /api/datasets/ReusedQueryTest/queries HTTP/1.1" 201 1614 "-" "Conquery (test client)" 4
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=ReusedQueryTest]	Received ShardResult(queryId=ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8, workerId=ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, startTime=2023-01-26T18:08:21.938926, finishTime=2023-01-26T18:08:21.939333) of size 0
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=ReusedQueryTest]	Received Result[size=0] for Query[ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8]
[DEBUG] [2023-01-26 18:08:21]	c.b.c.i.c.IntegrationUtils		Trying to get Query result
[INFO] [2023-01-26 18:08:21]	c.b.c.m.q.r.ShardResult		FINISHED Query[ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8] with 2 results within PT0.002148S
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=ReusedQueryTest]	Received ShardResult(queryId=ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8, workerId=ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, startTime=2023-01-26T18:08:21.938798, finishTime=2023-01-26T18:08:21.940946) of size 2
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=ReusedQueryTest]	Received Result[size=2] for Query[ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8]
[INFO] [2023-01-26 18:08:21]	c.b.c.m.e.ManagedExecution	Dataset[label=null, name=ReusedQueryTest]	DONE 008749db-0461-4909-be70-1dd993aed1a8 ManagedQuery within PT0.00412S
127.0.0.1 - - [26/Jan/2023:18:08:21 +0000] "GET /api/datasets/ReusedQueryTest/queries/ReusedQueryTest.008749db-0461-4909-be70-1dd993aed1a8 HTTP/1.1" 200 1845 "-" "Conquery (test client)" 4
[INFO] [2023-01-26 18:08:21]	c.b.c.a.QueryProcessor	user.SUPERUSER@SUPERUSER	Query posted on Dataset[ReusedQueryTest] by User[{user.SUPERUSER@SUPERUSER].
[INFO] [2023-01-26 18:08:21]	c.b.c.m.q.ExecutionManager	user.SUPERUSER@SUPERUSER	Executing Query[8e442479-576e-44d7-ab9f-34aad85a922d] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_ReusedQueryTest))]]
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	Started ConceptQuery ReusedQueryTest.8e442479-576e-44d7-ab9f-34aad85a922d
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	Started ConceptQuery ReusedQueryTest.8e442479-576e-44d7-ab9f-34aad85a922d
[WARN] [2023-01-26 18:08:21]	c.b.c.m.q.QueryExecutor	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	Entities for query are empty
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.QueryExecutor	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	QueryPlan for Query[ReusedQueryTest.8e442479-576e-44d7-ab9f-34aad85a922d] = `ConceptQueryPlan(child=QPParentNode(children=[ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[RealFilterNode(super=NumberFilterNode(super=FilterNode(filterValue=[1.0]), column=Column(id = ReusedQueryTest.table.value, type = REAL)))], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=table, name=table]])])), validityDateColumn=Column(id = ReusedQueryTest.table.datum, type = DATE_RANGE))), table=CQTable(filters=[FilterValue.CQRealRangeFilter(super=FilterValue(value=[1]))], selects=[], connector=ConceptTreeConnector[label=connector1, name=connector1], dateColumn=null), selectedSecondaryId=null), ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[RealFilterNode(super=NumberFilterNode(super=FilterNode(filterValue=[1.0]), column=Column(id = ReusedQueryTest.table2.value, type = REAL)))], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=table2, name=table2]])])), validityDateColumn=Column(id = ReusedQueryTest.table2.datum, type = DATE_RANGE))), table=CQTable(filters=[FilterValue.CQRealRangeFilter(super=FilterValue(value=[1]))], selects=[], connector=ConceptTreeConnector[label=connector2, name=connector2], dateColumn=null), selectedSecondaryId=null)]), dateAggregator=DateAggregator(action=MERGE))`
[INFO] [2023-01-26 18:08:21]	c.b.c.m.q.r.ShardResult	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	FINISHED Query[ReusedQueryTest.8e442479-576e-44d7-ab9f-34aad85a922d] with 0 results within PT0.000398S
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.QueryExecutor	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	QueryPlan for Query[ReusedQueryTest.8e442479-576e-44d7-ab9f-34aad85a922d] = `ConceptQueryPlan(child=QPParentNode(children=[ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[RealFilterNode(super=NumberFilterNode(super=FilterNode(filterValue=[1.0]), column=Column(id = ReusedQueryTest.table.value, type = REAL)))], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=table, name=table]])])), validityDateColumn=Column(id = ReusedQueryTest.table.datum, type = DATE_RANGE))), table=CQTable(filters=[FilterValue.CQRealRangeFilter(super=FilterValue(value=[1]))], selects=[], connector=ConceptTreeConnector[label=connector1, name=connector1], dateColumn=null), selectedSecondaryId=null), ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[RealFilterNode(super=NumberFilterNode(super=FilterNode(filterValue=[1.0]), column=Column(id = ReusedQueryTest.table2.value, type = REAL)))], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=table2, name=table2]])])), validityDateColumn=Column(id = ReusedQueryTest.table2.datum, type = DATE_RANGE))), table=CQTable(filters=[FilterValue.CQRealRangeFilter(super=FilterValue(value=[1]))], selects=[], connector=ConceptTreeConnector[label=connector2, name=connector2], dateColumn=null), selectedSecondaryId=null)]), dateAggregator=DateAggregator(action=MERGE))`
127.0.0.1 - - [26/Jan/2023:18:08:21 +0000] "POST /api/datasets/ReusedQueryTest/queries HTTP/1.1" 201 1014 "-" "Conquery (test client)" 6
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=ReusedQueryTest]	Received ShardResult(queryId=ReusedQueryTest.8e442479-576e-44d7-ab9f-34aad85a922d, workerId=ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, startTime=2023-01-26T18:08:21.968566, finishTime=2023-01-26T18:08:21.968964) of size 0
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=ReusedQueryTest]	Received Result[size=0] for Query[ReusedQueryTest.8e442479-576e-44d7-ab9f-34aad85a922d]
[INFO] [2023-01-26 18:08:21]	c.b.c.m.q.r.ShardResult		FINISHED Query[ReusedQueryTest.8e442479-576e-44d7-ab9f-34aad85a922d] with 2 results within PT0.001377S
[DEBUG] [2023-01-26 18:08:21]	c.b.c.i.c.IntegrationUtils		Trying to get Query result
[INFO] [2023-01-26 18:08:21]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=ReusedQueryTest]	Received ShardResult(queryId=ReusedQueryTest.8e442479-576e-44d7-ab9f-34aad85a922d, workerId=ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, startTime=2023-01-26T18:08:21.968523, finishTime=2023-01-26T18:08:21.969900) of size 2
[DEBUG] [2023-01-26 18:08:21]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=ReusedQueryTest]	Received Result[size=2] for Query[ReusedQueryTest.8e442479-576e-44d7-ab9f-34aad85a922d]
[INFO] [2023-01-26 18:08:21]	c.b.c.m.e.ManagedExecution	Dataset[label=null, name=ReusedQueryTest]	DONE 8e442479-576e-44d7-ab9f-34aad85a922d ManagedQuery within PT0.004556S
127.0.0.1 - - [26/Jan/2023:18:08:21 +0000] "GET /api/datasets/ReusedQueryTest/queries/ReusedQueryTest.8e442479-576e-44d7-ab9f-34aad85a922d HTTP/1.1" 200 1264 "-" "Conquery (test client)" 3
[INFO] [2023-01-26 18:08:22]	c.b.c.a.QueryProcessor	user.SUPERUSER@SUPERUSER	Query posted on Dataset[ReusedQueryTest] by User[{user.SUPERUSER@SUPERUSER].
[INFO] [2023-01-26 18:08:22]	c.b.c.m.q.ExecutionManager	user.SUPERUSER@SUPERUSER	Executing Query[43c7656b-1d71-41ab-ad44-b6460ab6af79] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_ReusedQueryTest))]]
[INFO] [2023-01-26 18:08:22]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	Started SecondaryIdQuery ReusedQueryTest.43c7656b-1d71-41ab-ad44-b6460ab6af79
[INFO] [2023-01-26 18:08:22]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	Started SecondaryIdQuery ReusedQueryTest.43c7656b-1d71-41ab-ad44-b6460ab6af79
[WARN] [2023-01-26 18:08:22]	c.b.c.m.q.QueryExecutor	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	Entities for query are empty
[DEBUG] [2023-01-26 18:08:22]	c.b.c.m.q.QueryExecutor	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	QueryPlan for Query[ReusedQueryTest.43c7656b-1d71-41ab-ad44-b6460ab6af79] = `com.bakdata.conquery.models.query.queryplan.SecondaryIdQueryPlan@82c9f07`
[DEBUG] [2023-01-26 18:08:22]	c.b.c.m.q.QueryExecutor	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	QueryPlan for Query[ReusedQueryTest.43c7656b-1d71-41ab-ad44-b6460ab6af79] = `com.bakdata.conquery.models.query.queryplan.SecondaryIdQueryPlan@2680d66b`
[INFO] [2023-01-26 18:08:22]	c.b.c.m.q.r.ShardResult	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	FINISHED Query[ReusedQueryTest.43c7656b-1d71-41ab-ad44-b6460ab6af79] with 0 results within PT0.000358S
[INFO] [2023-01-26 18:08:22]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=ReusedQueryTest]	Received ShardResult(queryId=ReusedQueryTest.43c7656b-1d71-41ab-ad44-b6460ab6af79, workerId=ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, startTime=2023-01-26T18:08:22.004934, finishTime=2023-01-26T18:08:22.005292) of size 0
[DEBUG] [2023-01-26 18:08:22]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=ReusedQueryTest]	Received Result[size=0] for Query[ReusedQueryTest.43c7656b-1d71-41ab-ad44-b6460ab6af79]
[INFO] [2023-01-26 18:08:22]	c.b.c.m.q.r.ShardResult		FINISHED Query[ReusedQueryTest.43c7656b-1d71-41ab-ad44-b6460ab6af79] with 2 results within PT0.001167S
[INFO] [2023-01-26 18:08:22]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=ReusedQueryTest]	Received ShardResult(queryId=ReusedQueryTest.43c7656b-1d71-41ab-ad44-b6460ab6af79, workerId=ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, startTime=2023-01-26T18:08:22.004838, finishTime=2023-01-26T18:08:22.006005) of size 2
[DEBUG] [2023-01-26 18:08:22]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=ReusedQueryTest]	Received Result[size=2] for Query[ReusedQueryTest.43c7656b-1d71-41ab-ad44-b6460ab6af79]
[INFO] [2023-01-26 18:08:22]	c.b.c.m.e.ManagedExecution	Dataset[label=null, name=ReusedQueryTest]	DONE 43c7656b-1d71-41ab-ad44-b6460ab6af79 ManagedQuery within PT0.004305S
127.0.0.1 - - [26/Jan/2023:18:08:22 +0000] "POST /api/datasets/ReusedQueryTest/queries HTTP/1.1" 201 1181 "-" "Conquery (test client)" 11
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.c.IntegrationUtils		Trying to get Query result
127.0.0.1 - - [26/Jan/2023:18:08:22 +0000] "GET /api/datasets/ReusedQueryTest/queries/ReusedQueryTest.43c7656b-1d71-41ab-ad44-b6460ab6af79 HTTP/1.1" 200 1432 "-" "Conquery (test client)" 5
[INFO] [2023-01-26 18:08:22]	c.b.c.a.QueryProcessor	user.shareholder	Query posted on Dataset[ReusedQueryTest] by User[{user.shareholder].
[INFO] [2023-01-26 18:08:22]	c.b.c.m.q.ExecutionManager	user.shareholder	Executing Query[1e6867b6-8233-45b1-af96-7f5facc6512a] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_ReusedQueryTest))]]
[INFO] [2023-01-26 18:08:22]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	Started SecondaryIdQuery ReusedQueryTest.1e6867b6-8233-45b1-af96-7f5facc6512a
[INFO] [2023-01-26 18:08:22]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	Started SecondaryIdQuery ReusedQueryTest.1e6867b6-8233-45b1-af96-7f5facc6512a
[WARN] [2023-01-26 18:08:22]	c.b.c.m.q.QueryExecutor	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	Entities for query are empty
[DEBUG] [2023-01-26 18:08:22]	c.b.c.m.q.QueryExecutor	Worker[ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, /127.0.0.1:49092]	QueryPlan for Query[ReusedQueryTest.1e6867b6-8233-45b1-af96-7f5facc6512a] = `com.bakdata.conquery.models.query.queryplan.SecondaryIdQueryPlan@60d6d5aa`
[DEBUG] [2023-01-26 18:08:22]	c.b.c.m.q.QueryExecutor	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	QueryPlan for Query[ReusedQueryTest.1e6867b6-8233-45b1-af96-7f5facc6512a] = `com.bakdata.conquery.models.query.queryplan.SecondaryIdQueryPlan@68c57748`
[INFO] [2023-01-26 18:08:22]	c.b.c.m.q.r.ShardResult	Worker[ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, /127.0.0.1:49088]	FINISHED Query[ReusedQueryTest.1e6867b6-8233-45b1-af96-7f5facc6512a] with 0 results within PT0.000445S
127.0.0.1 - - [26/Jan/2023:18:08:22 +0000] "POST /api/datasets/ReusedQueryTest/queries HTTP/1.1" 201 952 "-" "Conquery (test client)" 5
[INFO] [2023-01-26 18:08:22]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=ReusedQueryTest]	Received ShardResult(queryId=ReusedQueryTest.1e6867b6-8233-45b1-af96-7f5facc6512a, workerId=ReusedQueryTest.worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada, startTime=2023-01-26T18:08:22.039800, finishTime=2023-01-26T18:08:22.040245) of size 0
[DEBUG] [2023-01-26 18:08:22]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=ReusedQueryTest]	Received Result[size=0] for Query[ReusedQueryTest.1e6867b6-8233-45b1-af96-7f5facc6512a]
[INFO] [2023-01-26 18:08:22]	c.b.c.m.q.r.ShardResult		FINISHED Query[ReusedQueryTest.1e6867b6-8233-45b1-af96-7f5facc6512a] with 2 results within PT0.001733S
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.c.IntegrationUtils		Trying to get Query result
[INFO] [2023-01-26 18:08:22]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=ReusedQueryTest]	Received ShardResult(queryId=ReusedQueryTest.1e6867b6-8233-45b1-af96-7f5facc6512a, workerId=ReusedQueryTest.worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a, startTime=2023-01-26T18:08:22.039640, finishTime=2023-01-26T18:08:22.041373) of size 2
[DEBUG] [2023-01-26 18:08:22]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=ReusedQueryTest]	Received Result[size=2] for Query[ReusedQueryTest.1e6867b6-8233-45b1-af96-7f5facc6512a]
[INFO] [2023-01-26 18:08:22]	c.b.c.m.e.ManagedExecution	Dataset[label=null, name=ReusedQueryTest]	DONE 1e6867b6-8233-45b1-af96-7f5facc6512a ManagedQuery within PT0.004095S
127.0.0.1 - - [26/Jan/2023:18:08:22 +0000] "GET /api/datasets/ReusedQueryTest/queries/ReusedQueryTest.1e6867b6-8233-45b1-af96-7f5facc6512a HTTP/1.1" 200 966 "-" "Conquery (test client)" 4
[INFO] [2023-01-26 18:08:22]	c.b.c.m.j.JobExecutor		Closing Job Manager fast ReusedQueryTest
[INFO] [2023-01-26 18:08:22]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node1	removing worker for Dataset[label=ReusedQueryTest, name=ReusedQueryTest]
[INFO] [2023-01-26 18:08:22]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node0	removing worker for Dataset[label=ReusedQueryTest, name=ReusedQueryTest]
[INFO] [2023-01-26 18:08:22]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager fast worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada
[INFO] [2023-01-26 18:08:22]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager fast worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a
[INFO] [2023-01-26 18:08:22]	c.b.c.m.j.JobExecutor		Closing Job Manager slow ReusedQueryTest
[INFO] [2023-01-26 18:08:22]	c.b.c.m.w.Namespace		Removing namespace storage of ReusedQueryTest
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore		Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ReusedQueryTest
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore		Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ReusedQueryTest
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore		Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ReusedQueryTest
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore		Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ReusedQueryTest
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore		Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ReusedQueryTest
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore		Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ReusedQueryTest
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore		Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ReusedQueryTest
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore		Deleting store ID_MAPPING_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ReusedQueryTest
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore		Deleting store ID_MAPPING_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ReusedQueryTest
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore		Deleting store STRUCTURE from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ReusedQueryTest
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore		Deleting store WORKER_TO_BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ReusedQueryTest
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore		Deleting store PRIMARY_DICTIONARY from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ReusedQueryTest
[INFO] [2023-01-26 18:08:22]	c.b.c.m.c.XodusStoreFactory		Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ReusedQueryTest
[INFO] [2023-01-26 18:08:22]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager slow worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada
[INFO] [2023-01-26 18:08:22]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager slow worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada
[INFO] [2023-01-26 18:08:22]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node0	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ReusedQueryTest_2d772de0-1346-4e4c-a9e5-24aa896b4ada
[INFO] [2023-01-26 18:08:22]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a
[INFO] [2023-01-26 18:08:22]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node1	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ReusedQueryTest_cd53c3c2-006d-4e00-a8d2-65df5307ec4a
[INFO] [2023-01-26 18:08:22]	c.b.c.i.IntegrationTest$Wrapper	ReusedQueryTest	SUCCESS integration test ReusedQueryTest
[INFO] [2023-01-26 18:08:22]	c.b.c.i.IntegrationTest$Wrapper	RoleHandlingOnGroupTest	STARTING integration test RoleHandlingOnGroupTest
[INFO] [2023-01-26 18:08:22]	c.b.c.u.s.TestConquery	RoleHandlingOnGroupTest	Setting up dataset
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	RoleHandlingOnGroupTest	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	RoleHandlingOnGroupTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingOnGroupTest:DATASET}): 0 entries, 0 B within 128.8 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	RoleHandlingOnGroupTest	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	RoleHandlingOnGroupTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingOnGroupTest:SECONDARY_IDS}): 0 entries, 0 B within 63.28 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	RoleHandlingOnGroupTest	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	RoleHandlingOnGroupTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingOnGroupTest:TABLES}): 0 entries, 0 B within 51.43 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	RoleHandlingOnGroupTest	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	RoleHandlingOnGroupTest		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 77.87 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	RoleHandlingOnGroupTest	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	RoleHandlingOnGroupTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingOnGroupTest:IMPORTS}): 0 entries, 0 B within 57.79 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	RoleHandlingOnGroupTest	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	RoleHandlingOnGroupTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingOnGroupTest:CONCEPTS}): 0 entries, 0 B within 42.67 μs
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.NamespacedStorage	RoleHandlingOnGroupTest	Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	RoleHandlingOnGroupTest	While processing store ID_MAPPING_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	RoleHandlingOnGroupTest		loaded store cached big ID_MAPPING(EntityIdMap): 0 entries, 0 B within 46.11 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	RoleHandlingOnGroupTest	While processing store STRUCTURE:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	RoleHandlingOnGroupTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingOnGroupTest:STRUCTURE}): 0 entries, 0 B within 59.17 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	RoleHandlingOnGroupTest	While processing store WORKER_TO_BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	RoleHandlingOnGroupTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingOnGroupTest:WORKER_TO_BUCKETS}): 0 entries, 0 B within 45.41 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	RoleHandlingOnGroupTest	While processing store PRIMARY_DICTIONARY:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	RoleHandlingOnGroupTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingOnGroupTest:PRIMARY_DICTIONARY}): 0 entries, 0 B within 43.85 μs
[INFO] [2023-01-26 18:08:22]	c.b.c.m.m.n.s.AddWorker	Job Manager slow shard-node0	creating a new worker for Dataset[label=RoleHandlingOnGroupTest, name=RoleHandlingOnGroupTest]
[INFO] [2023-01-26 18:08:22]	c.b.c.m.m.n.s.AddWorker	Job Manager slow shard-node1	creating a new worker for Dataset[label=RoleHandlingOnGroupTest, name=RoleHandlingOnGroupTest]
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingOnGroupTest_c7281b78-ad06-4707-8e58-dc5a4ec84911:DATASET}): 0 entries, 0 B within 129.9 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingOnGroupTest_c7281b78-ad06-4707-8e58-dc5a4ec84911:SECONDARY_IDS}): 0 entries, 0 B within 48.52 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingOnGroupTest_c7281b78-ad06-4707-8e58-dc5a4ec84911:TABLES}): 0 entries, 0 B within 35.62 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 37.05 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingOnGroupTest_c7281b78-ad06-4707-8e58-dc5a4ec84911:IMPORTS}): 0 entries, 0 B within 31.96 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingOnGroupTest_c7281b78-ad06-4707-8e58-dc5a4ec84911:CONCEPTS}): 0 entries, 0 B within 32.51 μs
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.NamespacedStorage	Job Manager slow shard-node1	Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store WORKER:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingOnGroupTest_c7281b78-ad06-4707-8e58-dc5a4ec84911:WORKER}): 0 entries, 0 B within 29.63 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingOnGroupTest_c7281b78-ad06-4707-8e58-dc5a4ec84911:BUCKETS}): 0 entries, 0 B within 32.08 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingOnGroupTest_c7281b78-ad06-4707-8e58-dc5a4ec84911:C_BLOCKS}): 0 entries, 0 B within 28.48 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingOnGroupTest_41154205-be09-4104-89ca-da870453fa7f:DATASET}): 0 entries, 0 B within 96.97 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingOnGroupTest_41154205-be09-4104-89ca-da870453fa7f:SECONDARY_IDS}): 0 entries, 0 B within 51.77 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingOnGroupTest_41154205-be09-4104-89ca-da870453fa7f:TABLES}): 0 entries, 0 B within 20.69 ms
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 99.66 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingOnGroupTest_41154205-be09-4104-89ca-da870453fa7f:IMPORTS}): 0 entries, 0 B within 58.77 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingOnGroupTest_41154205-be09-4104-89ca-da870453fa7f:CONCEPTS}): 0 entries, 0 B within 34.29 μs
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.NamespacedStorage	Job Manager slow shard-node0	Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store WORKER:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingOnGroupTest_41154205-be09-4104-89ca-da870453fa7f:WORKER}): 0 entries, 0 B within 32.06 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingOnGroupTest_41154205-be09-4104-89ca-da870453fa7f:BUCKETS}): 0 entries, 0 B within 31.11 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingOnGroupTest_41154205-be09-4104-89ca-da870453fa7f:C_BLOCKS}): 0 entries, 0 B within 29.94 μs
[INFO] [2023-01-26 18:08:22]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=RoleHandlingOnGroupTest]	Imports of worker RoleHandlingOnGroupTest.worker_RoleHandlingOnGroupTest_41154205-be09-4104-89ca-da870453fa7f are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:22]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=RoleHandlingOnGroupTest]	Buckets of worker RoleHandlingOnGroupTest.worker_RoleHandlingOnGroupTest_41154205-be09-4104-89ca-da870453fa7f are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:22]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=RoleHandlingOnGroupTest]	Consistency check was successful
[INFO] [2023-01-26 18:08:22]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=RoleHandlingOnGroupTest]	Imports of worker RoleHandlingOnGroupTest.worker_RoleHandlingOnGroupTest_c7281b78-ad06-4707-8e58-dc5a4ec84911 are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:22]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=RoleHandlingOnGroupTest]	Buckets of worker RoleHandlingOnGroupTest.worker_RoleHandlingOnGroupTest_c7281b78-ad06-4707-8e58-dc5a4ec84911 are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:22]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=RoleHandlingOnGroupTest]	Consistency check was successful
[INFO] [2023-01-26 18:08:22]	c.b.c.u.s.TestConquery	RoleHandlingOnGroupTest	Waiting for jobs to finish
[DEBUG] [2023-01-26 18:08:22]	c.b.c.m.a.AuthorizationController	RoleHandlingOnGroupTest	Security manager registered
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.MetaStorage	RoleHandlingOnGroupTest	Remove User = user.user
[INFO] [2023-01-26 18:08:22]	c.b.c.m.j.JobExecutor	RoleHandlingOnGroupTest	Closing Job Manager fast RoleHandlingOnGroupTest
[INFO] [2023-01-26 18:08:22]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node1	removing worker for Dataset[label=RoleHandlingOnGroupTest, name=RoleHandlingOnGroupTest]
[INFO] [2023-01-26 18:08:22]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node0	removing worker for Dataset[label=RoleHandlingOnGroupTest, name=RoleHandlingOnGroupTest]
[INFO] [2023-01-26 18:08:22]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager fast worker_RoleHandlingOnGroupTest_c7281b78-ad06-4707-8e58-dc5a4ec84911
[INFO] [2023-01-26 18:08:22]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager fast worker_RoleHandlingOnGroupTest_41154205-be09-4104-89ca-da870453fa7f
[INFO] [2023-01-26 18:08:22]	c.b.c.m.j.JobExecutor	RoleHandlingOnGroupTest	Closing Job Manager slow RoleHandlingOnGroupTest
[INFO] [2023-01-26 18:08:22]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager slow worker_RoleHandlingOnGroupTest_c7281b78-ad06-4707-8e58-dc5a4ec84911
[INFO] [2023-01-26 18:08:22]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager slow worker_RoleHandlingOnGroupTest_41154205-be09-4104-89ca-da870453fa7f
[INFO] [2023-01-26 18:08:22]	c.b.c.m.w.Namespace	RoleHandlingOnGroupTest	Removing namespace storage of RoleHandlingOnGroupTest
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	RoleHandlingOnGroupTest	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingOnGroupTest
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	RoleHandlingOnGroupTest	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingOnGroupTest
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	RoleHandlingOnGroupTest	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingOnGroupTest
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	RoleHandlingOnGroupTest	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingOnGroupTest
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	RoleHandlingOnGroupTest	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingOnGroupTest
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	RoleHandlingOnGroupTest	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingOnGroupTest
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	RoleHandlingOnGroupTest	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingOnGroupTest
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	RoleHandlingOnGroupTest	Deleting store ID_MAPPING_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingOnGroupTest
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	RoleHandlingOnGroupTest	Deleting store ID_MAPPING_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingOnGroupTest
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	RoleHandlingOnGroupTest	Deleting store STRUCTURE from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingOnGroupTest
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	RoleHandlingOnGroupTest	Deleting store WORKER_TO_BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingOnGroupTest
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	RoleHandlingOnGroupTest	Deleting store PRIMARY_DICTIONARY from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingOnGroupTest
[INFO] [2023-01-26 18:08:22]	c.b.c.m.c.XodusStoreFactory	RoleHandlingOnGroupTest	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingOnGroupTest
[INFO] [2023-01-26 18:08:22]	c.b.c.u.s.TestConquery	RoleHandlingOnGroupTest	Waiting for jobs to finish
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingOnGroupTest_c7281b78-ad06-4707-8e58-dc5a4ec84911
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingOnGroupTest_c7281b78-ad06-4707-8e58-dc5a4ec84911
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingOnGroupTest_c7281b78-ad06-4707-8e58-dc5a4ec84911
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingOnGroupTest_c7281b78-ad06-4707-8e58-dc5a4ec84911
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingOnGroupTest_c7281b78-ad06-4707-8e58-dc5a4ec84911
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingOnGroupTest_c7281b78-ad06-4707-8e58-dc5a4ec84911
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingOnGroupTest_c7281b78-ad06-4707-8e58-dc5a4ec84911
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingOnGroupTest_c7281b78-ad06-4707-8e58-dc5a4ec84911
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingOnGroupTest_c7281b78-ad06-4707-8e58-dc5a4ec84911
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingOnGroupTest_c7281b78-ad06-4707-8e58-dc5a4ec84911
[INFO] [2023-01-26 18:08:22]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node1	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingOnGroupTest_c7281b78-ad06-4707-8e58-dc5a4ec84911
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingOnGroupTest_41154205-be09-4104-89ca-da870453fa7f
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingOnGroupTest_41154205-be09-4104-89ca-da870453fa7f
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingOnGroupTest_41154205-be09-4104-89ca-da870453fa7f
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingOnGroupTest_41154205-be09-4104-89ca-da870453fa7f
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingOnGroupTest_41154205-be09-4104-89ca-da870453fa7f
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingOnGroupTest_41154205-be09-4104-89ca-da870453fa7f
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingOnGroupTest_41154205-be09-4104-89ca-da870453fa7f
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingOnGroupTest_41154205-be09-4104-89ca-da870453fa7f
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingOnGroupTest_41154205-be09-4104-89ca-da870453fa7f
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingOnGroupTest_41154205-be09-4104-89ca-da870453fa7f
[INFO] [2023-01-26 18:08:22]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node0	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingOnGroupTest_41154205-be09-4104-89ca-da870453fa7f
[INFO] [2023-01-26 18:08:22]	c.b.c.i.IntegrationTest$Wrapper	RoleHandlingOnGroupTest	SUCCESS integration test RoleHandlingOnGroupTest
[INFO] [2023-01-26 18:08:22]	c.b.c.i.IntegrationTest$Wrapper	RoleHandlingTest	STARTING integration test RoleHandlingTest
[INFO] [2023-01-26 18:08:22]	c.b.c.u.s.TestConquery	RoleHandlingTest	Setting up dataset
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	RoleHandlingTest	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	RoleHandlingTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingTest:DATASET}): 0 entries, 0 B within 150.2 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	RoleHandlingTest	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	RoleHandlingTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingTest:SECONDARY_IDS}): 0 entries, 0 B within 93.84 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	RoleHandlingTest	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	RoleHandlingTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingTest:TABLES}): 0 entries, 0 B within 47.02 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	RoleHandlingTest	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	RoleHandlingTest		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 50.41 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	RoleHandlingTest	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	RoleHandlingTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingTest:IMPORTS}): 0 entries, 0 B within 45.49 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	RoleHandlingTest	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	RoleHandlingTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingTest:CONCEPTS}): 0 entries, 0 B within 52.40 μs
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.NamespacedStorage	RoleHandlingTest	Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	RoleHandlingTest	While processing store ID_MAPPING_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	RoleHandlingTest		loaded store cached big ID_MAPPING(EntityIdMap): 0 entries, 0 B within 47.18 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	RoleHandlingTest	While processing store STRUCTURE:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	RoleHandlingTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingTest:STRUCTURE}): 0 entries, 0 B within 45.65 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	RoleHandlingTest	While processing store WORKER_TO_BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	RoleHandlingTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingTest:WORKER_TO_BUCKETS}): 0 entries, 0 B within 59.45 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	RoleHandlingTest	While processing store PRIMARY_DICTIONARY:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	RoleHandlingTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingTest:PRIMARY_DICTIONARY}): 0 entries, 0 B within 46.23 μs
[INFO] [2023-01-26 18:08:22]	c.b.c.m.m.n.s.AddWorker	Job Manager slow shard-node1	creating a new worker for Dataset[label=RoleHandlingTest, name=RoleHandlingTest]
[INFO] [2023-01-26 18:08:22]	c.b.c.m.m.n.s.AddWorker	Job Manager slow shard-node0	creating a new worker for Dataset[label=RoleHandlingTest, name=RoleHandlingTest]
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingTest_d1f0a939-e826-4bc4-be39-94631ecdccd8:DATASET}): 0 entries, 0 B within 121.6 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingTest_d1f0a939-e826-4bc4-be39-94631ecdccd8:SECONDARY_IDS}): 0 entries, 0 B within 39.07 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingTest_d1f0a939-e826-4bc4-be39-94631ecdccd8:TABLES}): 0 entries, 0 B within 36.33 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 33.87 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingTest_d1f0a939-e826-4bc4-be39-94631ecdccd8:IMPORTS}): 0 entries, 0 B within 28.64 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingTest_d1f0a939-e826-4bc4-be39-94631ecdccd8:CONCEPTS}): 0 entries, 0 B within 27.22 μs
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.NamespacedStorage	Job Manager slow shard-node0	Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store WORKER:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingTest_d1f0a939-e826-4bc4-be39-94631ecdccd8:WORKER}): 0 entries, 0 B within 29.51 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingTest_d1f0a939-e826-4bc4-be39-94631ecdccd8:BUCKETS}): 0 entries, 0 B within 27.03 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingTest_d1f0a939-e826-4bc4-be39-94631ecdccd8:C_BLOCKS}): 0 entries, 0 B within 27.13 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingTest_489e9ae2-5172-4284-bbed-d3c3acc28275:DATASET}): 0 entries, 0 B within 84.22 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingTest_489e9ae2-5172-4284-bbed-d3c3acc28275:SECONDARY_IDS}): 0 entries, 0 B within 48.00 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingTest_489e9ae2-5172-4284-bbed-d3c3acc28275:TABLES}): 0 entries, 0 B within 42.00 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 63.76 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingTest_489e9ae2-5172-4284-bbed-d3c3acc28275:IMPORTS}): 0 entries, 0 B within 44.58 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingTest_489e9ae2-5172-4284-bbed-d3c3acc28275:CONCEPTS}): 0 entries, 0 B within 47.46 μs
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.NamespacedStorage	Job Manager slow shard-node1	Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store WORKER:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingTest_489e9ae2-5172-4284-bbed-d3c3acc28275:WORKER}): 0 entries, 0 B within 38.11 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingTest_489e9ae2-5172-4284-bbed-d3c3acc28275:BUCKETS}): 0 entries, 0 B within 34.98 μs
[DEBUG] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:22]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingTest_489e9ae2-5172-4284-bbed-d3c3acc28275:C_BLOCKS}): 0 entries, 0 B within 36.21 μs
[INFO] [2023-01-26 18:08:23]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=RoleHandlingTest]	Imports of worker RoleHandlingTest.worker_RoleHandlingTest_489e9ae2-5172-4284-bbed-d3c3acc28275 are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:23]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=RoleHandlingTest]	Buckets of worker RoleHandlingTest.worker_RoleHandlingTest_489e9ae2-5172-4284-bbed-d3c3acc28275 are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:23]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=RoleHandlingTest]	Consistency check was successful
[INFO] [2023-01-26 18:08:23]	c.b.c.u.s.TestConquery	RoleHandlingTest	Waiting for jobs to finish
[INFO] [2023-01-26 18:08:23]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=RoleHandlingTest]	Imports of worker RoleHandlingTest.worker_RoleHandlingTest_d1f0a939-e826-4bc4-be39-94631ecdccd8 are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:23]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=RoleHandlingTest]	Buckets of worker RoleHandlingTest.worker_RoleHandlingTest_d1f0a939-e826-4bc4-be39-94631ecdccd8 are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:23]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=RoleHandlingTest]	Consistency check was successful
[DEBUG] [2023-01-26 18:08:23]	c.b.c.m.a.AuthorizationController	RoleHandlingTest	Security manager registered
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.MetaStorage	RoleHandlingTest	Remove User = user.user
[INFO] [2023-01-26 18:08:23]	c.b.c.m.j.JobExecutor	RoleHandlingTest	Closing Job Manager fast RoleHandlingTest
[INFO] [2023-01-26 18:08:23]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node1	removing worker for Dataset[label=RoleHandlingTest, name=RoleHandlingTest]
[INFO] [2023-01-26 18:08:23]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager fast worker_RoleHandlingTest_489e9ae2-5172-4284-bbed-d3c3acc28275
[INFO] [2023-01-26 18:08:23]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node0	removing worker for Dataset[label=RoleHandlingTest, name=RoleHandlingTest]
[INFO] [2023-01-26 18:08:23]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager fast worker_RoleHandlingTest_d1f0a939-e826-4bc4-be39-94631ecdccd8
[INFO] [2023-01-26 18:08:23]	c.b.c.m.j.JobExecutor	RoleHandlingTest	Closing Job Manager slow RoleHandlingTest
[INFO] [2023-01-26 18:08:23]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager slow worker_RoleHandlingTest_489e9ae2-5172-4284-bbed-d3c3acc28275
[INFO] [2023-01-26 18:08:23]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager slow worker_RoleHandlingTest_d1f0a939-e826-4bc4-be39-94631ecdccd8
[INFO] [2023-01-26 18:08:23]	c.b.c.m.w.Namespace	RoleHandlingTest	Removing namespace storage of RoleHandlingTest
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	RoleHandlingTest	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingTest
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	RoleHandlingTest	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingTest
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	RoleHandlingTest	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingTest
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	RoleHandlingTest	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingTest
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	RoleHandlingTest	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingTest
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	RoleHandlingTest	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingTest
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	RoleHandlingTest	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingTest
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	RoleHandlingTest	Deleting store ID_MAPPING_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingTest
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	RoleHandlingTest	Deleting store ID_MAPPING_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingTest
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	RoleHandlingTest	Deleting store STRUCTURE from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingTest
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	RoleHandlingTest	Deleting store WORKER_TO_BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingTest
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	RoleHandlingTest	Deleting store PRIMARY_DICTIONARY from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingTest
[INFO] [2023-01-26 18:08:23]	c.b.c.m.c.XodusStoreFactory	RoleHandlingTest	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleHandlingTest
[INFO] [2023-01-26 18:08:23]	c.b.c.u.s.TestConquery	RoleHandlingTest	Waiting for jobs to finish
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingTest_d1f0a939-e826-4bc4-be39-94631ecdccd8
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingTest_489e9ae2-5172-4284-bbed-d3c3acc28275
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingTest_d1f0a939-e826-4bc4-be39-94631ecdccd8
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingTest_489e9ae2-5172-4284-bbed-d3c3acc28275
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingTest_489e9ae2-5172-4284-bbed-d3c3acc28275
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingTest_d1f0a939-e826-4bc4-be39-94631ecdccd8
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingTest_489e9ae2-5172-4284-bbed-d3c3acc28275
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingTest_d1f0a939-e826-4bc4-be39-94631ecdccd8
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingTest_489e9ae2-5172-4284-bbed-d3c3acc28275
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingTest_d1f0a939-e826-4bc4-be39-94631ecdccd8
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingTest_489e9ae2-5172-4284-bbed-d3c3acc28275
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingTest_d1f0a939-e826-4bc4-be39-94631ecdccd8
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingTest_489e9ae2-5172-4284-bbed-d3c3acc28275
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingTest_489e9ae2-5172-4284-bbed-d3c3acc28275
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingTest_d1f0a939-e826-4bc4-be39-94631ecdccd8
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingTest_489e9ae2-5172-4284-bbed-d3c3acc28275
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingTest_d1f0a939-e826-4bc4-be39-94631ecdccd8
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingTest_489e9ae2-5172-4284-bbed-d3c3acc28275
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingTest_d1f0a939-e826-4bc4-be39-94631ecdccd8
[INFO] [2023-01-26 18:08:23]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node1	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleHandlingTest_489e9ae2-5172-4284-bbed-d3c3acc28275
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingTest_d1f0a939-e826-4bc4-be39-94631ecdccd8
[INFO] [2023-01-26 18:08:23]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node0	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleHandlingTest_d1f0a939-e826-4bc4-be39-94631ecdccd8
[INFO] [2023-01-26 18:08:23]	c.b.c.i.IntegrationTest$Wrapper	RoleHandlingTest	SUCCESS integration test RoleHandlingTest
[INFO] [2023-01-26 18:08:23]	c.b.c.i.IntegrationTest$Wrapper	RoleUITest	STARTING integration test RoleUITest
[INFO] [2023-01-26 18:08:23]	c.b.c.u.s.TestConquery	RoleUITest	Setting up dataset
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	RoleUITest	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	RoleUITest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleUITest:DATASET}): 0 entries, 0 B within 158.4 μs
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	RoleUITest	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	RoleUITest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleUITest:SECONDARY_IDS}): 0 entries, 0 B within 68.93 μs
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	RoleUITest	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	RoleUITest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleUITest:TABLES}): 0 entries, 0 B within 53.51 μs
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	RoleUITest	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	RoleUITest		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 57.57 μs
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	RoleUITest	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	RoleUITest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleUITest:IMPORTS}): 0 entries, 0 B within 53.93 μs
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	RoleUITest	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	RoleUITest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleUITest:CONCEPTS}): 0 entries, 0 B within 55.20 μs
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.NamespacedStorage	RoleUITest	Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	RoleUITest	While processing store ID_MAPPING_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	RoleUITest		loaded store cached big ID_MAPPING(EntityIdMap): 0 entries, 0 B within 39.42 μs
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	RoleUITest	While processing store STRUCTURE:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	RoleUITest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleUITest:STRUCTURE}): 0 entries, 0 B within 28.14 μs
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	RoleUITest	While processing store WORKER_TO_BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	RoleUITest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleUITest:WORKER_TO_BUCKETS}): 0 entries, 0 B within 26.76 μs
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	RoleUITest	While processing store PRIMARY_DICTIONARY:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	RoleUITest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleUITest:PRIMARY_DICTIONARY}): 0 entries, 0 B within 26.61 μs
[INFO] [2023-01-26 18:08:23]	c.b.c.m.m.n.s.AddWorker	Job Manager slow shard-node0	creating a new worker for Dataset[label=RoleUITest, name=RoleUITest]
[INFO] [2023-01-26 18:08:23]	c.b.c.m.m.n.s.AddWorker	Job Manager slow shard-node1	creating a new worker for Dataset[label=RoleUITest, name=RoleUITest]
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleUITest_26df7868-144e-498a-a9df-9ae4d5438906:DATASET}): 0 entries, 0 B within 77.84 μs
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleUITest_26df7868-144e-498a-a9df-9ae4d5438906:SECONDARY_IDS}): 0 entries, 0 B within 22.51 μs
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleUITest_26df7868-144e-498a-a9df-9ae4d5438906:TABLES}): 0 entries, 0 B within 21.19 μs
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 26.70 μs
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleUITest_26df7868-144e-498a-a9df-9ae4d5438906:IMPORTS}): 0 entries, 0 B within 19.14 μs
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleUITest_26df7868-144e-498a-a9df-9ae4d5438906:CONCEPTS}): 0 entries, 0 B within 18.72 μs
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.NamespacedStorage	Job Manager slow shard-node1	Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store WORKER:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleUITest_26df7868-144e-498a-a9df-9ae4d5438906:WORKER}): 0 entries, 0 B within 18.43 μs
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleUITest_26df7868-144e-498a-a9df-9ae4d5438906:BUCKETS}): 0 entries, 0 B within 17.94 μs
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleUITest_26df7868-144e-498a-a9df-9ae4d5438906:C_BLOCKS}): 0 entries, 0 B within 17.60 μs
[INFO] [2023-01-26 18:08:23]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=RoleUITest]	Imports of worker RoleUITest.worker_RoleUITest_26df7868-144e-498a-a9df-9ae4d5438906 are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:23]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=RoleUITest]	Buckets of worker RoleUITest.worker_RoleUITest_26df7868-144e-498a-a9df-9ae4d5438906 are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:23]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=RoleUITest]	Consistency check was successful
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleUITest_b64be40c-3ff7-489d-a43f-c20fa2b75ffe:DATASET}): 0 entries, 0 B within 77.00 μs
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleUITest_b64be40c-3ff7-489d-a43f-c20fa2b75ffe:SECONDARY_IDS}): 0 entries, 0 B within 31.95 μs
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleUITest_b64be40c-3ff7-489d-a43f-c20fa2b75ffe:TABLES}): 0 entries, 0 B within 40.39 μs
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 37.29 μs
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleUITest_b64be40c-3ff7-489d-a43f-c20fa2b75ffe:IMPORTS}): 0 entries, 0 B within 32.17 μs
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleUITest_b64be40c-3ff7-489d-a43f-c20fa2b75ffe:CONCEPTS}): 0 entries, 0 B within 37.32 μs
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.NamespacedStorage	Job Manager slow shard-node0	Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store WORKER:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleUITest_b64be40c-3ff7-489d-a43f-c20fa2b75ffe:WORKER}): 0 entries, 0 B within 25.84 μs
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleUITest_b64be40c-3ff7-489d-a43f-c20fa2b75ffe:BUCKETS}): 0 entries, 0 B within 22.39 μs
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleUITest_b64be40c-3ff7-489d-a43f-c20fa2b75ffe:C_BLOCKS}): 0 entries, 0 B within 21.88 μs
[INFO] [2023-01-26 18:08:23]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=RoleUITest]	Imports of worker RoleUITest.worker_RoleUITest_b64be40c-3ff7-489d-a43f-c20fa2b75ffe are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:23]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=RoleUITest]	Buckets of worker RoleUITest.worker_RoleUITest_b64be40c-3ff7-489d-a43f-c20fa2b75ffe are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:23]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=RoleUITest]	Consistency check was successful
[INFO] [2023-01-26 18:08:23]	c.b.c.u.s.TestConquery	RoleUITest	Waiting for jobs to finish
[DEBUG] [2023-01-26 18:08:23]	c.b.c.m.a.AuthorizationController	RoleUITest	Security manager registered
127.0.0.1 - - [26/Jan/2023:18:08:23 +0000] "GET /admin/roles/role.testMandatorName HTTP/1.1" 200 197 "-" "Conquery (test client)" 8
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.MetaStorage	RoleUITest	Remove User = user.testUser@test$2ede
[INFO] [2023-01-26 18:08:23]	c.b.c.m.j.JobExecutor	RoleUITest	Closing Job Manager fast RoleUITest
[INFO] [2023-01-26 18:08:23]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node0	removing worker for Dataset[label=RoleUITest, name=RoleUITest]
[INFO] [2023-01-26 18:08:23]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node1	removing worker for Dataset[label=RoleUITest, name=RoleUITest]
[INFO] [2023-01-26 18:08:23]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager fast worker_RoleUITest_b64be40c-3ff7-489d-a43f-c20fa2b75ffe
[INFO] [2023-01-26 18:08:23]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager fast worker_RoleUITest_26df7868-144e-498a-a9df-9ae4d5438906
[INFO] [2023-01-26 18:08:23]	c.b.c.m.j.JobExecutor	RoleUITest	Closing Job Manager slow RoleUITest
[INFO] [2023-01-26 18:08:23]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager slow worker_RoleUITest_26df7868-144e-498a-a9df-9ae4d5438906
[INFO] [2023-01-26 18:08:23]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager slow worker_RoleUITest_b64be40c-3ff7-489d-a43f-c20fa2b75ffe
[INFO] [2023-01-26 18:08:23]	c.b.c.m.w.Namespace	RoleUITest	Removing namespace storage of RoleUITest
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	RoleUITest	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleUITest
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	RoleUITest	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleUITest
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	RoleUITest	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleUITest
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	RoleUITest	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleUITest
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	RoleUITest	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleUITest
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	RoleUITest	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleUITest
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	RoleUITest	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleUITest
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	RoleUITest	Deleting store ID_MAPPING_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleUITest
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	RoleUITest	Deleting store ID_MAPPING_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleUITest
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	RoleUITest	Deleting store STRUCTURE from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleUITest
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	RoleUITest	Deleting store WORKER_TO_BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleUITest
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	RoleUITest	Deleting store PRIMARY_DICTIONARY from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleUITest
[INFO] [2023-01-26 18:08:23]	c.b.c.m.c.XodusStoreFactory	RoleUITest	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_RoleUITest
[INFO] [2023-01-26 18:08:23]	c.b.c.u.s.TestConquery	RoleUITest	Waiting for jobs to finish
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleUITest_26df7868-144e-498a-a9df-9ae4d5438906
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleUITest_26df7868-144e-498a-a9df-9ae4d5438906
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleUITest_26df7868-144e-498a-a9df-9ae4d5438906
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleUITest_26df7868-144e-498a-a9df-9ae4d5438906
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleUITest_26df7868-144e-498a-a9df-9ae4d5438906
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleUITest_26df7868-144e-498a-a9df-9ae4d5438906
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleUITest_26df7868-144e-498a-a9df-9ae4d5438906
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleUITest_26df7868-144e-498a-a9df-9ae4d5438906
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleUITest_26df7868-144e-498a-a9df-9ae4d5438906
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleUITest_26df7868-144e-498a-a9df-9ae4d5438906
[INFO] [2023-01-26 18:08:23]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node1	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_RoleUITest_26df7868-144e-498a-a9df-9ae4d5438906
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleUITest_b64be40c-3ff7-489d-a43f-c20fa2b75ffe
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleUITest_b64be40c-3ff7-489d-a43f-c20fa2b75ffe
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleUITest_b64be40c-3ff7-489d-a43f-c20fa2b75ffe
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleUITest_b64be40c-3ff7-489d-a43f-c20fa2b75ffe
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleUITest_b64be40c-3ff7-489d-a43f-c20fa2b75ffe
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleUITest_b64be40c-3ff7-489d-a43f-c20fa2b75ffe
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleUITest_b64be40c-3ff7-489d-a43f-c20fa2b75ffe
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleUITest_b64be40c-3ff7-489d-a43f-c20fa2b75ffe
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleUITest_b64be40c-3ff7-489d-a43f-c20fa2b75ffe
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleUITest_b64be40c-3ff7-489d-a43f-c20fa2b75ffe
[INFO] [2023-01-26 18:08:23]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node0	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_RoleUITest_b64be40c-3ff7-489d-a43f-c20fa2b75ffe
[INFO] [2023-01-26 18:08:23]	c.b.c.i.IntegrationTest$Wrapper	RoleUITest	SUCCESS integration test RoleUITest
[INFO] [2023-01-26 18:08:23]	c.b.c.i.IntegrationTest$Wrapper	SecondaryIdEndpointTest	STARTING integration test SecondaryIdEndpointTest
[INFO] [2023-01-26 18:08:23]	c.b.c.u.s.TestConquery	SecondaryIdEndpointTest	Setting up dataset
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	SecondaryIdEndpointTest	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	SecondaryIdEndpointTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SecondaryIdEndpointTest:DATASET}): 0 entries, 0 B within 137.5 μs
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	SecondaryIdEndpointTest	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	SecondaryIdEndpointTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SecondaryIdEndpointTest:SECONDARY_IDS}): 0 entries, 0 B within 81.73 μs
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	SecondaryIdEndpointTest	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	SecondaryIdEndpointTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SecondaryIdEndpointTest:TABLES}): 0 entries, 0 B within 74.51 μs
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	SecondaryIdEndpointTest	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	SecondaryIdEndpointTest		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 72.76 μs
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	SecondaryIdEndpointTest	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	SecondaryIdEndpointTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SecondaryIdEndpointTest:IMPORTS}): 0 entries, 0 B within 68.24 μs
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	SecondaryIdEndpointTest	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	SecondaryIdEndpointTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SecondaryIdEndpointTest:CONCEPTS}): 0 entries, 0 B within 73.25 μs
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.NamespacedStorage	SecondaryIdEndpointTest	Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	SecondaryIdEndpointTest	While processing store ID_MAPPING_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	SecondaryIdEndpointTest		loaded store cached big ID_MAPPING(EntityIdMap): 0 entries, 0 B within 78.47 μs
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	SecondaryIdEndpointTest	While processing store STRUCTURE:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	SecondaryIdEndpointTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SecondaryIdEndpointTest:STRUCTURE}): 0 entries, 0 B within 76.45 μs
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	SecondaryIdEndpointTest	While processing store WORKER_TO_BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	SecondaryIdEndpointTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SecondaryIdEndpointTest:WORKER_TO_BUCKETS}): 0 entries, 0 B within 70.65 μs
[DEBUG] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.SerializingStore	SecondaryIdEndpointTest	While processing store PRIMARY_DICTIONARY:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:23]	c.b.c.i.s.x.s.CachedStore	SecondaryIdEndpointTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SecondaryIdEndpointTest:PRIMARY_DICTIONARY}): 0 entries, 0 B within 69.83 μs
[INFO] [2023-01-26 18:08:24]	c.b.c.m.m.n.s.AddWorker	Job Manager slow shard-node0	creating a new worker for Dataset[label=SecondaryIdEndpointTest, name=SecondaryIdEndpointTest]
[INFO] [2023-01-26 18:08:24]	c.b.c.m.m.n.s.AddWorker	Job Manager slow shard-node1	creating a new worker for Dataset[label=SecondaryIdEndpointTest, name=SecondaryIdEndpointTest]
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SecondaryIdEndpointTest_494d3366-1e4b-4fc1-8c31-6f50c9dd43b2:DATASET}): 0 entries, 0 B within 76.50 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SecondaryIdEndpointTest_494d3366-1e4b-4fc1-8c31-6f50c9dd43b2:SECONDARY_IDS}): 0 entries, 0 B within 27.28 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SecondaryIdEndpointTest_494d3366-1e4b-4fc1-8c31-6f50c9dd43b2:TABLES}): 0 entries, 0 B within 30.44 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 26.52 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SecondaryIdEndpointTest_494d3366-1e4b-4fc1-8c31-6f50c9dd43b2:IMPORTS}): 0 entries, 0 B within 24.85 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SecondaryIdEndpointTest_494d3366-1e4b-4fc1-8c31-6f50c9dd43b2:CONCEPTS}): 0 entries, 0 B within 24.39 μs
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.NamespacedStorage	Job Manager slow shard-node0	Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store WORKER:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SecondaryIdEndpointTest_494d3366-1e4b-4fc1-8c31-6f50c9dd43b2:WORKER}): 0 entries, 0 B within 23.68 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SecondaryIdEndpointTest_494d3366-1e4b-4fc1-8c31-6f50c9dd43b2:BUCKETS}): 0 entries, 0 B within 24.47 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SecondaryIdEndpointTest_494d3366-1e4b-4fc1-8c31-6f50c9dd43b2:C_BLOCKS}): 0 entries, 0 B within 21.65 μs
[INFO] [2023-01-26 18:08:24]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=SecondaryIdEndpointTest]	Imports of worker SecondaryIdEndpointTest.worker_SecondaryIdEndpointTest_494d3366-1e4b-4fc1-8c31-6f50c9dd43b2 are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:24]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=SecondaryIdEndpointTest]	Buckets of worker SecondaryIdEndpointTest.worker_SecondaryIdEndpointTest_494d3366-1e4b-4fc1-8c31-6f50c9dd43b2 are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:24]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=SecondaryIdEndpointTest]	Consistency check was successful
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SecondaryIdEndpointTest_4d2e5142-af20-4f3a-8715-95b507191c8c:DATASET}): 0 entries, 0 B within 98.86 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SecondaryIdEndpointTest_4d2e5142-af20-4f3a-8715-95b507191c8c:SECONDARY_IDS}): 0 entries, 0 B within 44.26 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SecondaryIdEndpointTest_4d2e5142-af20-4f3a-8715-95b507191c8c:TABLES}): 0 entries, 0 B within 33.58 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 37.74 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SecondaryIdEndpointTest_4d2e5142-af20-4f3a-8715-95b507191c8c:IMPORTS}): 0 entries, 0 B within 31.74 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SecondaryIdEndpointTest_4d2e5142-af20-4f3a-8715-95b507191c8c:CONCEPTS}): 0 entries, 0 B within 31.17 μs
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.NamespacedStorage	Job Manager slow shard-node1	Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store WORKER:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SecondaryIdEndpointTest_4d2e5142-af20-4f3a-8715-95b507191c8c:WORKER}): 0 entries, 0 B within 31.91 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SecondaryIdEndpointTest_4d2e5142-af20-4f3a-8715-95b507191c8c:BUCKETS}): 0 entries, 0 B within 30.85 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SecondaryIdEndpointTest_4d2e5142-af20-4f3a-8715-95b507191c8c:C_BLOCKS}): 0 entries, 0 B within 30.64 μs
[INFO] [2023-01-26 18:08:24]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=SecondaryIdEndpointTest]	Imports of worker SecondaryIdEndpointTest.worker_SecondaryIdEndpointTest_4d2e5142-af20-4f3a-8715-95b507191c8c are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:24]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=SecondaryIdEndpointTest]	Buckets of worker SecondaryIdEndpointTest.worker_SecondaryIdEndpointTest_4d2e5142-af20-4f3a-8715-95b507191c8c are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:24]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=SecondaryIdEndpointTest]	Consistency check was successful
[INFO] [2023-01-26 18:08:24]	c.b.c.u.s.TestConquery	SecondaryIdEndpointTest	Waiting for jobs to finish
[DEBUG] [2023-01-26 18:08:24]	c.b.c.m.a.AuthorizationController	SecondaryIdEndpointTest	Security manager registered
[INFO] [2023-01-26 18:08:24]	c.b.c.r.a.r.AdminDatasetProcessor	user.SUPERUSER@SUPERUSER	Received new SecondaryId[SecondaryIdEndpointTest.description-NAME]
[INFO] [2023-01-26 18:08:24]	c.b.c.m.m.n.s.UpdateSecondaryId	Worker[SecondaryIdEndpointTest.worker_SecondaryIdEndpointTest_494d3366-1e4b-4fc1-8c31-6f50c9dd43b2, /127.0.0.1:49088]	Received update of SecondaryId SecondaryIdEndpointTest.description-NAME
[INFO] [2023-01-26 18:08:24]	c.b.c.m.m.n.s.UpdateSecondaryId	Worker[SecondaryIdEndpointTest.worker_SecondaryIdEndpointTest_4d2e5142-af20-4f3a-8715-95b507191c8c, /127.0.0.1:49092]	Received update of SecondaryId SecondaryIdEndpointTest.description-NAME
127.0.0.1 - - [26/Jan/2023:18:08:24 +0000] "POST /admin/datasets/SecondaryIdEndpointTest/secondaryId HTTP/1.1" 204 0 "-" "Conquery (test client)" 5
[INFO] [2023-01-26 18:08:24]	c.b.c.i.t.SecondaryIdEndpointTest	SecondaryIdEndpointTest	InboundJaxrsResponse{context=ClientResponse{method=POST, uri=http://localhost:41661/admin/datasets/SecondaryIdEndpointTest/secondaryId, status=204, reason=No Content}}
[WARN] [2023-01-26 18:08:24]	c.b.c.m.d.c.FrontEndConceptBuilder	user.SUPERUSER@SUPERUSER	There are no displayable concepts in the dataset SecondaryIdEndpointTest
[WARN] [2023-01-26 18:08:24]	c.b.c.m.d.c.FrontEndConceptBuilder	user.SUPERUSER@SUPERUSER	No concepts could be collected for user.SUPERUSER@SUPERUSER on dataset SecondaryIdEndpointTest. The subject is possibly lacking the permission to use them.
127.0.0.1 - - [26/Jan/2023:18:08:24 +0000] "GET /api/datasets/SecondaryIdEndpointTest/concepts HTTP/1.1" 200 150 "-" "Conquery (test client)" 23
[INFO] [2023-01-26 18:08:24]	c.b.c.i.t.SecondaryIdEndpointTest	SecondaryIdEndpointTest	[FESecondaryId(id=SecondaryIdEndpointTest.description-NAME, label=description-LABEL, description=description-DESCRIPTION)]
127.0.0.1 - - [26/Jan/2023:18:08:24 +0000] "POST /admin/datasets/SecondaryIdEndpointTest/tables HTTP/1.1" 204 0 "-" "Conquery (test client)" 6
[INFO] [2023-01-26 18:08:24]	c.b.c.m.m.n.s.UpdateTable	Worker[SecondaryIdEndpointTest.worker_SecondaryIdEndpointTest_494d3366-1e4b-4fc1-8c31-6f50c9dd43b2, /127.0.0.1:49088]	Received update of Table SecondaryIdEndpointTest.table
[INFO] [2023-01-26 18:08:24]	c.b.c.m.m.n.s.UpdateTable	Worker[SecondaryIdEndpointTest.worker_SecondaryIdEndpointTest_4d2e5142-af20-4f3a-8715-95b507191c8c, /127.0.0.1:49092]	Received update of Table SecondaryIdEndpointTest.table
127.0.0.1 - - [26/Jan/2023:18:08:24 +0000] "GET /admin/datasets/SecondaryIdEndpointTest HTTP/1.1" 200 79 "-" "Conquery (test client)" 3
[ERROR] [2023-01-26 18:08:24]	c.b.c.r.a.r.AdminDatasetProcessor	user.SUPERUSER@SUPERUSER	SecondaryId[SecondaryIdDescription(id = SecondaryIdEndpointTest.description-NAME, label = description-LABEL )] still present on [SecondaryIdEndpointTest.table]
127.0.0.1 - - [26/Jan/2023:18:08:24 +0000] "DELETE /admin/datasets/SecondaryIdEndpointTest/secondaryId/SecondaryIdEndpointTest.description-NAME HTTP/1.1" 403 92 "-" "Conquery (test client)" 7
127.0.0.1 - - [26/Jan/2023:18:08:24 +0000] "DELETE /admin/datasets/SecondaryIdEndpointTest/tables/SecondaryIdEndpointTest.table HTTP/1.1" 200 2 "-" "Conquery (test client)" 10
[INFO] [2023-01-26 18:08:24]	c.b.c.m.m.n.s.RemoveTable	Worker[SecondaryIdEndpointTest.worker_SecondaryIdEndpointTest_4d2e5142-af20-4f3a-8715-95b507191c8c, /127.0.0.1:49092]	Received update of Table Table[label=table, name=table]
[INFO] [2023-01-26 18:08:24]	c.b.c.m.m.n.s.RemoveTable	Worker[SecondaryIdEndpointTest.worker_SecondaryIdEndpointTest_494d3366-1e4b-4fc1-8c31-6f50c9dd43b2, /127.0.0.1:49088]	Received update of Table Table[label=table, name=table]
[INFO] [2023-01-26 18:08:24]	c.b.c.r.a.r.AdminDatasetProcessor	user.SUPERUSER@SUPERUSER	Deleting SecondaryId[SecondaryIdDescription(id = SecondaryIdEndpointTest.description-NAME, label = description-LABEL )]
127.0.0.1 - - [26/Jan/2023:18:08:24 +0000] "DELETE /admin/datasets/SecondaryIdEndpointTest/secondaryId/SecondaryIdEndpointTest.description-NAME HTTP/1.1" 204 0 "-" "Conquery (test client)" 5
[INFO] [2023-01-26 18:08:24]	c.b.c.m.m.n.s.RemoveSecondaryId	Worker[SecondaryIdEndpointTest.worker_SecondaryIdEndpointTest_494d3366-1e4b-4fc1-8c31-6f50c9dd43b2, /127.0.0.1:49088]	Received Deletion of SecondaryId SecondaryIdDescription(id = SecondaryIdEndpointTest.description-NAME, label = description-LABEL )
[INFO] [2023-01-26 18:08:24]	c.b.c.m.m.n.s.RemoveSecondaryId	Worker[SecondaryIdEndpointTest.worker_SecondaryIdEndpointTest_4d2e5142-af20-4f3a-8715-95b507191c8c, /127.0.0.1:49092]	Received Deletion of SecondaryId SecondaryIdDescription(id = SecondaryIdEndpointTest.description-NAME, label = description-LABEL )
[WARN] [2023-01-26 18:08:24]	c.b.c.m.d.c.FrontEndConceptBuilder	user.SUPERUSER@SUPERUSER	There are no displayable concepts in the dataset SecondaryIdEndpointTest
[WARN] [2023-01-26 18:08:24]	c.b.c.m.d.c.FrontEndConceptBuilder	user.SUPERUSER@SUPERUSER	No concepts could be collected for user.SUPERUSER@SUPERUSER on dataset SecondaryIdEndpointTest. The subject is possibly lacking the permission to use them.
127.0.0.1 - - [26/Jan/2023:18:08:24 +0000] "GET /api/datasets/SecondaryIdEndpointTest/concepts HTTP/1.1" 200 33 "-" "Conquery (test client)" 10
[INFO] [2023-01-26 18:08:24]	c.b.c.i.t.SecondaryIdEndpointTest	SecondaryIdEndpointTest	[]
[INFO] [2023-01-26 18:08:24]	c.b.c.m.j.JobExecutor	SecondaryIdEndpointTest	Closing Job Manager fast SecondaryIdEndpointTest
[INFO] [2023-01-26 18:08:24]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node0	removing worker for Dataset[label=SecondaryIdEndpointTest, name=SecondaryIdEndpointTest]
[INFO] [2023-01-26 18:08:24]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager fast worker_SecondaryIdEndpointTest_494d3366-1e4b-4fc1-8c31-6f50c9dd43b2
[INFO] [2023-01-26 18:08:24]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node1	removing worker for Dataset[label=SecondaryIdEndpointTest, name=SecondaryIdEndpointTest]
[INFO] [2023-01-26 18:08:24]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager fast worker_SecondaryIdEndpointTest_4d2e5142-af20-4f3a-8715-95b507191c8c
[INFO] [2023-01-26 18:08:24]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager slow worker_SecondaryIdEndpointTest_494d3366-1e4b-4fc1-8c31-6f50c9dd43b2
[INFO] [2023-01-26 18:08:24]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager slow worker_SecondaryIdEndpointTest_4d2e5142-af20-4f3a-8715-95b507191c8c
[INFO] [2023-01-26 18:08:24]	c.b.c.m.j.JobExecutor	SecondaryIdEndpointTest	Closing Job Manager slow SecondaryIdEndpointTest
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SecondaryIdEndpointTest_494d3366-1e4b-4fc1-8c31-6f50c9dd43b2
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SecondaryIdEndpointTest_494d3366-1e4b-4fc1-8c31-6f50c9dd43b2
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SecondaryIdEndpointTest_494d3366-1e4b-4fc1-8c31-6f50c9dd43b2
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SecondaryIdEndpointTest_494d3366-1e4b-4fc1-8c31-6f50c9dd43b2
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SecondaryIdEndpointTest_494d3366-1e4b-4fc1-8c31-6f50c9dd43b2
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SecondaryIdEndpointTest_494d3366-1e4b-4fc1-8c31-6f50c9dd43b2
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SecondaryIdEndpointTest_494d3366-1e4b-4fc1-8c31-6f50c9dd43b2
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SecondaryIdEndpointTest_494d3366-1e4b-4fc1-8c31-6f50c9dd43b2
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SecondaryIdEndpointTest_494d3366-1e4b-4fc1-8c31-6f50c9dd43b2
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SecondaryIdEndpointTest_494d3366-1e4b-4fc1-8c31-6f50c9dd43b2
[INFO] [2023-01-26 18:08:24]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node0	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SecondaryIdEndpointTest_494d3366-1e4b-4fc1-8c31-6f50c9dd43b2
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SecondaryIdEndpointTest_4d2e5142-af20-4f3a-8715-95b507191c8c
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SecondaryIdEndpointTest_4d2e5142-af20-4f3a-8715-95b507191c8c
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SecondaryIdEndpointTest_4d2e5142-af20-4f3a-8715-95b507191c8c
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SecondaryIdEndpointTest_4d2e5142-af20-4f3a-8715-95b507191c8c
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SecondaryIdEndpointTest_4d2e5142-af20-4f3a-8715-95b507191c8c
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SecondaryIdEndpointTest_4d2e5142-af20-4f3a-8715-95b507191c8c
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SecondaryIdEndpointTest_4d2e5142-af20-4f3a-8715-95b507191c8c
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SecondaryIdEndpointTest_4d2e5142-af20-4f3a-8715-95b507191c8c
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SecondaryIdEndpointTest_4d2e5142-af20-4f3a-8715-95b507191c8c
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SecondaryIdEndpointTest_4d2e5142-af20-4f3a-8715-95b507191c8c
[INFO] [2023-01-26 18:08:24]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node1	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SecondaryIdEndpointTest_4d2e5142-af20-4f3a-8715-95b507191c8c
[INFO] [2023-01-26 18:08:24]	c.b.c.m.w.Namespace	SecondaryIdEndpointTest	Removing namespace storage of SecondaryIdEndpointTest
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	SecondaryIdEndpointTest	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SecondaryIdEndpointTest
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	SecondaryIdEndpointTest	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SecondaryIdEndpointTest
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	SecondaryIdEndpointTest	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SecondaryIdEndpointTest
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	SecondaryIdEndpointTest	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SecondaryIdEndpointTest
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	SecondaryIdEndpointTest	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SecondaryIdEndpointTest
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	SecondaryIdEndpointTest	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SecondaryIdEndpointTest
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	SecondaryIdEndpointTest	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SecondaryIdEndpointTest
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	SecondaryIdEndpointTest	Deleting store ID_MAPPING_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SecondaryIdEndpointTest
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	SecondaryIdEndpointTest	Deleting store ID_MAPPING_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SecondaryIdEndpointTest
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	SecondaryIdEndpointTest	Deleting store STRUCTURE from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SecondaryIdEndpointTest
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	SecondaryIdEndpointTest	Deleting store WORKER_TO_BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SecondaryIdEndpointTest
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	SecondaryIdEndpointTest	Deleting store PRIMARY_DICTIONARY from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SecondaryIdEndpointTest
[INFO] [2023-01-26 18:08:24]	c.b.c.m.c.XodusStoreFactory	SecondaryIdEndpointTest	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SecondaryIdEndpointTest
[INFO] [2023-01-26 18:08:24]	c.b.c.u.s.TestConquery	SecondaryIdEndpointTest	Waiting for jobs to finish
[INFO] [2023-01-26 18:08:24]	c.b.c.i.IntegrationTest$Wrapper	SecondaryIdEndpointTest	SUCCESS integration test SecondaryIdEndpointTest
[INFO] [2023-01-26 18:08:24]	c.b.c.i.IntegrationTest$Wrapper	SuperPermissionTest	STARTING integration test SuperPermissionTest
[INFO] [2023-01-26 18:08:24]	c.b.c.u.s.TestConquery	SuperPermissionTest	Setting up dataset
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	SuperPermissionTest	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	SuperPermissionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SuperPermissionTest:DATASET}): 0 entries, 0 B within 106.5 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	SuperPermissionTest	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	SuperPermissionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SuperPermissionTest:SECONDARY_IDS}): 0 entries, 0 B within 48.83 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	SuperPermissionTest	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	SuperPermissionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SuperPermissionTest:TABLES}): 0 entries, 0 B within 40.80 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	SuperPermissionTest	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	SuperPermissionTest		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 43.47 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	SuperPermissionTest	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	SuperPermissionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SuperPermissionTest:IMPORTS}): 0 entries, 0 B within 40.54 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	SuperPermissionTest	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	SuperPermissionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SuperPermissionTest:CONCEPTS}): 0 entries, 0 B within 39.71 μs
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.NamespacedStorage	SuperPermissionTest	Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	SuperPermissionTest	While processing store ID_MAPPING_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	SuperPermissionTest		loaded store cached big ID_MAPPING(EntityIdMap): 0 entries, 0 B within 36.57 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	SuperPermissionTest	While processing store STRUCTURE:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	SuperPermissionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SuperPermissionTest:STRUCTURE}): 0 entries, 0 B within 34.11 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	SuperPermissionTest	While processing store WORKER_TO_BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	SuperPermissionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SuperPermissionTest:WORKER_TO_BUCKETS}): 0 entries, 0 B within 34.28 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	SuperPermissionTest	While processing store PRIMARY_DICTIONARY:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	SuperPermissionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SuperPermissionTest:PRIMARY_DICTIONARY}): 0 entries, 0 B within 33.33 μs
[INFO] [2023-01-26 18:08:24]	c.b.c.m.m.n.s.AddWorker	Job Manager slow shard-node1	creating a new worker for Dataset[label=SuperPermissionTest, name=SuperPermissionTest]
[INFO] [2023-01-26 18:08:24]	c.b.c.m.m.n.s.AddWorker	Job Manager slow shard-node0	creating a new worker for Dataset[label=SuperPermissionTest, name=SuperPermissionTest]
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SuperPermissionTest_ccb56d29-aa38-4446-bb90-b5901590237c:DATASET}): 0 entries, 0 B within 112.7 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SuperPermissionTest_ccb56d29-aa38-4446-bb90-b5901590237c:SECONDARY_IDS}): 0 entries, 0 B within 39.96 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SuperPermissionTest_ccb56d29-aa38-4446-bb90-b5901590237c:TABLES}): 0 entries, 0 B within 34.25 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 42.37 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SuperPermissionTest_ccb56d29-aa38-4446-bb90-b5901590237c:IMPORTS}): 0 entries, 0 B within 33.68 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SuperPermissionTest_ccb56d29-aa38-4446-bb90-b5901590237c:CONCEPTS}): 0 entries, 0 B within 32.02 μs
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.NamespacedStorage	Job Manager slow shard-node1	Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store WORKER:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SuperPermissionTest_ccb56d29-aa38-4446-bb90-b5901590237c:WORKER}): 0 entries, 0 B within 27.99 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SuperPermissionTest_ccb56d29-aa38-4446-bb90-b5901590237c:BUCKETS}): 0 entries, 0 B within 34.46 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SuperPermissionTest_ccb56d29-aa38-4446-bb90-b5901590237c:C_BLOCKS}): 0 entries, 0 B within 27.44 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SuperPermissionTest_79d475fb-669e-40c4-ab0f-864a0be4f0bb:DATASET}): 0 entries, 0 B within 114.5 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SuperPermissionTest_79d475fb-669e-40c4-ab0f-864a0be4f0bb:SECONDARY_IDS}): 0 entries, 0 B within 60.15 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SuperPermissionTest_79d475fb-669e-40c4-ab0f-864a0be4f0bb:TABLES}): 0 entries, 0 B within 43.98 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 59.11 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SuperPermissionTest_79d475fb-669e-40c4-ab0f-864a0be4f0bb:IMPORTS}): 0 entries, 0 B within 43.70 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SuperPermissionTest_79d475fb-669e-40c4-ab0f-864a0be4f0bb:CONCEPTS}): 0 entries, 0 B within 29.88 μs
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.NamespacedStorage	Job Manager slow shard-node0	Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store WORKER:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SuperPermissionTest_79d475fb-669e-40c4-ab0f-864a0be4f0bb:WORKER}): 0 entries, 0 B within 25.34 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SuperPermissionTest_79d475fb-669e-40c4-ab0f-864a0be4f0bb:BUCKETS}): 0 entries, 0 B within 31.79 μs
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SuperPermissionTest_79d475fb-669e-40c4-ab0f-864a0be4f0bb:C_BLOCKS}): 0 entries, 0 B within 24.06 μs
[INFO] [2023-01-26 18:08:24]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=SuperPermissionTest]	Imports of worker SuperPermissionTest.worker_SuperPermissionTest_ccb56d29-aa38-4446-bb90-b5901590237c are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:24]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=SuperPermissionTest]	Buckets of worker SuperPermissionTest.worker_SuperPermissionTest_ccb56d29-aa38-4446-bb90-b5901590237c are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:24]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=SuperPermissionTest]	Consistency check was successful
[INFO] [2023-01-26 18:08:24]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=SuperPermissionTest]	Imports of worker SuperPermissionTest.worker_SuperPermissionTest_79d475fb-669e-40c4-ab0f-864a0be4f0bb are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:24]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=SuperPermissionTest]	Buckets of worker SuperPermissionTest.worker_SuperPermissionTest_79d475fb-669e-40c4-ab0f-864a0be4f0bb are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:24]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=SuperPermissionTest]	Consistency check was successful
[INFO] [2023-01-26 18:08:24]	c.b.c.u.s.TestConquery	SuperPermissionTest	Waiting for jobs to finish
[DEBUG] [2023-01-26 18:08:24]	c.b.c.m.a.AuthorizationController	SuperPermissionTest	Security manager registered
[INFO] [2023-01-26 18:08:24]	c.b.c.i.s.MetaStorage	SuperPermissionTest	Remove User = user.user
[INFO] [2023-01-26 18:08:24]	c.b.c.m.j.JobExecutor	SuperPermissionTest	Closing Job Manager fast SuperPermissionTest
[INFO] [2023-01-26 18:08:24]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node1	removing worker for Dataset[label=SuperPermissionTest, name=SuperPermissionTest]
[INFO] [2023-01-26 18:08:24]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node0	removing worker for Dataset[label=SuperPermissionTest, name=SuperPermissionTest]
[INFO] [2023-01-26 18:08:24]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager fast worker_SuperPermissionTest_ccb56d29-aa38-4446-bb90-b5901590237c
[INFO] [2023-01-26 18:08:24]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager fast worker_SuperPermissionTest_79d475fb-669e-40c4-ab0f-864a0be4f0bb
[INFO] [2023-01-26 18:08:24]	c.b.c.m.j.JobExecutor	SuperPermissionTest	Closing Job Manager slow SuperPermissionTest
[INFO] [2023-01-26 18:08:24]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager slow worker_SuperPermissionTest_79d475fb-669e-40c4-ab0f-864a0be4f0bb
[INFO] [2023-01-26 18:08:24]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager slow worker_SuperPermissionTest_ccb56d29-aa38-4446-bb90-b5901590237c
[INFO] [2023-01-26 18:08:24]	c.b.c.m.w.Namespace	SuperPermissionTest	Removing namespace storage of SuperPermissionTest
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	SuperPermissionTest	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SuperPermissionTest
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	SuperPermissionTest	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SuperPermissionTest
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	SuperPermissionTest	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SuperPermissionTest
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	SuperPermissionTest	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SuperPermissionTest
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	SuperPermissionTest	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SuperPermissionTest
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	SuperPermissionTest	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SuperPermissionTest
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	SuperPermissionTest	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SuperPermissionTest
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	SuperPermissionTest	Deleting store ID_MAPPING_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SuperPermissionTest
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	SuperPermissionTest	Deleting store ID_MAPPING_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SuperPermissionTest
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	SuperPermissionTest	Deleting store STRUCTURE from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SuperPermissionTest
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	SuperPermissionTest	Deleting store WORKER_TO_BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SuperPermissionTest
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	SuperPermissionTest	Deleting store PRIMARY_DICTIONARY from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SuperPermissionTest
[INFO] [2023-01-26 18:08:24]	c.b.c.m.c.XodusStoreFactory	SuperPermissionTest	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_SuperPermissionTest
[INFO] [2023-01-26 18:08:24]	c.b.c.u.s.TestConquery	SuperPermissionTest	Waiting for jobs to finish
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SuperPermissionTest_79d475fb-669e-40c4-ab0f-864a0be4f0bb
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SuperPermissionTest_ccb56d29-aa38-4446-bb90-b5901590237c
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SuperPermissionTest_ccb56d29-aa38-4446-bb90-b5901590237c
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SuperPermissionTest_79d475fb-669e-40c4-ab0f-864a0be4f0bb
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SuperPermissionTest_ccb56d29-aa38-4446-bb90-b5901590237c
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SuperPermissionTest_ccb56d29-aa38-4446-bb90-b5901590237c
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SuperPermissionTest_ccb56d29-aa38-4446-bb90-b5901590237c
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SuperPermissionTest_ccb56d29-aa38-4446-bb90-b5901590237c
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SuperPermissionTest_ccb56d29-aa38-4446-bb90-b5901590237c
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SuperPermissionTest_ccb56d29-aa38-4446-bb90-b5901590237c
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SuperPermissionTest_ccb56d29-aa38-4446-bb90-b5901590237c
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SuperPermissionTest_ccb56d29-aa38-4446-bb90-b5901590237c
[INFO] [2023-01-26 18:08:24]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node1	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_SuperPermissionTest_ccb56d29-aa38-4446-bb90-b5901590237c
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SuperPermissionTest_79d475fb-669e-40c4-ab0f-864a0be4f0bb
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SuperPermissionTest_79d475fb-669e-40c4-ab0f-864a0be4f0bb
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SuperPermissionTest_79d475fb-669e-40c4-ab0f-864a0be4f0bb
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SuperPermissionTest_79d475fb-669e-40c4-ab0f-864a0be4f0bb
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SuperPermissionTest_79d475fb-669e-40c4-ab0f-864a0be4f0bb
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SuperPermissionTest_79d475fb-669e-40c4-ab0f-864a0be4f0bb
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SuperPermissionTest_79d475fb-669e-40c4-ab0f-864a0be4f0bb
[DEBUG] [2023-01-26 18:08:24]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SuperPermissionTest_79d475fb-669e-40c4-ab0f-864a0be4f0bb
[INFO] [2023-01-26 18:08:24]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node0	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_SuperPermissionTest_79d475fb-669e-40c4-ab0f-864a0be4f0bb
[INFO] [2023-01-26 18:08:25]	c.b.c.i.IntegrationTest$Wrapper	SuperPermissionTest	SUCCESS integration test SuperPermissionTest
[INFO] [2023-01-26 18:08:25]	c.b.c.i.IntegrationTest$Wrapper	ConceptUpdateAndDeletionTest	STARTING integration test ConceptUpdateAndDeletionTest
[INFO] [2023-01-26 18:08:25]	c.b.c.u.s.TestConquery	ConceptUpdateAndDeletionTest	Setting up dataset
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.SerializingStore	ConceptUpdateAndDeletionTest	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.CachedStore	ConceptUpdateAndDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:DATASET}): 0 entries, 0 B within 201.9 μs
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.SerializingStore	ConceptUpdateAndDeletionTest	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.CachedStore	ConceptUpdateAndDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:SECONDARY_IDS}): 0 entries, 0 B within 65.69 μs
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.SerializingStore	ConceptUpdateAndDeletionTest	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.CachedStore	ConceptUpdateAndDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:TABLES}): 0 entries, 0 B within 57.90 μs
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.SerializingStore	ConceptUpdateAndDeletionTest	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.CachedStore	ConceptUpdateAndDeletionTest		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 52.12 μs
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.SerializingStore	ConceptUpdateAndDeletionTest	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.CachedStore	ConceptUpdateAndDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:IMPORTS}): 0 entries, 0 B within 45.81 μs
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.SerializingStore	ConceptUpdateAndDeletionTest	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.CachedStore	ConceptUpdateAndDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:CONCEPTS}): 0 entries, 0 B within 43.72 μs
[INFO] [2023-01-26 18:08:25]	c.b.c.i.s.NamespacedStorage	ConceptUpdateAndDeletionTest	Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.SerializingStore	ConceptUpdateAndDeletionTest	While processing store ID_MAPPING_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.CachedStore	ConceptUpdateAndDeletionTest		loaded store cached big ID_MAPPING(EntityIdMap): 0 entries, 0 B within 49.85 μs
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.SerializingStore	ConceptUpdateAndDeletionTest	While processing store STRUCTURE:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.CachedStore	ConceptUpdateAndDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:STRUCTURE}): 0 entries, 0 B within 44.46 μs
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.SerializingStore	ConceptUpdateAndDeletionTest	While processing store WORKER_TO_BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.CachedStore	ConceptUpdateAndDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:WORKER_TO_BUCKETS}): 0 entries, 0 B within 45.48 μs
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.SerializingStore	ConceptUpdateAndDeletionTest	While processing store PRIMARY_DICTIONARY:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.CachedStore	ConceptUpdateAndDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:PRIMARY_DICTIONARY}): 0 entries, 0 B within 38.50 μs
[INFO] [2023-01-26 18:08:25]	c.b.c.m.m.n.s.AddWorker	Job Manager slow shard-node0	creating a new worker for Dataset[label=ConceptUpdateAndDeletionTest, name=ConceptUpdateAndDeletionTest]
[INFO] [2023-01-26 18:08:25]	c.b.c.m.m.n.s.AddWorker	Job Manager slow shard-node1	creating a new worker for Dataset[label=ConceptUpdateAndDeletionTest, name=ConceptUpdateAndDeletionTest]
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:DATASET}): 0 entries, 0 B within 107.3 μs
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:SECONDARY_IDS}): 0 entries, 0 B within 44.51 μs
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:TABLES}): 0 entries, 0 B within 31.62 μs
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 36.83 μs
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:IMPORTS}): 0 entries, 0 B within 31.69 μs
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:CONCEPTS}): 0 entries, 0 B within 55.77 μs
[INFO] [2023-01-26 18:08:25]	c.b.c.i.s.NamespacedStorage	Job Manager slow shard-node0	Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store WORKER:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:WORKER}): 0 entries, 0 B within 35.08 μs
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:BUCKETS}): 0 entries, 0 B within 35.76 μs
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:C_BLOCKS}): 0 entries, 0 B within 34.66 μs
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:DATASET}): 0 entries, 0 B within 76.03 μs
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:SECONDARY_IDS}): 0 entries, 0 B within 36.07 μs
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:TABLES}): 0 entries, 0 B within 30.10 μs
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 34.34 μs
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:IMPORTS}): 0 entries, 0 B within 28.68 μs
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:CONCEPTS}): 0 entries, 0 B within 24.15 μs
[INFO] [2023-01-26 18:08:25]	c.b.c.i.s.NamespacedStorage	Job Manager slow shard-node1	Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store WORKER:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:WORKER}): 0 entries, 0 B within 30.93 μs
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:BUCKETS}): 0 entries, 0 B within 26.01 μs
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:25]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:C_BLOCKS}): 0 entries, 0 B within 31.03 μs
[INFO] [2023-01-26 18:08:25]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=ConceptUpdateAndDeletionTest]	Imports of worker ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9 are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:25]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=ConceptUpdateAndDeletionTest]	Buckets of worker ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9 are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:25]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=ConceptUpdateAndDeletionTest]	Consistency check was successful
[INFO] [2023-01-26 18:08:25]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=ConceptUpdateAndDeletionTest]	Imports of worker ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:25]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=ConceptUpdateAndDeletionTest]	Buckets of worker ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:25]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=ConceptUpdateAndDeletionTest]	Consistency check was successful
[INFO] [2023-01-26 18:08:25]	c.b.c.u.s.TestConquery	ConceptUpdateAndDeletionTest	Waiting for jobs to finish
[INFO] [2023-01-26 18:08:25]	c.b.c.u.s.TestConquery	ConceptUpdateAndDeletionTest	Waiting for jobs to finish
[INFO] [2023-01-26 18:08:25]	c.b.c.u.s.TestConquery	ConceptUpdateAndDeletionTest	Waiting for jobs to finish
[INFO] [2023-01-26 18:08:25]	c.b.c.m.m.n.s.UpdateTable	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b, /127.0.0.1:49092]	Received update of Table ConceptUpdateAndDeletionTest.test_table
[INFO] [2023-01-26 18:08:25]	c.b.c.m.m.n.s.UpdateTable	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9, /127.0.0.1:49088]	Received update of Table ConceptUpdateAndDeletionTest.test_table
[INFO] [2023-01-26 18:08:25]	c.b.c.u.s.TestConquery	ConceptUpdateAndDeletionTest	Waiting for jobs to finish
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.WorkerStorage	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9, /127.0.0.1:49088]	Updating Concept[ConceptUpdateAndDeletionTest.test_tree]
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.WorkerStorage	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b, /127.0.0.1:49092]	Updating Concept[ConceptUpdateAndDeletionTest.test_tree]
[INFO] [2023-01-26 18:08:25]	c.b.c.c.PreprocessorCommand	ConceptUpdateAndDeletionTest	Preprocessing from command line config.
[INFO] [2023-01-26 18:08:25]	c.b.c.c.PreprocessorCommand	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ConceptUpdateAndDeletionTest/test_table.import.json, tag=Optional.empty)	DOES NOT EXIST
[INFO] [2023-01-26 18:08:25]	c.b.c.c.PreprocessorCommand	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ConceptUpdateAndDeletionTest/test_table.import.json, tag=Optional.empty)	Required to preprocess 94 B in total
[INFO] [2023-01-26 18:08:25]	c.b.c.m.p.Preprocessor	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ConceptUpdateAndDeletionTest/test_table.import.json, tag=Optional.empty)	PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ConceptUpdateAndDeletionTest/test_table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000180333s[INFO] [2023-01-26 18:08:25]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content.csv]	Statistics = IntSummaryStatistics{count=4, sum=4, min=1, average=1.000000, max=1}
[INFO] [2023-01-26 18:08:25]	c.b.c.m.p.PPColumn	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content.csv]	Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=4, nullLines=0), encoding=null, prefix=, suffix=)
[DEBUG] [2023-01-26 18:08:25]	c.b.c.m.p.p.s.StringParser	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content.csv]		Chosen encoding is Base16UpperCase
[INFO] [2023-01-26 18:08:25]	c.b.c.m.p.PPColumn		Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=4, nullLines=0), subType=IntegerParser(super=Parser(lines=4, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@7bff73d5)
[DEBUG] [2023-01-26 18:08:25]	c.b.c.m.p.PPColumn			datum: DateParser(super=Parser(lines=4, nullLines=0), subType=IntegerParser(super=Parser(lines=4, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@7bff73d5) -> IntegerDateStore(store=ShortArrayStore())
[DEBUG] [2023-01-26 18:08:25]	c.b.c.m.p.p.s.StringParser	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content.csv]		Using com.bakdata.conquery.models.preproc.parser.specific.string.TrieTypeGuesser@6234ae87(est. 81 B)
[DEBUG] [2023-01-26 18:08:25]	c.b.c.m.p.PPColumn	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content.csv]		test_column: StringParser(super=Parser(lines=4, nullLines=0), encoding=Base16UpperCase, prefix=, suffix=) -> StringTypeEncoded(encoding=Base16UpperCase, subType=StringTypeDictionary(dictionary=SuccinctTrie[size=3], numberType=ByteArrayStore()))
[DEBUG] [2023-01-26 18:08:25]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content.csv]	Encode primary Dictionary
[DEBUG] [2023-01-26 18:08:25]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content.csv]	Writing Headers
[DEBUG] [2023-01-26 18:08:25]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content.csv]	Writing header
[DEBUG] [2023-01-26 18:08:25]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content.csv]	Writing Dictionaries
[DEBUG] [2023-01-26 18:08:25]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content.csv]	Writing data
[INFO] [2023-01-26 18:08:25]	c.b.c.m.p.Preprocessor	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content.csv]	PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ConceptUpdateAndDeletionTest/test_table.import.json, tag=Optional.empty)
[INFO] [2023-01-26 18:08:25]	c.b.c.c.PreprocessorCommand		Successfully Preprocess 1 Jobs:
[INFO] [2023-01-26 18:08:25]	c.b.c.c.PreprocessorCommand			Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ConceptUpdateAndDeletionTest/test_table.import.json, tag=Optional.empty)
[DEBUG] [2023-01-26 18:08:25]	c.b.c.m.j.ImportJob	user.SUPERUSER@SUPERUSER	Done reading data. Contains 4 Entities.
[INFO] [2023-01-26 18:08:25]	c.b.c.m.j.ImportJob	user.SUPERUSER@SUPERUSER	Importing test_table into ConceptUpdateAndDeletionTest.test_table
[DEBUG] [2023-01-26 18:08:25]	c.b.c.m.j.ImportJob	Job Manager slow ConceptUpdateAndDeletionTest	Mapped 4 new ids
[DEBUG] [2023-01-26 18:08:25]	c.b.c.m.j.ImportJob	Job Manager slow ConceptUpdateAndDeletionTest	Updating bucket assignments.
127.0.0.1 - - [26/Jan/2023:18:08:25 +0000] "POST /admin/datasets/ConceptUpdateAndDeletionTest/imports?file=%2Ftmp%2FconqueryIntegrationTest12910953884258704183%2Ftmp_ConceptUpdateAndDeletionTest%2Ftest_table.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 10
[DEBUG] [2023-01-26 18:08:25]	c.b.c.m.w.Namespace	Job Manager slow ConceptUpdateAndDeletionTest	Assigning Bucket[0] to Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9]
[DEBUG] [2023-01-26 18:08:25]	c.b.c.m.w.Namespace	Job Manager slow ConceptUpdateAndDeletionTest	Assigning Bucket[1] to Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b]
[INFO] [2023-01-26 18:08:25]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[INFO] [2023-01-26 18:08:25]	c.b.c.m.j.ImportJob	Job Manager slow ConceptUpdateAndDeletionTest	Importing Dictionaries
[DEBUG] [2023-01-26 18:08:25]	c.b.c.m.m.n.s.UpdateWorkerBucket	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b, /127.0.0.1:49092]	Received new WorkerInformation(size = 1,dataset = ConceptUpdateAndDeletionTest)
[DEBUG] [2023-01-26 18:08:25]	c.b.c.m.m.n.s.UpdateWorkerBucket	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9, /127.0.0.1:49088]	Received new WorkerInformation(size = 1,dataset = ConceptUpdateAndDeletionTest)
[INFO] [2023-01-26 18:08:25]	c.b.c.m.j.ImportJob	Job Manager slow ConceptUpdateAndDeletionTest	Remapping Dictionaries []
[WARN] [2023-01-26 18:08:25]	c.b.c.u.p.ProgressReporterImpl	Job Manager slow ConceptUpdateAndDeletionTest	Max cannot be decreased.
[DEBUG] [2023-01-26 18:08:25]	c.b.c.m.m.n.s.UpdateDictionary	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9, /127.0.0.1:49088]	Received Dictionary[ConceptUpdateAndDeletionTest.test_table#ConceptUpdateAndDeletionTest$2etest_table$2etest_column] of size 3.
[DEBUG] [2023-01-26 18:08:25]	c.b.c.m.m.n.s.UpdateDictionary	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b, /127.0.0.1:49092]	Received Dictionary[ConceptUpdateAndDeletionTest.test_table#ConceptUpdateAndDeletionTest$2etest_table$2etest_column] of size 3.
[INFO] [2023-01-26 18:08:25]	c.b.c.m.j.ImportJob	Job Manager slow ConceptUpdateAndDeletionTest	Start sending 2 Buckets
[WARN] [2023-01-26 18:08:25]	c.b.c.u.p.ProgressReporterImpl	Job Manager slow ConceptUpdateAndDeletionTest	One or more Children are not done yet
[INFO] [2023-01-26 18:08:25]	c.b.c.m.m.n.s.AddImport	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9, /127.0.0.1:49088]	Received Import[ConceptUpdateAndDeletionTest.test_table.test_table], containing 4 entries.
[INFO] [2023-01-26 18:08:25]	c.b.c.m.m.n.s.AddImport	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b, /127.0.0.1:49092]	Received Import[ConceptUpdateAndDeletionTest.test_table.test_table], containing 4 entries.
[INFO] [2023-01-26 18:08:25]	c.b.c.m.m.n.s.ImportBucket	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9, /127.0.0.1:49088]	Received ConceptUpdateAndDeletionTest.test_table.test_table.0
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.WorkerStorage	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9, /127.0.0.1:49088]	Adding Bucket[ConceptUpdateAndDeletionTest.test_table.test_table.0]
[INFO] [2023-01-26 18:08:25]	c.b.c.m.m.n.s.ImportBucket	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b, /127.0.0.1:49092]	Received ConceptUpdateAndDeletionTest.test_table.test_table.1
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.WorkerStorage	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b, /127.0.0.1:49092]	Adding Bucket[ConceptUpdateAndDeletionTest.test_table.test_table.1]
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.WorkerStorage		Adding CBlock[ConceptUpdateAndDeletionTest.test_table.test_table.1.ConceptUpdateAndDeletionTest.test_tree.test_column]
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.WorkerStorage		Adding CBlock[ConceptUpdateAndDeletionTest.test_table.test_table.0.ConceptUpdateAndDeletionTest.test_tree.test_column]
[INFO] [2023-01-26 18:08:25]	c.b.c.i.t.d.ConceptUpdateAndDeletionTest		Checking state before update
[INFO] [2023-01-26 18:08:25]	c.b.c.i.t.d.ConceptUpdateAndDeletionTest		Executing query before update
[INFO] [2023-01-26 18:08:25]	c.b.c.a.QueryProcessor	user.SUPERUSER@SUPERUSER	Query posted on Dataset[ConceptUpdateAndDeletionTest] by User[{user.SUPERUSER@SUPERUSER].
[INFO] [2023-01-26 18:08:25]	c.b.c.m.q.ExecutionManager	user.SUPERUSER@SUPERUSER	Executing Query[1f38796f-d54f-4759-8a56-c84f49f054bd] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_ConceptUpdateAndDeletionTest))]]
[INFO] [2023-01-26 18:08:25]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9, /127.0.0.1:49088]	Started ConceptQuery ConceptUpdateAndDeletionTest.1f38796f-d54f-4759-8a56-c84f49f054bd
[INFO] [2023-01-26 18:08:25]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b, /127.0.0.1:49092]	Started ConceptQuery ConceptUpdateAndDeletionTest.1f38796f-d54f-4759-8a56-c84f49f054bd
[DEBUG] [2023-01-26 18:08:25]	c.b.c.m.q.QueryExecutor	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9, /127.0.0.1:49088]	QueryPlan for Query[ConceptUpdateAndDeletionTest.1f38796f-d54f-4759-8a56-c84f49f054bd] = `ConceptQueryPlan(child=ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table, name=test_table]])])), validityDateColumn=Column(id = ConceptUpdateAndDeletionTest.test_table.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column], dateColumn=null), selectedSecondaryId=null), dateAggregator=DateAggregator(action=MERGE))`
[DEBUG] [2023-01-26 18:08:25]	c.b.c.m.q.QueryExecutor	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b, /127.0.0.1:49092]	QueryPlan for Query[ConceptUpdateAndDeletionTest.1f38796f-d54f-4759-8a56-c84f49f054bd] = `ConceptQueryPlan(child=ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table, name=test_table]])])), validityDateColumn=Column(id = ConceptUpdateAndDeletionTest.test_table.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column], dateColumn=null), selectedSecondaryId=null), dateAggregator=DateAggregator(action=MERGE))`
[INFO] [2023-01-26 18:08:25]	c.b.c.m.q.r.ShardResult		FINISHED Query[ConceptUpdateAndDeletionTest.1f38796f-d54f-4759-8a56-c84f49f054bd] with 0 results within PT0.001556S
127.0.0.1 - - [26/Jan/2023:18:08:25 +0000] "POST /api/datasets/ConceptUpdateAndDeletionTest/queries HTTP/1.1" 201 1148 "-" "Conquery (test client)" 9
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.c.IntegrationUtils		Trying to get Query result
[INFO] [2023-01-26 18:08:25]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=ConceptUpdateAndDeletionTest]	Received ShardResult(queryId=ConceptUpdateAndDeletionTest.1f38796f-d54f-4759-8a56-c84f49f054bd, workerId=ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b, startTime=2023-01-26T18:08:25.771657, finishTime=2023-01-26T18:08:25.773213) of size 0
[DEBUG] [2023-01-26 18:08:25]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=ConceptUpdateAndDeletionTest]	Received Result[size=0] for Query[ConceptUpdateAndDeletionTest.1f38796f-d54f-4759-8a56-c84f49f054bd]
[INFO] [2023-01-26 18:08:25]	c.b.c.m.q.r.ShardResult		FINISHED Query[ConceptUpdateAndDeletionTest.1f38796f-d54f-4759-8a56-c84f49f054bd] with 1 results within PT0.008356S
[INFO] [2023-01-26 18:08:25]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=ConceptUpdateAndDeletionTest]	Received ShardResult(queryId=ConceptUpdateAndDeletionTest.1f38796f-d54f-4759-8a56-c84f49f054bd, workerId=ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9, startTime=2023-01-26T18:08:25.771624, finishTime=2023-01-26T18:08:25.779980) of size 1
[DEBUG] [2023-01-26 18:08:25]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=ConceptUpdateAndDeletionTest]	Received Result[size=1] for Query[ConceptUpdateAndDeletionTest.1f38796f-d54f-4759-8a56-c84f49f054bd]
[INFO] [2023-01-26 18:08:25]	c.b.c.m.e.ManagedExecution	Dataset[label=null, name=ConceptUpdateAndDeletionTest]	DONE 1f38796f-d54f-4759-8a56-c84f49f054bd ManagedQuery within PT0.012471S
127.0.0.1 - - [26/Jan/2023:18:08:25 +0000] "GET /api/datasets/ConceptUpdateAndDeletionTest/queries/ConceptUpdateAndDeletionTest.1f38796f-d54f-4759-8a56-c84f49f054bd HTTP/1.1" 200 1452 "-" "Conquery (test client)" 3
[INFO] [2023-01-26 18:08:25]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[INFO] [2023-01-26 18:08:25]	c.b.c.i.t.d.ConceptUpdateAndDeletionTest		Query before update executed
[INFO] [2023-01-26 18:08:25]	c.b.c.i.t.d.ConceptUpdateAndDeletionTest		Executing  update
[INFO] [2023-01-26 18:08:25]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:08:25 +0000] "PUT /admin/datasets/ConceptUpdateAndDeletionTest/concepts HTTP/1.1" 204 0 "-" "Conquery (test client)" 13
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.WorkerStorage	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9, /127.0.0.1:49088]	Removing CBlock[ConceptUpdateAndDeletionTest.test_table.test_table.0.ConceptUpdateAndDeletionTest.test_tree.test_column]
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.WorkerStorage	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b, /127.0.0.1:49092]	Removing CBlock[ConceptUpdateAndDeletionTest.test_table.test_table.1.ConceptUpdateAndDeletionTest.test_tree.test_column]
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.WorkerStorage	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9, /127.0.0.1:49088]	Removing Concept[ConceptUpdateAndDeletionTest.test_tree]
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.WorkerStorage	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b, /127.0.0.1:49092]	Removing Concept[ConceptUpdateAndDeletionTest.test_tree]
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.WorkerStorage	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9, /127.0.0.1:49088]	Updating Concept[ConceptUpdateAndDeletionTest.test_tree]
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.WorkerStorage	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b, /127.0.0.1:49092]	Updating Concept[ConceptUpdateAndDeletionTest.test_tree]
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.WorkerStorage		Adding CBlock[ConceptUpdateAndDeletionTest.test_table.test_table.0.ConceptUpdateAndDeletionTest.test_tree.test_column]
[DEBUG] [2023-01-26 18:08:25]	c.b.c.i.s.WorkerStorage		Adding CBlock[ConceptUpdateAndDeletionTest.test_table.test_table.1.ConceptUpdateAndDeletionTest.test_tree.test_column]
[INFO] [2023-01-26 18:08:26]	c.b.c.i.t.d.ConceptUpdateAndDeletionTest		Update executed
[INFO] [2023-01-26 18:08:26]	c.b.c.i.t.d.ConceptUpdateAndDeletionTest		Checking state after update
[INFO] [2023-01-26 18:08:26]	c.b.c.i.t.d.ConceptUpdateAndDeletionTest		Executing query after update
[INFO] [2023-01-26 18:08:26]	c.b.c.a.QueryProcessor	user.SUPERUSER@SUPERUSER	Query posted on Dataset[ConceptUpdateAndDeletionTest] by User[{user.SUPERUSER@SUPERUSER].
[INFO] [2023-01-26 18:08:26]	c.b.c.m.q.ExecutionManager	user.SUPERUSER@SUPERUSER	Executing Query[43697a3a-0c52-49b7-a9e3-3e365a7db138] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_ConceptUpdateAndDeletionTest))]]
[INFO] [2023-01-26 18:08:26]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9, /127.0.0.1:49088]	Started ConceptQuery ConceptUpdateAndDeletionTest.43697a3a-0c52-49b7-a9e3-3e365a7db138
[INFO] [2023-01-26 18:08:26]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b, /127.0.0.1:49092]	Started ConceptQuery ConceptUpdateAndDeletionTest.43697a3a-0c52-49b7-a9e3-3e365a7db138
[DEBUG] [2023-01-26 18:08:26]	c.b.c.m.q.QueryExecutor	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9, /127.0.0.1:49088]	QueryPlan for Query[ConceptUpdateAndDeletionTest.43697a3a-0c52-49b7-a9e3-3e365a7db138] = `ConceptQueryPlan(child=ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table, name=test_table]])])), validityDateColumn=Column(id = ConceptUpdateAndDeletionTest.test_table.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column], dateColumn=null), selectedSecondaryId=null), dateAggregator=DateAggregator(action=MERGE))`
[DEBUG] [2023-01-26 18:08:26]	c.b.c.m.q.QueryExecutor	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b, /127.0.0.1:49092]	QueryPlan for Query[ConceptUpdateAndDeletionTest.43697a3a-0c52-49b7-a9e3-3e365a7db138] = `ConceptQueryPlan(child=ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table, name=test_table]])])), validityDateColumn=Column(id = ConceptUpdateAndDeletionTest.test_table.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column], dateColumn=null), selectedSecondaryId=null), dateAggregator=DateAggregator(action=MERGE))`
[INFO] [2023-01-26 18:08:26]	c.b.c.m.q.r.ShardResult		FINISHED Query[ConceptUpdateAndDeletionTest.43697a3a-0c52-49b7-a9e3-3e365a7db138] with 1 results within PT0.001245S
127.0.0.1 - - [26/Jan/2023:18:08:26 +0000] "POST /api/datasets/ConceptUpdateAndDeletionTest/queries HTTP/1.1" 201 1149 "-" "Conquery (test client)" 5
[DEBUG] [2023-01-26 18:08:26]	c.b.c.i.c.IntegrationUtils		Trying to get Query result
[INFO] [2023-01-26 18:08:26]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=ConceptUpdateAndDeletionTest]	Received ShardResult(queryId=ConceptUpdateAndDeletionTest.43697a3a-0c52-49b7-a9e3-3e365a7db138, workerId=ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b, startTime=2023-01-26T18:08:26.043183, finishTime=2023-01-26T18:08:26.044428) of size 1
[DEBUG] [2023-01-26 18:08:26]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=ConceptUpdateAndDeletionTest]	Received Result[size=1] for Query[ConceptUpdateAndDeletionTest.43697a3a-0c52-49b7-a9e3-3e365a7db138]
[INFO] [2023-01-26 18:08:26]	c.b.c.m.q.r.ShardResult		FINISHED Query[ConceptUpdateAndDeletionTest.43697a3a-0c52-49b7-a9e3-3e365a7db138] with 1 results within PT0.00487S
[INFO] [2023-01-26 18:08:26]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=ConceptUpdateAndDeletionTest]	Received ShardResult(queryId=ConceptUpdateAndDeletionTest.43697a3a-0c52-49b7-a9e3-3e365a7db138, workerId=ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9, startTime=2023-01-26T18:08:26.043178, finishTime=2023-01-26T18:08:26.048048) of size 1
[DEBUG] [2023-01-26 18:08:26]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=ConceptUpdateAndDeletionTest]	Received Result[size=1] for Query[ConceptUpdateAndDeletionTest.43697a3a-0c52-49b7-a9e3-3e365a7db138]
[INFO] [2023-01-26 18:08:26]	c.b.c.m.e.ManagedExecution	Dataset[label=null, name=ConceptUpdateAndDeletionTest]	DONE 43697a3a-0c52-49b7-a9e3-3e365a7db138 ManagedQuery within PT0.006812S
127.0.0.1 - - [26/Jan/2023:18:08:26 +0000] "GET /api/datasets/ConceptUpdateAndDeletionTest/queries/ConceptUpdateAndDeletionTest.43697a3a-0c52-49b7-a9e3-3e365a7db138 HTTP/1.1" 200 1452 "-" "Conquery (test client)" 3
[INFO] [2023-01-26 18:08:26]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[INFO] [2023-01-26 18:08:26]	c.b.c.i.t.d.ConceptUpdateAndDeletionTest		Query after update executed
[INFO] [2023-01-26 18:08:26]	c.b.c.m.j.JobExecutor		Closing Job Manager fast shard-node1
[INFO] [2023-01-26 18:08:26]	c.b.c.m.j.JobExecutor		Closing Job Manager slow shard-node1
[INFO] [2023-01-26 18:08:26]	c.b.c.m.j.JobExecutor		Closing Job Manager fast worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b
[INFO] [2023-01-26 18:08:26]	c.b.c.m.j.JobExecutor		Closing Job Manager slow worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:DATASET}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:SECONDARY_IDS}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:TABLES}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:DICTIONARIES_META}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:DICTIONARIES_DATA}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:IMPORTS}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:CONCEPTS}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:WORKER}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:BUCKETS}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:C_BLOCKS}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b
[INFO] [2023-01-26 18:08:26]	c.b.c.c.ShardNode		Connection was closed by ManagerNode
[INFO] [2023-01-26 18:08:26]	c.b.c.c.ShardNode	0.0.0.0/0.0.0.0:49092	Disconnected from ManagerNode
[INFO] [2023-01-26 18:08:26]	c.b.c.m.j.JobExecutor		Closing Job Manager fast shard-node0
[INFO] [2023-01-26 18:08:26]	c.b.c.c.ManagerNode	ManagerNode[0.0.0.0/0.0.0.0:34233]	Client 'null' disconnected 
[INFO] [2023-01-26 18:08:26]	c.b.c.m.j.JobExecutor		Closing Job Manager slow shard-node0
[INFO] [2023-01-26 18:08:26]	c.b.c.m.j.JobExecutor		Closing Job Manager fast worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9
[INFO] [2023-01-26 18:08:26]	c.b.c.m.j.JobExecutor		Closing Job Manager slow worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:DATASET}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:SECONDARY_IDS}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:TABLES}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:DICTIONARIES_META}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:DICTIONARIES_DATA}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:IMPORTS}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:CONCEPTS}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:WORKER}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:BUCKETS}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:C_BLOCKS}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9
[INFO] [2023-01-26 18:08:26]	c.b.c.c.ShardNode		Connection was closed by ManagerNode
[INFO] [2023-01-26 18:08:26]	c.b.c.c.ShardNode	0.0.0.0/0.0.0.0:49088	Disconnected from ManagerNode
[INFO] [2023-01-26 18:08:26]	c.b.c.m.j.JobExecutor		Closing Job Manager fast ManagerNode
[INFO] [2023-01-26 18:08:26]	c.b.c.c.ManagerNode	ManagerNode[0.0.0.0/0.0.0.0:34233]	Client 'null' disconnected 
[INFO] [2023-01-26 18:08:26]	c.b.c.m.j.JobExecutor		Closing Job Manager slow ManagerNode
[INFO] [2023-01-26 18:08:26]	c.b.c.m.j.JobExecutor		Closing Job Manager fast ConceptUpdateAndDeletionTest
[INFO] [2023-01-26 18:08:26]	c.b.c.m.j.JobExecutor		Closing Job Manager slow ConceptUpdateAndDeletionTest
[INFO] [2023-01-26 18:08:26]	c.b.c.m.w.Namespace		Closing namespace storage of ConceptUpdateAndDeletionTest
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:DATASET}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:SECONDARY_IDS}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:TABLES}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:DICTIONARIES_META}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:DICTIONARIES_DATA}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:IMPORTS}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:CONCEPTS}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:ID_MAPPING_META}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:ID_MAPPING_DATA}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:STRUCTURE}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:WORKER_TO_BUCKETS}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:PRIMARY_DICTIONARY}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/executions:EXECUTIONS}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/executions
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/formConfigs:FORM_CONFIG}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/formConfigs
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/users:AUTH_USER}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/users
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/roles:AUTH_ROLE}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/roles
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/groups:AUTH_GROUP}
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/groups
[INFO] [2023-01-26 18:08:26]	c.b.c.u.s.TestConquery		Working in temporary directory /tmp/conqueryIntegrationTest12910953884258704183
[DEBUG] [2023-01-26 18:08:26]	c.b.c.c.StandaloneCommand	ManagerNode	Starting ManagerNode
[DEBUG] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:26]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:26]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:DATASET}): 1 entries, 83 B within 208.2 μs
[DEBUG] [2023-01-26 18:08:26]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:26]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:SECONDARY_IDS}): 0 entries, 0 B within 38.33 μs
[DEBUG] [2023-01-26 18:08:26]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest	While processing store TABLES:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:26]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:TABLES}): 1 entries, 183 B within 172.2 μs
[DEBUG] [2023-01-26 18:08:26]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest	While processing store DICTIONARIES_META:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:26]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest		loaded store cached big DICTIONARIES(Dictionary): 1 entries, 43 B within 843.8 μs
[DEBUG] [2023-01-26 18:08:26]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest	While processing store IMPORTS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:26]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:IMPORTS}): 1 entries, 553 B within 3.700 ms
[DEBUG] [2023-01-26 18:08:26]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest	While processing store CONCEPTS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:26]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:CONCEPTS}): 1 entries, 508 B within 6.775 ms
[INFO] [2023-01-26 18:08:26]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest	Done reading Dataset[label=ConceptUpdateAndDeletionTest, name=ConceptUpdateAndDeletionTest] / com.bakdata.conquery.io.storage.NamespaceStorage
[DEBUG] [2023-01-26 18:08:26]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest	While processing store ID_MAPPING_META:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:26]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest		loaded store cached big ID_MAPPING(EntityIdMap): 1 entries, 43 B within 713.3 μs
[DEBUG] [2023-01-26 18:08:26]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest	While processing store STRUCTURE:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:26]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:STRUCTURE}): 0 entries, 0 B within 72.26 μs
[DEBUG] [2023-01-26 18:08:26]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest	While processing store WORKER_TO_BUCKETS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:26]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:WORKER_TO_BUCKETS}): 1 entries, 328 B within 159.8 μs
[DEBUG] [2023-01-26 18:08:26]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest	While processing store PRIMARY_DICTIONARY:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:26]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:PRIMARY_DICTIONARY}): 1 entries, 114 B within 799.3 μs
[DEBUG] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest	DONE reading Storage
[INFO] [2023-01-26 18:08:26]	c.b.c.m.c.XodusStoreFactory	ManagerNode	All WorkerStores loaded: [NamespacedStorage(pathName=dataset_ConceptUpdateAndDeletionTest)]
[INFO] [2023-01-26 18:08:26]	c.b.c.c.ManagerNode	ManagerNode	Opening MetaStorage
[INFO] [2023-01-26 18:08:27]	c.b.c.c.ManagerNode	ManagerNode	Loading MetaStorage
[DEBUG] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store AUTH_USER:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/users:AUTH_USER}): 1 entries, 149 B within 883.9 μs
[DEBUG] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store AUTH_ROLE:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/roles:AUTH_ROLE}): 0 entries, 0 B within 117.1 μs
[DEBUG] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store AUTH_GROUP:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/groups:AUTH_GROUP}): 0 entries, 0 B within 66.76 μs
[DEBUG] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store EXECUTIONS:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/executions:EXECUTIONS}): 2 entries, 1.1 KiB within 8.635 ms
[DEBUG] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store FORM_CONFIG:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/formConfigs:FORM_CONFIG}): 0 entries, 0 B within 92.54 μs
[INFO] [2023-01-26 18:08:27]	c.b.c.c.ManagerNode	ManagerNode	MetaStorage loaded com.bakdata.conquery.io.storage.MetaStorage@5c3325f7
[DEBUG] [2023-01-26 18:08:27]	c.b.c.m.a.AuthorizationController	ManagerNode	Security manager registered
[WARN] [2023-01-26 18:08:27]	c.b.c.m.a.d.DefaultInitialUserRealm	ManagerNode	
           §§
          §  §
         §    §
        §      §
       §  §§§§  §       You instantiated and are probably using a Shiro realm
      §   §§§§   §      that does not do any permission checks or authentication.
     §     §§     §     Access to all resources is granted to everyone.
    §      §§      §    DO NOT USE THIS REALM IN PRODUCTION
   $                §
  §        §§        §
 §                    §
 §§§§§§§§§§§§§§§§§§§§§§
[INFO] [2023-01-26 18:08:27]	c.b.c.m.a.AuthorizationController	ManagerNode	Registering the following realms to Shiro:
	com.bakdata.conquery.models.auth.conquerytoken.ConqueryTokenRealm_18
	com.bakdata.conquery.models.auth.ConqueryAuthorizationRealm_19
	com.bakdata.conquery.models.auth.develop.DefaultInitialUserRealm_20
[INFO] [2023-01-26 18:08:27]	c.b.c.c.ManagerNode	ManagerNode	Registering ResourcesProvider
[INFO] [2023-01-26 18:08:27]	c.b.c.m.f.f.FormScanner	ManagerNode	Form[EXPORT_FORM] from `Resource com/bakdata/conquery/frontend/forms/export_form.frontend_conf.json` of Type[com.bakdata.conquery.apiv1.forms.export_form.ExportForm]
[INFO] [2023-01-26 18:08:27]	c.b.c.m.f.f.FormScanner	ManagerNode	Form[FULL_EXPORT_FORM] from `Resource com/bakdata/conquery/frontend/forms/table_export_form.frontend_conf.json` of Type[com.bakdata.conquery.apiv1.forms.export_form.FullExportForm]
[DEBUG] [2023-01-26 18:08:27]	c.b.c.c.StandaloneCommand	ManagerNode	Waiting for ShardNodes to start
[DEBUG] [2023-01-26 18:08:27]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:27]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:DATASET}): 1 entries, 83 B within 136.8 μs
[DEBUG] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:DATASET}): 1 entries, 83 B within 123.6 μs
[DEBUG] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:SECONDARY_IDS}): 0 entries, 0 B within 43.34 μs
[DEBUG] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:SECONDARY_IDS}): 0 entries, 0 B within 42.98 μs
[DEBUG] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9	While processing store TABLES:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:TABLES}): 1 entries, 183 B within 141.8 μs
[DEBUG] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b	While processing store TABLES:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:TABLES}): 1 entries, 183 B within 125.0 μs
[DEBUG] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9	While processing store DICTIONARIES_META:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[DEBUG] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b	While processing store DICTIONARIES_META:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9		loaded store cached big DICTIONARIES(Dictionary): 1 entries, 43 B within 682.4 μs
[INFO] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b		loaded store cached big DICTIONARIES(Dictionary): 1 entries, 43 B within 647.5 μs
[DEBUG] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b	While processing store IMPORTS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[DEBUG] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9	While processing store IMPORTS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:IMPORTS}): 1 entries, 553 B within 3.005 ms
[INFO] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:IMPORTS}): 1 entries, 553 B within 2.994 ms
[DEBUG] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b	While processing store CONCEPTS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:CONCEPTS}): 1 entries, 508 B within 3.960 ms
[INFO] [2023-01-26 18:08:27]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b	Done reading Dataset[label=ConceptUpdateAndDeletionTest, name=ConceptUpdateAndDeletionTest] / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b	While processing store WORKER:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:WORKER}): 1 entries, 159 B within 141.1 μs
[DEBUG] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9	While processing store CONCEPTS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:CONCEPTS}): 1 entries, 508 B within 5.636 ms
[INFO] [2023-01-26 18:08:27]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9	Done reading Dataset[label=ConceptUpdateAndDeletionTest, name=ConceptUpdateAndDeletionTest] / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9	While processing store WORKER:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:WORKER}): 1 entries, 159 B within 111.5 μs
[DEBUG] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b	While processing store BUCKETS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:BUCKETS}): 1 entries, 398 B within 1.745 ms
[DEBUG] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b	While processing store C_BLOCKS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:C_BLOCKS}): 1 entries, 249 B within 269.9 μs
[DEBUG] [2023-01-26 18:08:27]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b	DONE reading Storage
[INFO] [2023-01-26 18:08:27]	c.b.c.m.c.XodusStoreFactory	shard-node1	All WorkerStores loaded: [WorkerStorage(worker=NamedImpl(name=worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b))]
[INFO] [2023-01-26 18:08:27]	c.b.c.c.ShardNode	shard-node1	All Worker Storages loaded: 1
[DEBUG] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9	While processing store BUCKETS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:BUCKETS}): 1 entries, 410 B within 1.895 ms
[DEBUG] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9	While processing store C_BLOCKS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:27]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:C_BLOCKS}): 1 entries, 248 B within 198.1 μs
[DEBUG] [2023-01-26 18:08:27]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9	DONE reading Storage
[INFO] [2023-01-26 18:08:27]	c.b.c.m.c.XodusStoreFactory	shard-node0	All WorkerStores loaded: [WorkerStorage(worker=NamedImpl(name=worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9))]
[INFO] [2023-01-26 18:08:27]	c.b.c.c.ShardNode	shard-node0	All Worker Storages loaded: 1
[DEBUG] [2023-01-26 18:08:27]	c.b.c.c.StandaloneCommand	ManagerNode	Starting REST Server
[INFO] [2023-01-26 18:08:27]	c.b.c.c.ManagerNode		Started ManagerNode @ /0:0:0:0:0:0:0:0:34233
[INFO] [2023-01-26 18:08:27]	c.b.c.c.ShardNode		Trying to connect to /127.0.0.1:34233
[INFO] [2023-01-26 18:08:27]	c.b.c.c.ManagerNode	ManagerNode[/127.0.0.1:34233]	New client /127.0.0.1:49838 connected, waiting for identity
[INFO] [2023-01-26 18:08:27]	c.b.c.c.ShardNode	/127.0.0.1:49838	Connected to ManagerNode @ /127.0.0.1:34233
[INFO] [2023-01-26 18:08:27]	c.b.c.c.ShardNode		Trying to connect to /127.0.0.1:34233
[INFO] [2023-01-26 18:08:27]	c.b.c.c.ManagerNode	ManagerNode[/127.0.0.1:34233]	New client /127.0.0.1:49840 connected, waiting for identity
[INFO] [2023-01-26 18:08:27]	c.b.c.c.ShardNode	/127.0.0.1:49840	Connected to ManagerNode @ /127.0.0.1:34233
[INFO] [2023-01-26 18:08:27]	c.b.c.c.ShardNode	/127.0.0.1:49838	Sending worker identity 'worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9'
[INFO] [2023-01-26 18:08:27]	c.b.c.c.ShardNode	/127.0.0.1:49840	Sending worker identity 'worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b'
[INFO] [2023-01-26 18:08:27]	c.b.c.m.m.n.s.AddShardNode	Job Manager fast ManagerNode	ShardNode `/127.0.0.1:49838` registered.
[INFO] [2023-01-26 18:08:27]	c.b.c.m.m.n.s.AddShardNode	Job Manager fast ManagerNode	ShardNode `/127.0.0.1:49840` registered.
[INFO] [2023-01-26 18:08:27]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=ConceptUpdateAndDeletionTest, name=ConceptUpdateAndDeletionTest]	Imports of worker ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b are consistent with the manager: 1 Imports
[INFO] [2023-01-26 18:08:27]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=ConceptUpdateAndDeletionTest, name=ConceptUpdateAndDeletionTest]	Buckets of worker ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b are consistent with the manager: 1 Buckets
[INFO] [2023-01-26 18:08:27]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=ConceptUpdateAndDeletionTest, name=ConceptUpdateAndDeletionTest]	Consistency check was successful
[INFO] [2023-01-26 18:08:27]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=ConceptUpdateAndDeletionTest, name=ConceptUpdateAndDeletionTest]	Imports of worker ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9 are consistent with the manager: 1 Imports
[INFO] [2023-01-26 18:08:27]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=ConceptUpdateAndDeletionTest, name=ConceptUpdateAndDeletionTest]	Buckets of worker ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9 are consistent with the manager: 1 Buckets
[INFO] [2023-01-26 18:08:27]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=ConceptUpdateAndDeletionTest, name=ConceptUpdateAndDeletionTest]	Consistency check was successful
[WARN] [2023-01-26 18:08:27]	o.g.j.i.Errors		The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.filters.Filter<?> from public void com.bakdata.conquery.resources.hierarchies.HFilters.setFilter(com.bakdata.conquery.models.datasets.concepts.filters.Filter<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public com.bakdata.conquery.apiv1.FullExecutionStatus com.bakdata.conquery.resources.api.QueryResource.getStatus(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) throws java.lang.InterruptedException is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public com.bakdata.conquery.apiv1.FullExecutionStatus com.bakdata.conquery.resources.api.QueryResource.patchQuery(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>,com.bakdata.conquery.apiv1.MetaDataPatch) throws com.bakdata.conquery.models.exceptions.JSONException is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public void com.bakdata.conquery.resources.api.QueryResource.deleteQuery(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>) is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public void com.bakdata.conquery.resources.api.QueryResource.cancel(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>) is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public com.bakdata.conquery.apiv1.FullExecutionStatus com.bakdata.conquery.resources.api.QueryResource.reexecute(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultExcelResource.get(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.identifiable.ids.specific.DatasetId,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultArrowStreamResource.get(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.datasets.Dataset,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultCsvResource.getAsCsv(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.datasets.Dataset,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.lang.String,java.lang.String,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultArrowFileResource.get(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.datasets.Dataset,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.filters.Filter<?> from public void com.bakdata.conquery.resources.hierarchies.HFilters.setFilter(com.bakdata.conquery.models.datasets.concepts.filters.Filter<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.

[WARN] [2023-01-26 18:08:27]	i.d.s.AdminEnvironment		
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!    THIS APPLICATION HAS NO HEALTHCHECKS. THIS MEANS YOU WILL NEVER KNOW      !
!     IF IT DIES IN PRODUCTION, WHICH MEANS YOU WILL NEVER KNOW IF YOU'RE      !
!    LETTING YOUR USERS DOWN. YOU SHOULD ADD A HEALTHCHECK FOR EACH OF YOUR    !
!         APPLICATION'S DEPENDENCIES WHICH FULLY (BUT LIGHTLY) TESTS IT.       !
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
[WARN] [2023-01-26 18:08:27]	o.g.j.i.Errors		The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.auth.entities.PermissionOwner<?> from public void com.bakdata.conquery.resources.hierarchies.HPermissions.setOwner(com.bakdata.conquery.models.auth.entities.PermissionOwner<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.auth.entities.PermissionOwner<?> from public void com.bakdata.conquery.resources.hierarchies.HPermissions.setOwner(com.bakdata.conquery.models.auth.entities.PermissionOwner<?>) is not resolvable to a concrete type.

[WARN] [2023-01-26 18:08:27]	o.g.j.i.Errors		The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter concept of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from protected com.bakdata.conquery.models.datasets.concepts.Concept<?> com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.concept is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter concept of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from protected com.bakdata.conquery.models.datasets.concepts.Concept<?> com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.concept is not resolvable to a concrete type.

[INFO] [2023-01-26 18:08:27]	c.b.c.u.s.TestConquery		loading dataset
[INFO] [2023-01-26 18:08:27]	c.b.c.u.s.TestConquery		Reusing existing folder /tmp/conqueryIntegrationTest12910953884258704183/tmp_ConceptUpdateAndDeletionTest for Support
[INFO] [2023-01-26 18:08:27]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[INFO] [2023-01-26 18:08:27]	c.b.c.i.t.d.ConceptUpdateAndDeletionTest		Checking state after re-start
[INFO] [2023-01-26 18:08:27]	c.b.c.i.t.d.ConceptUpdateAndDeletionTest		Executing query after restart.
[INFO] [2023-01-26 18:08:27]	c.b.c.a.QueryProcessor	user.SUPERUSER@SUPERUSER	Query posted on Dataset[ConceptUpdateAndDeletionTest] by User[{user.SUPERUSER@SUPERUSER].
[INFO] [2023-01-26 18:08:27]	c.b.c.m.q.ExecutionManager	user.SUPERUSER@SUPERUSER	Executing Query[3f1e88aa-8fe5-420d-86af-fb22f83b2288] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_ConceptUpdateAndDeletionTest))]]
[DEBUG] [2023-01-26 18:08:27]	c.b.c.i.c.IntegrationUtils		Trying to get Query result
127.0.0.1 - - [26/Jan/2023:18:08:27 +0000] "POST /api/datasets/ConceptUpdateAndDeletionTest/queries HTTP/1.1" 201 1149 "-" "Conquery (test client)" 32
[INFO] [2023-01-26 18:08:27]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9, /127.0.0.1:49838]	Started ConceptQuery ConceptUpdateAndDeletionTest.3f1e88aa-8fe5-420d-86af-fb22f83b2288
[INFO] [2023-01-26 18:08:27]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b, /127.0.0.1:49840]	Started ConceptQuery ConceptUpdateAndDeletionTest.3f1e88aa-8fe5-420d-86af-fb22f83b2288
[DEBUG] [2023-01-26 18:08:27]	c.b.c.m.q.QueryExecutor	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b, /127.0.0.1:49840]	QueryPlan for Query[ConceptUpdateAndDeletionTest.3f1e88aa-8fe5-420d-86af-fb22f83b2288] = `ConceptQueryPlan(child=ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table, name=test_table]])])), validityDateColumn=Column(id = ConceptUpdateAndDeletionTest.test_table.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column], dateColumn=null), selectedSecondaryId=null), dateAggregator=DateAggregator(action=MERGE))`
[DEBUG] [2023-01-26 18:08:27]	c.b.c.m.q.QueryExecutor	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9, /127.0.0.1:49838]	QueryPlan for Query[ConceptUpdateAndDeletionTest.3f1e88aa-8fe5-420d-86af-fb22f83b2288] = `ConceptQueryPlan(child=ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table, name=test_table]])])), validityDateColumn=Column(id = ConceptUpdateAndDeletionTest.test_table.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column], dateColumn=null), selectedSecondaryId=null), dateAggregator=DateAggregator(action=MERGE))`
[INFO] [2023-01-26 18:08:27]	c.b.c.m.q.r.ShardResult		FINISHED Query[ConceptUpdateAndDeletionTest.3f1e88aa-8fe5-420d-86af-fb22f83b2288] with 1 results within PT0.000748S
[INFO] [2023-01-26 18:08:27]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=ConceptUpdateAndDeletionTest, name=ConceptUpdateAndDeletionTest]	Received ShardResult(queryId=ConceptUpdateAndDeletionTest.3f1e88aa-8fe5-420d-86af-fb22f83b2288, workerId=ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b, startTime=2023-01-26T18:08:27.636663, finishTime=2023-01-26T18:08:27.637411) of size 1
[DEBUG] [2023-01-26 18:08:27]	c.b.c.m.q.ManagedQuery	Dataset[label=ConceptUpdateAndDeletionTest, name=ConceptUpdateAndDeletionTest]	Received Result[size=1] for Query[ConceptUpdateAndDeletionTest.3f1e88aa-8fe5-420d-86af-fb22f83b2288]
[INFO] [2023-01-26 18:08:27]	c.b.c.m.q.r.ShardResult		FINISHED Query[ConceptUpdateAndDeletionTest.3f1e88aa-8fe5-420d-86af-fb22f83b2288] with 1 results within PT0.007339S
[INFO] [2023-01-26 18:08:27]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=ConceptUpdateAndDeletionTest, name=ConceptUpdateAndDeletionTest]	Received ShardResult(queryId=ConceptUpdateAndDeletionTest.3f1e88aa-8fe5-420d-86af-fb22f83b2288, workerId=ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9, startTime=2023-01-26T18:08:27.636663, finishTime=2023-01-26T18:08:27.644002) of size 1
[DEBUG] [2023-01-26 18:08:27]	c.b.c.m.q.ManagedQuery	Dataset[label=ConceptUpdateAndDeletionTest, name=ConceptUpdateAndDeletionTest]	Received Result[size=1] for Query[ConceptUpdateAndDeletionTest.3f1e88aa-8fe5-420d-86af-fb22f83b2288]
[INFO] [2023-01-26 18:08:27]	c.b.c.m.e.ManagedExecution	Dataset[label=ConceptUpdateAndDeletionTest, name=ConceptUpdateAndDeletionTest]	DONE 3f1e88aa-8fe5-420d-86af-fb22f83b2288 ManagedQuery within PT0.01838S
127.0.0.1 - - [26/Jan/2023:18:08:27 +0000] "GET /api/datasets/ConceptUpdateAndDeletionTest/queries/ConceptUpdateAndDeletionTest.3f1e88aa-8fe5-420d-86af-fb22f83b2288 HTTP/1.1" 200 1453 "-" "Conquery (test client)" 5
[INFO] [2023-01-26 18:08:27]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[INFO] [2023-01-26 18:08:27]	c.b.c.i.t.d.ConceptUpdateAndDeletionTest		Issuing deletion of import ConceptUpdateAndDeletionTest.test_tree
[INFO] [2023-01-26 18:08:27]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[DEBUG] [2023-01-26 18:08:27]	c.b.c.i.s.WorkerStorage	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9, /127.0.0.1:49838]	Removing CBlock[ConceptUpdateAndDeletionTest.test_table.test_table.0.ConceptUpdateAndDeletionTest.test_tree.test_column]
[DEBUG] [2023-01-26 18:08:27]	c.b.c.i.s.WorkerStorage	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b, /127.0.0.1:49840]	Removing CBlock[ConceptUpdateAndDeletionTest.test_table.test_table.1.ConceptUpdateAndDeletionTest.test_tree.test_column]
[DEBUG] [2023-01-26 18:08:27]	c.b.c.i.s.WorkerStorage	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b, /127.0.0.1:49840]	Removing Concept[ConceptUpdateAndDeletionTest.test_tree]
[DEBUG] [2023-01-26 18:08:27]	c.b.c.i.s.WorkerStorage	Worker[ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9, /127.0.0.1:49838]	Removing Concept[ConceptUpdateAndDeletionTest.test_tree]
[INFO] [2023-01-26 18:08:27]	c.b.c.i.t.d.ConceptUpdateAndDeletionTest		Checking state after deletion
[INFO] [2023-01-26 18:08:27]	c.b.c.i.t.d.ConceptUpdateAndDeletionTest		Executing query after deletion (EXPECTING AN EXCEPTION IN THE LOGS!)
[DEBUG] [2023-01-26 18:08:27]	c.b.c.i.j.ConqueryJsonExceptionMapper	user.SUPERUSER@SUPERUSER	Unable to process JSON in request 'http://localhost:39407/api/datasets/ConceptUpdateAndDeletionTest/queries'
com.fasterxml.jackson.databind.JsonMappingException: Error while resolving entry ConceptUpdateAndDeletionTest.test_tree.test_column of type class com.bakdata.conquery.models.datasets.concepts.Connector (through reference chain: com.bakdata.conquery.apiv1.query.ConceptQuery["root"]->com.bakdata.conquery.apiv1.query.concept.specific.CQConcept["tables"]->java.util.ArrayList[0]->com.bakdata.conquery.apiv1.query.concept.filter.CQTable["id"])
	at com.fasterxml.jackson.databind.JsonMappingException.wrapWithPath(JsonMappingException.java:397)
	at com.fasterxml.jackson.databind.JsonMappingException.wrapWithPath(JsonMappingException.java:356)
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.wrapAndThrow(BeanDeserializerBase.java:1719)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:254)
	at com.fasterxml.jackson.module.afterburner.deser.SuperSonicBeanDeserializer.deserialize(SuperSonicBeanDeserializer.java:155)
	at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:286)
	at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:245)
	at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:27)
	at com.fasterxml.jackson.databind.deser.SettableBeanProperty.deserialize(SettableBeanProperty.java:530)
	at com.fasterxml.jackson.databind.deser.impl.ManagedReferenceProperty.deserializeAndSet(ManagedReferenceProperty.java:62)
	at com.fasterxml.jackson.module.afterburner.deser.SuperSonicBeanDeserializer.deserializeFromObject(SuperSonicBeanDeserializer.java:295)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:194)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:161)
	at com.fasterxml.jackson.module.afterburner.deser.SuperSonicBeanDeserializer.deserialize(SuperSonicBeanDeserializer.java:116)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer._deserializeTypedForId(AsPropertyTypeDeserializer.java:130)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromObject(AsPropertyTypeDeserializer.java:97)
	at com.fasterxml.jackson.databind.deser.AbstractDeserializer.deserializeWithType(AbstractDeserializer.java:254)
	at com.fasterxml.jackson.databind.deser.impl.MethodProperty.deserializeAndSet(MethodProperty.java:138)
	at com.fasterxml.jackson.module.afterburner.deser.SuperSonicBeanDeserializer.deserializeFromObject(SuperSonicBeanDeserializer.java:278)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:194)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:161)
	at com.fasterxml.jackson.module.afterburner.deser.SuperSonicBeanDeserializer.deserialize(SuperSonicBeanDeserializer.java:116)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer._deserializeTypedForId(AsPropertyTypeDeserializer.java:130)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromObject(AsPropertyTypeDeserializer.java:97)
	at com.fasterxml.jackson.databind.deser.AbstractDeserializer.deserializeWithType(AbstractDeserializer.java:254)
	at com.fasterxml.jackson.databind.deser.impl.TypeWrappedDeserializer.deserialize(TypeWrappedDeserializer.java:68)
	at com.fasterxml.jackson.databind.ObjectReader._bind(ObjectReader.java:1682)
	at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:977)
	at com.fasterxml.jackson.jaxrs.base.ProviderBase.readFrom(ProviderBase.java:814)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.invokeReadFrom(ReaderInterceptorExecutor.java:233)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.aroundReadFrom(ReaderInterceptorExecutor.java:212)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundReadFrom(MappableExceptionWrapperInterceptor.java:49)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.message.internal.MessageBodyFactory.readFrom(MessageBodyFactory.java:1072)
	at org.glassfish.jersey.message.internal.InboundMessageContext.readEntity(InboundMessageContext.java:885)
	at org.glassfish.jersey.server.ContainerRequest.readEntity(ContainerRequest.java:282)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:73)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:56)
	at org.glassfish.jersey.server.spi.internal.ParamValueFactoryWithSource.apply(ParamValueFactoryWithSource.java:50)
	at org.glassfish.jersey.server.spi.internal.ParameterValueHelper.getParameterValues(ParameterValueHelper.java:68)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$AbstractMethodParamInvoker.getParamValues(JavaResourceMethodDispatcherProvider.java:109)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
	at io.dropwizard.servlets.ThreadNameFilter.doFilter(ThreadNameFilter.java:35)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
	at io.dropwizard.jersey.filter.AllowedMethodsFilter.handle(AllowedMethodsFilter.java:47)
	at io.dropwizard.jersey.filter.AllowedMethodsFilter.doFilter(AllowedMethodsFilter.java:41)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:313)
	at io.dropwizard.jetty.RoutingHandler.handle(RoutingHandler.java:52)
	at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:713)
	at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:54)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:179)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.lang.RuntimeException: Error while resolving entry ConceptUpdateAndDeletionTest.test_tree.test_column of type class com.bakdata.conquery.models.datasets.concepts.Connector
	at com.bakdata.conquery.io.jackson.serializer.NsIdReferenceDeserializer.deserialize(NsIdReferenceDeserializer.java:65)
	at com.bakdata.conquery.io.jackson.serializer.NsIdReferenceDeserializer.deserialize(NsIdReferenceDeserializer.java:26)
	at com.fasterxml.jackson.databind.deser.impl.MethodProperty.deserializeAndSet(MethodProperty.java:129)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:252)
	... 96 common frames omitted
Caused by: com.bakdata.conquery.io.jackson.serializer.IdReferenceResolvingException: Could not find entry `ConceptUpdateAndDeletionTest.test_tree.test_column` of type com.bakdata.conquery.models.datasets.concepts.Connector
 at [Source: (org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$UnCloseableInputStream); line: 1, column: 123]
	at com.bakdata.conquery.io.jackson.serializer.NsIdReferenceDeserializer.deserialize(NsIdReferenceDeserializer.java:55)
	... 99 common frames omitted
127.0.0.1 - - [26/Jan/2023:18:08:27 +0000] "POST /api/datasets/ConceptUpdateAndDeletionTest/queries HTTP/1.1" 400 208 "-" "Conquery (test client)" 18
[INFO] [2023-01-26 18:08:27]	c.b.c.m.j.JobExecutor		Closing Job Manager fast shard-node1
[INFO] [2023-01-26 18:08:27]	c.b.c.m.j.JobExecutor		Closing Job Manager slow shard-node1
[INFO] [2023-01-26 18:08:27]	c.b.c.m.j.JobExecutor		Closing Job Manager fast worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b
[INFO] [2023-01-26 18:08:28]	c.b.c.m.j.JobExecutor		Closing Job Manager slow worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:DATASET}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:SECONDARY_IDS}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:TABLES}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:DICTIONARIES_META}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:DICTIONARIES_DATA}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:IMPORTS}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:CONCEPTS}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:WORKER}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:BUCKETS}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:C_BLOCKS}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b
[INFO] [2023-01-26 18:08:28]	c.b.c.c.ShardNode		Connection was closed by ManagerNode
[INFO] [2023-01-26 18:08:28]	c.b.c.c.ShardNode	0.0.0.0/0.0.0.0:49840	Disconnected from ManagerNode
[INFO] [2023-01-26 18:08:28]	c.b.c.c.ManagerNode	ManagerNode[0.0.0.0/0.0.0.0:34233]	Client 'null' disconnected 
[INFO] [2023-01-26 18:08:28]	c.b.c.m.j.JobExecutor		Closing Job Manager fast shard-node0
[INFO] [2023-01-26 18:08:28]	c.b.c.m.j.JobExecutor		Closing Job Manager slow shard-node0
[INFO] [2023-01-26 18:08:28]	c.b.c.m.j.JobExecutor		Closing Job Manager fast worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9
[INFO] [2023-01-26 18:08:28]	c.b.c.m.j.JobExecutor		Closing Job Manager slow worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:DATASET}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:SECONDARY_IDS}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:TABLES}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:DICTIONARIES_META}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:DICTIONARIES_DATA}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:IMPORTS}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:CONCEPTS}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:WORKER}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:BUCKETS}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:C_BLOCKS}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9
[INFO] [2023-01-26 18:08:28]	c.b.c.c.ShardNode		Connection was closed by ManagerNode
[INFO] [2023-01-26 18:08:28]	c.b.c.c.ShardNode	0.0.0.0/0.0.0.0:49838	Disconnected from ManagerNode
[INFO] [2023-01-26 18:08:28]	c.b.c.m.j.JobExecutor		Closing Job Manager fast ManagerNode
[INFO] [2023-01-26 18:08:28]	c.b.c.c.ManagerNode	ManagerNode[0.0.0.0/0.0.0.0:34233]	Client 'null' disconnected 
[INFO] [2023-01-26 18:08:28]	c.b.c.m.j.JobExecutor		Closing Job Manager slow ManagerNode
[INFO] [2023-01-26 18:08:28]	c.b.c.m.j.JobExecutor		Closing Job Manager fast ConceptUpdateAndDeletionTest
[INFO] [2023-01-26 18:08:28]	c.b.c.m.j.JobExecutor		Closing Job Manager slow ConceptUpdateAndDeletionTest
[INFO] [2023-01-26 18:08:28]	c.b.c.m.w.Namespace		Closing namespace storage of ConceptUpdateAndDeletionTest
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:DATASET}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:SECONDARY_IDS}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:TABLES}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:DICTIONARIES_META}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:DICTIONARIES_DATA}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:IMPORTS}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:CONCEPTS}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:ID_MAPPING_META}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:ID_MAPPING_DATA}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:STRUCTURE}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:WORKER_TO_BUCKETS}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:PRIMARY_DICTIONARY}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/executions:EXECUTIONS}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/executions
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/formConfigs:FORM_CONFIG}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/formConfigs
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/users:AUTH_USER}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/users
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/roles:AUTH_ROLE}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/roles
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/groups:AUTH_GROUP}
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/groups
[INFO] [2023-01-26 18:08:28]	c.b.c.u.s.TestConquery		Working in temporary directory /tmp/conqueryIntegrationTest12910953884258704183
[DEBUG] [2023-01-26 18:08:28]	c.b.c.c.StandaloneCommand	ManagerNode	Starting ManagerNode
[DEBUG] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:DATASET}): 1 entries, 83 B within 260.5 μs
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:SECONDARY_IDS}): 0 entries, 0 B within 49.12 μs
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest	While processing store TABLES:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:TABLES}): 1 entries, 183 B within 257.7 μs
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest	While processing store DICTIONARIES_META:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest		loaded store cached big DICTIONARIES(Dictionary): 1 entries, 43 B within 1.049 ms
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest	While processing store IMPORTS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:IMPORTS}): 1 entries, 553 B within 5.373 ms
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:CONCEPTS}): 0 entries, 0 B within 53.00 μs
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest	Done reading Dataset[label=ConceptUpdateAndDeletionTest, name=ConceptUpdateAndDeletionTest] / com.bakdata.conquery.io.storage.NamespaceStorage
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest	While processing store ID_MAPPING_META:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest		loaded store cached big ID_MAPPING(EntityIdMap): 1 entries, 43 B within 359.8 μs
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest	While processing store STRUCTURE:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:STRUCTURE}): 0 entries, 0 B within 37.10 μs
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest	While processing store WORKER_TO_BUCKETS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:WORKER_TO_BUCKETS}): 1 entries, 328 B within 157.3 μs
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest	While processing store PRIMARY_DICTIONARY:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest:PRIMARY_DICTIONARY}): 1 entries, 114 B within 655.4 μs
[DEBUG] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest	DONE reading Storage
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory	ManagerNode	All WorkerStores loaded: [NamespacedStorage(pathName=dataset_ConceptUpdateAndDeletionTest)]
[INFO] [2023-01-26 18:08:28]	c.b.c.c.ManagerNode	ManagerNode	Opening MetaStorage
[INFO] [2023-01-26 18:08:28]	c.b.c.c.ManagerNode	ManagerNode	Loading MetaStorage
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store AUTH_USER:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/users:AUTH_USER}): 1 entries, 149 B within 775.3 μs
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store AUTH_ROLE:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/roles:AUTH_ROLE}): 0 entries, 0 B within 84.42 μs
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store AUTH_GROUP:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/groups:AUTH_GROUP}): 0 entries, 0 B within 52.05 μs
[WARN] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	Could not parse value for key [ConceptUpdateAndDeletionTest.1f38796f-d54f-4759-8a56-c84f49f054bd]
[WARN] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	Could not parse value for key [ConceptUpdateAndDeletionTest.3f1e88aa-8fe5-420d-86af-fb22f83b2288]
[WARN] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	Could not parse value for key [ConceptUpdateAndDeletionTest.43697a3a-0c52-49b7-a9e3-3e365a7db138]
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store EXECUTIONS:
	Entries processed:	3
	Key read failure:	0 (0.00%)
	Value read failure:	3 (100.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/executions:EXECUTIONS}): 0 entries, 0 B within 14.59 ms
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store FORM_CONFIG:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/formConfigs:FORM_CONFIG}): 0 entries, 0 B within 98.39 μs
[INFO] [2023-01-26 18:08:28]	c.b.c.c.ManagerNode	ManagerNode	MetaStorage loaded com.bakdata.conquery.io.storage.MetaStorage@2b48c44b
[DEBUG] [2023-01-26 18:08:28]	c.b.c.m.a.AuthorizationController	ManagerNode	Security manager registered
[WARN] [2023-01-26 18:08:28]	c.b.c.m.a.d.DefaultInitialUserRealm	ManagerNode	
           §§
          §  §
         §    §
        §      §
       §  §§§§  §       You instantiated and are probably using a Shiro realm
      §   §§§§   §      that does not do any permission checks or authentication.
     §     §§     §     Access to all resources is granted to everyone.
    §      §§      §    DO NOT USE THIS REALM IN PRODUCTION
   $                §
  §        §§        §
 §                    §
 §§§§§§§§§§§§§§§§§§§§§§
[INFO] [2023-01-26 18:08:28]	c.b.c.m.a.AuthorizationController	ManagerNode	Registering the following realms to Shiro:
	com.bakdata.conquery.models.auth.conquerytoken.ConqueryTokenRealm_21
	com.bakdata.conquery.models.auth.ConqueryAuthorizationRealm_22
	com.bakdata.conquery.models.auth.develop.DefaultInitialUserRealm_23
[INFO] [2023-01-26 18:08:28]	c.b.c.c.ManagerNode	ManagerNode	Registering ResourcesProvider
[INFO] [2023-01-26 18:08:28]	c.b.c.m.f.f.FormScanner	ManagerNode	Form[EXPORT_FORM] from `Resource com/bakdata/conquery/frontend/forms/export_form.frontend_conf.json` of Type[com.bakdata.conquery.apiv1.forms.export_form.ExportForm]
[INFO] [2023-01-26 18:08:28]	c.b.c.m.f.f.FormScanner	ManagerNode	Form[FULL_EXPORT_FORM] from `Resource com/bakdata/conquery/frontend/forms/table_export_form.frontend_conf.json` of Type[com.bakdata.conquery.apiv1.forms.export_form.FullExportForm]
[DEBUG] [2023-01-26 18:08:28]	c.b.c.c.StandaloneCommand	ManagerNode	Waiting for ShardNodes to start
[DEBUG] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:DATASET}): 1 entries, 83 B within 194.5 μs
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:SECONDARY_IDS}): 0 entries, 0 B within 42.06 μs
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9	While processing store TABLES:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:TABLES}): 1 entries, 183 B within 208.2 μs
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9	While processing store DICTIONARIES_META:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9		loaded store cached big DICTIONARIES(Dictionary): 1 entries, 43 B within 849.2 μs
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9	While processing store IMPORTS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:IMPORTS}): 1 entries, 553 B within 21.90 ms
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:CONCEPTS}): 0 entries, 0 B within 56.80 μs
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9	Done reading Dataset[label=ConceptUpdateAndDeletionTest, name=ConceptUpdateAndDeletionTest] / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9	While processing store WORKER:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:WORKER}): 1 entries, 159 B within 122.6 μs
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9	While processing store BUCKETS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:BUCKETS}): 1 entries, 410 B within 2.110 ms
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9:C_BLOCKS}): 0 entries, 0 B within 38.92 μs
[DEBUG] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9	DONE reading Storage
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory	shard-node0	All WorkerStores loaded: [WorkerStorage(worker=NamedImpl(name=worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9))]
[DEBUG] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:DATASET}): 1 entries, 83 B within 150.2 μs
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:SECONDARY_IDS}): 0 entries, 0 B within 27.12 μs
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b	While processing store TABLES:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:TABLES}): 1 entries, 183 B within 151.5 μs
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b	While processing store DICTIONARIES_META:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b		loaded store cached big DICTIONARIES(Dictionary): 1 entries, 43 B within 763.3 μs
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b	While processing store IMPORTS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:IMPORTS}): 1 entries, 553 B within 3.530 ms
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:CONCEPTS}): 0 entries, 0 B within 35.45 μs
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b	Done reading Dataset[label=ConceptUpdateAndDeletionTest, name=ConceptUpdateAndDeletionTest] / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b	While processing store WORKER:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:WORKER}): 1 entries, 159 B within 266.8 μs
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b	While processing store BUCKETS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:BUCKETS}): 1 entries, 398 B within 2.020 ms
[DEBUG] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:28]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b:C_BLOCKS}): 0 entries, 0 B within 37.01 μs
[DEBUG] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b	DONE reading Storage
[INFO] [2023-01-26 18:08:28]	c.b.c.m.c.XodusStoreFactory	shard-node1	All WorkerStores loaded: [WorkerStorage(worker=NamedImpl(name=worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b))]
[INFO] [2023-01-26 18:08:28]	c.b.c.c.ShardNode	shard-node0	All Worker Storages loaded: 1
[INFO] [2023-01-26 18:08:28]	c.b.c.c.ShardNode	shard-node1	All Worker Storages loaded: 1
[DEBUG] [2023-01-26 18:08:28]	c.b.c.c.StandaloneCommand	ManagerNode	Starting REST Server
[INFO] [2023-01-26 18:08:28]	c.b.c.c.ManagerNode		Started ManagerNode @ /0:0:0:0:0:0:0:0:34233
[INFO] [2023-01-26 18:08:28]	c.b.c.c.ShardNode		Trying to connect to /127.0.0.1:34233
[INFO] [2023-01-26 18:08:28]	c.b.c.c.ManagerNode	ManagerNode[/127.0.0.1:34233]	New client /127.0.0.1:49982 connected, waiting for identity
[INFO] [2023-01-26 18:08:28]	c.b.c.c.ShardNode	/127.0.0.1:49982	Connected to ManagerNode @ /127.0.0.1:34233
[INFO] [2023-01-26 18:08:28]	c.b.c.c.ShardNode		Trying to connect to /127.0.0.1:34233
[INFO] [2023-01-26 18:08:28]	c.b.c.c.ShardNode	/127.0.0.1:49982	Sending worker identity 'worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9'
[INFO] [2023-01-26 18:08:28]	c.b.c.c.ManagerNode	ManagerNode[/127.0.0.1:34233]	New client /127.0.0.1:49984 connected, waiting for identity
[INFO] [2023-01-26 18:08:28]	c.b.c.c.ShardNode	/127.0.0.1:49984	Connected to ManagerNode @ /127.0.0.1:34233
[INFO] [2023-01-26 18:08:28]	c.b.c.c.ShardNode	/127.0.0.1:49984	Sending worker identity 'worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b'
[INFO] [2023-01-26 18:08:28]	c.b.c.m.m.n.s.AddShardNode	Job Manager fast ManagerNode	ShardNode `/127.0.0.1:49982` registered.
[INFO] [2023-01-26 18:08:28]	c.b.c.m.m.n.s.AddShardNode	Job Manager fast ManagerNode	ShardNode `/127.0.0.1:49984` registered.
[INFO] [2023-01-26 18:08:28]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=ConceptUpdateAndDeletionTest, name=ConceptUpdateAndDeletionTest]	Imports of worker ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9 are consistent with the manager: 1 Imports
[INFO] [2023-01-26 18:08:28]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=ConceptUpdateAndDeletionTest, name=ConceptUpdateAndDeletionTest]	Buckets of worker ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9 are consistent with the manager: 1 Buckets
[INFO] [2023-01-26 18:08:28]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=ConceptUpdateAndDeletionTest, name=ConceptUpdateAndDeletionTest]	Consistency check was successful
[INFO] [2023-01-26 18:08:28]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=ConceptUpdateAndDeletionTest, name=ConceptUpdateAndDeletionTest]	Imports of worker ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b are consistent with the manager: 1 Imports
[INFO] [2023-01-26 18:08:28]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=ConceptUpdateAndDeletionTest, name=ConceptUpdateAndDeletionTest]	Buckets of worker ConceptUpdateAndDeletionTest.worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b are consistent with the manager: 1 Buckets
[INFO] [2023-01-26 18:08:28]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=ConceptUpdateAndDeletionTest, name=ConceptUpdateAndDeletionTest]	Consistency check was successful
[WARN] [2023-01-26 18:08:29]	o.g.j.i.Errors		The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.filters.Filter<?> from public void com.bakdata.conquery.resources.hierarchies.HFilters.setFilter(com.bakdata.conquery.models.datasets.concepts.filters.Filter<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public com.bakdata.conquery.apiv1.FullExecutionStatus com.bakdata.conquery.resources.api.QueryResource.getStatus(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) throws java.lang.InterruptedException is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public com.bakdata.conquery.apiv1.FullExecutionStatus com.bakdata.conquery.resources.api.QueryResource.patchQuery(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>,com.bakdata.conquery.apiv1.MetaDataPatch) throws com.bakdata.conquery.models.exceptions.JSONException is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public void com.bakdata.conquery.resources.api.QueryResource.deleteQuery(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>) is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public void com.bakdata.conquery.resources.api.QueryResource.cancel(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>) is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public com.bakdata.conquery.apiv1.FullExecutionStatus com.bakdata.conquery.resources.api.QueryResource.reexecute(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultExcelResource.get(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.identifiable.ids.specific.DatasetId,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultArrowStreamResource.get(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.datasets.Dataset,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultCsvResource.getAsCsv(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.datasets.Dataset,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.lang.String,java.lang.String,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultArrowFileResource.get(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.datasets.Dataset,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.filters.Filter<?> from public void com.bakdata.conquery.resources.hierarchies.HFilters.setFilter(com.bakdata.conquery.models.datasets.concepts.filters.Filter<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.

[WARN] [2023-01-26 18:08:29]	i.d.s.AdminEnvironment		
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!    THIS APPLICATION HAS NO HEALTHCHECKS. THIS MEANS YOU WILL NEVER KNOW      !
!     IF IT DIES IN PRODUCTION, WHICH MEANS YOU WILL NEVER KNOW IF YOU'RE      !
!    LETTING YOUR USERS DOWN. YOU SHOULD ADD A HEALTHCHECK FOR EACH OF YOUR    !
!         APPLICATION'S DEPENDENCIES WHICH FULLY (BUT LIGHTLY) TESTS IT.       !
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
[WARN] [2023-01-26 18:08:29]	o.g.j.i.Errors		The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.auth.entities.PermissionOwner<?> from public void com.bakdata.conquery.resources.hierarchies.HPermissions.setOwner(com.bakdata.conquery.models.auth.entities.PermissionOwner<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.auth.entities.PermissionOwner<?> from public void com.bakdata.conquery.resources.hierarchies.HPermissions.setOwner(com.bakdata.conquery.models.auth.entities.PermissionOwner<?>) is not resolvable to a concrete type.

[WARN] [2023-01-26 18:08:29]	o.g.j.i.Errors		The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter concept of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from protected com.bakdata.conquery.models.datasets.concepts.Concept<?> com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.concept is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter concept of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from protected com.bakdata.conquery.models.datasets.concepts.Concept<?> com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.concept is not resolvable to a concrete type.

[INFO] [2023-01-26 18:08:29]	c.b.c.u.s.TestConquery		loading dataset
[INFO] [2023-01-26 18:08:29]	c.b.c.u.s.TestConquery		Reusing existing folder /tmp/conqueryIntegrationTest12910953884258704183/tmp_ConceptUpdateAndDeletionTest for Support
[INFO] [2023-01-26 18:08:29]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[INFO] [2023-01-26 18:08:29]	c.b.c.i.t.d.ConceptUpdateAndDeletionTest		Checking state after restart
[INFO] [2023-01-26 18:08:29]	c.b.c.i.t.d.ConceptUpdateAndDeletionTest		Executing query after restart (EXPECTING AN EXCEPTION IN THE LOGS!)
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.j.ConqueryJsonExceptionMapper	user.SUPERUSER@SUPERUSER	Unable to process JSON in request 'http://localhost:39407/api/datasets/ConceptUpdateAndDeletionTest/queries'
com.fasterxml.jackson.databind.JsonMappingException: Error while resolving entry ConceptUpdateAndDeletionTest.test_tree.test_column of type class com.bakdata.conquery.models.datasets.concepts.Connector (through reference chain: com.bakdata.conquery.apiv1.query.ConceptQuery["root"]->com.bakdata.conquery.apiv1.query.concept.specific.CQConcept["tables"]->java.util.ArrayList[0]->com.bakdata.conquery.apiv1.query.concept.filter.CQTable["id"])
	at com.fasterxml.jackson.databind.JsonMappingException.wrapWithPath(JsonMappingException.java:397)
	at com.fasterxml.jackson.databind.JsonMappingException.wrapWithPath(JsonMappingException.java:356)
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.wrapAndThrow(BeanDeserializerBase.java:1719)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:254)
	at com.fasterxml.jackson.module.afterburner.deser.SuperSonicBeanDeserializer.deserialize(SuperSonicBeanDeserializer.java:155)
	at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:286)
	at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:245)
	at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:27)
	at com.fasterxml.jackson.databind.deser.SettableBeanProperty.deserialize(SettableBeanProperty.java:530)
	at com.fasterxml.jackson.databind.deser.impl.ManagedReferenceProperty.deserializeAndSet(ManagedReferenceProperty.java:62)
	at com.fasterxml.jackson.module.afterburner.deser.SuperSonicBeanDeserializer.deserializeFromObject(SuperSonicBeanDeserializer.java:295)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:194)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:161)
	at com.fasterxml.jackson.module.afterburner.deser.SuperSonicBeanDeserializer.deserialize(SuperSonicBeanDeserializer.java:116)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer._deserializeTypedForId(AsPropertyTypeDeserializer.java:130)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromObject(AsPropertyTypeDeserializer.java:97)
	at com.fasterxml.jackson.databind.deser.AbstractDeserializer.deserializeWithType(AbstractDeserializer.java:254)
	at com.fasterxml.jackson.databind.deser.impl.MethodProperty.deserializeAndSet(MethodProperty.java:138)
	at com.fasterxml.jackson.module.afterburner.deser.SuperSonicBeanDeserializer.deserializeFromObject(SuperSonicBeanDeserializer.java:278)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:194)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:161)
	at com.fasterxml.jackson.module.afterburner.deser.SuperSonicBeanDeserializer.deserialize(SuperSonicBeanDeserializer.java:116)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer._deserializeTypedForId(AsPropertyTypeDeserializer.java:130)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromObject(AsPropertyTypeDeserializer.java:97)
	at com.fasterxml.jackson.databind.deser.AbstractDeserializer.deserializeWithType(AbstractDeserializer.java:254)
	at com.fasterxml.jackson.databind.deser.impl.TypeWrappedDeserializer.deserialize(TypeWrappedDeserializer.java:68)
	at com.fasterxml.jackson.databind.ObjectReader._bind(ObjectReader.java:1682)
	at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:977)
	at com.fasterxml.jackson.jaxrs.base.ProviderBase.readFrom(ProviderBase.java:814)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.invokeReadFrom(ReaderInterceptorExecutor.java:233)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.aroundReadFrom(ReaderInterceptorExecutor.java:212)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundReadFrom(MappableExceptionWrapperInterceptor.java:49)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.message.internal.MessageBodyFactory.readFrom(MessageBodyFactory.java:1072)
	at org.glassfish.jersey.message.internal.InboundMessageContext.readEntity(InboundMessageContext.java:885)
	at org.glassfish.jersey.server.ContainerRequest.readEntity(ContainerRequest.java:282)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:73)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:56)
	at org.glassfish.jersey.server.spi.internal.ParamValueFactoryWithSource.apply(ParamValueFactoryWithSource.java:50)
	at org.glassfish.jersey.server.spi.internal.ParameterValueHelper.getParameterValues(ParameterValueHelper.java:68)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$AbstractMethodParamInvoker.getParamValues(JavaResourceMethodDispatcherProvider.java:109)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
	at io.dropwizard.servlets.ThreadNameFilter.doFilter(ThreadNameFilter.java:35)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
	at io.dropwizard.jersey.filter.AllowedMethodsFilter.handle(AllowedMethodsFilter.java:47)
	at io.dropwizard.jersey.filter.AllowedMethodsFilter.doFilter(AllowedMethodsFilter.java:41)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:313)
	at io.dropwizard.jetty.RoutingHandler.handle(RoutingHandler.java:52)
	at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:713)
	at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:54)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:179)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.lang.RuntimeException: Error while resolving entry ConceptUpdateAndDeletionTest.test_tree.test_column of type class com.bakdata.conquery.models.datasets.concepts.Connector
	at com.bakdata.conquery.io.jackson.serializer.NsIdReferenceDeserializer.deserialize(NsIdReferenceDeserializer.java:65)
	at com.bakdata.conquery.io.jackson.serializer.NsIdReferenceDeserializer.deserialize(NsIdReferenceDeserializer.java:26)
	at com.fasterxml.jackson.databind.deser.impl.MethodProperty.deserializeAndSet(MethodProperty.java:129)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:252)
	... 92 common frames omitted
Caused by: com.bakdata.conquery.io.jackson.serializer.IdReferenceResolvingException: Could not find entry `ConceptUpdateAndDeletionTest.test_tree.test_column` of type com.bakdata.conquery.models.datasets.concepts.Connector
 at [Source: (org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$UnCloseableInputStream); line: 1, column: 123]
	at com.bakdata.conquery.io.jackson.serializer.NsIdReferenceDeserializer.deserialize(NsIdReferenceDeserializer.java:55)
	... 95 common frames omitted
127.0.0.1 - - [26/Jan/2023:18:08:29 +0000] "POST /api/datasets/ConceptUpdateAndDeletionTest/queries HTTP/1.1" 400 208 "-" "Conquery (test client)" 8
[INFO] [2023-01-26 18:08:29]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node1	removing worker for Dataset[label=ConceptUpdateAndDeletionTest, name=ConceptUpdateAndDeletionTest]
[INFO] [2023-01-26 18:08:29]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager fast worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b
[INFO] [2023-01-26 18:08:29]	c.b.c.m.j.JobExecutor		Closing Job Manager fast ConceptUpdateAndDeletionTest
[INFO] [2023-01-26 18:08:29]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node0	removing worker for Dataset[label=ConceptUpdateAndDeletionTest, name=ConceptUpdateAndDeletionTest]
[INFO] [2023-01-26 18:08:29]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager fast worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9
[INFO] [2023-01-26 18:08:29]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager slow worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9
[INFO] [2023-01-26 18:08:29]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager slow worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9
[INFO] [2023-01-26 18:08:29]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node0	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ConceptUpdateAndDeletionTest_26390e1e-8e5a-4e2a-817e-1ac9be1f4bf9
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b
[INFO] [2023-01-26 18:08:29]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node1	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ConceptUpdateAndDeletionTest_1f3968a4-86c6-423e-bac8-326cecedbb1b
[INFO] [2023-01-26 18:08:29]	c.b.c.m.j.JobExecutor		Closing Job Manager slow ConceptUpdateAndDeletionTest
[INFO] [2023-01-26 18:08:29]	c.b.c.m.w.Namespace		Removing namespace storage of ConceptUpdateAndDeletionTest
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore		Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore		Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore		Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore		Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore		Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore		Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore		Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore		Deleting store ID_MAPPING_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore		Deleting store ID_MAPPING_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore		Deleting store STRUCTURE from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore		Deleting store WORKER_TO_BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.XodusStore		Deleting store PRIMARY_DICTIONARY from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest
[INFO] [2023-01-26 18:08:29]	c.b.c.m.c.XodusStoreFactory		Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ConceptUpdateAndDeletionTest
[INFO] [2023-01-26 18:08:29]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[INFO] [2023-01-26 18:08:29]	c.b.c.i.IntegrationTest$Wrapper	ConceptUpdateAndDeletionTest	SUCCESS integration test ConceptUpdateAndDeletionTest
[INFO] [2023-01-26 18:08:29]	c.b.c.i.IntegrationTest$Wrapper	DatasetDeletionTest	STARTING integration test DatasetDeletionTest
[INFO] [2023-01-26 18:08:29]	c.b.c.u.s.TestConquery	DatasetDeletionTest	Setting up dataset
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.SerializingStore	DatasetDeletionTest	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.CachedStore	DatasetDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest:DATASET}): 0 entries, 0 B within 116.1 μs
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.SerializingStore	DatasetDeletionTest	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.CachedStore	DatasetDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest:SECONDARY_IDS}): 0 entries, 0 B within 62.26 μs
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.SerializingStore	DatasetDeletionTest	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.CachedStore	DatasetDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest:TABLES}): 0 entries, 0 B within 52.08 μs
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.SerializingStore	DatasetDeletionTest	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.CachedStore	DatasetDeletionTest		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 56.33 μs
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.SerializingStore	DatasetDeletionTest	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.CachedStore	DatasetDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest:IMPORTS}): 0 entries, 0 B within 47.48 μs
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.SerializingStore	DatasetDeletionTest	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.CachedStore	DatasetDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest:CONCEPTS}): 0 entries, 0 B within 78.62 μs
[INFO] [2023-01-26 18:08:29]	c.b.c.i.s.NamespacedStorage	DatasetDeletionTest	Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.SerializingStore	DatasetDeletionTest	While processing store ID_MAPPING_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.CachedStore	DatasetDeletionTest		loaded store cached big ID_MAPPING(EntityIdMap): 0 entries, 0 B within 53.32 μs
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.SerializingStore	DatasetDeletionTest	While processing store STRUCTURE:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.CachedStore	DatasetDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest:STRUCTURE}): 0 entries, 0 B within 47.28 μs
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.SerializingStore	DatasetDeletionTest	While processing store WORKER_TO_BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.CachedStore	DatasetDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest:WORKER_TO_BUCKETS}): 0 entries, 0 B within 47.12 μs
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.SerializingStore	DatasetDeletionTest	While processing store PRIMARY_DICTIONARY:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.CachedStore	DatasetDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest:PRIMARY_DICTIONARY}): 0 entries, 0 B within 55.75 μs
[INFO] [2023-01-26 18:08:29]	c.b.c.m.m.n.s.AddWorker	Job Manager slow shard-node0	creating a new worker for Dataset[label=DatasetDeletionTest, name=DatasetDeletionTest]
[INFO] [2023-01-26 18:08:29]	c.b.c.m.m.n.s.AddWorker	Job Manager slow shard-node1	creating a new worker for Dataset[label=DatasetDeletionTest, name=DatasetDeletionTest]
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e:DATASET}): 0 entries, 0 B within 111.1 μs
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e:SECONDARY_IDS}): 0 entries, 0 B within 37.51 μs
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e:TABLES}): 0 entries, 0 B within 34.42 μs
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 33.62 μs
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e:IMPORTS}): 0 entries, 0 B within 30.39 μs
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e:CONCEPTS}): 0 entries, 0 B within 27.49 μs
[INFO] [2023-01-26 18:08:29]	c.b.c.i.s.NamespacedStorage	Job Manager slow shard-node1	Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store WORKER:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e:WORKER}): 0 entries, 0 B within 32.70 μs
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e:BUCKETS}): 0 entries, 0 B within 27.47 μs
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e:C_BLOCKS}): 0 entries, 0 B within 31.92 μs
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9:DATASET}): 0 entries, 0 B within 79.47 μs
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9:SECONDARY_IDS}): 0 entries, 0 B within 40.52 μs
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9:TABLES}): 0 entries, 0 B within 27.86 μs
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 55.32 μs
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9:IMPORTS}): 0 entries, 0 B within 40.53 μs
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9:CONCEPTS}): 0 entries, 0 B within 40.30 μs
[INFO] [2023-01-26 18:08:29]	c.b.c.i.s.NamespacedStorage	Job Manager slow shard-node0	Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store WORKER:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9:WORKER}): 0 entries, 0 B within 46.42 μs
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9:BUCKETS}): 0 entries, 0 B within 37.34 μs
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:29]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9:C_BLOCKS}): 0 entries, 0 B within 36.61 μs
[INFO] [2023-01-26 18:08:29]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=DatasetDeletionTest]	Imports of worker DatasetDeletionTest.worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:29]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=DatasetDeletionTest]	Buckets of worker DatasetDeletionTest.worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:29]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=DatasetDeletionTest]	Consistency check was successful
[INFO] [2023-01-26 18:08:29]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=DatasetDeletionTest]	Imports of worker DatasetDeletionTest.worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9 are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:29]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=DatasetDeletionTest]	Buckets of worker DatasetDeletionTest.worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9 are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:29]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=DatasetDeletionTest]	Consistency check was successful
[INFO] [2023-01-26 18:08:29]	c.b.c.u.s.TestConquery	DatasetDeletionTest	Waiting for jobs to finish
[INFO] [2023-01-26 18:08:29]	c.b.c.u.s.TestConquery	DatasetDeletionTest	Waiting for jobs to finish
[INFO] [2023-01-26 18:08:29]	c.b.c.u.s.TestConquery	DatasetDeletionTest	Waiting for jobs to finish
[INFO] [2023-01-26 18:08:29]	c.b.c.m.m.n.s.UpdateTable	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e, /127.0.0.1:49984]	Received update of Table DatasetDeletionTest.test_table
[INFO] [2023-01-26 18:08:29]	c.b.c.m.m.n.s.UpdateTable	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e, /127.0.0.1:49984]	Received update of Table DatasetDeletionTest.test_table2
[INFO] [2023-01-26 18:08:29]	c.b.c.m.m.n.s.UpdateTable	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9, /127.0.0.1:49982]	Received update of Table DatasetDeletionTest.test_table
[INFO] [2023-01-26 18:08:29]	c.b.c.m.m.n.s.UpdateTable	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9, /127.0.0.1:49982]	Received update of Table DatasetDeletionTest.test_table2
[INFO] [2023-01-26 18:08:29]	c.b.c.u.s.TestConquery	DatasetDeletionTest	Waiting for jobs to finish
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.WorkerStorage	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9, /127.0.0.1:49982]	Updating Concept[DatasetDeletionTest.test_tree]
[DEBUG] [2023-01-26 18:08:29]	c.b.c.i.s.WorkerStorage	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e, /127.0.0.1:49984]	Updating Concept[DatasetDeletionTest.test_tree]
[INFO] [2023-01-26 18:08:29]	c.b.c.c.PreprocessorCommand	DatasetDeletionTest	Preprocessing from command line config.
[INFO] [2023-01-26 18:08:29]	c.b.c.c.PreprocessorCommand	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_DatasetDeletionTest/test_table.import.json, tag=Optional.empty)	DOES NOT EXIST
[INFO] [2023-01-26 18:08:29]	c.b.c.c.PreprocessorCommand	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_DatasetDeletionTest/test_table2.import.json, tag=Optional.empty)	DOES NOT EXIST
[INFO] [2023-01-26 18:08:29]	c.b.c.c.PreprocessorCommand	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_DatasetDeletionTest/test_table2.import.json, tag=Optional.empty)	Required to preprocess 115 B in total
[INFO] [2023-01-26 18:08:29]	c.b.c.m.p.Preprocessor	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_DatasetDeletionTest/test_table.import.json, tag=Optional.empty)	PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_DatasetDeletionTest/test_table.import.json, tag=Optional.empty)
█████████████████████████                         ▌  50%	est. time remaining: 0.02381416s[INFO] [2023-01-26 18:08:29]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	Statistics = IntSummaryStatistics{count=2, sum=2, min=1, average=1.000000, max=1}
[INFO] [2023-01-26 18:08:29]	c.b.c.m.p.PPColumn		Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=2, nullLines=0), subType=IntegerParser(super=Parser(lines=2, nullLines=0), minValue=15655, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@3efdf2ce)
[DEBUG] [2023-01-26 18:08:29]	c.b.c.m.p.PPColumn			datum: DateParser(super=Parser(lines=2, nullLines=0), subType=IntegerParser(super=Parser(lines=2, nullLines=0), minValue=15655, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@3efdf2ce) -> IntegerDateStore(store=ShortArrayStore())
[INFO] [2023-01-26 18:08:29]	c.b.c.m.p.PPColumn	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=2, nullLines=0), encoding=null, prefix=, suffix=)
[DEBUG] [2023-01-26 18:08:29]	c.b.c.m.p.p.s.StringParser	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]		Chosen encoding is Base16UpperCase
[DEBUG] [2023-01-26 18:08:29]	c.b.c.m.p.p.s.StringParser	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]		Using com.bakdata.conquery.models.preproc.parser.specific.string.TrieTypeGuesser@3fde4486(est. 62 B)
[DEBUG] [2023-01-26 18:08:29]	c.b.c.m.p.PPColumn	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]		test_column: StringParser(super=Parser(lines=2, nullLines=0), encoding=Base16UpperCase, prefix=, suffix=) -> StringTypeEncoded(encoding=Base16UpperCase, subType=StringTypeDictionary(dictionary=SuccinctTrie[size=2], numberType=ByteArrayStore()))
[DEBUG] [2023-01-26 18:08:29]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	Encode primary Dictionary
[DEBUG] [2023-01-26 18:08:29]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	Writing Headers
[DEBUG] [2023-01-26 18:08:29]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	Writing header
[DEBUG] [2023-01-26 18:08:29]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	Writing Dictionaries
[DEBUG] [2023-01-26 18:08:29]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	Writing data
[INFO] [2023-01-26 18:08:29]	c.b.c.m.p.Preprocessor	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_DatasetDeletionTest/test_table.import.json, tag=Optional.empty)
[INFO] [2023-01-26 18:08:29]	c.b.c.m.p.Preprocessor	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_DatasetDeletionTest/test_table2.import.json, tag=Optional.empty)	PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_DatasetDeletionTest/test_table2.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000486844s[INFO] [2023-01-26 18:08:30]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Statistics = IntSummaryStatistics{count=2, sum=2, min=1, average=1.000000, max=1}
[INFO] [2023-01-26 18:08:30]	c.b.c.m.p.PPColumn		Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=2, nullLines=0), subType=IntegerParser(super=Parser(lines=2, nullLines=0), minValue=14805, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@77f60784)
[DEBUG] [2023-01-26 18:08:30]	c.b.c.m.p.PPColumn			datum: DateParser(super=Parser(lines=2, nullLines=0), subType=IntegerParser(super=Parser(lines=2, nullLines=0), minValue=14805, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@77f60784) -> IntegerDateStore(store=ShortArrayStore())
[INFO] [2023-01-26 18:08:30]	c.b.c.m.p.PPColumn	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=2, nullLines=0), encoding=null, prefix=, suffix=)
[DEBUG] [2023-01-26 18:08:30]	c.b.c.m.p.p.s.StringParser	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]		Chosen encoding is Base16UpperCase
[DEBUG] [2023-01-26 18:08:30]	c.b.c.m.p.p.s.StringParser	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]		Using com.bakdata.conquery.models.preproc.parser.specific.string.TrieTypeGuesser@392c4b14(est. 62 B)
[DEBUG] [2023-01-26 18:08:30]	c.b.c.m.p.PPColumn	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]		test_column: StringParser(super=Parser(lines=2, nullLines=0), encoding=Base16UpperCase, prefix=, suffix=) -> StringTypeEncoded(encoding=Base16UpperCase, subType=StringTypeDictionary(dictionary=SuccinctTrie[size=2], numberType=ByteArrayStore()))
[DEBUG] [2023-01-26 18:08:30]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Encode primary Dictionary
[DEBUG] [2023-01-26 18:08:30]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Writing Headers
[DEBUG] [2023-01-26 18:08:30]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Writing header
[DEBUG] [2023-01-26 18:08:30]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Writing Dictionaries
[DEBUG] [2023-01-26 18:08:30]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Writing data
[INFO] [2023-01-26 18:08:30]	c.b.c.m.p.Preprocessor	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_DatasetDeletionTest/test_table2.import.json, tag=Optional.empty)
[INFO] [2023-01-26 18:08:30]	c.b.c.c.PreprocessorCommand		Successfully Preprocess 2 Jobs:
[INFO] [2023-01-26 18:08:30]	c.b.c.c.PreprocessorCommand			Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_DatasetDeletionTest/test_table.import.json, tag=Optional.empty)
[INFO] [2023-01-26 18:08:30]	c.b.c.c.PreprocessorCommand			Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_DatasetDeletionTest/test_table2.import.json, tag=Optional.empty)
[DEBUG] [2023-01-26 18:08:30]	c.b.c.m.j.ImportJob	user.SUPERUSER@SUPERUSER	Done reading data. Contains 2 Entities.
[INFO] [2023-01-26 18:08:30]	c.b.c.m.j.ImportJob	user.SUPERUSER@SUPERUSER	Importing test_table into DatasetDeletionTest.test_table
[DEBUG] [2023-01-26 18:08:30]	c.b.c.m.j.ImportJob	Job Manager slow DatasetDeletionTest	Mapped 2 new ids
[DEBUG] [2023-01-26 18:08:30]	c.b.c.m.j.ImportJob	Job Manager slow DatasetDeletionTest	Updating bucket assignments.
127.0.0.1 - - [26/Jan/2023:18:08:30 +0000] "POST /admin/datasets/DatasetDeletionTest/imports?file=%2Ftmp%2FconqueryIntegrationTest12910953884258704183%2Ftmp_DatasetDeletionTest%2Ftest_table.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 14
[DEBUG] [2023-01-26 18:08:30]	c.b.c.m.w.Namespace	Job Manager slow DatasetDeletionTest	Assigning Bucket[0] to Worker[DatasetDeletionTest.worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9]
[INFO] [2023-01-26 18:08:30]	c.b.c.m.j.ImportJob	Job Manager slow DatasetDeletionTest	Importing Dictionaries
[DEBUG] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.UpdateWorkerBucket	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e, /127.0.0.1:49984]	Received new WorkerInformation(size = 0,dataset = DatasetDeletionTest)
[DEBUG] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.UpdateWorkerBucket	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9, /127.0.0.1:49982]	Received new WorkerInformation(size = 1,dataset = DatasetDeletionTest)
[INFO] [2023-01-26 18:08:30]	c.b.c.m.j.ImportJob	Job Manager slow DatasetDeletionTest	Remapping Dictionaries []
[WARN] [2023-01-26 18:08:30]	c.b.c.u.p.ProgressReporterImpl	Job Manager slow DatasetDeletionTest	Max cannot be decreased.
[DEBUG] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.UpdateDictionary	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e, /127.0.0.1:49984]	Received Dictionary[DatasetDeletionTest.test_table#DatasetDeletionTest$2etest_table$2etest_column] of size 2.
[DEBUG] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.UpdateDictionary	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9, /127.0.0.1:49982]	Received Dictionary[DatasetDeletionTest.test_table#DatasetDeletionTest$2etest_table$2etest_column] of size 2.
[INFO] [2023-01-26 18:08:30]	c.b.c.m.j.ImportJob	Job Manager slow DatasetDeletionTest	Start sending 1 Buckets
[WARN] [2023-01-26 18:08:30]	c.b.c.u.p.ProgressReporterImpl	Job Manager slow DatasetDeletionTest	One or more Children are not done yet
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.AddImport	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e, /127.0.0.1:49984]	Received Import[DatasetDeletionTest.test_table.test_table], containing 2 entries.
[DEBUG] [2023-01-26 18:08:30]	c.b.c.m.j.ImportJob	user.SUPERUSER@SUPERUSER	Done reading data. Contains 2 Entities.
[INFO] [2023-01-26 18:08:30]	c.b.c.m.j.ImportJob	user.SUPERUSER@SUPERUSER	Importing test_table2 into DatasetDeletionTest.test_table2
127.0.0.1 - - [26/Jan/2023:18:08:30 +0000] "POST /admin/datasets/DatasetDeletionTest/imports?file=%2Ftmp%2FconqueryIntegrationTest12910953884258704183%2Ftmp_DatasetDeletionTest%2Ftest_table2.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 18
[INFO] [2023-01-26 18:08:30]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.AddImport	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9, /127.0.0.1:49982]	Received Import[DatasetDeletionTest.test_table.test_table], containing 2 entries.
[DEBUG] [2023-01-26 18:08:30]	c.b.c.m.j.ImportJob	Job Manager slow DatasetDeletionTest	Mapped 2 new ids
[DEBUG] [2023-01-26 18:08:30]	c.b.c.m.j.ImportJob	Job Manager slow DatasetDeletionTest	Updating bucket assignments.
[DEBUG] [2023-01-26 18:08:30]	c.b.c.m.w.Namespace	Job Manager slow DatasetDeletionTest	Assigning Bucket[1] to Worker[DatasetDeletionTest.worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e]
[INFO] [2023-01-26 18:08:30]	c.b.c.m.j.ImportJob	Job Manager slow DatasetDeletionTest	Importing Dictionaries
[DEBUG] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.UpdateWorkerBucket	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9, /127.0.0.1:49982]	Received new WorkerInformation(size = 1,dataset = DatasetDeletionTest)
[DEBUG] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.UpdateWorkerBucket	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e, /127.0.0.1:49984]	Received new WorkerInformation(size = 1,dataset = DatasetDeletionTest)
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.ImportBucket	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9, /127.0.0.1:49982]	Received DatasetDeletionTest.test_table.test_table.0
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.WorkerStorage	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9, /127.0.0.1:49982]	Adding Bucket[DatasetDeletionTest.test_table.test_table.0]
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.WorkerStorage		Adding CBlock[DatasetDeletionTest.test_table.test_table.0.DatasetDeletionTest.test_tree.test_column]
[INFO] [2023-01-26 18:08:30]	c.b.c.m.j.ImportJob	Job Manager slow DatasetDeletionTest	Remapping Dictionaries []
[WARN] [2023-01-26 18:08:30]	c.b.c.u.p.ProgressReporterImpl	Job Manager slow DatasetDeletionTest	Max cannot be decreased.
[DEBUG] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.UpdateDictionary	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e, /127.0.0.1:49984]	Received Dictionary[DatasetDeletionTest.test_table2#DatasetDeletionTest$2etest_table2$2etest_column] of size 2.
[DEBUG] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.UpdateDictionary	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9, /127.0.0.1:49982]	Received Dictionary[DatasetDeletionTest.test_table2#DatasetDeletionTest$2etest_table2$2etest_column] of size 2.
[INFO] [2023-01-26 18:08:30]	c.b.c.m.j.ImportJob	Job Manager slow DatasetDeletionTest	Start sending 2 Buckets
[WARN] [2023-01-26 18:08:30]	c.b.c.u.p.ProgressReporterImpl	Job Manager slow DatasetDeletionTest	One or more Children are not done yet
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.AddImport	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e, /127.0.0.1:49984]	Received Import[DatasetDeletionTest.test_table2.test_table2], containing 2 entries.
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.ImportBucket	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e, /127.0.0.1:49984]	Received DatasetDeletionTest.test_table2.test_table2.1
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.WorkerStorage	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e, /127.0.0.1:49984]	Adding Bucket[DatasetDeletionTest.test_table2.test_table2.1]
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.AddImport	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9, /127.0.0.1:49982]	Received Import[DatasetDeletionTest.test_table2.test_table2], containing 2 entries.
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.ImportBucket	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9, /127.0.0.1:49982]	Received DatasetDeletionTest.test_table2.test_table2.0
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.WorkerStorage	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9, /127.0.0.1:49982]	Adding Bucket[DatasetDeletionTest.test_table2.test_table2.0]
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.WorkerStorage		Adding CBlock[DatasetDeletionTest.test_table2.test_table2.0.DatasetDeletionTest.test_tree.test_column2]
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.WorkerStorage		Adding CBlock[DatasetDeletionTest.test_table2.test_table2.1.DatasetDeletionTest.test_tree.test_column2]
[INFO] [2023-01-26 18:08:30]	c.b.c.i.t.d.DatasetDeletionTest		Checking state before deletion
[INFO] [2023-01-26 18:08:30]	c.b.c.i.t.d.DatasetDeletionTest		Executing query before deletion
[INFO] [2023-01-26 18:08:30]	c.b.c.a.QueryProcessor	user.SUPERUSER@SUPERUSER	Query posted on Dataset[DatasetDeletionTest] by User[{user.SUPERUSER@SUPERUSER].
[INFO] [2023-01-26 18:08:30]	c.b.c.m.q.ExecutionManager	user.SUPERUSER@SUPERUSER	Executing Query[5d23a746-8faa-47fc-8599-1e9609e00354] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_DatasetDeletionTest))]]
127.0.0.1 - - [26/Jan/2023:18:08:30 +0000] "POST /api/datasets/DatasetDeletionTest/queries HTTP/1.1" 201 1218 "-" "Conquery (test client)" 14
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.c.IntegrationUtils		Trying to get Query result
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.ExecuteQuery	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e, /127.0.0.1:49984]	Started ConceptQuery DatasetDeletionTest.5d23a746-8faa-47fc-8599-1e9609e00354
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.ExecuteQuery	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9, /127.0.0.1:49982]	Started ConceptQuery DatasetDeletionTest.5d23a746-8faa-47fc-8599-1e9609e00354
[DEBUG] [2023-01-26 18:08:30]	c.b.c.m.q.QueryExecutor	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e, /127.0.0.1:49984]	QueryPlan for Query[DatasetDeletionTest.5d23a746-8faa-47fc-8599-1e9609e00354] = `ConceptQueryPlan(child=QPParentNode(children=[ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table, name=test_table]])])), validityDateColumn=Column(id = DatasetDeletionTest.test_table.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column], dateColumn=null), selectedSecondaryId=null), ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table2, name=test_table2]])])), validityDateColumn=Column(id = DatasetDeletionTest.test_table2.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column2], dateColumn=null), selectedSecondaryId=null)]), dateAggregator=DateAggregator(action=MERGE))`
[DEBUG] [2023-01-26 18:08:30]	c.b.c.m.q.QueryExecutor	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9, /127.0.0.1:49982]	QueryPlan for Query[DatasetDeletionTest.5d23a746-8faa-47fc-8599-1e9609e00354] = `ConceptQueryPlan(child=QPParentNode(children=[ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table, name=test_table]])])), validityDateColumn=Column(id = DatasetDeletionTest.test_table.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column], dateColumn=null), selectedSecondaryId=null), ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table2, name=test_table2]])])), validityDateColumn=Column(id = DatasetDeletionTest.test_table2.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column2], dateColumn=null), selectedSecondaryId=null)]), dateAggregator=DateAggregator(action=MERGE))`
[INFO] [2023-01-26 18:08:30]	c.b.c.m.q.r.ShardResult		FINISHED Query[DatasetDeletionTest.5d23a746-8faa-47fc-8599-1e9609e00354] with 0 results within PT0.001175S
[INFO] [2023-01-26 18:08:30]	c.b.c.m.q.r.ShardResult		FINISHED Query[DatasetDeletionTest.5d23a746-8faa-47fc-8599-1e9609e00354] with 2 results within PT0.001862S
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=DatasetDeletionTest]	Received ShardResult(queryId=DatasetDeletionTest.5d23a746-8faa-47fc-8599-1e9609e00354, workerId=DatasetDeletionTest.worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e, startTime=2023-01-26T18:08:30.276306, finishTime=2023-01-26T18:08:30.277481) of size 0
[DEBUG] [2023-01-26 18:08:30]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=DatasetDeletionTest]	Received Result[size=0] for Query[DatasetDeletionTest.5d23a746-8faa-47fc-8599-1e9609e00354]
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=DatasetDeletionTest]	Received ShardResult(queryId=DatasetDeletionTest.5d23a746-8faa-47fc-8599-1e9609e00354, workerId=DatasetDeletionTest.worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9, startTime=2023-01-26T18:08:30.276309, finishTime=2023-01-26T18:08:30.278171) of size 2
[DEBUG] [2023-01-26 18:08:30]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=DatasetDeletionTest]	Received Result[size=2] for Query[DatasetDeletionTest.5d23a746-8faa-47fc-8599-1e9609e00354]
[INFO] [2023-01-26 18:08:30]	c.b.c.m.e.ManagedExecution	Dataset[label=null, name=DatasetDeletionTest]	DONE 5d23a746-8faa-47fc-8599-1e9609e00354 ManagedQuery within PT0.01356S
127.0.0.1 - - [26/Jan/2023:18:08:30 +0000] "GET /api/datasets/DatasetDeletionTest/queries/DatasetDeletionTest.5d23a746-8faa-47fc-8599-1e9609e00354 HTTP/1.1" 200 1486 "-" "Conquery (test client)" 4
[INFO] [2023-01-26 18:08:30]	c.b.c.i.t.d.DatasetDeletionTest		Issuing deletion of import Dataset[label=null, name=DatasetDeletionTest]
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.WorkerStorage	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e, /127.0.0.1:49984]	Removing CBlock[DatasetDeletionTest.test_table2.test_table2.1.DatasetDeletionTest.test_tree.test_column2]
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.WorkerStorage	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e, /127.0.0.1:49984]	Removing Concept[DatasetDeletionTest.test_tree]
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.RemoveImportJob	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9, /127.0.0.1:49982]	Deleting Import[NamedImpl(name=test_table)]
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.WorkerStorage	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9, /127.0.0.1:49982]	Removing CBlock[DatasetDeletionTest.test_table.test_table.0.DatasetDeletionTest.test_tree.test_column]
[INFO] [2023-01-26 18:08:30]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.WorkerStorage	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9, /127.0.0.1:49982]	Removing Bucket[DatasetDeletionTest.test_table.test_table.0]
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.WorkerStorage	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9, /127.0.0.1:49982]	Removing CBlock[DatasetDeletionTest.test_table2.test_table2.0.DatasetDeletionTest.test_tree.test_column2]
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.WorkerStorage	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9, /127.0.0.1:49982]	Removing Concept[DatasetDeletionTest.test_tree]
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.RemoveTable	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9, /127.0.0.1:49982]	Received update of Table Table[label=test_table, name=test_table]
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.RemoveImportJob	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9, /127.0.0.1:49982]	Deleting Import[NamedImpl(name=test_table2)]
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.WorkerStorage	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9, /127.0.0.1:49982]	Removing Bucket[DatasetDeletionTest.test_table2.test_table2.0]
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.RemoveTable	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9, /127.0.0.1:49982]	Received update of Table Table[label=test_table2, name=test_table2]
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.RemoveImportJob	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e, /127.0.0.1:49984]	Deleting Import[NamedImpl(name=test_table)]
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.RemoveTable	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e, /127.0.0.1:49984]	Received update of Table Table[label=test_table, name=test_table]
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.RemoveImportJob	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e, /127.0.0.1:49984]	Deleting Import[NamedImpl(name=test_table2)]
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.WorkerStorage	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e, /127.0.0.1:49984]	Removing Bucket[DatasetDeletionTest.test_table2.test_table2.1]
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.RemoveTable	Worker[DatasetDeletionTest.worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e, /127.0.0.1:49984]	Received update of Table Table[label=test_table2, name=test_table2]
[INFO] [2023-01-26 18:08:30]	c.b.c.m.j.JobExecutor		Closing Job Manager fast DatasetDeletionTest
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node0	removing worker for Dataset[label=DatasetDeletionTest, name=DatasetDeletionTest]
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node1	removing worker for Dataset[label=DatasetDeletionTest, name=DatasetDeletionTest]
[INFO] [2023-01-26 18:08:30]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager fast worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9
[INFO] [2023-01-26 18:08:30]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager fast worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e
[INFO] [2023-01-26 18:08:30]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager slow worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e
[INFO] [2023-01-26 18:08:30]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager slow worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9
[INFO] [2023-01-26 18:08:30]	c.b.c.m.j.JobExecutor		Closing Job Manager slow DatasetDeletionTest
[INFO] [2023-01-26 18:08:30]	c.b.c.m.w.Namespace		Removing namespace storage of DatasetDeletionTest
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore		Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore		Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore		Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore		Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore		Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore		Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore		Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore		Deleting store ID_MAPPING_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore		Deleting store ID_MAPPING_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore		Deleting store STRUCTURE from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore		Deleting store WORKER_TO_BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore		Deleting store PRIMARY_DICTIONARY from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest
[INFO] [2023-01-26 18:08:30]	c.b.c.m.c.XodusStoreFactory		Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e
[INFO] [2023-01-26 18:08:30]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node0	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest_37cfc776-b24d-4de4-9907-c8d7e8a84ee9
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e
[INFO] [2023-01-26 18:08:30]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node1	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest_7ae44d5c-9359-4791-88b4-ed67f162a26e
[INFO] [2023-01-26 18:08:30]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[INFO] [2023-01-26 18:08:30]	c.b.c.i.t.d.DatasetDeletionTest		Checking state after deletion
[WARN] [2023-01-26 18:08:30]	o.g.j.i.Errors	user.SUPERUSER@SUPERUSER	The following warnings have been detected: WARNING: Unknown HK2 failure detected:
MultiException stack 1 of 3
org.glassfish.jersey.server.ParamException$PathParamException: HTTP 404 Not Found
	at org.glassfish.jersey.server.internal.inject.PathParamValueParamProvider$PathParamValueProvider.apply(PathParamValueParamProvider.java:94)
	at org.glassfish.jersey.server.internal.inject.PathParamValueParamProvider$PathParamValueProvider.apply(PathParamValueParamProvider.java:79)
	at org.glassfish.jersey.server.internal.inject.ParamInjectionResolver.resolve(ParamInjectionResolver.java:97)
	at org.glassfish.jersey.inject.hk2.InjectionResolverWrapper.resolve(InjectionResolverWrapper.java:62)
	at org.jvnet.hk2.internal.ClazzCreator.resolve(ClazzCreator.java:188)
	at org.jvnet.hk2.internal.ClazzCreator.resolveAllDependencies(ClazzCreator.java:211)
	at org.jvnet.hk2.internal.ClazzCreator.create(ClazzCreator.java:334)
	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:463)
	at org.glassfish.jersey.inject.hk2.RequestContext.findOrCreate(RequestContext.java:59)
	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2102)
	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:758)
	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:721)
	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:691)
	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:160)
	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:30)
	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:105)
	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:260)
	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:51)
	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:86)
	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:69)
	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:38)
	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:173)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:247)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
	at io.dropwizard.servlets.ThreadNameFilter.doFilter(ThreadNameFilter.java:35)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
	at io.dropwizard.jersey.filter.AllowedMethodsFilter.handle(AllowedMethodsFilter.java:47)
	at io.dropwizard.jersey.filter.AllowedMethodsFilter.doFilter(AllowedMethodsFilter.java:41)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:313)
	at io.dropwizard.jetty.RoutingHandler.handle(RoutingHandler.java:52)
	at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:713)
	at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:54)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:179)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.util.NoSuchElementException: Did not find Dataset[DatasetDeletionTest] in [[]]
	at com.bakdata.conquery.models.worker.DatasetRegistry.findRegistry(DatasetRegistry.java:80)
	at com.bakdata.conquery.models.worker.IdResolveContext.resolve(IdResolveContext.java:43)
	at com.bakdata.conquery.io.jackson.NamespacedIdRefParamConverter.fromString(NamespacedIdRefParamConverter.java:23)
	at com.bakdata.conquery.io.jackson.NamespacedIdRefParamConverter.fromString(NamespacedIdRefParamConverter.java:12)
	at org.glassfish.jersey.server.internal.inject.AbstractParamValueExtractor.convert(AbstractParamValueExtractor.java:116)
	at org.glassfish.jersey.server.internal.inject.AbstractParamValueExtractor.fromString(AbstractParamValueExtractor.java:107)
	at org.glassfish.jersey.server.internal.inject.SingleValueExtractor.extract(SingleValueExtractor.java:61)
	at org.glassfish.jersey.server.internal.inject.PathParamValueParamProvider$PathParamValueProvider.apply(PathParamValueParamProvider.java:92)
	... 77 more
MultiException stack 2 of 3
java.lang.IllegalArgumentException: While attempting to resolve the dependencies of com.bakdata.conquery.resources.api.QueryResource errors were found
	at org.jvnet.hk2.internal.ClazzCreator.resolveAllDependencies(ClazzCreator.java:224)
	at org.jvnet.hk2.internal.ClazzCreator.create(ClazzCreator.java:334)
	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:463)
	at org.glassfish.jersey.inject.hk2.RequestContext.findOrCreate(RequestContext.java:59)
	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2102)
	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:758)
	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:721)
	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:691)
	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:160)
	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:30)
	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:105)
	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:260)
	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:51)
	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:86)
	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:69)
	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:38)
	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:173)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:247)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
	at io.dropwizard.servlets.ThreadNameFilter.doFilter(ThreadNameFilter.java:35)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
	at io.dropwizard.jersey.filter.AllowedMethodsFilter.handle(AllowedMethodsFilter.java:47)
	at io.dropwizard.jersey.filter.AllowedMethodsFilter.doFilter(AllowedMethodsFilter.java:41)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:313)
	at io.dropwizard.jetty.RoutingHandler.handle(RoutingHandler.java:52)
	at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:713)
	at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:54)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:179)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:829)
MultiException stack 3 of 3
java.lang.IllegalStateException: Unable to perform operation: resolve on com.bakdata.conquery.resources.api.QueryResource
	at org.jvnet.hk2.internal.ClazzCreator.create(ClazzCreator.java:363)
	at org.jvnet.hk2.internal.SystemDescriptor.create(SystemDescriptor.java:463)
	at org.glassfish.jersey.inject.hk2.RequestContext.findOrCreate(RequestContext.java:59)
	at org.jvnet.hk2.internal.Utilities.createService(Utilities.java:2102)
	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:758)
	at org.jvnet.hk2.internal.ServiceLocatorImpl.internalGetService(ServiceLocatorImpl.java:721)
	at org.jvnet.hk2.internal.ServiceLocatorImpl.getService(ServiceLocatorImpl.java:691)
	at org.glassfish.jersey.inject.hk2.AbstractHk2InjectionManager.getInstance(AbstractHk2InjectionManager.java:160)
	at org.glassfish.jersey.inject.hk2.ImmediateHk2InjectionManager.getInstance(ImmediateHk2InjectionManager.java:30)
	at org.glassfish.jersey.internal.inject.Injections.getOrCreate(Injections.java:105)
	at org.glassfish.jersey.server.model.MethodHandler$ClassBasedMethodHandler.getInstance(MethodHandler.java:260)
	at org.glassfish.jersey.server.internal.routing.PushMethodHandlerRouter.apply(PushMethodHandlerRouter.java:51)
	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:86)
	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
	at org.glassfish.jersey.server.internal.routing.RoutingStage._apply(RoutingStage.java:89)
	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:69)
	at org.glassfish.jersey.server.internal.routing.RoutingStage.apply(RoutingStage.java:38)
	at org.glassfish.jersey.process.internal.Stages.process(Stages.java:173)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:247)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
	at io.dropwizard.servlets.ThreadNameFilter.doFilter(ThreadNameFilter.java:35)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
	at io.dropwizard.jersey.filter.AllowedMethodsFilter.handle(AllowedMethodsFilter.java:47)
	at io.dropwizard.jersey.filter.AllowedMethodsFilter.doFilter(AllowedMethodsFilter.java:41)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:313)
	at io.dropwizard.jetty.RoutingHandler.handle(RoutingHandler.java:52)
	at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:713)
	at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:54)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:179)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:829)


[INFO] [2023-01-26 18:08:30]	c.b.c.u.s.TestConquery		Setting up dataset
127.0.0.1 - - [26/Jan/2023:18:08:30 +0000] "POST /api/datasets/DatasetDeletionTest/queries HTTP/1.1" 404 43 "-" "Conquery (test client)" 6
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.SerializingStore		While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.CachedStore			loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]:DATASET}): 0 entries, 0 B within 113.7 μs
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.SerializingStore		While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.CachedStore			loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]:SECONDARY_IDS}): 0 entries, 0 B within 47.25 μs
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.SerializingStore		While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.CachedStore			loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]:TABLES}): 0 entries, 0 B within 40.76 μs
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.SerializingStore		While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.CachedStore			loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 42.23 μs
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.SerializingStore		While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.CachedStore			loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]:IMPORTS}): 0 entries, 0 B within 36.82 μs
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.SerializingStore		While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.CachedStore			loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]:CONCEPTS}): 0 entries, 0 B within 37.61 μs
[INFO] [2023-01-26 18:08:30]	c.b.c.i.s.NamespacedStorage		Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.SerializingStore		While processing store ID_MAPPING_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.CachedStore			loaded store cached big ID_MAPPING(EntityIdMap): 0 entries, 0 B within 38.23 μs
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.SerializingStore		While processing store STRUCTURE:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.CachedStore			loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]:STRUCTURE}): 0 entries, 0 B within 35.72 μs
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.SerializingStore		While processing store WORKER_TO_BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.CachedStore			loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]:WORKER_TO_BUCKETS}): 0 entries, 0 B within 34.51 μs
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.SerializingStore		While processing store PRIMARY_DICTIONARY:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.CachedStore			loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]:PRIMARY_DICTIONARY}): 0 entries, 0 B within 34.68 μs
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.AddWorker	Job Manager slow shard-node1	creating a new worker for Dataset[label=DatasetDeletionTest[1], name=DatasetDeletionTest[1]]
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.AddWorker	Job Manager slow shard-node0	creating a new worker for Dataset[label=DatasetDeletionTest[1], name=DatasetDeletionTest[1]]
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e:DATASET}): 0 entries, 0 B within 103.9 μs
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e:SECONDARY_IDS}): 0 entries, 0 B within 33.80 μs
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e:TABLES}): 0 entries, 0 B within 25.87 μs
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 29.93 μs
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e:IMPORTS}): 0 entries, 0 B within 25.76 μs
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e:CONCEPTS}): 0 entries, 0 B within 29.16 μs
[INFO] [2023-01-26 18:08:30]	c.b.c.i.s.NamespacedStorage	Job Manager slow shard-node1	Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store WORKER:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e:WORKER}): 0 entries, 0 B within 30.12 μs
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e:BUCKETS}): 0 entries, 0 B within 39.28 μs
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e:C_BLOCKS}): 0 entries, 0 B within 25.89 μs
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=DatasetDeletionTest[1]]	Imports of worker DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=DatasetDeletionTest[1]]	Buckets of worker DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=DatasetDeletionTest[1]]	Consistency check was successful
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b:DATASET}): 0 entries, 0 B within 133.7 μs
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b:SECONDARY_IDS}): 0 entries, 0 B within 63.42 μs
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b:TABLES}): 0 entries, 0 B within 50.90 μs
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 54.78 μs
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b:IMPORTS}): 0 entries, 0 B within 47.24 μs
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b:CONCEPTS}): 0 entries, 0 B within 49.69 μs
[INFO] [2023-01-26 18:08:30]	c.b.c.i.s.NamespacedStorage	Job Manager slow shard-node0	Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store WORKER:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b:WORKER}): 0 entries, 0 B within 46.58 μs
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b:BUCKETS}): 0 entries, 0 B within 45.53 μs
[DEBUG] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:30]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b:C_BLOCKS}): 0 entries, 0 B within 44.61 μs
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=DatasetDeletionTest[1]]	Imports of worker DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=DatasetDeletionTest[1]]	Buckets of worker DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=DatasetDeletionTest[1]]	Consistency check was successful
[INFO] [2023-01-26 18:08:30]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.UpdateTable	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e, /127.0.0.1:49984]	Received update of Table DatasetDeletionTest[1].test_table
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.UpdateTable	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b, /127.0.0.1:49982]	Received update of Table DatasetDeletionTest[1].test_table
[INFO] [2023-01-26 18:08:30]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.UpdateTable	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e, /127.0.0.1:49984]	Received update of Table DatasetDeletionTest[1].test_table2
[INFO] [2023-01-26 18:08:30]	c.b.c.m.m.n.s.UpdateTable	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b, /127.0.0.1:49982]	Received update of Table DatasetDeletionTest[1].test_table2
[INFO] [2023-01-26 18:08:31]	c.b.c.c.PreprocessorCommand		Preprocessing from command line config.
[INFO] [2023-01-26 18:08:31]	c.b.c.c.PreprocessorCommand	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_DatasetDeletionTest[1]/test_table.import.json, tag=Optional.empty)	DOES NOT EXIST
[INFO] [2023-01-26 18:08:31]	c.b.c.c.PreprocessorCommand	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_DatasetDeletionTest[1]/test_table2.import.json, tag=Optional.empty)	DOES NOT EXIST
[INFO] [2023-01-26 18:08:31]	c.b.c.c.PreprocessorCommand	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_DatasetDeletionTest[1]/test_table2.import.json, tag=Optional.empty)	Required to preprocess 115 B in total
[INFO] [2023-01-26 18:08:31]	c.b.c.m.p.Preprocessor	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_DatasetDeletionTest[1]/test_table.import.json, tag=Optional.empty)	PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_DatasetDeletionTest[1]/test_table.import.json, tag=Optional.empty)
█████████████████████████                         ▌  50%	est. time remaining: 0.049905937s[INFO] [2023-01-26 18:08:31]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	Statistics = IntSummaryStatistics{count=2, sum=2, min=1, average=1.000000, max=1}
[INFO] [2023-01-26 18:08:31]	c.b.c.m.p.PPColumn		Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=2, nullLines=0), subType=IntegerParser(super=Parser(lines=2, nullLines=0), minValue=15655, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@f894edf)
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.p.PPColumn			datum: DateParser(super=Parser(lines=2, nullLines=0), subType=IntegerParser(super=Parser(lines=2, nullLines=0), minValue=15655, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@f894edf) -> IntegerDateStore(store=ShortArrayStore())
[INFO] [2023-01-26 18:08:31]	c.b.c.m.p.PPColumn	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=2, nullLines=0), encoding=null, prefix=, suffix=)
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.p.p.s.StringParser	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]		Chosen encoding is Base16UpperCase
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.p.p.s.StringParser	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]		Using com.bakdata.conquery.models.preproc.parser.specific.string.TrieTypeGuesser@77fe2456(est. 62 B)
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.p.PPColumn	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]		test_column: StringParser(super=Parser(lines=2, nullLines=0), encoding=Base16UpperCase, prefix=, suffix=) -> StringTypeEncoded(encoding=Base16UpperCase, subType=StringTypeDictionary(dictionary=SuccinctTrie[size=2], numberType=ByteArrayStore()))
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	Encode primary Dictionary
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	Writing Headers
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	Writing header
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	Writing Dictionaries
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	Writing data
[INFO] [2023-01-26 18:08:31]	c.b.c.m.p.Preprocessor	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_DatasetDeletionTest[1]/test_table.import.json, tag=Optional.empty)
[INFO] [2023-01-26 18:08:31]	c.b.c.m.p.Preprocessor	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_DatasetDeletionTest[1]/test_table2.import.json, tag=Optional.empty)	PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_DatasetDeletionTest[1]/test_table2.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000772439s[INFO] [2023-01-26 18:08:31]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Statistics = IntSummaryStatistics{count=2, sum=2, min=1, average=1.000000, max=1}
[INFO] [2023-01-26 18:08:31]	c.b.c.m.p.PPColumn	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=2, nullLines=0), encoding=null, prefix=, suffix=)
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.p.p.s.StringParser	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]		Chosen encoding is Base16UpperCase
[INFO] [2023-01-26 18:08:31]	c.b.c.m.p.PPColumn		Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=2, nullLines=0), subType=IntegerParser(super=Parser(lines=2, nullLines=0), minValue=14805, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@f68e520)
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.p.PPColumn			datum: DateParser(super=Parser(lines=2, nullLines=0), subType=IntegerParser(super=Parser(lines=2, nullLines=0), minValue=14805, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@f68e520) -> IntegerDateStore(store=ShortArrayStore())
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.p.p.s.StringParser	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]		Using com.bakdata.conquery.models.preproc.parser.specific.string.TrieTypeGuesser@3cf1383f(est. 62 B)
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.p.PPColumn	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]		test_column: StringParser(super=Parser(lines=2, nullLines=0), encoding=Base16UpperCase, prefix=, suffix=) -> StringTypeEncoded(encoding=Base16UpperCase, subType=StringTypeDictionary(dictionary=SuccinctTrie[size=2], numberType=ByteArrayStore()))
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Encode primary Dictionary
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Writing Headers
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Writing header
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Writing Dictionaries
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Writing data
[INFO] [2023-01-26 18:08:31]	c.b.c.m.p.Preprocessor	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_DatasetDeletionTest[1]/test_table2.import.json, tag=Optional.empty)
[INFO] [2023-01-26 18:08:31]	c.b.c.c.PreprocessorCommand		Successfully Preprocess 2 Jobs:
[INFO] [2023-01-26 18:08:31]	c.b.c.c.PreprocessorCommand			Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_DatasetDeletionTest[1]/test_table.import.json, tag=Optional.empty)
[INFO] [2023-01-26 18:08:31]	c.b.c.c.PreprocessorCommand			Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_DatasetDeletionTest[1]/test_table2.import.json, tag=Optional.empty)
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.j.ImportJob	user.SUPERUSER@SUPERUSER	Done reading data. Contains 2 Entities.
[INFO] [2023-01-26 18:08:31]	c.b.c.m.j.ImportJob	user.SUPERUSER@SUPERUSER	Importing test_table into DatasetDeletionTest[1].test_table
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.j.ImportJob	Job Manager slow DatasetDeletionTest[1]	Mapped 2 new ids
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.j.ImportJob	Job Manager slow DatasetDeletionTest[1]	Updating bucket assignments.
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.w.Namespace	Job Manager slow DatasetDeletionTest[1]	Assigning Bucket[0] to Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e]
127.0.0.1 - - [26/Jan/2023:18:08:31 +0000] "POST /admin/datasets/DatasetDeletionTest%5B1%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest12910953884258704183%2Ftmp_DatasetDeletionTest%5B1%5D%2Ftest_table.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 23
[INFO] [2023-01-26 18:08:31]	c.b.c.m.j.ImportJob	Job Manager slow DatasetDeletionTest[1]	Importing Dictionaries
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.m.n.s.UpdateWorkerBucket	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b, /127.0.0.1:49982]	Received new WorkerInformation(size = 0,dataset = DatasetDeletionTest[1])
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.m.n.s.UpdateWorkerBucket	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e, /127.0.0.1:49984]	Received new WorkerInformation(size = 1,dataset = DatasetDeletionTest[1])
[INFO] [2023-01-26 18:08:31]	c.b.c.m.j.ImportJob	Job Manager slow DatasetDeletionTest[1]	Remapping Dictionaries []
[WARN] [2023-01-26 18:08:31]	c.b.c.u.p.ProgressReporterImpl	Job Manager slow DatasetDeletionTest[1]	Max cannot be decreased.
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.m.n.s.UpdateDictionary	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b, /127.0.0.1:49982]	Received Dictionary[DatasetDeletionTest[1].test_table#DatasetDeletionTest[1]$2etest_table$2etest_column] of size 2.
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.m.n.s.UpdateDictionary	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e, /127.0.0.1:49984]	Received Dictionary[DatasetDeletionTest[1].test_table#DatasetDeletionTest[1]$2etest_table$2etest_column] of size 2.
[INFO] [2023-01-26 18:08:31]	c.b.c.m.j.ImportJob	Job Manager slow DatasetDeletionTest[1]	Start sending 1 Buckets
[WARN] [2023-01-26 18:08:31]	c.b.c.u.p.ProgressReporterImpl	Job Manager slow DatasetDeletionTest[1]	One or more Children are not done yet
[INFO] [2023-01-26 18:08:31]	c.b.c.m.m.n.s.AddImport	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b, /127.0.0.1:49982]	Received Import[DatasetDeletionTest[1].test_table.test_table], containing 2 entries.
[INFO] [2023-01-26 18:08:31]	c.b.c.m.m.n.s.AddImport	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e, /127.0.0.1:49984]	Received Import[DatasetDeletionTest[1].test_table.test_table], containing 2 entries.
[INFO] [2023-01-26 18:08:31]	c.b.c.m.m.n.s.ImportBucket	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e, /127.0.0.1:49984]	Received DatasetDeletionTest[1].test_table.test_table.0
[DEBUG] [2023-01-26 18:08:31]	c.b.c.i.s.WorkerStorage	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e, /127.0.0.1:49984]	Adding Bucket[DatasetDeletionTest[1].test_table.test_table.0]
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.j.ImportJob	user.SUPERUSER@SUPERUSER	Done reading data. Contains 2 Entities.
[INFO] [2023-01-26 18:08:31]	c.b.c.m.j.ImportJob	user.SUPERUSER@SUPERUSER	Importing test_table2 into DatasetDeletionTest[1].test_table2
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.j.ImportJob	Job Manager slow DatasetDeletionTest[1]	Mapped 2 new ids
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.j.ImportJob	Job Manager slow DatasetDeletionTest[1]	Updating bucket assignments.
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.w.Namespace	Job Manager slow DatasetDeletionTest[1]	Assigning Bucket[1] to Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b]
[INFO] [2023-01-26 18:08:31]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:08:31 +0000] "POST /admin/datasets/DatasetDeletionTest%5B1%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest12910953884258704183%2Ftmp_DatasetDeletionTest%5B1%5D%2Ftest_table2.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
[INFO] [2023-01-26 18:08:31]	c.b.c.m.j.ImportJob	Job Manager slow DatasetDeletionTest[1]	Importing Dictionaries
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.m.n.s.UpdateWorkerBucket	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e, /127.0.0.1:49984]	Received new WorkerInformation(size = 1,dataset = DatasetDeletionTest[1])
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.m.n.s.UpdateWorkerBucket	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b, /127.0.0.1:49982]	Received new WorkerInformation(size = 1,dataset = DatasetDeletionTest[1])
[INFO] [2023-01-26 18:08:31]	c.b.c.m.j.ImportJob	Job Manager slow DatasetDeletionTest[1]	Remapping Dictionaries []
[WARN] [2023-01-26 18:08:31]	c.b.c.u.p.ProgressReporterImpl	Job Manager slow DatasetDeletionTest[1]	Max cannot be decreased.
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.m.n.s.UpdateDictionary	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e, /127.0.0.1:49984]	Received Dictionary[DatasetDeletionTest[1].test_table2#DatasetDeletionTest[1]$2etest_table2$2etest_column] of size 2.
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.m.n.s.UpdateDictionary	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b, /127.0.0.1:49982]	Received Dictionary[DatasetDeletionTest[1].test_table2#DatasetDeletionTest[1]$2etest_table2$2etest_column] of size 2.
[INFO] [2023-01-26 18:08:31]	c.b.c.m.j.ImportJob	Job Manager slow DatasetDeletionTest[1]	Start sending 2 Buckets
[WARN] [2023-01-26 18:08:31]	c.b.c.u.p.ProgressReporterImpl	Job Manager slow DatasetDeletionTest[1]	One or more Children are not done yet
[INFO] [2023-01-26 18:08:31]	c.b.c.m.m.n.s.AddImport	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b, /127.0.0.1:49982]	Received Import[DatasetDeletionTest[1].test_table2.test_table2], containing 2 entries.
[INFO] [2023-01-26 18:08:31]	c.b.c.m.m.n.s.ImportBucket	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b, /127.0.0.1:49982]	Received DatasetDeletionTest[1].test_table2.test_table2.1
[DEBUG] [2023-01-26 18:08:31]	c.b.c.i.s.WorkerStorage	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b, /127.0.0.1:49982]	Adding Bucket[DatasetDeletionTest[1].test_table2.test_table2.1]
[INFO] [2023-01-26 18:08:31]	c.b.c.m.m.n.s.AddImport	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e, /127.0.0.1:49984]	Received Import[DatasetDeletionTest[1].test_table2.test_table2], containing 2 entries.
[INFO] [2023-01-26 18:08:31]	c.b.c.m.m.n.s.ImportBucket	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e, /127.0.0.1:49984]	Received DatasetDeletionTest[1].test_table2.test_table2.0
[DEBUG] [2023-01-26 18:08:31]	c.b.c.i.s.WorkerStorage	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e, /127.0.0.1:49984]	Adding Bucket[DatasetDeletionTest[1].test_table2.test_table2.0]
[INFO] [2023-01-26 18:08:31]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[DEBUG] [2023-01-26 18:08:31]	c.b.c.i.s.WorkerStorage	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b, /127.0.0.1:49982]	Updating Concept[DatasetDeletionTest[1].test_tree]
[DEBUG] [2023-01-26 18:08:31]	c.b.c.i.s.WorkerStorage	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e, /127.0.0.1:49984]	Updating Concept[DatasetDeletionTest[1].test_tree]
[DEBUG] [2023-01-26 18:08:31]	c.b.c.i.s.WorkerStorage		Adding CBlock[DatasetDeletionTest[1].test_table.test_table.0.DatasetDeletionTest[1].test_tree.test_column]
[DEBUG] [2023-01-26 18:08:31]	c.b.c.i.s.WorkerStorage		Adding CBlock[DatasetDeletionTest[1].test_table2.test_table2.0.DatasetDeletionTest[1].test_tree.test_column2]
[DEBUG] [2023-01-26 18:08:31]	c.b.c.i.s.WorkerStorage		Adding CBlock[DatasetDeletionTest[1].test_table2.test_table2.1.DatasetDeletionTest[1].test_tree.test_column2]
[INFO] [2023-01-26 18:08:31]	c.b.c.i.t.d.DatasetDeletionTest		Executing query after re-import
[INFO] [2023-01-26 18:08:31]	c.b.c.a.QueryProcessor	user.SUPERUSER@SUPERUSER	Query posted on Dataset[DatasetDeletionTest[1]] by User[{user.SUPERUSER@SUPERUSER].
[INFO] [2023-01-26 18:08:31]	c.b.c.m.q.ExecutionManager	user.SUPERUSER@SUPERUSER	Executing Query[f744659f-a5d2-4078-a3f7-554a2c203cb3] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_DatasetDeletionTest[1]))]]
[INFO] [2023-01-26 18:08:31]	c.b.c.m.m.n.s.ExecuteQuery	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e, /127.0.0.1:49984]	Started ConceptQuery DatasetDeletionTest[1].f744659f-a5d2-4078-a3f7-554a2c203cb3
[INFO] [2023-01-26 18:08:31]	c.b.c.m.m.n.s.ExecuteQuery	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b, /127.0.0.1:49982]	Started ConceptQuery DatasetDeletionTest[1].f744659f-a5d2-4078-a3f7-554a2c203cb3
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.q.QueryExecutor	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e, /127.0.0.1:49984]	QueryPlan for Query[DatasetDeletionTest[1].f744659f-a5d2-4078-a3f7-554a2c203cb3] = `ConceptQueryPlan(child=QPParentNode(children=[ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table, name=test_table]])])), validityDateColumn=Column(id = DatasetDeletionTest[1].test_table.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column], dateColumn=null), selectedSecondaryId=null), ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table2, name=test_table2]])])), validityDateColumn=Column(id = DatasetDeletionTest[1].test_table2.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column2], dateColumn=null), selectedSecondaryId=null)]), dateAggregator=DateAggregator(action=MERGE))`
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.q.QueryExecutor	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b, /127.0.0.1:49982]	QueryPlan for Query[DatasetDeletionTest[1].f744659f-a5d2-4078-a3f7-554a2c203cb3] = `ConceptQueryPlan(child=QPParentNode(children=[ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table, name=test_table]])])), validityDateColumn=Column(id = DatasetDeletionTest[1].test_table.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column], dateColumn=null), selectedSecondaryId=null), ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table2, name=test_table2]])])), validityDateColumn=Column(id = DatasetDeletionTest[1].test_table2.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column2], dateColumn=null), selectedSecondaryId=null)]), dateAggregator=DateAggregator(action=MERGE))`
[INFO] [2023-01-26 18:08:31]	c.b.c.m.q.r.ShardResult		FINISHED Query[DatasetDeletionTest[1].f744659f-a5d2-4078-a3f7-554a2c203cb3] with 0 results within PT0.001714S
127.0.0.1 - - [26/Jan/2023:18:08:31 +0000] "POST /api/datasets/DatasetDeletionTest%5B1%5D/queries HTTP/1.1" 201 1229 "-" "Conquery (test client)" 12
[INFO] [2023-01-26 18:08:31]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=DatasetDeletionTest[1]]	Received ShardResult(queryId=DatasetDeletionTest[1].f744659f-a5d2-4078-a3f7-554a2c203cb3, workerId=DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b, startTime=2023-01-26T18:08:31.482230, finishTime=2023-01-26T18:08:31.483944) of size 0
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=DatasetDeletionTest[1]]	Received Result[size=0] for Query[DatasetDeletionTest[1].f744659f-a5d2-4078-a3f7-554a2c203cb3]
[DEBUG] [2023-01-26 18:08:31]	c.b.c.i.c.IntegrationUtils		Trying to get Query result
[INFO] [2023-01-26 18:08:31]	c.b.c.m.q.r.ShardResult		FINISHED Query[DatasetDeletionTest[1].f744659f-a5d2-4078-a3f7-554a2c203cb3] with 2 results within PT0.002807S
[INFO] [2023-01-26 18:08:31]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=DatasetDeletionTest[1]]	Received ShardResult(queryId=DatasetDeletionTest[1].f744659f-a5d2-4078-a3f7-554a2c203cb3, workerId=DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e, startTime=2023-01-26T18:08:31.482214, finishTime=2023-01-26T18:08:31.485021) of size 2
[DEBUG] [2023-01-26 18:08:31]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=DatasetDeletionTest[1]]	Received Result[size=2] for Query[DatasetDeletionTest[1].f744659f-a5d2-4078-a3f7-554a2c203cb3]
[INFO] [2023-01-26 18:08:31]	c.b.c.m.e.ManagedExecution	Dataset[label=null, name=DatasetDeletionTest[1]]	DONE f744659f-a5d2-4078-a3f7-554a2c203cb3 ManagedQuery within PT0.010079S
127.0.0.1 - - [26/Jan/2023:18:08:31 +0000] "GET /api/datasets/DatasetDeletionTest%5B1%5D/queries/DatasetDeletionTest%5B1%5D.f744659f-a5d2-4078-a3f7-554a2c203cb3 HTTP/1.1" 200 1749 "-" "Conquery (test client)" 4
[INFO] [2023-01-26 18:08:31]	c.b.c.m.j.JobExecutor		Closing Job Manager fast shard-node1
[INFO] [2023-01-26 18:08:31]	c.b.c.m.j.JobExecutor		Closing Job Manager slow shard-node1
[INFO] [2023-01-26 18:08:31]	c.b.c.m.j.JobExecutor		Closing Job Manager fast worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e
[INFO] [2023-01-26 18:08:31]	c.b.c.m.j.JobExecutor		Closing Job Manager slow worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e
[INFO] [2023-01-26 18:08:31]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e:DATASET}
[INFO] [2023-01-26 18:08:31]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e:SECONDARY_IDS}
[INFO] [2023-01-26 18:08:31]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e:TABLES}
[INFO] [2023-01-26 18:08:31]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e:DICTIONARIES_META}
[INFO] [2023-01-26 18:08:31]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e:DICTIONARIES_DATA}
[INFO] [2023-01-26 18:08:31]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e:IMPORTS}
[INFO] [2023-01-26 18:08:31]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e:CONCEPTS}
[INFO] [2023-01-26 18:08:31]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e:WORKER}
[INFO] [2023-01-26 18:08:31]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e:BUCKETS}
[INFO] [2023-01-26 18:08:31]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e:C_BLOCKS}
[INFO] [2023-01-26 18:08:31]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e
[INFO] [2023-01-26 18:08:31]	c.b.c.c.ShardNode		Connection was closed by ManagerNode
[INFO] [2023-01-26 18:08:31]	c.b.c.c.ShardNode	0.0.0.0/0.0.0.0:49984	Disconnected from ManagerNode
[INFO] [2023-01-26 18:08:31]	c.b.c.m.j.JobExecutor		Closing Job Manager fast shard-node0
[INFO] [2023-01-26 18:08:31]	c.b.c.c.ManagerNode	ManagerNode[0.0.0.0/0.0.0.0:34233]	Client 'null' disconnected 
[INFO] [2023-01-26 18:08:31]	c.b.c.m.j.JobExecutor		Closing Job Manager slow shard-node0
[INFO] [2023-01-26 18:08:31]	c.b.c.m.j.JobExecutor		Closing Job Manager fast worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b
[INFO] [2023-01-26 18:08:31]	c.b.c.m.j.JobExecutor		Closing Job Manager slow worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b
[INFO] [2023-01-26 18:08:31]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b:DATASET}
[INFO] [2023-01-26 18:08:31]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b:SECONDARY_IDS}
[INFO] [2023-01-26 18:08:31]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b:TABLES}
[INFO] [2023-01-26 18:08:31]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b:DICTIONARIES_META}
[INFO] [2023-01-26 18:08:31]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b:DICTIONARIES_DATA}
[INFO] [2023-01-26 18:08:31]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b:IMPORTS}
[INFO] [2023-01-26 18:08:31]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b:CONCEPTS}
[INFO] [2023-01-26 18:08:31]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b:WORKER}
[INFO] [2023-01-26 18:08:31]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b:BUCKETS}
[INFO] [2023-01-26 18:08:31]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b:C_BLOCKS}
[INFO] [2023-01-26 18:08:31]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b
[INFO] [2023-01-26 18:08:31]	c.b.c.c.ShardNode		Connection was closed by ManagerNode
[INFO] [2023-01-26 18:08:31]	c.b.c.c.ShardNode	0.0.0.0/0.0.0.0:49982	Disconnected from ManagerNode
[INFO] [2023-01-26 18:08:31]	c.b.c.m.j.JobExecutor		Closing Job Manager fast ManagerNode
[INFO] [2023-01-26 18:08:31]	c.b.c.c.ManagerNode	ManagerNode[0.0.0.0/0.0.0.0:34233]	Client 'null' disconnected 
[INFO] [2023-01-26 18:08:32]	c.b.c.m.j.JobExecutor		Closing Job Manager slow ManagerNode
[INFO] [2023-01-26 18:08:32]	c.b.c.m.j.JobExecutor		Closing Job Manager fast DatasetDeletionTest[1]
[INFO] [2023-01-26 18:08:32]	c.b.c.m.j.JobExecutor		Closing Job Manager slow DatasetDeletionTest[1]
[INFO] [2023-01-26 18:08:32]	c.b.c.m.w.Namespace		Closing namespace storage of DatasetDeletionTest[1]
[INFO] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]:DATASET}
[INFO] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]:SECONDARY_IDS}
[INFO] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]:TABLES}
[INFO] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]:DICTIONARIES_META}
[INFO] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]:DICTIONARIES_DATA}
[INFO] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]:IMPORTS}
[INFO] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]:CONCEPTS}
[INFO] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]:ID_MAPPING_META}
[INFO] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]:ID_MAPPING_DATA}
[INFO] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]:STRUCTURE}
[INFO] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]:WORKER_TO_BUCKETS}
[INFO] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]:PRIMARY_DICTIONARY}
[INFO] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]
[INFO] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/executions:EXECUTIONS}
[INFO] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/executions
[INFO] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/formConfigs:FORM_CONFIG}
[INFO] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/formConfigs
[INFO] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/users:AUTH_USER}
[INFO] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/users
[INFO] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/roles:AUTH_ROLE}
[INFO] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/roles
[INFO] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/groups:AUTH_GROUP}
[INFO] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/groups
[INFO] [2023-01-26 18:08:32]	c.b.c.u.s.TestConquery		Working in temporary directory /tmp/conqueryIntegrationTest12910953884258704183
[DEBUG] [2023-01-26 18:08:32]	c.b.c.c.StandaloneCommand	ManagerNode	Starting ManagerNode
[DEBUG] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]:DATASET}): 1 entries, 71 B within 160.8 μs
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]:SECONDARY_IDS}): 0 entries, 0 B within 43.25 μs
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]	While processing store TABLES:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]:TABLES}): 2 entries, 356 B within 299.3 μs
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]	While processing store DICTIONARIES_META:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]		loaded store cached big DICTIONARIES(Dictionary): 2 entries, 86 B within 1.110 ms
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]	While processing store IMPORTS:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]:IMPORTS}): 2 entries, 1 KiB within 5.110 ms
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]	While processing store CONCEPTS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]:CONCEPTS}): 1 entries, 642 B within 5.010 ms
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]	Done reading Dataset[label=DatasetDeletionTest[1], name=DatasetDeletionTest[1]] / com.bakdata.conquery.io.storage.NamespaceStorage
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]	While processing store ID_MAPPING_META:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]		loaded store cached big ID_MAPPING(EntityIdMap): 1 entries, 43 B within 274.8 μs
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]	While processing store STRUCTURE:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]:STRUCTURE}): 0 entries, 0 B within 28.59 μs
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]	While processing store WORKER_TO_BUCKETS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]:WORKER_TO_BUCKETS}): 1 entries, 343 B within 127.3 μs
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]	While processing store PRIMARY_DICTIONARY:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]:PRIMARY_DICTIONARY}): 1 entries, 108 B within 631.0 μs
[DEBUG] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]	DONE reading Storage
[INFO] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory	ManagerNode	All WorkerStores loaded: [NamespacedStorage(pathName=dataset_DatasetDeletionTest[1])]
[INFO] [2023-01-26 18:08:32]	c.b.c.c.ManagerNode	ManagerNode	Opening MetaStorage
[INFO] [2023-01-26 18:08:32]	c.b.c.c.ManagerNode	ManagerNode	Loading MetaStorage
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store AUTH_USER:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/users:AUTH_USER}): 1 entries, 149 B within 830.7 μs
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store AUTH_ROLE:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/roles:AUTH_ROLE}): 0 entries, 0 B within 58.66 μs
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store AUTH_GROUP:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/groups:AUTH_GROUP}): 0 entries, 0 B within 45.97 μs
[WARN] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	Could not parse value for key [DatasetDeletionTest.5d23a746-8faa-47fc-8599-1e9609e00354]
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store EXECUTIONS:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	1 (50.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/executions:EXECUTIONS}): 1 entries, 617 B within 7.509 ms
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store FORM_CONFIG:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/formConfigs:FORM_CONFIG}): 0 entries, 0 B within 63.51 μs
[INFO] [2023-01-26 18:08:32]	c.b.c.c.ManagerNode	ManagerNode	MetaStorage loaded com.bakdata.conquery.io.storage.MetaStorage@170a3fcb
[DEBUG] [2023-01-26 18:08:32]	c.b.c.m.a.AuthorizationController	ManagerNode	Security manager registered
[WARN] [2023-01-26 18:08:32]	c.b.c.m.a.d.DefaultInitialUserRealm	ManagerNode	
           §§
          §  §
         §    §
        §      §
       §  §§§§  §       You instantiated and are probably using a Shiro realm
      §   §§§§   §      that does not do any permission checks or authentication.
     §     §§     §     Access to all resources is granted to everyone.
    §      §§      §    DO NOT USE THIS REALM IN PRODUCTION
   $                §
  §        §§        §
 §                    §
 §§§§§§§§§§§§§§§§§§§§§§
[INFO] [2023-01-26 18:08:32]	c.b.c.m.a.AuthorizationController	ManagerNode	Registering the following realms to Shiro:
	com.bakdata.conquery.models.auth.conquerytoken.ConqueryTokenRealm_24
	com.bakdata.conquery.models.auth.ConqueryAuthorizationRealm_25
	com.bakdata.conquery.models.auth.develop.DefaultInitialUserRealm_26
[INFO] [2023-01-26 18:08:32]	c.b.c.c.ManagerNode	ManagerNode	Registering ResourcesProvider
[INFO] [2023-01-26 18:08:32]	c.b.c.m.f.f.FormScanner	ManagerNode	Form[EXPORT_FORM] from `Resource com/bakdata/conquery/frontend/forms/export_form.frontend_conf.json` of Type[com.bakdata.conquery.apiv1.forms.export_form.ExportForm]
[INFO] [2023-01-26 18:08:32]	c.b.c.m.f.f.FormScanner	ManagerNode	Form[FULL_EXPORT_FORM] from `Resource com/bakdata/conquery/frontend/forms/table_export_form.frontend_conf.json` of Type[com.bakdata.conquery.apiv1.forms.export_form.FullExportForm]
[DEBUG] [2023-01-26 18:08:32]	c.b.c.c.StandaloneCommand	ManagerNode	Waiting for ShardNodes to start
[DEBUG] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b:DATASET}): 1 entries, 71 B within 119.8 μs
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b:SECONDARY_IDS}): 0 entries, 0 B within 25.94 μs
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b	While processing store TABLES:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b:TABLES}): 2 entries, 356 B within 197.9 μs
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b	While processing store DICTIONARIES_META:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b		loaded store cached big DICTIONARIES(Dictionary): 2 entries, 86 B within 830.2 μs
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b	While processing store IMPORTS:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b:IMPORTS}): 2 entries, 1 KiB within 2.901 ms
[DEBUG] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e:DATASET}): 1 entries, 71 B within 117.3 μs
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e:SECONDARY_IDS}): 0 entries, 0 B within 33.26 μs
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e	While processing store TABLES:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e:TABLES}): 2 entries, 356 B within 184.2 μs
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b	While processing store CONCEPTS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b:CONCEPTS}): 1 entries, 642 B within 3.772 ms
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b	Done reading Dataset[label=DatasetDeletionTest[1], name=DatasetDeletionTest[1]] / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b	While processing store WORKER:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b:WORKER}): 1 entries, 147 B within 72.15 μs
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e	While processing store DICTIONARIES_META:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e		loaded store cached big DICTIONARIES(Dictionary): 2 entries, 86 B within 886.2 μs
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b	While processing store BUCKETS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b:BUCKETS}): 1 entries, 384 B within 1.365 ms
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b	While processing store C_BLOCKS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b:C_BLOCKS}): 1 entries, 240 B within 138.7 μs
[DEBUG] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b	DONE reading Storage
[INFO] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory	shard-node0	All WorkerStores loaded: [WorkerStorage(worker=NamedImpl(name=worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b))]
[INFO] [2023-01-26 18:08:32]	c.b.c.c.ShardNode	shard-node0	All Worker Storages loaded: 1
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e	While processing store IMPORTS:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e:IMPORTS}): 2 entries, 1 KiB within 3.352 ms
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e	While processing store CONCEPTS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e:CONCEPTS}): 1 entries, 642 B within 3.812 ms
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e	Done reading Dataset[label=DatasetDeletionTest[1], name=DatasetDeletionTest[1]] / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e	While processing store WORKER:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e:WORKER}): 1 entries, 147 B within 101.6 μs
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e	While processing store BUCKETS:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e:BUCKETS}): 2 entries, 770 B within 1.583 ms
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e	While processing store C_BLOCKS:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e:C_BLOCKS}): 2 entries, 477 B within 211.5 μs
[DEBUG] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e	DONE reading Storage
[INFO] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory	shard-node1	All WorkerStores loaded: [WorkerStorage(worker=NamedImpl(name=worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e))]
[INFO] [2023-01-26 18:08:32]	c.b.c.c.ShardNode	shard-node1	All Worker Storages loaded: 1
[DEBUG] [2023-01-26 18:08:32]	c.b.c.c.StandaloneCommand	ManagerNode	Starting REST Server
[INFO] [2023-01-26 18:08:32]	c.b.c.c.ManagerNode		Started ManagerNode @ /0:0:0:0:0:0:0:0:34233
[INFO] [2023-01-26 18:08:32]	c.b.c.c.ShardNode		Trying to connect to /127.0.0.1:34233
[INFO] [2023-01-26 18:08:32]	c.b.c.c.ManagerNode	ManagerNode[/127.0.0.1:34233]	New client /127.0.0.1:50284 connected, waiting for identity
[INFO] [2023-01-26 18:08:32]	c.b.c.c.ShardNode	/127.0.0.1:50284	Connected to ManagerNode @ /127.0.0.1:34233
[INFO] [2023-01-26 18:08:32]	c.b.c.c.ShardNode		Trying to connect to /127.0.0.1:34233
[INFO] [2023-01-26 18:08:32]	c.b.c.c.ShardNode	/127.0.0.1:50286	Connected to ManagerNode @ /127.0.0.1:34233
[INFO] [2023-01-26 18:08:32]	c.b.c.c.ManagerNode	ManagerNode[/127.0.0.1:34233]	New client /127.0.0.1:50286 connected, waiting for identity
[INFO] [2023-01-26 18:08:32]	c.b.c.c.ShardNode	/127.0.0.1:50284	Sending worker identity 'worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e'
[INFO] [2023-01-26 18:08:32]	c.b.c.c.ShardNode	/127.0.0.1:50286	Sending worker identity 'worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b'
[INFO] [2023-01-26 18:08:32]	c.b.c.m.m.n.s.AddShardNode	Job Manager fast ManagerNode	ShardNode `/127.0.0.1:50284` registered.
[INFO] [2023-01-26 18:08:32]	c.b.c.m.m.n.s.AddShardNode	Job Manager fast ManagerNode	ShardNode `/127.0.0.1:50286` registered.
[INFO] [2023-01-26 18:08:32]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=DatasetDeletionTest[1], name=DatasetDeletionTest[1]]	Imports of worker DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b are consistent with the manager: 2 Imports
[INFO] [2023-01-26 18:08:32]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=DatasetDeletionTest[1], name=DatasetDeletionTest[1]]	Buckets of worker DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b are consistent with the manager: 1 Buckets
[INFO] [2023-01-26 18:08:32]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=DatasetDeletionTest[1], name=DatasetDeletionTest[1]]	Consistency check was successful
[INFO] [2023-01-26 18:08:32]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=DatasetDeletionTest[1], name=DatasetDeletionTest[1]]	Imports of worker DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e are consistent with the manager: 2 Imports
[INFO] [2023-01-26 18:08:32]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=DatasetDeletionTest[1], name=DatasetDeletionTest[1]]	Buckets of worker DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e are consistent with the manager: 2 Buckets
[INFO] [2023-01-26 18:08:32]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=DatasetDeletionTest[1], name=DatasetDeletionTest[1]]	Consistency check was successful
[WARN] [2023-01-26 18:08:32]	o.g.j.i.Errors		The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.filters.Filter<?> from public void com.bakdata.conquery.resources.hierarchies.HFilters.setFilter(com.bakdata.conquery.models.datasets.concepts.filters.Filter<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public com.bakdata.conquery.apiv1.FullExecutionStatus com.bakdata.conquery.resources.api.QueryResource.getStatus(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) throws java.lang.InterruptedException is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public com.bakdata.conquery.apiv1.FullExecutionStatus com.bakdata.conquery.resources.api.QueryResource.patchQuery(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>,com.bakdata.conquery.apiv1.MetaDataPatch) throws com.bakdata.conquery.models.exceptions.JSONException is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public void com.bakdata.conquery.resources.api.QueryResource.deleteQuery(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>) is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public void com.bakdata.conquery.resources.api.QueryResource.cancel(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>) is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public com.bakdata.conquery.apiv1.FullExecutionStatus com.bakdata.conquery.resources.api.QueryResource.reexecute(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultExcelResource.get(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.identifiable.ids.specific.DatasetId,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultArrowStreamResource.get(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.datasets.Dataset,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultCsvResource.getAsCsv(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.datasets.Dataset,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.lang.String,java.lang.String,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultArrowFileResource.get(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.datasets.Dataset,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.filters.Filter<?> from public void com.bakdata.conquery.resources.hierarchies.HFilters.setFilter(com.bakdata.conquery.models.datasets.concepts.filters.Filter<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.

[WARN] [2023-01-26 18:08:32]	i.d.s.AdminEnvironment		
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!    THIS APPLICATION HAS NO HEALTHCHECKS. THIS MEANS YOU WILL NEVER KNOW      !
!     IF IT DIES IN PRODUCTION, WHICH MEANS YOU WILL NEVER KNOW IF YOU'RE      !
!    LETTING YOUR USERS DOWN. YOU SHOULD ADD A HEALTHCHECK FOR EACH OF YOUR    !
!         APPLICATION'S DEPENDENCIES WHICH FULLY (BUT LIGHTLY) TESTS IT.       !
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
[WARN] [2023-01-26 18:08:32]	o.g.j.i.Errors		The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.auth.entities.PermissionOwner<?> from public void com.bakdata.conquery.resources.hierarchies.HPermissions.setOwner(com.bakdata.conquery.models.auth.entities.PermissionOwner<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.auth.entities.PermissionOwner<?> from public void com.bakdata.conquery.resources.hierarchies.HPermissions.setOwner(com.bakdata.conquery.models.auth.entities.PermissionOwner<?>) is not resolvable to a concrete type.

[WARN] [2023-01-26 18:08:32]	o.g.j.i.Errors		The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter concept of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from protected com.bakdata.conquery.models.datasets.concepts.Concept<?> com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.concept is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter concept of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from protected com.bakdata.conquery.models.datasets.concepts.Concept<?> com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.concept is not resolvable to a concrete type.

[INFO] [2023-01-26 18:08:32]	c.b.c.u.s.TestConquery		loading dataset
[INFO] [2023-01-26 18:08:32]	c.b.c.u.s.TestConquery		Reusing existing folder /tmp/conqueryIntegrationTest12910953884258704183/tmp_DatasetDeletionTest[1] for Support
[INFO] [2023-01-26 18:08:32]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[INFO] [2023-01-26 18:08:32]	c.b.c.i.t.d.DatasetDeletionTest		Checking state after re-start
[INFO] [2023-01-26 18:08:32]	c.b.c.i.t.d.DatasetDeletionTest		Executing query after restart
[INFO] [2023-01-26 18:08:32]	c.b.c.a.QueryProcessor	user.SUPERUSER@SUPERUSER	Query posted on Dataset[DatasetDeletionTest[1]] by User[{user.SUPERUSER@SUPERUSER].
[INFO] [2023-01-26 18:08:32]	c.b.c.m.q.ExecutionManager	user.SUPERUSER@SUPERUSER	Executing Query[b20cbbaf-e989-4483-8843-8b40cd660918] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_DatasetDeletionTest[1]))]]
127.0.0.1 - - [26/Jan/2023:18:08:32 +0000] "POST /api/datasets/DatasetDeletionTest%5B1%5D/queries HTTP/1.1" 201 1230 "-" "Conquery (test client)" 23
[INFO] [2023-01-26 18:08:32]	c.b.c.m.m.n.s.ExecuteQuery	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b, /127.0.0.1:50286]	Started ConceptQuery DatasetDeletionTest[1].b20cbbaf-e989-4483-8843-8b40cd660918
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.c.IntegrationUtils		Trying to get Query result
[DEBUG] [2023-01-26 18:08:32]	c.b.c.m.q.QueryExecutor	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b, /127.0.0.1:50286]	QueryPlan for Query[DatasetDeletionTest[1].b20cbbaf-e989-4483-8843-8b40cd660918] = `ConceptQueryPlan(child=QPParentNode(children=[ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table, name=test_table]])])), validityDateColumn=Column(id = DatasetDeletionTest[1].test_table.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column], dateColumn=null), selectedSecondaryId=null), ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table2, name=test_table2]])])), validityDateColumn=Column(id = DatasetDeletionTest[1].test_table2.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column2], dateColumn=null), selectedSecondaryId=null)]), dateAggregator=DateAggregator(action=MERGE))`
[INFO] [2023-01-26 18:08:32]	c.b.c.m.m.n.s.ExecuteQuery	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e, /127.0.0.1:50284]	Started ConceptQuery DatasetDeletionTest[1].b20cbbaf-e989-4483-8843-8b40cd660918
[DEBUG] [2023-01-26 18:08:32]	c.b.c.m.q.QueryExecutor	Worker[DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e, /127.0.0.1:50284]	QueryPlan for Query[DatasetDeletionTest[1].b20cbbaf-e989-4483-8843-8b40cd660918] = `ConceptQueryPlan(child=QPParentNode(children=[ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table, name=test_table]])])), validityDateColumn=Column(id = DatasetDeletionTest[1].test_table.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column], dateColumn=null), selectedSecondaryId=null), ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table2, name=test_table2]])])), validityDateColumn=Column(id = DatasetDeletionTest[1].test_table2.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column2], dateColumn=null), selectedSecondaryId=null)]), dateAggregator=DateAggregator(action=MERGE))`
[INFO] [2023-01-26 18:08:32]	c.b.c.m.q.r.ShardResult		FINISHED Query[DatasetDeletionTest[1].b20cbbaf-e989-4483-8843-8b40cd660918] with 0 results within PT0.005499S
[INFO] [2023-01-26 18:08:32]	c.b.c.m.q.r.ShardResult		FINISHED Query[DatasetDeletionTest[1].b20cbbaf-e989-4483-8843-8b40cd660918] with 2 results within PT0.005325S
[INFO] [2023-01-26 18:08:32]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=DatasetDeletionTest[1], name=DatasetDeletionTest[1]]	Received ShardResult(queryId=DatasetDeletionTest[1].b20cbbaf-e989-4483-8843-8b40cd660918, workerId=DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b, startTime=2023-01-26T18:08:32.840558, finishTime=2023-01-26T18:08:32.846057) of size 0
[DEBUG] [2023-01-26 18:08:32]	c.b.c.m.q.ManagedQuery	Dataset[label=DatasetDeletionTest[1], name=DatasetDeletionTest[1]]	Received Result[size=0] for Query[DatasetDeletionTest[1].b20cbbaf-e989-4483-8843-8b40cd660918]
[INFO] [2023-01-26 18:08:32]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=DatasetDeletionTest[1], name=DatasetDeletionTest[1]]	Received ShardResult(queryId=DatasetDeletionTest[1].b20cbbaf-e989-4483-8843-8b40cd660918, workerId=DatasetDeletionTest[1].worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e, startTime=2023-01-26T18:08:32.841195, finishTime=2023-01-26T18:08:32.846520) of size 2
[DEBUG] [2023-01-26 18:08:32]	c.b.c.m.q.ManagedQuery	Dataset[label=DatasetDeletionTest[1], name=DatasetDeletionTest[1]]	Received Result[size=2] for Query[DatasetDeletionTest[1].b20cbbaf-e989-4483-8843-8b40cd660918]
[INFO] [2023-01-26 18:08:32]	c.b.c.m.e.ManagedExecution	Dataset[label=DatasetDeletionTest[1], name=DatasetDeletionTest[1]]	DONE b20cbbaf-e989-4483-8843-8b40cd660918 ManagedQuery within PT0.015698S
127.0.0.1 - - [26/Jan/2023:18:08:32 +0000] "GET /api/datasets/DatasetDeletionTest%5B1%5D/queries/DatasetDeletionTest%5B1%5D.b20cbbaf-e989-4483-8843-8b40cd660918 HTTP/1.1" 200 1750 "-" "Conquery (test client)" 4
[INFO] [2023-01-26 18:08:32]	c.b.c.m.j.JobExecutor		Closing Job Manager fast DatasetDeletionTest[1]
[INFO] [2023-01-26 18:08:32]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node1	removing worker for Dataset[label=DatasetDeletionTest[1], name=DatasetDeletionTest[1]]
[INFO] [2023-01-26 18:08:32]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager fast worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e
[INFO] [2023-01-26 18:08:32]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node0	removing worker for Dataset[label=DatasetDeletionTest[1], name=DatasetDeletionTest[1]]
[INFO] [2023-01-26 18:08:32]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager fast worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b
[INFO] [2023-01-26 18:08:32]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager slow worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b
[INFO] [2023-01-26 18:08:32]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager slow worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b
[DEBUG] [2023-01-26 18:08:32]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e
[INFO] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node0	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_DatasetDeletionTest[1]_fdcd1200-32fc-4dd7-b7c2-64b464b08c2b
[INFO] [2023-01-26 18:08:32]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node1	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_DatasetDeletionTest[1]_330711c1-4514-4854-b42b-7d265aeed72e
[INFO] [2023-01-26 18:08:32]	c.b.c.m.j.JobExecutor		Closing Job Manager slow DatasetDeletionTest[1]
[INFO] [2023-01-26 18:08:33]	c.b.c.m.w.Namespace		Removing namespace storage of DatasetDeletionTest[1]
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.XodusStore		Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.XodusStore		Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.XodusStore		Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.XodusStore		Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.XodusStore		Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.XodusStore		Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.XodusStore		Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.XodusStore		Deleting store ID_MAPPING_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.XodusStore		Deleting store ID_MAPPING_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.XodusStore		Deleting store STRUCTURE from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.XodusStore		Deleting store WORKER_TO_BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.XodusStore		Deleting store PRIMARY_DICTIONARY from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]
[INFO] [2023-01-26 18:08:33]	c.b.c.m.c.XodusStoreFactory		Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_DatasetDeletionTest[1]
[INFO] [2023-01-26 18:08:33]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[INFO] [2023-01-26 18:08:33]	c.b.c.i.IntegrationTest$Wrapper	DatasetDeletionTest	SUCCESS integration test DatasetDeletionTest
[INFO] [2023-01-26 18:08:33]	c.b.c.i.IntegrationTest$Wrapper	ImportDeletionTest	STARTING integration test ImportDeletionTest
[INFO] [2023-01-26 18:08:33]	c.b.c.u.s.TestConquery	ImportDeletionTest	Setting up dataset
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.SerializingStore	ImportDeletionTest	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.CachedStore	ImportDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest:DATASET}): 0 entries, 0 B within 101.0 μs
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.SerializingStore	ImportDeletionTest	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.CachedStore	ImportDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest:SECONDARY_IDS}): 0 entries, 0 B within 52.41 μs
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.SerializingStore	ImportDeletionTest	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.CachedStore	ImportDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest:TABLES}): 0 entries, 0 B within 105.5 μs
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.SerializingStore	ImportDeletionTest	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.CachedStore	ImportDeletionTest		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 88.44 μs
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.SerializingStore	ImportDeletionTest	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.CachedStore	ImportDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest:IMPORTS}): 0 entries, 0 B within 37.53 μs
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.SerializingStore	ImportDeletionTest	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.CachedStore	ImportDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest:CONCEPTS}): 0 entries, 0 B within 34.38 μs
[INFO] [2023-01-26 18:08:33]	c.b.c.i.s.NamespacedStorage	ImportDeletionTest	Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.SerializingStore	ImportDeletionTest	While processing store ID_MAPPING_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.CachedStore	ImportDeletionTest		loaded store cached big ID_MAPPING(EntityIdMap): 0 entries, 0 B within 34.13 μs
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.SerializingStore	ImportDeletionTest	While processing store STRUCTURE:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.CachedStore	ImportDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest:STRUCTURE}): 0 entries, 0 B within 35.72 μs
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.SerializingStore	ImportDeletionTest	While processing store WORKER_TO_BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.CachedStore	ImportDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest:WORKER_TO_BUCKETS}): 0 entries, 0 B within 29.80 μs
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.SerializingStore	ImportDeletionTest	While processing store PRIMARY_DICTIONARY:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.CachedStore	ImportDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest:PRIMARY_DICTIONARY}): 0 entries, 0 B within 33.75 μs
[INFO] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.AddWorker	Job Manager slow shard-node1	creating a new worker for Dataset[label=ImportDeletionTest, name=ImportDeletionTest]
[INFO] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.AddWorker	Job Manager slow shard-node0	creating a new worker for Dataset[label=ImportDeletionTest, name=ImportDeletionTest]
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd:DATASET}): 0 entries, 0 B within 95.41 μs
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd:SECONDARY_IDS}): 0 entries, 0 B within 26.48 μs
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd:TABLES}): 0 entries, 0 B within 34.49 μs
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 36.99 μs
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd:IMPORTS}): 0 entries, 0 B within 25.00 μs
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd:CONCEPTS}): 0 entries, 0 B within 28.36 μs
[INFO] [2023-01-26 18:08:33]	c.b.c.i.s.NamespacedStorage	Job Manager slow shard-node1	Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store WORKER:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd:WORKER}): 0 entries, 0 B within 27.55 μs
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd:BUCKETS}): 0 entries, 0 B within 26.39 μs
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd:C_BLOCKS}): 0 entries, 0 B within 26.05 μs
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f:DATASET}): 0 entries, 0 B within 80.30 μs
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f:SECONDARY_IDS}): 0 entries, 0 B within 34.73 μs
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f:TABLES}): 0 entries, 0 B within 32.83 μs
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 37.53 μs
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f:IMPORTS}): 0 entries, 0 B within 40.27 μs
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f:CONCEPTS}): 0 entries, 0 B within 33.70 μs
[INFO] [2023-01-26 18:08:33]	c.b.c.i.s.NamespacedStorage	Job Manager slow shard-node0	Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store WORKER:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f:WORKER}): 0 entries, 0 B within 29.29 μs
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f:BUCKETS}): 0 entries, 0 B within 29.56 μs
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:33]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f:C_BLOCKS}): 0 entries, 0 B within 27.61 μs
[INFO] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=ImportDeletionTest]	Imports of worker ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=ImportDeletionTest]	Buckets of worker ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=ImportDeletionTest]	Consistency check was successful
[INFO] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=ImportDeletionTest]	Imports of worker ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=ImportDeletionTest]	Buckets of worker ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=ImportDeletionTest]	Consistency check was successful
[INFO] [2023-01-26 18:08:33]	c.b.c.u.s.TestConquery	ImportDeletionTest	Waiting for jobs to finish
[INFO] [2023-01-26 18:08:33]	c.b.c.u.s.TestConquery	ImportDeletionTest	Waiting for jobs to finish
[INFO] [2023-01-26 18:08:33]	c.b.c.u.s.TestConquery	ImportDeletionTest	Waiting for jobs to finish
[INFO] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.UpdateTable	Worker[ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd, /127.0.0.1:50284]	Received update of Table ImportDeletionTest.test_table
[INFO] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.UpdateTable	Worker[ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, /127.0.0.1:50286]	Received update of Table ImportDeletionTest.test_table
[INFO] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.UpdateTable	Worker[ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, /127.0.0.1:50286]	Received update of Table ImportDeletionTest.test_table2
[INFO] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.UpdateTable	Worker[ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd, /127.0.0.1:50284]	Received update of Table ImportDeletionTest.test_table2
[INFO] [2023-01-26 18:08:33]	c.b.c.u.s.TestConquery	ImportDeletionTest	Waiting for jobs to finish
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.WorkerStorage	Worker[ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, /127.0.0.1:50286]	Updating Concept[ImportDeletionTest.test_tree]
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.WorkerStorage	Worker[ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd, /127.0.0.1:50284]	Updating Concept[ImportDeletionTest.test_tree]
[INFO] [2023-01-26 18:08:33]	c.b.c.c.PreprocessorCommand	ImportDeletionTest	Preprocessing from command line config.
[INFO] [2023-01-26 18:08:33]	c.b.c.c.PreprocessorCommand	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ImportDeletionTest/test_table.import.json, tag=Optional.empty)	DOES NOT EXIST
[INFO] [2023-01-26 18:08:33]	c.b.c.c.PreprocessorCommand	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ImportDeletionTest/test_table2.import.json, tag=Optional.empty)	DOES NOT EXIST
[INFO] [2023-01-26 18:08:33]	c.b.c.c.PreprocessorCommand	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ImportDeletionTest/test_table2.import.json, tag=Optional.empty)	Required to preprocess 115 B in total
[INFO] [2023-01-26 18:08:33]	c.b.c.m.p.Preprocessor	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ImportDeletionTest/test_table.import.json, tag=Optional.empty)	PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ImportDeletionTest/test_table.import.json, tag=Optional.empty)
█████████████████████████                         ▌  50%	est. time remaining: 0.035847255s[INFO] [2023-01-26 18:08:33]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	Statistics = IntSummaryStatistics{count=2, sum=2, min=1, average=1.000000, max=1}
[INFO] [2023-01-26 18:08:33]	c.b.c.m.p.PPColumn	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=2, nullLines=0), encoding=null, prefix=, suffix=)
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.p.p.s.StringParser	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]		Chosen encoding is Base16UpperCase
[INFO] [2023-01-26 18:08:33]	c.b.c.m.p.PPColumn		Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=2, nullLines=0), subType=IntegerParser(super=Parser(lines=2, nullLines=0), minValue=15655, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@5ed20d81)
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.p.PPColumn			datum: DateParser(super=Parser(lines=2, nullLines=0), subType=IntegerParser(super=Parser(lines=2, nullLines=0), minValue=15655, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@5ed20d81) -> IntegerDateStore(store=ShortArrayStore())
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.p.p.s.StringParser	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]		Using com.bakdata.conquery.models.preproc.parser.specific.string.TrieTypeGuesser@68cb8583(est. 62 B)
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.p.PPColumn	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]		test_column: StringParser(super=Parser(lines=2, nullLines=0), encoding=Base16UpperCase, prefix=, suffix=) -> StringTypeEncoded(encoding=Base16UpperCase, subType=StringTypeDictionary(dictionary=SuccinctTrie[size=2], numberType=ByteArrayStore()))
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	Encode primary Dictionary
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	Writing Headers
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	Writing header
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	Writing Dictionaries
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	Writing data
[INFO] [2023-01-26 18:08:33]	c.b.c.m.p.Preprocessor	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ImportDeletionTest/test_table.import.json, tag=Optional.empty)
[INFO] [2023-01-26 18:08:33]	c.b.c.m.p.Preprocessor	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ImportDeletionTest/test_table2.import.json, tag=Optional.empty)	PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ImportDeletionTest/test_table2.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000677602s[INFO] [2023-01-26 18:08:33]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Statistics = IntSummaryStatistics{count=2, sum=2, min=1, average=1.000000, max=1}
[INFO] [2023-01-26 18:08:33]	c.b.c.m.p.PPColumn	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=2, nullLines=0), encoding=null, prefix=, suffix=)
[INFO] [2023-01-26 18:08:33]	c.b.c.m.p.PPColumn		Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=2, nullLines=0), subType=IntegerParser(super=Parser(lines=2, nullLines=0), minValue=14805, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@195ffbf8)
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.p.PPColumn			datum: DateParser(super=Parser(lines=2, nullLines=0), subType=IntegerParser(super=Parser(lines=2, nullLines=0), minValue=14805, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@195ffbf8) -> IntegerDateStore(store=ShortArrayStore())
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.p.p.s.StringParser	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]		Chosen encoding is Base16UpperCase
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.p.p.s.StringParser	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]		Using com.bakdata.conquery.models.preproc.parser.specific.string.TrieTypeGuesser@68398d77(est. 62 B)
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.p.PPColumn	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]		test_column: StringParser(super=Parser(lines=2, nullLines=0), encoding=Base16UpperCase, prefix=, suffix=) -> StringTypeEncoded(encoding=Base16UpperCase, subType=StringTypeDictionary(dictionary=SuccinctTrie[size=2], numberType=ByteArrayStore()))
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Encode primary Dictionary
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Writing Headers
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Writing header
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Writing Dictionaries
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Writing data
[INFO] [2023-01-26 18:08:33]	c.b.c.m.p.Preprocessor	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ImportDeletionTest/test_table2.import.json, tag=Optional.empty)
[INFO] [2023-01-26 18:08:33]	c.b.c.c.PreprocessorCommand		Successfully Preprocess 2 Jobs:
[INFO] [2023-01-26 18:08:33]	c.b.c.c.PreprocessorCommand			Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ImportDeletionTest/test_table.import.json, tag=Optional.empty)
[INFO] [2023-01-26 18:08:33]	c.b.c.c.PreprocessorCommand			Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ImportDeletionTest/test_table2.import.json, tag=Optional.empty)
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.j.ImportJob	user.SUPERUSER@SUPERUSER	Done reading data. Contains 2 Entities.
[INFO] [2023-01-26 18:08:33]	c.b.c.m.j.ImportJob	user.SUPERUSER@SUPERUSER	Importing test_table into ImportDeletionTest.test_table
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.j.ImportJob	Job Manager slow ImportDeletionTest	Mapped 2 new ids
127.0.0.1 - - [26/Jan/2023:18:08:33 +0000] "POST /admin/datasets/ImportDeletionTest/imports?file=%2Ftmp%2FconqueryIntegrationTest12910953884258704183%2Ftmp_ImportDeletionTest%2Ftest_table.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 11
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.j.ImportJob	Job Manager slow ImportDeletionTest	Updating bucket assignments.
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.w.Namespace	Job Manager slow ImportDeletionTest	Assigning Bucket[0] to Worker[ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f]
[INFO] [2023-01-26 18:08:33]	c.b.c.m.j.ImportJob	Job Manager slow ImportDeletionTest	Importing Dictionaries
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.UpdateWorkerBucket	Worker[ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd, /127.0.0.1:50284]	Received new WorkerInformation(size = 0,dataset = ImportDeletionTest)
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.UpdateWorkerBucket	Worker[ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, /127.0.0.1:50286]	Received new WorkerInformation(size = 1,dataset = ImportDeletionTest)
[INFO] [2023-01-26 18:08:33]	c.b.c.m.j.ImportJob	Job Manager slow ImportDeletionTest	Remapping Dictionaries []
[WARN] [2023-01-26 18:08:33]	c.b.c.u.p.ProgressReporterImpl	Job Manager slow ImportDeletionTest	Max cannot be decreased.
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.UpdateDictionary	Worker[ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd, /127.0.0.1:50284]	Received Dictionary[ImportDeletionTest.test_table#ImportDeletionTest$2etest_table$2etest_column] of size 2.
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.UpdateDictionary	Worker[ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, /127.0.0.1:50286]	Received Dictionary[ImportDeletionTest.test_table#ImportDeletionTest$2etest_table$2etest_column] of size 2.
[INFO] [2023-01-26 18:08:33]	c.b.c.m.j.ImportJob	Job Manager slow ImportDeletionTest	Start sending 1 Buckets
[WARN] [2023-01-26 18:08:33]	c.b.c.u.p.ProgressReporterImpl	Job Manager slow ImportDeletionTest	One or more Children are not done yet
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.j.ImportJob	user.SUPERUSER@SUPERUSER	Done reading data. Contains 2 Entities.
[INFO] [2023-01-26 18:08:33]	c.b.c.m.j.ImportJob	user.SUPERUSER@SUPERUSER	Importing test_table2 into ImportDeletionTest.test_table2
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.j.ImportJob	Job Manager slow ImportDeletionTest	Mapped 2 new ids
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.j.ImportJob	Job Manager slow ImportDeletionTest	Updating bucket assignments.
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.w.Namespace	Job Manager slow ImportDeletionTest	Assigning Bucket[1] to Worker[ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd]
[INFO] [2023-01-26 18:08:33]	c.b.c.m.j.ImportJob	Job Manager slow ImportDeletionTest	Importing Dictionaries
127.0.0.1 - - [26/Jan/2023:18:08:33 +0000] "POST /admin/datasets/ImportDeletionTest/imports?file=%2Ftmp%2FconqueryIntegrationTest12910953884258704183%2Ftmp_ImportDeletionTest%2Ftest_table2.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
[INFO] [2023-01-26 18:08:33]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.UpdateWorkerBucket	Worker[ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, /127.0.0.1:50286]	Received new WorkerInformation(size = 1,dataset = ImportDeletionTest)
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.UpdateWorkerBucket	Worker[ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd, /127.0.0.1:50284]	Received new WorkerInformation(size = 1,dataset = ImportDeletionTest)
[INFO] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.AddImport	Worker[ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd, /127.0.0.1:50284]	Received Import[ImportDeletionTest.test_table.test_table], containing 2 entries.
[INFO] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.AddImport	Worker[ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, /127.0.0.1:50286]	Received Import[ImportDeletionTest.test_table.test_table], containing 2 entries.
[INFO] [2023-01-26 18:08:33]	c.b.c.m.j.ImportJob	Job Manager slow ImportDeletionTest	Remapping Dictionaries []
[WARN] [2023-01-26 18:08:33]	c.b.c.u.p.ProgressReporterImpl	Job Manager slow ImportDeletionTest	Max cannot be decreased.
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.UpdateDictionary	Worker[ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd, /127.0.0.1:50284]	Received Dictionary[ImportDeletionTest.test_table2#ImportDeletionTest$2etest_table2$2etest_column] of size 2.
[INFO] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.ImportBucket	Worker[ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, /127.0.0.1:50286]	Received ImportDeletionTest.test_table.test_table.0
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.WorkerStorage	Worker[ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, /127.0.0.1:50286]	Adding Bucket[ImportDeletionTest.test_table.test_table.0]
[INFO] [2023-01-26 18:08:33]	c.b.c.m.j.ImportJob	Job Manager slow ImportDeletionTest	Start sending 2 Buckets
[WARN] [2023-01-26 18:08:33]	c.b.c.u.p.ProgressReporterImpl	Job Manager slow ImportDeletionTest	One or more Children are not done yet
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.UpdateDictionary	Worker[ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, /127.0.0.1:50286]	Received Dictionary[ImportDeletionTest.test_table2#ImportDeletionTest$2etest_table2$2etest_column] of size 2.
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.WorkerStorage		Adding CBlock[ImportDeletionTest.test_table.test_table.0.ImportDeletionTest.test_tree.test_column]
[INFO] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.AddImport	Worker[ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd, /127.0.0.1:50284]	Received Import[ImportDeletionTest.test_table2.test_table2], containing 2 entries.
[INFO] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.ImportBucket	Worker[ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd, /127.0.0.1:50284]	Received ImportDeletionTest.test_table2.test_table2.1
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.WorkerStorage	Worker[ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd, /127.0.0.1:50284]	Adding Bucket[ImportDeletionTest.test_table2.test_table2.1]
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.WorkerStorage		Adding CBlock[ImportDeletionTest.test_table2.test_table2.1.ImportDeletionTest.test_tree.test_column2]
[INFO] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.AddImport	Worker[ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, /127.0.0.1:50286]	Received Import[ImportDeletionTest.test_table2.test_table2], containing 2 entries.
[INFO] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.ImportBucket	Worker[ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, /127.0.0.1:50286]	Received ImportDeletionTest.test_table2.test_table2.0
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.WorkerStorage	Worker[ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, /127.0.0.1:50286]	Adding Bucket[ImportDeletionTest.test_table2.test_table2.0]
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.WorkerStorage		Adding CBlock[ImportDeletionTest.test_table2.test_table2.0.ImportDeletionTest.test_tree.test_column2]
[INFO] [2023-01-26 18:08:33]	c.b.c.i.t.d.ImportDeletionTest		Checking state before deletion
[INFO] [2023-01-26 18:08:33]	c.b.c.i.t.d.ImportDeletionTest		Executing query before deletion
[INFO] [2023-01-26 18:08:33]	c.b.c.a.QueryProcessor	user.SUPERUSER@SUPERUSER	Query posted on Dataset[ImportDeletionTest] by User[{user.SUPERUSER@SUPERUSER].
[INFO] [2023-01-26 18:08:33]	c.b.c.m.q.ExecutionManager	user.SUPERUSER@SUPERUSER	Executing Query[0ea86b20-2d41-43d4-b6be-620d1ee8a9f5] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_ImportDeletionTest))]]
[INFO] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, /127.0.0.1:50286]	Started ConceptQuery ImportDeletionTest.0ea86b20-2d41-43d4-b6be-620d1ee8a9f5
[INFO] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd, /127.0.0.1:50284]	Started ConceptQuery ImportDeletionTest.0ea86b20-2d41-43d4-b6be-620d1ee8a9f5
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.q.QueryExecutor	Worker[ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, /127.0.0.1:50286]	QueryPlan for Query[ImportDeletionTest.0ea86b20-2d41-43d4-b6be-620d1ee8a9f5] = `ConceptQueryPlan(child=QPParentNode(children=[ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table, name=test_table]])])), validityDateColumn=Column(id = ImportDeletionTest.test_table.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column], dateColumn=null), selectedSecondaryId=null), ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table2, name=test_table2]])])), validityDateColumn=Column(id = ImportDeletionTest.test_table2.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column2], dateColumn=null), selectedSecondaryId=null)]), dateAggregator=DateAggregator(action=MERGE))`
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.q.QueryExecutor	Worker[ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd, /127.0.0.1:50284]	QueryPlan for Query[ImportDeletionTest.0ea86b20-2d41-43d4-b6be-620d1ee8a9f5] = `ConceptQueryPlan(child=QPParentNode(children=[ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table, name=test_table]])])), validityDateColumn=Column(id = ImportDeletionTest.test_table.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column], dateColumn=null), selectedSecondaryId=null), ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table2, name=test_table2]])])), validityDateColumn=Column(id = ImportDeletionTest.test_table2.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column2], dateColumn=null), selectedSecondaryId=null)]), dateAggregator=DateAggregator(action=MERGE))`
[INFO] [2023-01-26 18:08:33]	c.b.c.m.q.r.ShardResult		FINISHED Query[ImportDeletionTest.0ea86b20-2d41-43d4-b6be-620d1ee8a9f5] with 0 results within PT0.000713S
[INFO] [2023-01-26 18:08:33]	c.b.c.m.q.r.ShardResult		FINISHED Query[ImportDeletionTest.0ea86b20-2d41-43d4-b6be-620d1ee8a9f5] with 2 results within PT0.00103S
127.0.0.1 - - [26/Jan/2023:18:08:33 +0000] "POST /api/datasets/ImportDeletionTest/queries HTTP/1.1" 201 1214 "-" "Conquery (test client)" 7
[INFO] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=ImportDeletionTest]	Received ShardResult(queryId=ImportDeletionTest.0ea86b20-2d41-43d4-b6be-620d1ee8a9f5, workerId=ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd, startTime=2023-01-26T18:08:33.928300, finishTime=2023-01-26T18:08:33.929013) of size 0
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=ImportDeletionTest]	Received Result[size=0] for Query[ImportDeletionTest.0ea86b20-2d41-43d4-b6be-620d1ee8a9f5]
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.c.IntegrationUtils		Trying to get Query result
[INFO] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=ImportDeletionTest]	Received ShardResult(queryId=ImportDeletionTest.0ea86b20-2d41-43d4-b6be-620d1ee8a9f5, workerId=ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, startTime=2023-01-26T18:08:33.928222, finishTime=2023-01-26T18:08:33.929252) of size 2
[DEBUG] [2023-01-26 18:08:33]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=ImportDeletionTest]	Received Result[size=2] for Query[ImportDeletionTest.0ea86b20-2d41-43d4-b6be-620d1ee8a9f5]
[INFO] [2023-01-26 18:08:33]	c.b.c.m.e.ManagedExecution	Dataset[label=null, name=ImportDeletionTest]	DONE 0ea86b20-2d41-43d4-b6be-620d1ee8a9f5 ManagedQuery within PT0.004731S
127.0.0.1 - - [26/Jan/2023:18:08:33 +0000] "GET /api/datasets/ImportDeletionTest/queries/ImportDeletionTest.0ea86b20-2d41-43d4-b6be-620d1ee8a9f5 HTTP/1.1" 200 1477 "-" "Conquery (test client)" 3
[INFO] [2023-01-26 18:08:33]	c.b.c.i.t.d.ImportDeletionTest		Issuing deletion of import ImportDeletionTest.test_table2.test_table2
127.0.0.1 - - [26/Jan/2023:18:08:33 +0000] "DELETE /admin/datasets/ImportDeletionTest/tables/ImportDeletionTest.test_table2/imports/ImportDeletionTest.test_table2.test_table2 HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
[INFO] [2023-01-26 18:08:33]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[INFO] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.RemoveImportJob	Worker[ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd, /127.0.0.1:50284]	Deleting Import[NamedImpl(name=test_table2)]
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.WorkerStorage	Worker[ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd, /127.0.0.1:50284]	Removing CBlock[ImportDeletionTest.test_table2.test_table2.1.ImportDeletionTest.test_tree.test_column2]
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.WorkerStorage	Worker[ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd, /127.0.0.1:50284]	Removing Bucket[ImportDeletionTest.test_table2.test_table2.1]
[INFO] [2023-01-26 18:08:33]	c.b.c.m.m.n.s.RemoveImportJob	Worker[ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, /127.0.0.1:50286]	Deleting Import[NamedImpl(name=test_table2)]
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.WorkerStorage	Worker[ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, /127.0.0.1:50286]	Removing CBlock[ImportDeletionTest.test_table2.test_table2.0.ImportDeletionTest.test_tree.test_column2]
[DEBUG] [2023-01-26 18:08:33]	c.b.c.i.s.WorkerStorage	Worker[ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, /127.0.0.1:50286]	Removing Bucket[ImportDeletionTest.test_table2.test_table2.0]
[INFO] [2023-01-26 18:08:34]	c.b.c.i.t.d.ImportDeletionTest		Checking state after deletion
[INFO] [2023-01-26 18:08:34]	c.b.c.i.t.d.ImportDeletionTest		Executing query after deletion
[INFO] [2023-01-26 18:08:34]	c.b.c.a.QueryProcessor	user.SUPERUSER@SUPERUSER	Query posted on Dataset[ImportDeletionTest] by User[{user.SUPERUSER@SUPERUSER].
[INFO] [2023-01-26 18:08:34]	c.b.c.m.q.ExecutionManager	user.SUPERUSER@SUPERUSER	Executing Query[6230c72e-a07b-4c5c-900b-2bda37dc6b67] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_ImportDeletionTest))]]
[INFO] [2023-01-26 18:08:34]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, /127.0.0.1:50286]	Started ConceptQuery ImportDeletionTest.6230c72e-a07b-4c5c-900b-2bda37dc6b67
[INFO] [2023-01-26 18:08:34]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd, /127.0.0.1:50284]	Started ConceptQuery ImportDeletionTest.6230c72e-a07b-4c5c-900b-2bda37dc6b67
[DEBUG] [2023-01-26 18:08:34]	c.b.c.m.q.QueryExecutor	Worker[ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, /127.0.0.1:50286]	QueryPlan for Query[ImportDeletionTest.6230c72e-a07b-4c5c-900b-2bda37dc6b67] = `ConceptQueryPlan(child=QPParentNode(children=[ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table, name=test_table]])])), validityDateColumn=Column(id = ImportDeletionTest.test_table.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column], dateColumn=null), selectedSecondaryId=null), ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table2, name=test_table2]])])), validityDateColumn=Column(id = ImportDeletionTest.test_table2.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column2], dateColumn=null), selectedSecondaryId=null)]), dateAggregator=DateAggregator(action=MERGE))`
[DEBUG] [2023-01-26 18:08:34]	c.b.c.m.q.QueryExecutor	Worker[ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd, /127.0.0.1:50284]	QueryPlan for Query[ImportDeletionTest.6230c72e-a07b-4c5c-900b-2bda37dc6b67] = `ConceptQueryPlan(child=QPParentNode(children=[ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table, name=test_table]])])), validityDateColumn=Column(id = ImportDeletionTest.test_table.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column], dateColumn=null), selectedSecondaryId=null), ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table2, name=test_table2]])])), validityDateColumn=Column(id = ImportDeletionTest.test_table2.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column2], dateColumn=null), selectedSecondaryId=null)]), dateAggregator=DateAggregator(action=MERGE))`
[INFO] [2023-01-26 18:08:34]	c.b.c.m.q.r.ShardResult		FINISHED Query[ImportDeletionTest.6230c72e-a07b-4c5c-900b-2bda37dc6b67] with 0 results within PT0.001448S
127.0.0.1 - - [26/Jan/2023:18:08:34 +0000] "POST /api/datasets/ImportDeletionTest/queries HTTP/1.1" 201 1213 "-" "Conquery (test client)" 6
[INFO] [2023-01-26 18:08:34]	c.b.c.m.q.r.ShardResult		FINISHED Query[ImportDeletionTest.6230c72e-a07b-4c5c-900b-2bda37dc6b67] with 1 results within PT0.001698S
[DEBUG] [2023-01-26 18:08:34]	c.b.c.i.c.IntegrationUtils		Trying to get Query result
[INFO] [2023-01-26 18:08:34]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=ImportDeletionTest]	Received ShardResult(queryId=ImportDeletionTest.6230c72e-a07b-4c5c-900b-2bda37dc6b67, workerId=ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd, startTime=2023-01-26T18:08:34.082421, finishTime=2023-01-26T18:08:34.083869) of size 0
[DEBUG] [2023-01-26 18:08:34]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=ImportDeletionTest]	Received Result[size=0] for Query[ImportDeletionTest.6230c72e-a07b-4c5c-900b-2bda37dc6b67]
[INFO] [2023-01-26 18:08:34]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=ImportDeletionTest]	Received ShardResult(queryId=ImportDeletionTest.6230c72e-a07b-4c5c-900b-2bda37dc6b67, workerId=ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, startTime=2023-01-26T18:08:34.082359, finishTime=2023-01-26T18:08:34.084057) of size 1
[DEBUG] [2023-01-26 18:08:34]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=ImportDeletionTest]	Received Result[size=1] for Query[ImportDeletionTest.6230c72e-a07b-4c5c-900b-2bda37dc6b67]
[INFO] [2023-01-26 18:08:34]	c.b.c.m.e.ManagedExecution	Dataset[label=null, name=ImportDeletionTest]	DONE 6230c72e-a07b-4c5c-900b-2bda37dc6b67 ManagedQuery within PT0.005531S
127.0.0.1 - - [26/Jan/2023:18:08:34 +0000] "GET /api/datasets/ImportDeletionTest/queries/ImportDeletionTest.6230c72e-a07b-4c5c-900b-2bda37dc6b67 HTTP/1.1" 200 1476 "-" "Conquery (test client)" 3
[INFO] [2023-01-26 18:08:34]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[INFO] [2023-01-26 18:08:34]	c.b.c.c.PreprocessorCommand		Preprocessing from command line config.
[INFO] [2023-01-26 18:08:34]	c.b.c.c.PreprocessorCommand	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ImportDeletionTest/test_table2.import.json, tag=Optional.empty)	EXISTS ALREADY
[INFO] [2023-01-26 18:08:34]	c.b.c.c.PreprocessorCommand	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ImportDeletionTest/test_table2.import.json, tag=Optional.empty)		HASH OUTDATED
[INFO] [2023-01-26 18:08:34]	c.b.c.c.PreprocessorCommand	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ImportDeletionTest/test_table2.import.json, tag=Optional.empty)	Required to preprocess 75 B in total
[INFO] [2023-01-26 18:08:34]	c.b.c.m.p.Preprocessor	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ImportDeletionTest/test_table2.import.json, tag=Optional.empty)	PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ImportDeletionTest/test_table2.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000489531s[INFO] [2023-01-26 18:08:34]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Statistics = IntSummaryStatistics{count=2, sum=3, min=1, average=1.500000, max=2}
[INFO] [2023-01-26 18:08:34]	c.b.c.m.p.PPColumn	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=3, nullLines=0), encoding=null, prefix=, suffix=)
[DEBUG] [2023-01-26 18:08:34]	c.b.c.m.p.p.s.StringParser	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]		Chosen encoding is Base16UpperCase
[INFO] [2023-01-26 18:08:34]	c.b.c.m.p.PPColumn		Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=3, nullLines=0), subType=IntegerParser(super=Parser(lines=3, nullLines=0), minValue=14805, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@5c65a1ba)
[DEBUG] [2023-01-26 18:08:34]	c.b.c.m.p.PPColumn			datum: DateParser(super=Parser(lines=3, nullLines=0), subType=IntegerParser(super=Parser(lines=3, nullLines=0), minValue=14805, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@5c65a1ba) -> IntegerDateStore(store=ShortArrayStore())
[DEBUG] [2023-01-26 18:08:34]	c.b.c.m.p.p.s.StringParser	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]		Using com.bakdata.conquery.models.preproc.parser.specific.string.TrieTypeGuesser@12441cdc(est. 80 B)
[DEBUG] [2023-01-26 18:08:34]	c.b.c.m.p.PPColumn	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]		test_column: StringParser(super=Parser(lines=3, nullLines=0), encoding=Base16UpperCase, prefix=, suffix=) -> StringTypeEncoded(encoding=Base16UpperCase, subType=StringTypeDictionary(dictionary=SuccinctTrie[size=3], numberType=ByteArrayStore()))
[DEBUG] [2023-01-26 18:08:34]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Encode primary Dictionary
[DEBUG] [2023-01-26 18:08:34]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Writing Headers
[DEBUG] [2023-01-26 18:08:34]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Writing header
[DEBUG] [2023-01-26 18:08:34]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Writing Dictionaries
[DEBUG] [2023-01-26 18:08:34]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Writing data
[INFO] [2023-01-26 18:08:34]	c.b.c.m.p.Preprocessor	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ImportDeletionTest/test_table2.import.json, tag=Optional.empty)
[INFO] [2023-01-26 18:08:34]	c.b.c.c.PreprocessorCommand		Successfully Preprocess 1 Jobs:
[INFO] [2023-01-26 18:08:34]	c.b.c.c.PreprocessorCommand			Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_ImportDeletionTest/test_table2.import.json, tag=Optional.empty)
[DEBUG] [2023-01-26 18:08:34]	c.b.c.m.j.ImportJob		Done reading data. Contains 2 Entities.
[INFO] [2023-01-26 18:08:34]	c.b.c.m.j.ImportJob		Importing test_table2 into ImportDeletionTest.test_table2
[INFO] [2023-01-26 18:08:34]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[DEBUG] [2023-01-26 18:08:34]	c.b.c.m.j.ImportJob	Job Manager slow ImportDeletionTest	Mapped 0 new ids
[DEBUG] [2023-01-26 18:08:34]	c.b.c.m.j.ImportJob	Job Manager slow ImportDeletionTest	Updating bucket assignments.
[INFO] [2023-01-26 18:08:34]	c.b.c.m.j.ImportJob	Job Manager slow ImportDeletionTest	Importing Dictionaries
[DEBUG] [2023-01-26 18:08:34]	c.b.c.m.m.n.s.UpdateWorkerBucket	Worker[ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd, /127.0.0.1:50284]	Received new WorkerInformation(size = 1,dataset = ImportDeletionTest)
[DEBUG] [2023-01-26 18:08:34]	c.b.c.m.m.n.s.UpdateWorkerBucket	Worker[ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, /127.0.0.1:50286]	Received new WorkerInformation(size = 1,dataset = ImportDeletionTest)
[INFO] [2023-01-26 18:08:34]	c.b.c.m.j.ImportJob	Job Manager slow ImportDeletionTest	Remapping Dictionaries []
[WARN] [2023-01-26 18:08:34]	c.b.c.u.p.ProgressReporterImpl	Job Manager slow ImportDeletionTest	Max cannot be decreased.
[DEBUG] [2023-01-26 18:08:34]	c.b.c.m.m.n.s.UpdateDictionary	Worker[ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, /127.0.0.1:50286]	Received Dictionary[ImportDeletionTest.test_table2#ImportDeletionTest$2etest_table2$2etest_column] of size 3.
[DEBUG] [2023-01-26 18:08:34]	c.b.c.m.m.n.s.UpdateDictionary	Worker[ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd, /127.0.0.1:50284]	Received Dictionary[ImportDeletionTest.test_table2#ImportDeletionTest$2etest_table2$2etest_column] of size 3.
[INFO] [2023-01-26 18:08:34]	c.b.c.m.j.ImportJob	Job Manager slow ImportDeletionTest	Start sending 2 Buckets
[WARN] [2023-01-26 18:08:34]	c.b.c.u.p.ProgressReporterImpl	Job Manager slow ImportDeletionTest	One or more Children are not done yet
[INFO] [2023-01-26 18:08:34]	c.b.c.m.m.n.s.AddImport	Worker[ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd, /127.0.0.1:50284]	Received Import[ImportDeletionTest.test_table2.test_table2], containing 3 entries.
[INFO] [2023-01-26 18:08:34]	c.b.c.m.m.n.s.AddImport	Worker[ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, /127.0.0.1:50286]	Received Import[ImportDeletionTest.test_table2.test_table2], containing 3 entries.
[INFO] [2023-01-26 18:08:34]	c.b.c.m.m.n.s.ImportBucket	Worker[ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd, /127.0.0.1:50284]	Received ImportDeletionTest.test_table2.test_table2.1
[DEBUG] [2023-01-26 18:08:34]	c.b.c.i.s.WorkerStorage	Worker[ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd, /127.0.0.1:50284]	Adding Bucket[ImportDeletionTest.test_table2.test_table2.1]
[INFO] [2023-01-26 18:08:34]	c.b.c.m.m.n.s.ImportBucket	Worker[ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, /127.0.0.1:50286]	Received ImportDeletionTest.test_table2.test_table2.0
[DEBUG] [2023-01-26 18:08:34]	c.b.c.i.s.WorkerStorage	Worker[ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, /127.0.0.1:50286]	Adding Bucket[ImportDeletionTest.test_table2.test_table2.0]
[DEBUG] [2023-01-26 18:08:34]	c.b.c.i.s.WorkerStorage		Adding CBlock[ImportDeletionTest.test_table2.test_table2.1.ImportDeletionTest.test_tree.test_column2]
[DEBUG] [2023-01-26 18:08:34]	c.b.c.i.s.WorkerStorage		Adding CBlock[ImportDeletionTest.test_table2.test_table2.0.ImportDeletionTest.test_tree.test_column2]
[INFO] [2023-01-26 18:08:34]	c.b.c.i.t.d.ImportDeletionTest		Checking state after re-import
[INFO] [2023-01-26 18:08:34]	c.b.c.i.t.d.ImportDeletionTest		Executing query after re-import
[INFO] [2023-01-26 18:08:34]	c.b.c.a.QueryProcessor	user.SUPERUSER@SUPERUSER	Query posted on Dataset[ImportDeletionTest] by User[{user.SUPERUSER@SUPERUSER].
[INFO] [2023-01-26 18:08:34]	c.b.c.m.q.ExecutionManager	user.SUPERUSER@SUPERUSER	Executing Query[20acbbe2-72a5-4f6c-8980-7a857198ade3] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_ImportDeletionTest))]]
[INFO] [2023-01-26 18:08:34]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd, /127.0.0.1:50284]	Started ConceptQuery ImportDeletionTest.20acbbe2-72a5-4f6c-8980-7a857198ade3
[INFO] [2023-01-26 18:08:34]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, /127.0.0.1:50286]	Started ConceptQuery ImportDeletionTest.20acbbe2-72a5-4f6c-8980-7a857198ade3
[DEBUG] [2023-01-26 18:08:34]	c.b.c.m.q.QueryExecutor	Worker[ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd, /127.0.0.1:50284]	QueryPlan for Query[ImportDeletionTest.20acbbe2-72a5-4f6c-8980-7a857198ade3] = `ConceptQueryPlan(child=QPParentNode(children=[ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table, name=test_table]])])), validityDateColumn=Column(id = ImportDeletionTest.test_table.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column], dateColumn=null), selectedSecondaryId=null), ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table2, name=test_table2]])])), validityDateColumn=Column(id = ImportDeletionTest.test_table2.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column2], dateColumn=null), selectedSecondaryId=null)]), dateAggregator=DateAggregator(action=MERGE))`
[DEBUG] [2023-01-26 18:08:34]	c.b.c.m.q.QueryExecutor	Worker[ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, /127.0.0.1:50286]	QueryPlan for Query[ImportDeletionTest.20acbbe2-72a5-4f6c-8980-7a857198ade3] = `ConceptQueryPlan(child=QPParentNode(children=[ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table, name=test_table]])])), validityDateColumn=Column(id = ImportDeletionTest.test_table.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column], dateColumn=null), selectedSecondaryId=null), ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table2, name=test_table2]])])), validityDateColumn=Column(id = ImportDeletionTest.test_table2.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column2], dateColumn=null), selectedSecondaryId=null)]), dateAggregator=DateAggregator(action=MERGE))`
[INFO] [2023-01-26 18:08:34]	c.b.c.m.q.r.ShardResult		FINISHED Query[ImportDeletionTest.20acbbe2-72a5-4f6c-8980-7a857198ade3] with 0 results within PT0.000905S
127.0.0.1 - - [26/Jan/2023:18:08:34 +0000] "POST /api/datasets/ImportDeletionTest/queries HTTP/1.1" 201 1213 "-" "Conquery (test client)" 5
[INFO] [2023-01-26 18:08:34]	c.b.c.m.q.r.ShardResult		FINISHED Query[ImportDeletionTest.20acbbe2-72a5-4f6c-8980-7a857198ade3] with 2 results within PT0.001545S
[INFO] [2023-01-26 18:08:34]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=ImportDeletionTest]	Received ShardResult(queryId=ImportDeletionTest.20acbbe2-72a5-4f6c-8980-7a857198ade3, workerId=ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd, startTime=2023-01-26T18:08:34.396043, finishTime=2023-01-26T18:08:34.396948) of size 0
[DEBUG] [2023-01-26 18:08:34]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=ImportDeletionTest]	Received Result[size=0] for Query[ImportDeletionTest.20acbbe2-72a5-4f6c-8980-7a857198ade3]
[DEBUG] [2023-01-26 18:08:34]	c.b.c.i.c.IntegrationUtils		Trying to get Query result
[INFO] [2023-01-26 18:08:34]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=ImportDeletionTest]	Received ShardResult(queryId=ImportDeletionTest.20acbbe2-72a5-4f6c-8980-7a857198ade3, workerId=ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, startTime=2023-01-26T18:08:34.396036, finishTime=2023-01-26T18:08:34.397581) of size 2
[DEBUG] [2023-01-26 18:08:34]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=ImportDeletionTest]	Received Result[size=2] for Query[ImportDeletionTest.20acbbe2-72a5-4f6c-8980-7a857198ade3]
[INFO] [2023-01-26 18:08:34]	c.b.c.m.e.ManagedExecution	Dataset[label=null, name=ImportDeletionTest]	DONE 20acbbe2-72a5-4f6c-8980-7a857198ade3 ManagedQuery within PT0.003512S
127.0.0.1 - - [26/Jan/2023:18:08:34 +0000] "GET /api/datasets/ImportDeletionTest/queries/ImportDeletionTest.20acbbe2-72a5-4f6c-8980-7a857198ade3 HTTP/1.1" 200 1475 "-" "Conquery (test client)" 2
[INFO] [2023-01-26 18:08:34]	c.b.c.m.j.JobExecutor		Closing Job Manager fast shard-node0
[INFO] [2023-01-26 18:08:34]	c.b.c.m.j.JobExecutor		Closing Job Manager slow shard-node0
[INFO] [2023-01-26 18:08:34]	c.b.c.m.j.JobExecutor		Closing Job Manager fast worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f
[INFO] [2023-01-26 18:08:34]	c.b.c.m.j.JobExecutor		Closing Job Manager slow worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f
[INFO] [2023-01-26 18:08:34]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f:DATASET}
[INFO] [2023-01-26 18:08:34]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f:SECONDARY_IDS}
[INFO] [2023-01-26 18:08:34]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f:TABLES}
[INFO] [2023-01-26 18:08:34]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f:DICTIONARIES_META}
[INFO] [2023-01-26 18:08:34]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f:DICTIONARIES_DATA}
[INFO] [2023-01-26 18:08:34]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f:IMPORTS}
[INFO] [2023-01-26 18:08:34]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f:CONCEPTS}
[INFO] [2023-01-26 18:08:34]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f:WORKER}
[INFO] [2023-01-26 18:08:34]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f:BUCKETS}
[INFO] [2023-01-26 18:08:34]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f:C_BLOCKS}
[INFO] [2023-01-26 18:08:34]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f
[INFO] [2023-01-26 18:08:34]	c.b.c.c.ShardNode		Connection was closed by ManagerNode
[INFO] [2023-01-26 18:08:34]	c.b.c.c.ShardNode	0.0.0.0/0.0.0.0:50286	Disconnected from ManagerNode
[INFO] [2023-01-26 18:08:34]	c.b.c.c.ManagerNode	ManagerNode[0.0.0.0/0.0.0.0:34233]	Client 'null' disconnected 
[INFO] [2023-01-26 18:08:34]	c.b.c.m.j.JobExecutor		Closing Job Manager fast shard-node1
[INFO] [2023-01-26 18:08:34]	c.b.c.m.j.JobExecutor		Closing Job Manager slow shard-node1
[INFO] [2023-01-26 18:08:34]	c.b.c.m.j.JobExecutor		Closing Job Manager fast worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd
[INFO] [2023-01-26 18:08:34]	c.b.c.m.j.JobExecutor		Closing Job Manager slow worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd
[INFO] [2023-01-26 18:08:34]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd:DATASET}
[INFO] [2023-01-26 18:08:34]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd:SECONDARY_IDS}
[INFO] [2023-01-26 18:08:34]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd:TABLES}
[INFO] [2023-01-26 18:08:34]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd:DICTIONARIES_META}
[INFO] [2023-01-26 18:08:34]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd:DICTIONARIES_DATA}
[INFO] [2023-01-26 18:08:34]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd:IMPORTS}
[INFO] [2023-01-26 18:08:34]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd:CONCEPTS}
[INFO] [2023-01-26 18:08:34]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd:WORKER}
[INFO] [2023-01-26 18:08:34]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd:BUCKETS}
[INFO] [2023-01-26 18:08:34]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd:C_BLOCKS}
[INFO] [2023-01-26 18:08:34]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd
[INFO] [2023-01-26 18:08:34]	c.b.c.c.ShardNode		Connection was closed by ManagerNode
[INFO] [2023-01-26 18:08:34]	c.b.c.c.ShardNode	0.0.0.0/0.0.0.0:50284	Disconnected from ManagerNode
[INFO] [2023-01-26 18:08:34]	c.b.c.m.j.JobExecutor		Closing Job Manager fast ManagerNode
[INFO] [2023-01-26 18:08:34]	c.b.c.c.ManagerNode	ManagerNode[0.0.0.0/0.0.0.0:34233]	Client 'null' disconnected 
[INFO] [2023-01-26 18:08:34]	c.b.c.m.j.JobExecutor		Closing Job Manager slow ManagerNode
[INFO] [2023-01-26 18:08:34]	c.b.c.m.j.JobExecutor		Closing Job Manager fast ImportDeletionTest
[INFO] [2023-01-26 18:08:35]	c.b.c.m.j.JobExecutor		Closing Job Manager slow ImportDeletionTest
[INFO] [2023-01-26 18:08:35]	c.b.c.m.w.Namespace		Closing namespace storage of ImportDeletionTest
[INFO] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest:DATASET}
[INFO] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest:SECONDARY_IDS}
[INFO] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest:TABLES}
[INFO] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest:DICTIONARIES_META}
[INFO] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest:DICTIONARIES_DATA}
[INFO] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest:IMPORTS}
[INFO] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest:CONCEPTS}
[INFO] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest:ID_MAPPING_META}
[INFO] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest:ID_MAPPING_DATA}
[INFO] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest:STRUCTURE}
[INFO] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest:WORKER_TO_BUCKETS}
[INFO] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest:PRIMARY_DICTIONARY}
[INFO] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest
[INFO] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/executions:EXECUTIONS}
[INFO] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/executions
[INFO] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/formConfigs:FORM_CONFIG}
[INFO] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/formConfigs
[INFO] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/users:AUTH_USER}
[INFO] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/users
[INFO] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/roles:AUTH_ROLE}
[INFO] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/roles
[INFO] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/groups:AUTH_GROUP}
[INFO] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/groups
[INFO] [2023-01-26 18:08:35]	c.b.c.u.s.TestConquery		Working in temporary directory /tmp/conqueryIntegrationTest12910953884258704183
[DEBUG] [2023-01-26 18:08:35]	c.b.c.c.StandaloneCommand	ManagerNode	Starting ManagerNode
[DEBUG] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest:DATASET}): 1 entries, 63 B within 235.4 μs
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest:SECONDARY_IDS}): 0 entries, 0 B within 55.15 μs
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest	While processing store TABLES:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest:TABLES}): 2 entries, 348 B within 255.9 μs
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest	While processing store DICTIONARIES_META:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest		loaded store cached big DICTIONARIES(Dictionary): 2 entries, 86 B within 901.2 μs
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest	While processing store IMPORTS:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest:IMPORTS}): 2 entries, 1,012 B within 4.479 ms
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest	While processing store CONCEPTS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest:CONCEPTS}): 1 entries, 622 B within 4.766 ms
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest	Done reading Dataset[label=ImportDeletionTest, name=ImportDeletionTest] / com.bakdata.conquery.io.storage.NamespaceStorage
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest	While processing store ID_MAPPING_META:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest		loaded store cached big ID_MAPPING(EntityIdMap): 1 entries, 43 B within 269.2 μs
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest	While processing store STRUCTURE:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest:STRUCTURE}): 0 entries, 0 B within 30.41 μs
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest	While processing store WORKER_TO_BUCKETS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest:WORKER_TO_BUCKETS}): 1 entries, 315 B within 113.0 μs
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest	While processing store PRIMARY_DICTIONARY:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest:PRIMARY_DICTIONARY}): 1 entries, 104 B within 604.8 μs
[DEBUG] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest	DONE reading Storage
[INFO] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory	ManagerNode	All WorkerStores loaded: [NamespacedStorage(pathName=dataset_ImportDeletionTest)]
[INFO] [2023-01-26 18:08:35]	c.b.c.c.ManagerNode	ManagerNode	Opening MetaStorage
[INFO] [2023-01-26 18:08:35]	c.b.c.c.ManagerNode	ManagerNode	Loading MetaStorage
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store AUTH_USER:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/users:AUTH_USER}): 1 entries, 149 B within 1.225 ms
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store AUTH_ROLE:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/roles:AUTH_ROLE}): 0 entries, 0 B within 88.20 μs
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store AUTH_GROUP:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/groups:AUTH_GROUP}): 0 entries, 0 B within 72.49 μs
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store EXECUTIONS:
	Entries processed:	3
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/executions:EXECUTIONS}): 3 entries, 1.8 KiB within 7.702 ms
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store FORM_CONFIG:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/formConfigs:FORM_CONFIG}): 0 entries, 0 B within 51.39 μs
[INFO] [2023-01-26 18:08:35]	c.b.c.c.ManagerNode	ManagerNode	MetaStorage loaded com.bakdata.conquery.io.storage.MetaStorage@5f1a8fc3
[DEBUG] [2023-01-26 18:08:35]	c.b.c.m.a.AuthorizationController	ManagerNode	Security manager registered
[WARN] [2023-01-26 18:08:35]	c.b.c.m.a.d.DefaultInitialUserRealm	ManagerNode	
           §§
          §  §
         §    §
        §      §
       §  §§§§  §       You instantiated and are probably using a Shiro realm
      §   §§§§   §      that does not do any permission checks or authentication.
     §     §§     §     Access to all resources is granted to everyone.
    §      §§      §    DO NOT USE THIS REALM IN PRODUCTION
   $                §
  §        §§        §
 §                    §
 §§§§§§§§§§§§§§§§§§§§§§
[INFO] [2023-01-26 18:08:35]	c.b.c.m.a.AuthorizationController	ManagerNode	Registering the following realms to Shiro:
	com.bakdata.conquery.models.auth.conquerytoken.ConqueryTokenRealm_27
	com.bakdata.conquery.models.auth.ConqueryAuthorizationRealm_28
	com.bakdata.conquery.models.auth.develop.DefaultInitialUserRealm_29
[INFO] [2023-01-26 18:08:35]	c.b.c.c.ManagerNode	ManagerNode	Registering ResourcesProvider
[INFO] [2023-01-26 18:08:35]	c.b.c.m.f.f.FormScanner	ManagerNode	Form[EXPORT_FORM] from `Resource com/bakdata/conquery/frontend/forms/export_form.frontend_conf.json` of Type[com.bakdata.conquery.apiv1.forms.export_form.ExportForm]
[INFO] [2023-01-26 18:08:35]	c.b.c.m.f.f.FormScanner	ManagerNode	Form[FULL_EXPORT_FORM] from `Resource com/bakdata/conquery/frontend/forms/table_export_form.frontend_conf.json` of Type[com.bakdata.conquery.apiv1.forms.export_form.FullExportForm]
[DEBUG] [2023-01-26 18:08:35]	c.b.c.c.StandaloneCommand	ManagerNode	Waiting for ShardNodes to start
[DEBUG] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd:DATASET}): 1 entries, 63 B within 134.5 μs
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd:SECONDARY_IDS}): 0 entries, 0 B within 31.84 μs
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd	While processing store TABLES:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd:TABLES}): 2 entries, 348 B within 196.1 μs
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd	While processing store DICTIONARIES_META:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd		loaded store cached big DICTIONARIES(Dictionary): 2 entries, 86 B within 1.044 ms
[DEBUG] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f:DATASET}): 1 entries, 63 B within 161.4 μs
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f:SECONDARY_IDS}): 0 entries, 0 B within 45.60 μs
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f	While processing store TABLES:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f:TABLES}): 2 entries, 348 B within 185.6 μs
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd	While processing store IMPORTS:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd:IMPORTS}): 2 entries, 1,012 B within 3.374 ms
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f	While processing store DICTIONARIES_META:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f		loaded store cached big DICTIONARIES(Dictionary): 2 entries, 86 B within 835.5 μs
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f	While processing store IMPORTS:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f:IMPORTS}): 2 entries, 1,012 B within 3.099 ms
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd	While processing store CONCEPTS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd:CONCEPTS}): 1 entries, 622 B within 4.035 ms
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd	Done reading Dataset[label=ImportDeletionTest, name=ImportDeletionTest] / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd	While processing store WORKER:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd:WORKER}): 1 entries, 138 B within 75.18 μs
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd	While processing store BUCKETS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd:BUCKETS}): 1 entries, 377 B within 1.302 ms
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd	While processing store C_BLOCKS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd:C_BLOCKS}): 1 entries, 235 B within 157.0 μs
[DEBUG] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd	DONE reading Storage
[INFO] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory	shard-node1	All WorkerStores loaded: [WorkerStorage(worker=NamedImpl(name=worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd))]
[INFO] [2023-01-26 18:08:35]	c.b.c.c.ShardNode	shard-node1	All Worker Storages loaded: 1
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f	While processing store CONCEPTS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f:CONCEPTS}): 1 entries, 622 B within 4.399 ms
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f	Done reading Dataset[label=ImportDeletionTest, name=ImportDeletionTest] / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f	While processing store WORKER:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f:WORKER}): 1 entries, 138 B within 106.9 μs
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f	While processing store BUCKETS:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f:BUCKETS}): 2 entries, 746 B within 1.865 ms
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f	While processing store C_BLOCKS:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:35]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f:C_BLOCKS}): 2 entries, 461 B within 344.2 μs
[DEBUG] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f	DONE reading Storage
[INFO] [2023-01-26 18:08:35]	c.b.c.m.c.XodusStoreFactory	shard-node0	All WorkerStores loaded: [WorkerStorage(worker=NamedImpl(name=worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f))]
[INFO] [2023-01-26 18:08:35]	c.b.c.c.ShardNode	shard-node0	All Worker Storages loaded: 1
[DEBUG] [2023-01-26 18:08:35]	c.b.c.c.StandaloneCommand	ManagerNode	Starting REST Server
[INFO] [2023-01-26 18:08:35]	c.b.c.c.ManagerNode		Started ManagerNode @ /0:0:0:0:0:0:0:0:34233
[INFO] [2023-01-26 18:08:35]	c.b.c.c.ShardNode		Trying to connect to /127.0.0.1:34233
[INFO] [2023-01-26 18:08:35]	c.b.c.c.ManagerNode	ManagerNode[/127.0.0.1:34233]	New client /127.0.0.1:50550 connected, waiting for identity
[INFO] [2023-01-26 18:08:35]	c.b.c.c.ShardNode	/127.0.0.1:50550	Connected to ManagerNode @ /127.0.0.1:34233
[INFO] [2023-01-26 18:08:35]	c.b.c.c.ShardNode		Trying to connect to /127.0.0.1:34233
[INFO] [2023-01-26 18:08:35]	c.b.c.c.ShardNode	/127.0.0.1:50552	Connected to ManagerNode @ /127.0.0.1:34233
[INFO] [2023-01-26 18:08:35]	c.b.c.c.ShardNode	/127.0.0.1:50550	Sending worker identity 'worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f'
[INFO] [2023-01-26 18:08:35]	c.b.c.c.ManagerNode	ManagerNode[/127.0.0.1:34233]	New client /127.0.0.1:50552 connected, waiting for identity
[INFO] [2023-01-26 18:08:35]	c.b.c.c.ShardNode	/127.0.0.1:50552	Sending worker identity 'worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd'
[INFO] [2023-01-26 18:08:35]	c.b.c.m.m.n.s.AddShardNode	Job Manager fast ManagerNode	ShardNode `/127.0.0.1:50550` registered.
[INFO] [2023-01-26 18:08:35]	c.b.c.m.m.n.s.AddShardNode	Job Manager fast ManagerNode	ShardNode `/127.0.0.1:50552` registered.
[INFO] [2023-01-26 18:08:35]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=ImportDeletionTest, name=ImportDeletionTest]	Imports of worker ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd are consistent with the manager: 2 Imports
[INFO] [2023-01-26 18:08:35]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=ImportDeletionTest, name=ImportDeletionTest]	Buckets of worker ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd are consistent with the manager: 1 Buckets
[INFO] [2023-01-26 18:08:35]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=ImportDeletionTest, name=ImportDeletionTest]	Consistency check was successful
[INFO] [2023-01-26 18:08:35]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=ImportDeletionTest, name=ImportDeletionTest]	Imports of worker ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f are consistent with the manager: 2 Imports
[INFO] [2023-01-26 18:08:35]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=ImportDeletionTest, name=ImportDeletionTest]	Buckets of worker ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f are consistent with the manager: 2 Buckets
[INFO] [2023-01-26 18:08:35]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=ImportDeletionTest, name=ImportDeletionTest]	Consistency check was successful
[WARN] [2023-01-26 18:08:35]	o.g.j.i.Errors		The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.filters.Filter<?> from public void com.bakdata.conquery.resources.hierarchies.HFilters.setFilter(com.bakdata.conquery.models.datasets.concepts.filters.Filter<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public com.bakdata.conquery.apiv1.FullExecutionStatus com.bakdata.conquery.resources.api.QueryResource.getStatus(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) throws java.lang.InterruptedException is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public com.bakdata.conquery.apiv1.FullExecutionStatus com.bakdata.conquery.resources.api.QueryResource.patchQuery(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>,com.bakdata.conquery.apiv1.MetaDataPatch) throws com.bakdata.conquery.models.exceptions.JSONException is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public void com.bakdata.conquery.resources.api.QueryResource.deleteQuery(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>) is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public void com.bakdata.conquery.resources.api.QueryResource.cancel(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>) is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public com.bakdata.conquery.apiv1.FullExecutionStatus com.bakdata.conquery.resources.api.QueryResource.reexecute(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultExcelResource.get(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.identifiable.ids.specific.DatasetId,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultArrowStreamResource.get(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.datasets.Dataset,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultCsvResource.getAsCsv(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.datasets.Dataset,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.lang.String,java.lang.String,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultArrowFileResource.get(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.datasets.Dataset,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.filters.Filter<?> from public void com.bakdata.conquery.resources.hierarchies.HFilters.setFilter(com.bakdata.conquery.models.datasets.concepts.filters.Filter<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.

[WARN] [2023-01-26 18:08:35]	i.d.s.AdminEnvironment		
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!    THIS APPLICATION HAS NO HEALTHCHECKS. THIS MEANS YOU WILL NEVER KNOW      !
!     IF IT DIES IN PRODUCTION, WHICH MEANS YOU WILL NEVER KNOW IF YOU'RE      !
!    LETTING YOUR USERS DOWN. YOU SHOULD ADD A HEALTHCHECK FOR EACH OF YOUR    !
!         APPLICATION'S DEPENDENCIES WHICH FULLY (BUT LIGHTLY) TESTS IT.       !
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
[WARN] [2023-01-26 18:08:35]	o.g.j.i.Errors		The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.auth.entities.PermissionOwner<?> from public void com.bakdata.conquery.resources.hierarchies.HPermissions.setOwner(com.bakdata.conquery.models.auth.entities.PermissionOwner<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.auth.entities.PermissionOwner<?> from public void com.bakdata.conquery.resources.hierarchies.HPermissions.setOwner(com.bakdata.conquery.models.auth.entities.PermissionOwner<?>) is not resolvable to a concrete type.

[WARN] [2023-01-26 18:08:35]	o.g.j.i.Errors		The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter concept of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from protected com.bakdata.conquery.models.datasets.concepts.Concept<?> com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.concept is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter concept of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from protected com.bakdata.conquery.models.datasets.concepts.Concept<?> com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.concept is not resolvable to a concrete type.

[INFO] [2023-01-26 18:08:35]	c.b.c.u.s.TestConquery		loading dataset
[INFO] [2023-01-26 18:08:35]	c.b.c.u.s.TestConquery		Reusing existing folder /tmp/conqueryIntegrationTest12910953884258704183/tmp_ImportDeletionTest for Support
[INFO] [2023-01-26 18:08:35]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[INFO] [2023-01-26 18:08:35]	c.b.c.i.t.d.ImportDeletionTest		Checking state after re-start
[INFO] [2023-01-26 18:08:35]	c.b.c.i.t.d.ImportDeletionTest		Executing query after re-import
[INFO] [2023-01-26 18:08:35]	c.b.c.a.QueryProcessor	user.SUPERUSER@SUPERUSER	Query posted on Dataset[ImportDeletionTest] by User[{user.SUPERUSER@SUPERUSER].
[INFO] [2023-01-26 18:08:35]	c.b.c.m.q.ExecutionManager	user.SUPERUSER@SUPERUSER	Executing Query[6414252e-5914-44f3-82ae-362e7dd13d6f] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_ImportDeletionTest))]]
127.0.0.1 - - [26/Jan/2023:18:08:35 +0000] "POST /api/datasets/ImportDeletionTest/queries HTTP/1.1" 201 1214 "-" "Conquery (test client)" 24
[DEBUG] [2023-01-26 18:08:35]	c.b.c.i.c.IntegrationUtils		Trying to get Query result
[INFO] [2023-01-26 18:08:35]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, /127.0.0.1:50550]	Started ConceptQuery ImportDeletionTest.6414252e-5914-44f3-82ae-362e7dd13d6f
[DEBUG] [2023-01-26 18:08:35]	c.b.c.m.q.QueryExecutor	Worker[ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, /127.0.0.1:50550]	QueryPlan for Query[ImportDeletionTest.6414252e-5914-44f3-82ae-362e7dd13d6f] = `ConceptQueryPlan(child=QPParentNode(children=[ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table, name=test_table]])])), validityDateColumn=Column(id = ImportDeletionTest.test_table.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column], dateColumn=null), selectedSecondaryId=null), ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table2, name=test_table2]])])), validityDateColumn=Column(id = ImportDeletionTest.test_table2.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column2], dateColumn=null), selectedSecondaryId=null)]), dateAggregator=DateAggregator(action=MERGE))`
[INFO] [2023-01-26 18:08:35]	c.b.c.m.m.n.s.ExecuteQuery	Worker[ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd, /127.0.0.1:50552]	Started ConceptQuery ImportDeletionTest.6414252e-5914-44f3-82ae-362e7dd13d6f
[DEBUG] [2023-01-26 18:08:35]	c.b.c.m.q.QueryExecutor	Worker[ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd, /127.0.0.1:50552]	QueryPlan for Query[ImportDeletionTest.6414252e-5914-44f3-82ae-362e7dd13d6f] = `ConceptQueryPlan(child=QPParentNode(children=[ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table, name=test_table]])])), validityDateColumn=Column(id = ImportDeletionTest.test_table.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column], dateColumn=null), selectedSecondaryId=null), ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table2, name=test_table2]])])), validityDateColumn=Column(id = ImportDeletionTest.test_table2.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column2], dateColumn=null), selectedSecondaryId=null)]), dateAggregator=DateAggregator(action=MERGE))`
[INFO] [2023-01-26 18:08:35]	c.b.c.m.q.r.ShardResult		FINISHED Query[ImportDeletionTest.6414252e-5914-44f3-82ae-362e7dd13d6f] with 0 results within PT0.006145S
[INFO] [2023-01-26 18:08:35]	c.b.c.m.q.r.ShardResult		FINISHED Query[ImportDeletionTest.6414252e-5914-44f3-82ae-362e7dd13d6f] with 2 results within PT0.009497S
[INFO] [2023-01-26 18:08:35]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=ImportDeletionTest, name=ImportDeletionTest]	Received ShardResult(queryId=ImportDeletionTest.6414252e-5914-44f3-82ae-362e7dd13d6f, workerId=ImportDeletionTest.worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd, startTime=2023-01-26T18:08:35.972155, finishTime=2023-01-26T18:08:35.978300) of size 0
[DEBUG] [2023-01-26 18:08:35]	c.b.c.m.q.ManagedQuery	Dataset[label=ImportDeletionTest, name=ImportDeletionTest]	Received Result[size=0] for Query[ImportDeletionTest.6414252e-5914-44f3-82ae-362e7dd13d6f]
[INFO] [2023-01-26 18:08:35]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=ImportDeletionTest, name=ImportDeletionTest]	Received ShardResult(queryId=ImportDeletionTest.6414252e-5914-44f3-82ae-362e7dd13d6f, workerId=ImportDeletionTest.worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f, startTime=2023-01-26T18:08:35.970665, finishTime=2023-01-26T18:08:35.980162) of size 2
[DEBUG] [2023-01-26 18:08:35]	c.b.c.m.q.ManagedQuery	Dataset[label=ImportDeletionTest, name=ImportDeletionTest]	Received Result[size=2] for Query[ImportDeletionTest.6414252e-5914-44f3-82ae-362e7dd13d6f]
[INFO] [2023-01-26 18:08:35]	c.b.c.m.e.ManagedExecution	Dataset[label=ImportDeletionTest, name=ImportDeletionTest]	DONE 6414252e-5914-44f3-82ae-362e7dd13d6f ManagedQuery within PT0.019975S
127.0.0.1 - - [26/Jan/2023:18:08:35 +0000] "GET /api/datasets/ImportDeletionTest/queries/ImportDeletionTest.6414252e-5914-44f3-82ae-362e7dd13d6f HTTP/1.1" 200 1478 "-" "Conquery (test client)" 7
[INFO] [2023-01-26 18:08:36]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node0	removing worker for Dataset[label=ImportDeletionTest, name=ImportDeletionTest]
[INFO] [2023-01-26 18:08:36]	c.b.c.m.j.JobExecutor		Closing Job Manager fast ImportDeletionTest
[INFO] [2023-01-26 18:08:36]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node1	removing worker for Dataset[label=ImportDeletionTest, name=ImportDeletionTest]
[INFO] [2023-01-26 18:08:36]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager fast worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd
[INFO] [2023-01-26 18:08:36]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager fast worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f
[INFO] [2023-01-26 18:08:36]	c.b.c.m.j.JobExecutor		Closing Job Manager slow ImportDeletionTest
[INFO] [2023-01-26 18:08:36]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager slow worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd
[INFO] [2023-01-26 18:08:36]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager slow worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f
[INFO] [2023-01-26 18:08:36]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node1	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_ImportDeletionTest_c1e9751c-3209-42e4-8ec1-fb95f4353fdd
[INFO] [2023-01-26 18:08:36]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node0	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_ImportDeletionTest_d0b7bc0c-c8b9-46e8-bb24-07b62bed261f
[INFO] [2023-01-26 18:08:36]	c.b.c.m.w.Namespace		Removing namespace storage of ImportDeletionTest
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore		Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore		Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore		Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore		Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore		Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore		Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore		Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore		Deleting store ID_MAPPING_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore		Deleting store ID_MAPPING_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore		Deleting store STRUCTURE from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore		Deleting store WORKER_TO_BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.XodusStore		Deleting store PRIMARY_DICTIONARY from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest
[INFO] [2023-01-26 18:08:36]	c.b.c.m.c.XodusStoreFactory		Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_ImportDeletionTest
[INFO] [2023-01-26 18:08:36]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[INFO] [2023-01-26 18:08:36]	c.b.c.i.IntegrationTest$Wrapper	ImportDeletionTest	SUCCESS integration test ImportDeletionTest
[INFO] [2023-01-26 18:08:36]	c.b.c.i.IntegrationTest$Wrapper	TableDeletionTest	STARTING integration test TableDeletionTest
[INFO] [2023-01-26 18:08:36]	c.b.c.u.s.TestConquery	TableDeletionTest	Setting up dataset
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.SerializingStore	TableDeletionTest	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.CachedStore	TableDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest:DATASET}): 0 entries, 0 B within 4.010 ms
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.SerializingStore	TableDeletionTest	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.CachedStore	TableDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest:SECONDARY_IDS}): 0 entries, 0 B within 72.39 μs
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.SerializingStore	TableDeletionTest	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.CachedStore	TableDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest:TABLES}): 0 entries, 0 B within 51.68 μs
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.SerializingStore	TableDeletionTest	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.CachedStore	TableDeletionTest		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 53.70 μs
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.SerializingStore	TableDeletionTest	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.CachedStore	TableDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest:IMPORTS}): 0 entries, 0 B within 47.37 μs
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.SerializingStore	TableDeletionTest	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.CachedStore	TableDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest:CONCEPTS}): 0 entries, 0 B within 47.10 μs
[INFO] [2023-01-26 18:08:36]	c.b.c.i.s.NamespacedStorage	TableDeletionTest	Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.SerializingStore	TableDeletionTest	While processing store ID_MAPPING_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.CachedStore	TableDeletionTest		loaded store cached big ID_MAPPING(EntityIdMap): 0 entries, 0 B within 54.23 μs
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.SerializingStore	TableDeletionTest	While processing store STRUCTURE:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.CachedStore	TableDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest:STRUCTURE}): 0 entries, 0 B within 949.0 μs
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.SerializingStore	TableDeletionTest	While processing store WORKER_TO_BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.CachedStore	TableDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest:WORKER_TO_BUCKETS}): 0 entries, 0 B within 2.368 ms
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.SerializingStore	TableDeletionTest	While processing store PRIMARY_DICTIONARY:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.CachedStore	TableDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest:PRIMARY_DICTIONARY}): 0 entries, 0 B within 112.5 μs
[INFO] [2023-01-26 18:08:36]	c.b.c.m.m.n.s.AddWorker	Job Manager slow shard-node0	creating a new worker for Dataset[label=TableDeletionTest, name=TableDeletionTest]
[INFO] [2023-01-26 18:08:36]	c.b.c.m.m.n.s.AddWorker	Job Manager slow shard-node1	creating a new worker for Dataset[label=TableDeletionTest, name=TableDeletionTest]
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56:DATASET}): 0 entries, 0 B within 109.5 μs
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56:SECONDARY_IDS}): 0 entries, 0 B within 39.65 μs
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56:TABLES}): 0 entries, 0 B within 25.10 μs
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 32.20 μs
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56:IMPORTS}): 0 entries, 0 B within 23.32 μs
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56:CONCEPTS}): 0 entries, 0 B within 16.24 μs
[INFO] [2023-01-26 18:08:36]	c.b.c.i.s.NamespacedStorage	Job Manager slow shard-node0	Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store WORKER:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56:WORKER}): 0 entries, 0 B within 16.67 μs
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56:BUCKETS}): 0 entries, 0 B within 16.06 μs
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node0	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node0		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56:C_BLOCKS}): 0 entries, 0 B within 13.41 μs
[INFO] [2023-01-26 18:08:36]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=TableDeletionTest]	Imports of worker TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56 are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:36]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=TableDeletionTest]	Buckets of worker TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56 are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:36]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=TableDeletionTest]	Consistency check was successful
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store DATASET:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52:DATASET}): 0 entries, 0 B within 113.4 μs
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52:SECONDARY_IDS}): 0 entries, 0 B within 54.92 μs
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store TABLES:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52:TABLES}): 0 entries, 0 B within 31.77 μs
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store DICTIONARIES_META:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached big DICTIONARIES(Dictionary): 0 entries, 0 B within 33.79 μs
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store IMPORTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52:IMPORTS}): 0 entries, 0 B within 42.59 μs
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store CONCEPTS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52:CONCEPTS}): 0 entries, 0 B within 27.74 μs
[INFO] [2023-01-26 18:08:36]	c.b.c.i.s.NamespacedStorage	Job Manager slow shard-node1	Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store WORKER:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52:WORKER}): 0 entries, 0 B within 27.89 μs
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store BUCKETS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52:BUCKETS}): 0 entries, 0 B within 36.44 μs
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.SerializingStore	Job Manager slow shard-node1	While processing store C_BLOCKS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:36]	c.b.c.i.s.x.s.CachedStore	Job Manager slow shard-node1		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52:C_BLOCKS}): 0 entries, 0 B within 27.55 μs
[INFO] [2023-01-26 18:08:36]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=TableDeletionTest]	Imports of worker TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52 are consistent with the manager: 0 Imports
[INFO] [2023-01-26 18:08:36]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=TableDeletionTest]	Buckets of worker TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52 are consistent with the manager: 0 Buckets
[INFO] [2023-01-26 18:08:36]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=null, name=TableDeletionTest]	Consistency check was successful
[INFO] [2023-01-26 18:08:36]	c.b.c.u.s.TestConquery	TableDeletionTest	Waiting for jobs to finish
[INFO] [2023-01-26 18:08:36]	c.b.c.u.s.TestConquery	TableDeletionTest	Waiting for jobs to finish
[INFO] [2023-01-26 18:08:36]	c.b.c.u.s.TestConquery	TableDeletionTest	Waiting for jobs to finish
[INFO] [2023-01-26 18:08:36]	c.b.c.m.m.n.s.UpdateTable	Worker[TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, /127.0.0.1:50552]	Received update of Table TableDeletionTest.test_table
[INFO] [2023-01-26 18:08:36]	c.b.c.m.m.n.s.UpdateTable	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50550]	Received update of Table TableDeletionTest.test_table
[INFO] [2023-01-26 18:08:36]	c.b.c.m.m.n.s.UpdateTable	Worker[TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, /127.0.0.1:50552]	Received update of Table TableDeletionTest.test_table2
[INFO] [2023-01-26 18:08:36]	c.b.c.m.m.n.s.UpdateTable	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50550]	Received update of Table TableDeletionTest.test_table2
[INFO] [2023-01-26 18:08:36]	c.b.c.u.s.TestConquery	TableDeletionTest	Waiting for jobs to finish
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.WorkerStorage	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50550]	Updating Concept[TableDeletionTest.test_tree]
[DEBUG] [2023-01-26 18:08:36]	c.b.c.i.s.WorkerStorage	Worker[TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, /127.0.0.1:50552]	Updating Concept[TableDeletionTest.test_tree]
[INFO] [2023-01-26 18:08:36]	c.b.c.c.PreprocessorCommand	TableDeletionTest	Preprocessing from command line config.
[INFO] [2023-01-26 18:08:36]	c.b.c.c.PreprocessorCommand	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_TableDeletionTest/test_table.import.json, tag=Optional.empty)	DOES NOT EXIST
[INFO] [2023-01-26 18:08:36]	c.b.c.c.PreprocessorCommand	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_TableDeletionTest/test_table2.import.json, tag=Optional.empty)	DOES NOT EXIST
[INFO] [2023-01-26 18:08:36]	c.b.c.c.PreprocessorCommand	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_TableDeletionTest/test_table2.import.json, tag=Optional.empty)	Required to preprocess 115 B in total
[INFO] [2023-01-26 18:08:36]	c.b.c.m.p.Preprocessor	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_TableDeletionTest/test_table.import.json, tag=Optional.empty)	PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_TableDeletionTest/test_table.import.json, tag=Optional.empty)
█████████████████████████                         ▌  50%	est. time remaining: 0.099895214s[INFO] [2023-01-26 18:08:36]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	Statistics = IntSummaryStatistics{count=2, sum=2, min=1, average=1.000000, max=1}
[INFO] [2023-01-26 18:08:36]	c.b.c.m.p.PPColumn	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=2, nullLines=0), encoding=null, prefix=, suffix=)
[DEBUG] [2023-01-26 18:08:36]	c.b.c.m.p.p.s.StringParser	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]		Chosen encoding is Base16UpperCase
[INFO] [2023-01-26 18:08:36]	c.b.c.m.p.PPColumn		Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=2, nullLines=0), subType=IntegerParser(super=Parser(lines=2, nullLines=0), minValue=15655, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@146c0ef3)
[DEBUG] [2023-01-26 18:08:36]	c.b.c.m.p.PPColumn			datum: DateParser(super=Parser(lines=2, nullLines=0), subType=IntegerParser(super=Parser(lines=2, nullLines=0), minValue=15655, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@146c0ef3) -> IntegerDateStore(store=ShortArrayStore())
[DEBUG] [2023-01-26 18:08:36]	c.b.c.m.p.p.s.StringParser	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]		Using com.bakdata.conquery.models.preproc.parser.specific.string.TrieTypeGuesser@20026165(est. 62 B)
[DEBUG] [2023-01-26 18:08:36]	c.b.c.m.p.PPColumn	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]		test_column: StringParser(super=Parser(lines=2, nullLines=0), encoding=Base16UpperCase, prefix=, suffix=) -> StringTypeEncoded(encoding=Base16UpperCase, subType=StringTypeDictionary(dictionary=SuccinctTrie[size=2], numberType=ByteArrayStore()))
[DEBUG] [2023-01-26 18:08:36]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	Encode primary Dictionary
[DEBUG] [2023-01-26 18:08:36]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	Writing Headers
[DEBUG] [2023-01-26 18:08:36]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	Writing header
[DEBUG] [2023-01-26 18:08:36]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	Writing Dictionaries
[DEBUG] [2023-01-26 18:08:36]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	Writing data
[INFO] [2023-01-26 18:08:36]	c.b.c.m.p.Preprocessor	ImportDescriptor [table=test_table, name=test_table]:test_table[0/content1.csv]	PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_TableDeletionTest/test_table.import.json, tag=Optional.empty)
[INFO] [2023-01-26 18:08:36]	c.b.c.m.p.Preprocessor	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_TableDeletionTest/test_table2.import.json, tag=Optional.empty)	PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_TableDeletionTest/test_table2.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.001222646s[INFO] [2023-01-26 18:08:36]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Statistics = IntSummaryStatistics{count=2, sum=2, min=1, average=1.000000, max=1}
[INFO] [2023-01-26 18:08:36]	c.b.c.m.p.PPColumn		Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=2, nullLines=0), subType=IntegerParser(super=Parser(lines=2, nullLines=0), minValue=14805, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@5a9cb7fa)
[DEBUG] [2023-01-26 18:08:36]	c.b.c.m.p.PPColumn			datum: DateParser(super=Parser(lines=2, nullLines=0), subType=IntegerParser(super=Parser(lines=2, nullLines=0), minValue=14805, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@5a9cb7fa) -> IntegerDateStore(store=ShortArrayStore())
[INFO] [2023-01-26 18:08:36]	c.b.c.m.p.PPColumn	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=2, nullLines=0), encoding=null, prefix=, suffix=)
[DEBUG] [2023-01-26 18:08:36]	c.b.c.m.p.p.s.StringParser	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]		Chosen encoding is Base16UpperCase
[DEBUG] [2023-01-26 18:08:36]	c.b.c.m.p.p.s.StringParser	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]		Using com.bakdata.conquery.models.preproc.parser.specific.string.TrieTypeGuesser@75f9539a(est. 62 B)
[DEBUG] [2023-01-26 18:08:36]	c.b.c.m.p.PPColumn	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]		test_column: StringParser(super=Parser(lines=2, nullLines=0), encoding=Base16UpperCase, prefix=, suffix=) -> StringTypeEncoded(encoding=Base16UpperCase, subType=StringTypeDictionary(dictionary=SuccinctTrie[size=2], numberType=ByteArrayStore()))
[DEBUG] [2023-01-26 18:08:36]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Encode primary Dictionary
[DEBUG] [2023-01-26 18:08:36]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Writing Headers
[DEBUG] [2023-01-26 18:08:36]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Writing header
[DEBUG] [2023-01-26 18:08:36]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Writing Dictionaries
[DEBUG] [2023-01-26 18:08:36]	c.b.c.m.p.Preprocessed	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	Writing data
[INFO] [2023-01-26 18:08:36]	c.b.c.m.p.Preprocessor	ImportDescriptor [table=test_table2, name=test_table2]:test_table2[0/content2.csv]	PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_TableDeletionTest/test_table2.import.json, tag=Optional.empty)
[INFO] [2023-01-26 18:08:36]	c.b.c.c.PreprocessorCommand		Successfully Preprocess 2 Jobs:
[INFO] [2023-01-26 18:08:36]	c.b.c.c.PreprocessorCommand			Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_TableDeletionTest/test_table.import.json, tag=Optional.empty)
[INFO] [2023-01-26 18:08:36]	c.b.c.c.PreprocessorCommand			Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_TableDeletionTest/test_table2.import.json, tag=Optional.empty)
[DEBUG] [2023-01-26 18:08:36]	c.b.c.m.j.ImportJob	user.SUPERUSER@SUPERUSER	Done reading data. Contains 2 Entities.
[INFO] [2023-01-26 18:08:36]	c.b.c.m.j.ImportJob	user.SUPERUSER@SUPERUSER	Importing test_table into TableDeletionTest.test_table
127.0.0.1 - - [26/Jan/2023:18:08:36 +0000] "POST /admin/datasets/TableDeletionTest/imports?file=%2Ftmp%2FconqueryIntegrationTest12910953884258704183%2Ftmp_TableDeletionTest%2Ftest_table.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 15
[DEBUG] [2023-01-26 18:08:36]	c.b.c.m.j.ImportJob	Job Manager slow TableDeletionTest	Mapped 2 new ids
[DEBUG] [2023-01-26 18:08:36]	c.b.c.m.j.ImportJob	Job Manager slow TableDeletionTest	Updating bucket assignments.
[DEBUG] [2023-01-26 18:08:36]	c.b.c.m.w.Namespace	Job Manager slow TableDeletionTest	Assigning Bucket[0] to Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56]
[INFO] [2023-01-26 18:08:36]	c.b.c.m.j.ImportJob	Job Manager slow TableDeletionTest	Importing Dictionaries
[DEBUG] [2023-01-26 18:08:36]	c.b.c.m.m.n.s.UpdateWorkerBucket	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50550]	Received new WorkerInformation(size = 1,dataset = TableDeletionTest)
[DEBUG] [2023-01-26 18:08:36]	c.b.c.m.m.n.s.UpdateWorkerBucket	Worker[TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, /127.0.0.1:50552]	Received new WorkerInformation(size = 0,dataset = TableDeletionTest)
[INFO] [2023-01-26 18:08:36]	c.b.c.m.j.ImportJob	Job Manager slow TableDeletionTest	Remapping Dictionaries []
[WARN] [2023-01-26 18:08:36]	c.b.c.u.p.ProgressReporterImpl	Job Manager slow TableDeletionTest	Max cannot be decreased.
[DEBUG] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.UpdateDictionary	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50550]	Received Dictionary[TableDeletionTest.test_table#TableDeletionTest$2etest_table$2etest_column] of size 2.
[DEBUG] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.UpdateDictionary	Worker[TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, /127.0.0.1:50552]	Received Dictionary[TableDeletionTest.test_table#TableDeletionTest$2etest_table$2etest_column] of size 2.
[INFO] [2023-01-26 18:08:37]	c.b.c.m.j.ImportJob	Job Manager slow TableDeletionTest	Start sending 1 Buckets
[WARN] [2023-01-26 18:08:37]	c.b.c.u.p.ProgressReporterImpl	Job Manager slow TableDeletionTest	One or more Children are not done yet
[DEBUG] [2023-01-26 18:08:37]	c.b.c.m.j.ImportJob	user.SUPERUSER@SUPERUSER	Done reading data. Contains 2 Entities.
[INFO] [2023-01-26 18:08:37]	c.b.c.m.j.ImportJob	user.SUPERUSER@SUPERUSER	Importing test_table2 into TableDeletionTest.test_table2
[DEBUG] [2023-01-26 18:08:37]	c.b.c.m.j.ImportJob	Job Manager slow TableDeletionTest	Mapped 2 new ids
[DEBUG] [2023-01-26 18:08:37]	c.b.c.m.j.ImportJob	Job Manager slow TableDeletionTest	Updating bucket assignments.
[DEBUG] [2023-01-26 18:08:37]	c.b.c.m.w.Namespace	Job Manager slow TableDeletionTest	Assigning Bucket[1] to Worker[TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52]
[INFO] [2023-01-26 18:08:37]	c.b.c.m.j.ImportJob	Job Manager slow TableDeletionTest	Importing Dictionaries
127.0.0.1 - - [26/Jan/2023:18:08:37 +0000] "POST /admin/datasets/TableDeletionTest/imports?file=%2Ftmp%2FconqueryIntegrationTest12910953884258704183%2Ftmp_TableDeletionTest%2Ftest_table2.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 11
[INFO] [2023-01-26 18:08:37]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[DEBUG] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.UpdateWorkerBucket	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50550]	Received new WorkerInformation(size = 1,dataset = TableDeletionTest)
[DEBUG] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.UpdateWorkerBucket	Worker[TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, /127.0.0.1:50552]	Received new WorkerInformation(size = 1,dataset = TableDeletionTest)
[INFO] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.AddImport	Worker[TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, /127.0.0.1:50552]	Received Import[TableDeletionTest.test_table.test_table], containing 2 entries.
[INFO] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.AddImport	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50550]	Received Import[TableDeletionTest.test_table.test_table], containing 2 entries.
[INFO] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.ImportBucket	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50550]	Received TableDeletionTest.test_table.test_table.0
[DEBUG] [2023-01-26 18:08:37]	c.b.c.i.s.WorkerStorage	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50550]	Adding Bucket[TableDeletionTest.test_table.test_table.0]
[INFO] [2023-01-26 18:08:37]	c.b.c.m.j.ImportJob	Job Manager slow TableDeletionTest	Remapping Dictionaries []
[WARN] [2023-01-26 18:08:37]	c.b.c.u.p.ProgressReporterImpl	Job Manager slow TableDeletionTest	Max cannot be decreased.
[DEBUG] [2023-01-26 18:08:37]	c.b.c.i.s.WorkerStorage		Adding CBlock[TableDeletionTest.test_table.test_table.0.TableDeletionTest.test_tree.test_column]
[DEBUG] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.UpdateDictionary	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50550]	Received Dictionary[TableDeletionTest.test_table2#TableDeletionTest$2etest_table2$2etest_column] of size 2.
[DEBUG] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.UpdateDictionary	Worker[TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, /127.0.0.1:50552]	Received Dictionary[TableDeletionTest.test_table2#TableDeletionTest$2etest_table2$2etest_column] of size 2.
[INFO] [2023-01-26 18:08:37]	c.b.c.m.j.ImportJob	Job Manager slow TableDeletionTest	Start sending 2 Buckets
[WARN] [2023-01-26 18:08:37]	c.b.c.u.p.ProgressReporterImpl	Job Manager slow TableDeletionTest	One or more Children are not done yet
[INFO] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.AddImport	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50550]	Received Import[TableDeletionTest.test_table2.test_table2], containing 2 entries.
[INFO] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.ImportBucket	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50550]	Received TableDeletionTest.test_table2.test_table2.0
[DEBUG] [2023-01-26 18:08:37]	c.b.c.i.s.WorkerStorage	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50550]	Adding Bucket[TableDeletionTest.test_table2.test_table2.0]
[DEBUG] [2023-01-26 18:08:37]	c.b.c.i.s.WorkerStorage		Adding CBlock[TableDeletionTest.test_table2.test_table2.0.TableDeletionTest.test_tree.test_column2]
[INFO] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.AddImport	Worker[TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, /127.0.0.1:50552]	Received Import[TableDeletionTest.test_table2.test_table2], containing 2 entries.
[INFO] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.ImportBucket	Worker[TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, /127.0.0.1:50552]	Received TableDeletionTest.test_table2.test_table2.1
[DEBUG] [2023-01-26 18:08:37]	c.b.c.i.s.WorkerStorage	Worker[TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, /127.0.0.1:50552]	Adding Bucket[TableDeletionTest.test_table2.test_table2.1]
[DEBUG] [2023-01-26 18:08:37]	c.b.c.i.s.WorkerStorage		Adding CBlock[TableDeletionTest.test_table2.test_table2.1.TableDeletionTest.test_tree.test_column2]
[INFO] [2023-01-26 18:08:37]	c.b.c.i.t.d.TableDeletionTest		Checking state before deletion
[INFO] [2023-01-26 18:08:37]	c.b.c.i.t.d.TableDeletionTest		Executing query before deletion
[INFO] [2023-01-26 18:08:37]	c.b.c.a.QueryProcessor	user.SUPERUSER@SUPERUSER	Query posted on Dataset[TableDeletionTest] by User[{user.SUPERUSER@SUPERUSER].
[INFO] [2023-01-26 18:08:37]	c.b.c.m.q.ExecutionManager	user.SUPERUSER@SUPERUSER	Executing Query[c48696e3-0ccc-473e-a711-ee2c30a75386] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_TableDeletionTest))]]
[INFO] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.ExecuteQuery	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50550]	Started ConceptQuery TableDeletionTest.c48696e3-0ccc-473e-a711-ee2c30a75386
[INFO] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.ExecuteQuery	Worker[TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, /127.0.0.1:50552]	Started ConceptQuery TableDeletionTest.c48696e3-0ccc-473e-a711-ee2c30a75386
[DEBUG] [2023-01-26 18:08:37]	c.b.c.m.q.QueryExecutor	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50550]	QueryPlan for Query[TableDeletionTest.c48696e3-0ccc-473e-a711-ee2c30a75386] = `ConceptQueryPlan(child=QPParentNode(children=[ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table, name=test_table]])])), validityDateColumn=Column(id = TableDeletionTest.test_table.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column], dateColumn=null), selectedSecondaryId=null), ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table2, name=test_table2]])])), validityDateColumn=Column(id = TableDeletionTest.test_table2.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column2], dateColumn=null), selectedSecondaryId=null)]), dateAggregator=DateAggregator(action=MERGE))`
[DEBUG] [2023-01-26 18:08:37]	c.b.c.m.q.QueryExecutor	Worker[TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, /127.0.0.1:50552]	QueryPlan for Query[TableDeletionTest.c48696e3-0ccc-473e-a711-ee2c30a75386] = `ConceptQueryPlan(child=QPParentNode(children=[ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table, name=test_table]])])), validityDateColumn=Column(id = TableDeletionTest.test_table.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column], dateColumn=null), selectedSecondaryId=null), ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table2, name=test_table2]])])), validityDateColumn=Column(id = TableDeletionTest.test_table2.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column2], dateColumn=null), selectedSecondaryId=null)]), dateAggregator=DateAggregator(action=MERGE))`
[INFO] [2023-01-26 18:08:37]	c.b.c.m.q.r.ShardResult		FINISHED Query[TableDeletionTest.c48696e3-0ccc-473e-a711-ee2c30a75386] with 0 results within PT0.000814S
[INFO] [2023-01-26 18:08:37]	c.b.c.m.q.r.ShardResult		FINISHED Query[TableDeletionTest.c48696e3-0ccc-473e-a711-ee2c30a75386] with 2 results within PT0.001119S
[INFO] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=TableDeletionTest]	Received ShardResult(queryId=TableDeletionTest.c48696e3-0ccc-473e-a711-ee2c30a75386, workerId=TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, startTime=2023-01-26T18:08:37.161153, finishTime=2023-01-26T18:08:37.161967) of size 0
[DEBUG] [2023-01-26 18:08:37]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=TableDeletionTest]	Received Result[size=0] for Query[TableDeletionTest.c48696e3-0ccc-473e-a711-ee2c30a75386]
[INFO] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=TableDeletionTest]	Received ShardResult(queryId=TableDeletionTest.c48696e3-0ccc-473e-a711-ee2c30a75386, workerId=TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, startTime=2023-01-26T18:08:37.161148, finishTime=2023-01-26T18:08:37.162267) of size 2
[DEBUG] [2023-01-26 18:08:37]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=TableDeletionTest]	Received Result[size=2] for Query[TableDeletionTest.c48696e3-0ccc-473e-a711-ee2c30a75386]
127.0.0.1 - - [26/Jan/2023:18:08:37 +0000] "POST /api/datasets/TableDeletionTest/queries HTTP/1.1" 201 1210 "-" "Conquery (test client)" 8
[INFO] [2023-01-26 18:08:37]	c.b.c.m.e.ManagedExecution	Dataset[label=null, name=TableDeletionTest]	DONE c48696e3-0ccc-473e-a711-ee2c30a75386 ManagedQuery within PT0.004645S
[DEBUG] [2023-01-26 18:08:37]	c.b.c.i.c.IntegrationUtils		Trying to get Query result
127.0.0.1 - - [26/Jan/2023:18:08:37 +0000] "GET /api/datasets/TableDeletionTest/queries/TableDeletionTest.c48696e3-0ccc-473e-a711-ee2c30a75386 HTTP/1.1" 200 1469 "-" "Conquery (test client)" 4
[INFO] [2023-01-26 18:08:37]	c.b.c.i.t.d.TableDeletionTest		Issuing deletion of import TableDeletionTest.test_table2
127.0.0.1 - - [26/Jan/2023:18:08:37 +0000] "DELETE /admin/datasets/TableDeletionTest/tables/TableDeletionTest.test_table2 HTTP/1.1" 409 31 "-" "Conquery (test client)" 7
[DEBUG] [2023-01-26 18:08:37]	c.b.c.i.s.WorkerStorage	Worker[TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, /127.0.0.1:50552]	Removing CBlock[TableDeletionTest.test_table2.test_table2.1.TableDeletionTest.test_tree.test_column2]
[DEBUG] [2023-01-26 18:08:37]	c.b.c.i.s.WorkerStorage	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50550]	Removing CBlock[TableDeletionTest.test_table.test_table.0.TableDeletionTest.test_tree.test_column]
[DEBUG] [2023-01-26 18:08:37]	c.b.c.i.s.WorkerStorage	Worker[TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, /127.0.0.1:50552]	Removing Concept[TableDeletionTest.test_tree]
[DEBUG] [2023-01-26 18:08:37]	c.b.c.i.s.WorkerStorage	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50550]	Removing CBlock[TableDeletionTest.test_table2.test_table2.0.TableDeletionTest.test_tree.test_column2]
[DEBUG] [2023-01-26 18:08:37]	c.b.c.i.s.WorkerStorage	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50550]	Removing Concept[TableDeletionTest.test_tree]
[INFO] [2023-01-26 18:08:37]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[INFO] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.RemoveImportJob	Worker[TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, /127.0.0.1:50552]	Deleting Import[NamedImpl(name=test_table2)]
127.0.0.1 - - [26/Jan/2023:18:08:37 +0000] "DELETE /admin/datasets/TableDeletionTest/tables/TableDeletionTest.test_table2 HTTP/1.1" 200 2 "-" "Conquery (test client)" 7
[DEBUG] [2023-01-26 18:08:37]	c.b.c.i.s.WorkerStorage	Worker[TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, /127.0.0.1:50552]	Removing Bucket[TableDeletionTest.test_table2.test_table2.1]
[INFO] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.RemoveTable	Worker[TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, /127.0.0.1:50552]	Received update of Table Table[label=test_table2, name=test_table2]
[INFO] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.RemoveImportJob	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50550]	Deleting Import[NamedImpl(name=test_table2)]
[DEBUG] [2023-01-26 18:08:37]	c.b.c.i.s.WorkerStorage	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50550]	Removing Bucket[TableDeletionTest.test_table2.test_table2.0]
[INFO] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.RemoveTable	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50550]	Received update of Table Table[label=test_table2, name=test_table2]
[INFO] [2023-01-26 18:08:37]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[INFO] [2023-01-26 18:08:37]	c.b.c.i.t.d.TableDeletionTest		Checking state after deletion
[INFO] [2023-01-26 18:08:37]	c.b.c.i.t.d.TableDeletionTest		Executing query after deletion
[DEBUG] [2023-01-26 18:08:37]	c.b.c.i.j.ConqueryJsonExceptionMapper	user.SUPERUSER@SUPERUSER	Unable to process JSON in request 'http://localhost:39407/api/datasets/TableDeletionTest/queries'
com.fasterxml.jackson.databind.JsonMappingException: Error while resolving entry TableDeletionTest.test_tree.test_column of type class com.bakdata.conquery.models.datasets.concepts.Connector (through reference chain: com.bakdata.conquery.apiv1.query.ConceptQuery["root"]->com.bakdata.conquery.apiv1.query.concept.specific.CQConcept["tables"]->java.util.ArrayList[0]->com.bakdata.conquery.apiv1.query.concept.filter.CQTable["id"])
	at com.fasterxml.jackson.databind.JsonMappingException.wrapWithPath(JsonMappingException.java:397)
	at com.fasterxml.jackson.databind.JsonMappingException.wrapWithPath(JsonMappingException.java:356)
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.wrapAndThrow(BeanDeserializerBase.java:1719)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:254)
	at com.fasterxml.jackson.module.afterburner.deser.SuperSonicBeanDeserializer.deserialize(SuperSonicBeanDeserializer.java:155)
	at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:286)
	at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:245)
	at com.fasterxml.jackson.databind.deser.std.CollectionDeserializer.deserialize(CollectionDeserializer.java:27)
	at com.fasterxml.jackson.databind.deser.SettableBeanProperty.deserialize(SettableBeanProperty.java:530)
	at com.fasterxml.jackson.databind.deser.impl.ManagedReferenceProperty.deserializeAndSet(ManagedReferenceProperty.java:62)
	at com.fasterxml.jackson.module.afterburner.deser.SuperSonicBeanDeserializer.deserializeFromObject(SuperSonicBeanDeserializer.java:295)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:194)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:161)
	at com.fasterxml.jackson.module.afterburner.deser.SuperSonicBeanDeserializer.deserialize(SuperSonicBeanDeserializer.java:116)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer._deserializeTypedForId(AsPropertyTypeDeserializer.java:130)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromObject(AsPropertyTypeDeserializer.java:97)
	at com.fasterxml.jackson.databind.deser.AbstractDeserializer.deserializeWithType(AbstractDeserializer.java:254)
	at com.fasterxml.jackson.databind.deser.impl.MethodProperty.deserializeAndSet(MethodProperty.java:138)
	at com.fasterxml.jackson.module.afterburner.deser.SuperSonicBeanDeserializer.deserializeFromObject(SuperSonicBeanDeserializer.java:278)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeOther(BeanDeserializer.java:194)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:161)
	at com.fasterxml.jackson.module.afterburner.deser.SuperSonicBeanDeserializer.deserialize(SuperSonicBeanDeserializer.java:116)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer._deserializeTypedForId(AsPropertyTypeDeserializer.java:130)
	at com.fasterxml.jackson.databind.jsontype.impl.AsPropertyTypeDeserializer.deserializeTypedFromObject(AsPropertyTypeDeserializer.java:97)
	at com.fasterxml.jackson.databind.deser.AbstractDeserializer.deserializeWithType(AbstractDeserializer.java:254)
	at com.fasterxml.jackson.databind.deser.impl.TypeWrappedDeserializer.deserialize(TypeWrappedDeserializer.java:68)
	at com.fasterxml.jackson.databind.ObjectReader._bind(ObjectReader.java:1682)
	at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:977)
	at com.fasterxml.jackson.jaxrs.base.ProviderBase.readFrom(ProviderBase.java:814)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.invokeReadFrom(ReaderInterceptorExecutor.java:233)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.aroundReadFrom(ReaderInterceptorExecutor.java:212)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundReadFrom(MappableExceptionWrapperInterceptor.java:49)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.message.internal.MessageBodyFactory.readFrom(MessageBodyFactory.java:1072)
	at org.glassfish.jersey.message.internal.InboundMessageContext.readEntity(InboundMessageContext.java:885)
	at org.glassfish.jersey.server.ContainerRequest.readEntity(ContainerRequest.java:282)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:73)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:56)
	at org.glassfish.jersey.server.spi.internal.ParamValueFactoryWithSource.apply(ParamValueFactoryWithSource.java:50)
	at org.glassfish.jersey.server.spi.internal.ParameterValueHelper.getParameterValues(ParameterValueHelper.java:68)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$AbstractMethodParamInvoker.getParamValues(JavaResourceMethodDispatcherProvider.java:109)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:79)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:475)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:397)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:255)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:234)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:680)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:366)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:319)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler$ChainEnd.doFilter(ServletHandler.java:1626)
	at io.dropwizard.servlets.ThreadNameFilter.doFilter(ThreadNameFilter.java:35)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
	at io.dropwizard.jersey.filter.AllowedMethodsFilter.handle(AllowedMethodsFilter.java:47)
	at io.dropwizard.jersey.filter.AllowedMethodsFilter.doFilter(AllowedMethodsFilter.java:41)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at com.codahale.metrics.jetty9.InstrumentedHandler.handle(InstrumentedHandler.java:313)
	at io.dropwizard.jetty.RoutingHandler.handle(RoutingHandler.java:52)
	at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:713)
	at org.eclipse.jetty.server.handler.RequestLogHandler.handle(RequestLogHandler.java:54)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:179)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.lang.RuntimeException: Error while resolving entry TableDeletionTest.test_tree.test_column of type class com.bakdata.conquery.models.datasets.concepts.Connector
	at com.bakdata.conquery.io.jackson.serializer.NsIdReferenceDeserializer.deserialize(NsIdReferenceDeserializer.java:65)
	at com.bakdata.conquery.io.jackson.serializer.NsIdReferenceDeserializer.deserialize(NsIdReferenceDeserializer.java:26)
	at com.fasterxml.jackson.databind.deser.impl.MethodProperty.deserializeAndSet(MethodProperty.java:129)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:252)
	... 96 common frames omitted
Caused by: com.bakdata.conquery.io.jackson.serializer.IdReferenceResolvingException: Could not find entry `TableDeletionTest.test_tree.test_column` of type com.bakdata.conquery.models.datasets.concepts.Connector
 at [Source: (org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$UnCloseableInputStream); line: 1, column: 123]
	at com.bakdata.conquery.io.jackson.serializer.NsIdReferenceDeserializer.deserialize(NsIdReferenceDeserializer.java:55)
	... 99 common frames omitted
127.0.0.1 - - [26/Jan/2023:18:08:37 +0000] "POST /api/datasets/TableDeletionTest/queries HTTP/1.1" 400 197 "-" "Conquery (test client)" 5
[INFO] [2023-01-26 18:08:37]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[INFO] [2023-01-26 18:08:37]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[INFO] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.UpdateTable	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50550]	Received update of Table TableDeletionTest.test_table2
[INFO] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.UpdateTable	Worker[TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, /127.0.0.1:50552]	Received update of Table TableDeletionTest.test_table2
[INFO] [2023-01-26 18:08:37]	c.b.c.c.PreprocessorCommand		Preprocessing from command line config.
[INFO] [2023-01-26 18:08:37]	c.b.c.c.PreprocessorCommand	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_TableDeletionTest/test_table2.import.json, tag=Optional.empty)	EXISTS ALREADY
[INFO] [2023-01-26 18:08:37]	c.b.c.c.PreprocessorCommand	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_TableDeletionTest/test_table2.import.json, tag=Optional.empty)		HASH STILL VALID
[INFO] [2023-01-26 18:08:37]	c.b.c.c.PreprocessorCommand	PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest12910953884258704183/tmp_TableDeletionTest/test_table2.import.json, tag=Optional.empty)	Required to preprocess 0 B in total
[DEBUG] [2023-01-26 18:08:37]	c.b.c.m.j.ImportJob	user.SUPERUSER@SUPERUSER	Done reading data. Contains 2 Entities.
[INFO] [2023-01-26 18:08:37]	c.b.c.m.j.ImportJob	user.SUPERUSER@SUPERUSER	Importing test_table2 into TableDeletionTest.test_table2
[DEBUG] [2023-01-26 18:08:37]	c.b.c.m.j.ImportJob	Job Manager slow TableDeletionTest	Mapped 0 new ids
[DEBUG] [2023-01-26 18:08:37]	c.b.c.m.j.ImportJob	Job Manager slow TableDeletionTest	Updating bucket assignments.
[INFO] [2023-01-26 18:08:37]	c.b.c.m.j.ImportJob	Job Manager slow TableDeletionTest	Importing Dictionaries
[DEBUG] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.UpdateWorkerBucket	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50550]	Received new WorkerInformation(size = 1,dataset = TableDeletionTest)
[DEBUG] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.UpdateWorkerBucket	Worker[TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, /127.0.0.1:50552]	Received new WorkerInformation(size = 1,dataset = TableDeletionTest)
127.0.0.1 - - [26/Jan/2023:18:08:37 +0000] "POST /admin/datasets/TableDeletionTest/imports?file=%2Ftmp%2FconqueryIntegrationTest12910953884258704183%2Ftmp_TableDeletionTest%2Ftest_table2.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 11
[INFO] [2023-01-26 18:08:37]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[INFO] [2023-01-26 18:08:37]	c.b.c.m.j.ImportJob	Job Manager slow TableDeletionTest	Remapping Dictionaries []
[WARN] [2023-01-26 18:08:37]	c.b.c.u.p.ProgressReporterImpl	Job Manager slow TableDeletionTest	Max cannot be decreased.
[DEBUG] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.UpdateDictionary	Worker[TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, /127.0.0.1:50552]	Received Dictionary[TableDeletionTest.test_table2#TableDeletionTest$2etest_table2$2etest_column] of size 2.
[DEBUG] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.UpdateDictionary	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50550]	Received Dictionary[TableDeletionTest.test_table2#TableDeletionTest$2etest_table2$2etest_column] of size 2.
[INFO] [2023-01-26 18:08:37]	c.b.c.m.j.ImportJob	Job Manager slow TableDeletionTest	Start sending 2 Buckets
[WARN] [2023-01-26 18:08:37]	c.b.c.u.p.ProgressReporterImpl	Job Manager slow TableDeletionTest	One or more Children are not done yet
[INFO] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.AddImport	Worker[TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, /127.0.0.1:50552]	Received Import[TableDeletionTest.test_table2.test_table2], containing 2 entries.
[INFO] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.ImportBucket	Worker[TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, /127.0.0.1:50552]	Received TableDeletionTest.test_table2.test_table2.1
[DEBUG] [2023-01-26 18:08:37]	c.b.c.i.s.WorkerStorage	Worker[TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, /127.0.0.1:50552]	Adding Bucket[TableDeletionTest.test_table2.test_table2.1]
[INFO] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.AddImport	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50550]	Received Import[TableDeletionTest.test_table2.test_table2], containing 2 entries.
[INFO] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.ImportBucket	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50550]	Received TableDeletionTest.test_table2.test_table2.0
[DEBUG] [2023-01-26 18:08:37]	c.b.c.i.s.WorkerStorage	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50550]	Adding Bucket[TableDeletionTest.test_table2.test_table2.0]
[INFO] [2023-01-26 18:08:37]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[DEBUG] [2023-01-26 18:08:37]	c.b.c.i.s.WorkerStorage	Worker[TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, /127.0.0.1:50552]	Updating Concept[TableDeletionTest.test_tree]
[DEBUG] [2023-01-26 18:08:37]	c.b.c.i.s.WorkerStorage	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50550]	Updating Concept[TableDeletionTest.test_tree]
[DEBUG] [2023-01-26 18:08:37]	c.b.c.i.s.WorkerStorage		Adding CBlock[TableDeletionTest.test_table2.test_table2.0.TableDeletionTest.test_tree.test_column2]
[DEBUG] [2023-01-26 18:08:37]	c.b.c.i.s.WorkerStorage		Adding CBlock[TableDeletionTest.test_table2.test_table2.1.TableDeletionTest.test_tree.test_column2]
[DEBUG] [2023-01-26 18:08:37]	c.b.c.i.s.WorkerStorage		Adding CBlock[TableDeletionTest.test_table.test_table.0.TableDeletionTest.test_tree.test_column]
[INFO] [2023-01-26 18:08:37]	c.b.c.i.t.d.TableDeletionTest		Checking state after re-import
[INFO] [2023-01-26 18:08:37]	c.b.c.i.t.d.TableDeletionTest		Executing query after re-import
[INFO] [2023-01-26 18:08:37]	c.b.c.a.QueryProcessor	user.SUPERUSER@SUPERUSER	Query posted on Dataset[TableDeletionTest] by User[{user.SUPERUSER@SUPERUSER].
[INFO] [2023-01-26 18:08:37]	c.b.c.m.q.ExecutionManager	user.SUPERUSER@SUPERUSER	Executing Query[3d6b7172-e7d1-4781-bf17-609576e6b8fb] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_TableDeletionTest))]]
[INFO] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.ExecuteQuery	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50550]	Started ConceptQuery TableDeletionTest.3d6b7172-e7d1-4781-bf17-609576e6b8fb
[INFO] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.ExecuteQuery	Worker[TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, /127.0.0.1:50552]	Started ConceptQuery TableDeletionTest.3d6b7172-e7d1-4781-bf17-609576e6b8fb
[DEBUG] [2023-01-26 18:08:37]	c.b.c.m.q.QueryExecutor	Worker[TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, /127.0.0.1:50552]	QueryPlan for Query[TableDeletionTest.3d6b7172-e7d1-4781-bf17-609576e6b8fb] = `ConceptQueryPlan(child=QPParentNode(children=[ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table, name=test_table]])])), validityDateColumn=Column(id = TableDeletionTest.test_table.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column], dateColumn=null), selectedSecondaryId=null), ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table2, name=test_table2]])])), validityDateColumn=Column(id = TableDeletionTest.test_table2.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column2], dateColumn=null), selectedSecondaryId=null)]), dateAggregator=DateAggregator(action=MERGE))`
[DEBUG] [2023-01-26 18:08:37]	c.b.c.m.q.QueryExecutor	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50550]	QueryPlan for Query[TableDeletionTest.3d6b7172-e7d1-4781-bf17-609576e6b8fb] = `ConceptQueryPlan(child=QPParentNode(children=[ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table, name=test_table]])])), validityDateColumn=Column(id = TableDeletionTest.test_table.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column], dateColumn=null), selectedSecondaryId=null), ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table2, name=test_table2]])])), validityDateColumn=Column(id = TableDeletionTest.test_table2.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column2], dateColumn=null), selectedSecondaryId=null)]), dateAggregator=DateAggregator(action=MERGE))`
[INFO] [2023-01-26 18:08:37]	c.b.c.m.q.r.ShardResult		FINISHED Query[TableDeletionTest.3d6b7172-e7d1-4781-bf17-609576e6b8fb] with 0 results within PT0.001426S
127.0.0.1 - - [26/Jan/2023:18:08:37 +0000] "POST /api/datasets/TableDeletionTest/queries HTTP/1.1" 201 1210 "-" "Conquery (test client)" 5
[DEBUG] [2023-01-26 18:08:37]	c.b.c.i.c.IntegrationUtils		Trying to get Query result
[INFO] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=TableDeletionTest]	Received ShardResult(queryId=TableDeletionTest.3d6b7172-e7d1-4781-bf17-609576e6b8fb, workerId=TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, startTime=2023-01-26T18:08:37.850976, finishTime=2023-01-26T18:08:37.852402) of size 0
[DEBUG] [2023-01-26 18:08:37]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=TableDeletionTest]	Received Result[size=0] for Query[TableDeletionTest.3d6b7172-e7d1-4781-bf17-609576e6b8fb]
[INFO] [2023-01-26 18:08:37]	c.b.c.m.q.r.ShardResult		FINISHED Query[TableDeletionTest.3d6b7172-e7d1-4781-bf17-609576e6b8fb] with 2 results within PT0.008264S
[INFO] [2023-01-26 18:08:37]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=null, name=TableDeletionTest]	Received ShardResult(queryId=TableDeletionTest.3d6b7172-e7d1-4781-bf17-609576e6b8fb, workerId=TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, startTime=2023-01-26T18:08:37.850981, finishTime=2023-01-26T18:08:37.859245) of size 2
[DEBUG] [2023-01-26 18:08:37]	c.b.c.m.q.ManagedQuery	Dataset[label=null, name=TableDeletionTest]	Received Result[size=2] for Query[TableDeletionTest.3d6b7172-e7d1-4781-bf17-609576e6b8fb]
[INFO] [2023-01-26 18:08:37]	c.b.c.m.e.ManagedExecution	Dataset[label=null, name=TableDeletionTest]	DONE 3d6b7172-e7d1-4781-bf17-609576e6b8fb ManagedQuery within PT0.011177S
127.0.0.1 - - [26/Jan/2023:18:08:37 +0000] "GET /api/datasets/TableDeletionTest/queries/TableDeletionTest.3d6b7172-e7d1-4781-bf17-609576e6b8fb HTTP/1.1" 200 1470 "-" "Conquery (test client)" 4
[INFO] [2023-01-26 18:08:37]	c.b.c.m.j.JobExecutor		Closing Job Manager fast shard-node1
[INFO] [2023-01-26 18:08:37]	c.b.c.m.j.JobExecutor		Closing Job Manager slow shard-node1
[INFO] [2023-01-26 18:08:38]	c.b.c.m.j.JobExecutor		Closing Job Manager fast worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52
[INFO] [2023-01-26 18:08:38]	c.b.c.m.j.JobExecutor		Closing Job Manager slow worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52:DATASET}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52:SECONDARY_IDS}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52:TABLES}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52:DICTIONARIES_META}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52:DICTIONARIES_DATA}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52:IMPORTS}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52:CONCEPTS}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52:WORKER}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52:BUCKETS}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52:C_BLOCKS}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52
[INFO] [2023-01-26 18:08:38]	c.b.c.c.ShardNode		Connection was closed by ManagerNode
[INFO] [2023-01-26 18:08:38]	c.b.c.c.ShardNode	0.0.0.0/0.0.0.0:50552	Disconnected from ManagerNode
[INFO] [2023-01-26 18:08:38]	c.b.c.m.j.JobExecutor		Closing Job Manager fast shard-node0
[INFO] [2023-01-26 18:08:38]	c.b.c.c.ManagerNode	ManagerNode[0.0.0.0/0.0.0.0:34233]	Client 'null' disconnected 
[INFO] [2023-01-26 18:08:38]	c.b.c.m.j.JobExecutor		Closing Job Manager slow shard-node0
[INFO] [2023-01-26 18:08:38]	c.b.c.m.j.JobExecutor		Closing Job Manager fast worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56
[INFO] [2023-01-26 18:08:38]	c.b.c.m.j.JobExecutor		Closing Job Manager slow worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56:DATASET}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56:SECONDARY_IDS}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56:TABLES}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56:DICTIONARIES_META}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56:DICTIONARIES_DATA}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56:IMPORTS}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56:CONCEPTS}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56:WORKER}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56:BUCKETS}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56:C_BLOCKS}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56
[INFO] [2023-01-26 18:08:38]	c.b.c.c.ShardNode		Connection was closed by ManagerNode
[INFO] [2023-01-26 18:08:38]	c.b.c.c.ShardNode	0.0.0.0/0.0.0.0:50550	Disconnected from ManagerNode
[INFO] [2023-01-26 18:08:38]	c.b.c.m.j.JobExecutor		Closing Job Manager fast ManagerNode
[INFO] [2023-01-26 18:08:38]	c.b.c.c.ManagerNode	ManagerNode[0.0.0.0/0.0.0.0:34233]	Client 'null' disconnected 
[INFO] [2023-01-26 18:08:38]	c.b.c.m.j.JobExecutor		Closing Job Manager slow ManagerNode
[INFO] [2023-01-26 18:08:38]	c.b.c.m.j.JobExecutor		Closing Job Manager fast TableDeletionTest
[INFO] [2023-01-26 18:08:38]	c.b.c.m.j.JobExecutor		Closing Job Manager slow TableDeletionTest
[INFO] [2023-01-26 18:08:38]	c.b.c.m.w.Namespace		Closing namespace storage of TableDeletionTest
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest:DATASET}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest:SECONDARY_IDS}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest:TABLES}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest:DICTIONARIES_META}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest:DICTIONARIES_DATA}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest:IMPORTS}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest:CONCEPTS}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest:ID_MAPPING_META}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest:ID_MAPPING_DATA}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest:STRUCTURE}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest:WORKER_TO_BUCKETS}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest:PRIMARY_DICTIONARY}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/executions:EXECUTIONS}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/executions
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/formConfigs:FORM_CONFIG}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/formConfigs
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/users:AUTH_USER}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/users
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/roles:AUTH_ROLE}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/roles
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/groups:AUTH_GROUP}
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory		Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/groups
[INFO] [2023-01-26 18:08:38]	c.b.c.u.s.TestConquery		Working in temporary directory /tmp/conqueryIntegrationTest12910953884258704183
[DEBUG] [2023-01-26 18:08:38]	c.b.c.c.StandaloneCommand	ManagerNode	Starting ManagerNode
[DEBUG] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest:DATASET}): 1 entries, 61 B within 191.2 μs
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest:SECONDARY_IDS}): 0 entries, 0 B within 35.18 μs
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest	While processing store TABLES:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest:TABLES}): 2 entries, 346 B within 266.1 μs
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest	While processing store DICTIONARIES_META:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest		loaded store cached big DICTIONARIES(Dictionary): 2 entries, 86 B within 962.4 μs
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest	While processing store IMPORTS:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest:IMPORTS}): 2 entries, 1,002 B within 4.562 ms
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest	While processing store CONCEPTS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest:CONCEPTS}): 1 entries, 617 B within 5.733 ms
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest	Done reading Dataset[label=TableDeletionTest, name=TableDeletionTest] / com.bakdata.conquery.io.storage.NamespaceStorage
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest	While processing store ID_MAPPING_META:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest		loaded store cached big ID_MAPPING(EntityIdMap): 1 entries, 43 B within 392.7 μs
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest	While processing store STRUCTURE:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest:STRUCTURE}): 0 entries, 0 B within 55.42 μs
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest	While processing store WORKER_TO_BUCKETS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest:WORKER_TO_BUCKETS}): 1 entries, 308 B within 179.2 μs
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest	While processing store PRIMARY_DICTIONARY:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest:PRIMARY_DICTIONARY}): 1 entries, 103 B within 1.010 ms
[DEBUG] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest	DONE reading Storage
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory	ManagerNode	All WorkerStores loaded: [NamespacedStorage(pathName=dataset_TableDeletionTest)]
[INFO] [2023-01-26 18:08:38]	c.b.c.c.ManagerNode	ManagerNode	Opening MetaStorage
[INFO] [2023-01-26 18:08:38]	c.b.c.c.ManagerNode	ManagerNode	Loading MetaStorage
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store AUTH_USER:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/users:AUTH_USER}): 1 entries, 149 B within 630.8 μs
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store AUTH_ROLE:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/roles:AUTH_ROLE}): 0 entries, 0 B within 35.48 μs
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store AUTH_GROUP:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/groups:AUTH_GROUP}): 0 entries, 0 B within 25.66 μs
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store EXECUTIONS:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/executions:EXECUTIONS}): 2 entries, 1.2 KiB within 6.161 ms
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	ManagerNode	While processing store FORM_CONFIG:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	ManagerNode		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/formConfigs:FORM_CONFIG}): 0 entries, 0 B within 38.16 μs
[INFO] [2023-01-26 18:08:38]	c.b.c.c.ManagerNode	ManagerNode	MetaStorage loaded com.bakdata.conquery.io.storage.MetaStorage@3d606637
[DEBUG] [2023-01-26 18:08:38]	c.b.c.m.a.AuthorizationController	ManagerNode	Security manager registered
[WARN] [2023-01-26 18:08:38]	c.b.c.m.a.d.DefaultInitialUserRealm	ManagerNode	
           §§
          §  §
         §    §
        §      §
       §  §§§§  §       You instantiated and are probably using a Shiro realm
      §   §§§§   §      that does not do any permission checks or authentication.
     §     §§     §     Access to all resources is granted to everyone.
    §      §§      §    DO NOT USE THIS REALM IN PRODUCTION
   $                §
  §        §§        §
 §                    §
 §§§§§§§§§§§§§§§§§§§§§§
[INFO] [2023-01-26 18:08:38]	c.b.c.m.a.AuthorizationController	ManagerNode	Registering the following realms to Shiro:
	com.bakdata.conquery.models.auth.conquerytoken.ConqueryTokenRealm_30
	com.bakdata.conquery.models.auth.ConqueryAuthorizationRealm_31
	com.bakdata.conquery.models.auth.develop.DefaultInitialUserRealm_32
[INFO] [2023-01-26 18:08:38]	c.b.c.c.ManagerNode	ManagerNode	Registering ResourcesProvider
[INFO] [2023-01-26 18:08:38]	c.b.c.m.f.f.FormScanner	ManagerNode	Form[EXPORT_FORM] from `Resource com/bakdata/conquery/frontend/forms/export_form.frontend_conf.json` of Type[com.bakdata.conquery.apiv1.forms.export_form.ExportForm]
[INFO] [2023-01-26 18:08:38]	c.b.c.m.f.f.FormScanner	ManagerNode	Form[FULL_EXPORT_FORM] from `Resource com/bakdata/conquery/frontend/forms/table_export_form.frontend_conf.json` of Type[com.bakdata.conquery.apiv1.forms.export_form.FullExportForm]
[DEBUG] [2023-01-26 18:08:38]	c.b.c.c.StandaloneCommand	ManagerNode	Waiting for ShardNodes to start
[DEBUG] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56:DATASET}): 1 entries, 61 B within 146.2 μs
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56:SECONDARY_IDS}): 0 entries, 0 B within 41.54 μs
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56	While processing store TABLES:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56:TABLES}): 2 entries, 346 B within 216.7 μs
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56	While processing store DICTIONARIES_META:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56		loaded store cached big DICTIONARIES(Dictionary): 2 entries, 86 B within 971.3 μs
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56	While processing store IMPORTS:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56:IMPORTS}): 2 entries, 1,002 B within 3.911 ms
[DEBUG] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52	BEGIN reading Storage
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52	While processing store DATASET:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52:DATASET}): 1 entries, 61 B within 91.58 μs
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52	While processing store SECONDARY_IDS:
	Entries processed:	0
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52:SECONDARY_IDS}): 0 entries, 0 B within 23.31 μs
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52	While processing store TABLES:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52:TABLES}): 2 entries, 346 B within 172.9 μs
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52	While processing store DICTIONARIES_META:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52		loaded store cached big DICTIONARIES(Dictionary): 2 entries, 86 B within 699.3 μs
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56	While processing store CONCEPTS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52	While processing store IMPORTS:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56:CONCEPTS}): 1 entries, 617 B within 5.359 ms
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52:IMPORTS}): 2 entries, 1,002 B within 2.920 ms
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56	Done reading Dataset[label=TableDeletionTest, name=TableDeletionTest] / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56	While processing store WORKER:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56:WORKER}): 1 entries, 136 B within 95.41 μs
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56	While processing store BUCKETS:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56:BUCKETS}): 2 entries, 740 B within 1.848 ms
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56	While processing store C_BLOCKS:
	Entries processed:	2
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56:C_BLOCKS}): 2 entries, 457 B within 260.7 μs
[DEBUG] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56	DONE reading Storage
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory	shard-node0	All WorkerStores loaded: [WorkerStorage(worker=NamedImpl(name=worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56))]
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52	While processing store CONCEPTS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52:CONCEPTS}): 1 entries, 617 B within 5.393 ms
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.NamespacedStorage	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52	Done reading Dataset[label=TableDeletionTest, name=TableDeletionTest] / com.bakdata.conquery.io.storage.WorkerStorage
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52	While processing store WORKER:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52:WORKER}): 1 entries, 136 B within 107.3 μs
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52	While processing store BUCKETS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52:BUCKETS}): 1 entries, 369 B within 1.374 ms
[DEBUG] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.SerializingStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52	While processing store C_BLOCKS:
	Entries processed:	1
	Key read failure:	0 (0.00%)
	Value read failure:	0 (0.00%)
[INFO] [2023-01-26 18:08:38]	c.b.c.i.s.x.s.CachedStore	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52		loaded store cached SerializingStore(store=XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52:C_BLOCKS}): 1 entries, 230 B within 185.7 μs
[DEBUG] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory	/tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52	DONE reading Storage
[INFO] [2023-01-26 18:08:38]	c.b.c.m.c.XodusStoreFactory	shard-node1	All WorkerStores loaded: [WorkerStorage(worker=NamedImpl(name=worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52))]
[INFO] [2023-01-26 18:08:38]	c.b.c.c.ShardNode	shard-node0	All Worker Storages loaded: 1
[INFO] [2023-01-26 18:08:38]	c.b.c.c.ShardNode	shard-node1	All Worker Storages loaded: 1
[DEBUG] [2023-01-26 18:08:38]	c.b.c.c.StandaloneCommand	ManagerNode	Starting REST Server
[INFO] [2023-01-26 18:08:38]	c.b.c.c.ManagerNode		Started ManagerNode @ /0:0:0:0:0:0:0:0:34233
[INFO] [2023-01-26 18:08:38]	c.b.c.c.ShardNode		Trying to connect to /127.0.0.1:34233
[INFO] [2023-01-26 18:08:38]	c.b.c.c.ManagerNode	ManagerNode[/127.0.0.1:34233]	New client /127.0.0.1:50846 connected, waiting for identity
[INFO] [2023-01-26 18:08:38]	c.b.c.c.ShardNode	/127.0.0.1:50846	Connected to ManagerNode @ /127.0.0.1:34233
[INFO] [2023-01-26 18:08:39]	c.b.c.c.ShardNode		Trying to connect to /127.0.0.1:34233
[INFO] [2023-01-26 18:08:39]	c.b.c.c.ManagerNode	ManagerNode[/127.0.0.1:34233]	New client /127.0.0.1:50848 connected, waiting for identity
[INFO] [2023-01-26 18:08:39]	c.b.c.c.ShardNode	/127.0.0.1:50848	Connected to ManagerNode @ /127.0.0.1:34233
[INFO] [2023-01-26 18:08:39]	c.b.c.c.ShardNode	/127.0.0.1:50846	Sending worker identity 'worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56'
[INFO] [2023-01-26 18:08:39]	c.b.c.c.ShardNode	/127.0.0.1:50848	Sending worker identity 'worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52'
[INFO] [2023-01-26 18:08:39]	c.b.c.m.m.n.s.AddShardNode	Job Manager fast ManagerNode	ShardNode `/127.0.0.1:50846` registered.
[INFO] [2023-01-26 18:08:39]	c.b.c.m.m.n.s.AddShardNode	Job Manager fast ManagerNode	ShardNode `/127.0.0.1:50848` registered.
[INFO] [2023-01-26 18:08:39]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=TableDeletionTest, name=TableDeletionTest]	Imports of worker TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52 are consistent with the manager: 2 Imports
[INFO] [2023-01-26 18:08:39]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=TableDeletionTest, name=TableDeletionTest]	Buckets of worker TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52 are consistent with the manager: 1 Buckets
[INFO] [2023-01-26 18:08:39]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=TableDeletionTest, name=TableDeletionTest]	Consistency check was successful
[INFO] [2023-01-26 18:08:39]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=TableDeletionTest, name=TableDeletionTest]	Imports of worker TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56 are consistent with the manager: 2 Imports
[INFO] [2023-01-26 18:08:39]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=TableDeletionTest, name=TableDeletionTest]	Buckets of worker TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56 are consistent with the manager: 2 Buckets
[INFO] [2023-01-26 18:08:39]	c.b.c.m.m.n.s.ReportConsistency	Dataset[label=TableDeletionTest, name=TableDeletionTest]	Consistency check was successful
[WARN] [2023-01-26 18:08:39]	o.g.j.i.Errors		The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.filters.Filter<?> from public void com.bakdata.conquery.resources.hierarchies.HFilters.setFilter(com.bakdata.conquery.models.datasets.concepts.filters.Filter<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public com.bakdata.conquery.apiv1.FullExecutionStatus com.bakdata.conquery.resources.api.QueryResource.getStatus(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) throws java.lang.InterruptedException is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public com.bakdata.conquery.apiv1.FullExecutionStatus com.bakdata.conquery.resources.api.QueryResource.patchQuery(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>,com.bakdata.conquery.apiv1.MetaDataPatch) throws com.bakdata.conquery.models.exceptions.JSONException is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public void com.bakdata.conquery.resources.api.QueryResource.deleteQuery(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>) is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public void com.bakdata.conquery.resources.api.QueryResource.cancel(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>) is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public com.bakdata.conquery.apiv1.FullExecutionStatus com.bakdata.conquery.resources.api.QueryResource.reexecute(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultExcelResource.get(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.identifiable.ids.specific.DatasetId,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultArrowStreamResource.get(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.datasets.Dataset,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultCsvResource.getAsCsv(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.datasets.Dataset,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.lang.String,java.lang.String,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultArrowFileResource.get(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.datasets.Dataset,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.filters.Filter<?> from public void com.bakdata.conquery.resources.hierarchies.HFilters.setFilter(com.bakdata.conquery.models.datasets.concepts.filters.Filter<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.

[WARN] [2023-01-26 18:08:39]	i.d.s.AdminEnvironment		
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!    THIS APPLICATION HAS NO HEALTHCHECKS. THIS MEANS YOU WILL NEVER KNOW      !
!     IF IT DIES IN PRODUCTION, WHICH MEANS YOU WILL NEVER KNOW IF YOU'RE      !
!    LETTING YOUR USERS DOWN. YOU SHOULD ADD A HEALTHCHECK FOR EACH OF YOUR    !
!         APPLICATION'S DEPENDENCIES WHICH FULLY (BUT LIGHTLY) TESTS IT.       !
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
[WARN] [2023-01-26 18:08:39]	o.g.j.i.Errors		The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.auth.entities.PermissionOwner<?> from public void com.bakdata.conquery.resources.hierarchies.HPermissions.setOwner(com.bakdata.conquery.models.auth.entities.PermissionOwner<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.auth.entities.PermissionOwner<?> from public void com.bakdata.conquery.resources.hierarchies.HPermissions.setOwner(com.bakdata.conquery.models.auth.entities.PermissionOwner<?>) is not resolvable to a concrete type.

[WARN] [2023-01-26 18:08:39]	o.g.j.i.Errors		The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter concept of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from protected com.bakdata.conquery.models.datasets.concepts.Concept<?> com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.concept is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter concept of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from protected com.bakdata.conquery.models.datasets.concepts.Concept<?> com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.concept is not resolvable to a concrete type.

[INFO] [2023-01-26 18:08:39]	c.b.c.u.s.TestConquery		loading dataset
[INFO] [2023-01-26 18:08:39]	c.b.c.u.s.TestConquery		Reusing existing folder /tmp/conqueryIntegrationTest12910953884258704183/tmp_TableDeletionTest for Support
[INFO] [2023-01-26 18:08:39]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[INFO] [2023-01-26 18:08:39]	c.b.c.i.t.d.TableDeletionTest		Checking state after re-start
[INFO] [2023-01-26 18:08:39]	c.b.c.i.t.d.TableDeletionTest		Executing query after re-import
[INFO] [2023-01-26 18:08:39]	c.b.c.a.QueryProcessor	user.SUPERUSER@SUPERUSER	Query posted on Dataset[TableDeletionTest] by User[{user.SUPERUSER@SUPERUSER].
[INFO] [2023-01-26 18:08:39]	c.b.c.m.q.ExecutionManager	user.SUPERUSER@SUPERUSER	Executing Query[a30b5069-b267-407f-a1a3-289d86b736ea] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_TableDeletionTest))]]
[INFO] [2023-01-26 18:08:39]	c.b.c.m.m.n.s.ExecuteQuery	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50846]	Started ConceptQuery TableDeletionTest.a30b5069-b267-407f-a1a3-289d86b736ea
127.0.0.1 - - [26/Jan/2023:18:08:39 +0000] "POST /api/datasets/TableDeletionTest/queries HTTP/1.1" 201 1210 "-" "Conquery (test client)" 65
[DEBUG] [2023-01-26 18:08:39]	c.b.c.m.q.QueryExecutor	Worker[TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, /127.0.0.1:50846]	QueryPlan for Query[TableDeletionTest.a30b5069-b267-407f-a1a3-289d86b736ea] = `ConceptQueryPlan(child=QPParentNode(children=[ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table, name=test_table]])])), validityDateColumn=Column(id = TableDeletionTest.test_table.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column], dateColumn=null), selectedSecondaryId=null), ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table2, name=test_table2]])])), validityDateColumn=Column(id = TableDeletionTest.test_table2.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column2], dateColumn=null), selectedSecondaryId=null)]), dateAggregator=DateAggregator(action=MERGE))`
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.c.IntegrationUtils		Trying to get Query result
[INFO] [2023-01-26 18:08:39]	c.b.c.m.m.n.s.ExecuteQuery	Worker[TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, /127.0.0.1:50848]	Started ConceptQuery TableDeletionTest.a30b5069-b267-407f-a1a3-289d86b736ea
[DEBUG] [2023-01-26 18:08:39]	c.b.c.m.q.QueryExecutor	Worker[TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, /127.0.0.1:50848]	QueryPlan for Query[TableDeletionTest.a30b5069-b267-407f-a1a3-289d86b736ea] = `ConceptQueryPlan(child=QPParentNode(children=[ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table, name=test_table]])])), validityDateColumn=Column(id = TableDeletionTest.test_table.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column], dateColumn=null), selectedSecondaryId=null), ConceptNode(super=QPChainNode(child=ValidityDateNode(super=QPChainNode(child=FiltersNode(filters=[], aggregators=[EventDateUnionAggregator(requiredTables=[Table[label=test_table2, name=test_table2]])])), validityDateColumn=Column(id = TableDeletionTest.test_table2.datum, type = DATE))), table=CQTable(filters=[], selects=[], connector=ConceptTreeConnector[label=tree_label, name=test_column2], dateColumn=null), selectedSecondaryId=null)]), dateAggregator=DateAggregator(action=MERGE))`
[INFO] [2023-01-26 18:08:39]	c.b.c.m.q.r.ShardResult		FINISHED Query[TableDeletionTest.a30b5069-b267-407f-a1a3-289d86b736ea] with 0 results within PT0.001742S
[INFO] [2023-01-26 18:08:39]	c.b.c.m.q.r.ShardResult		FINISHED Query[TableDeletionTest.a30b5069-b267-407f-a1a3-289d86b736ea] with 2 results within PT0.010291S
[INFO] [2023-01-26 18:08:39]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=TableDeletionTest, name=TableDeletionTest]	Received ShardResult(queryId=TableDeletionTest.a30b5069-b267-407f-a1a3-289d86b736ea, workerId=TableDeletionTest.worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52, startTime=2023-01-26T18:08:39.440852, finishTime=2023-01-26T18:08:39.442594) of size 0
[DEBUG] [2023-01-26 18:08:39]	c.b.c.m.q.ManagedQuery	Dataset[label=TableDeletionTest, name=TableDeletionTest]	Received Result[size=0] for Query[TableDeletionTest.a30b5069-b267-407f-a1a3-289d86b736ea]
[INFO] [2023-01-26 18:08:39]	c.b.c.m.m.n.s.CollectQueryResult	Dataset[label=TableDeletionTest, name=TableDeletionTest]	Received ShardResult(queryId=TableDeletionTest.a30b5069-b267-407f-a1a3-289d86b736ea, workerId=TableDeletionTest.worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56, startTime=2023-01-26T18:08:39.433831, finishTime=2023-01-26T18:08:39.444122) of size 2
[DEBUG] [2023-01-26 18:08:39]	c.b.c.m.q.ManagedQuery	Dataset[label=TableDeletionTest, name=TableDeletionTest]	Received Result[size=2] for Query[TableDeletionTest.a30b5069-b267-407f-a1a3-289d86b736ea]
[INFO] [2023-01-26 18:08:39]	c.b.c.m.e.ManagedExecution	Dataset[label=TableDeletionTest, name=TableDeletionTest]	DONE a30b5069-b267-407f-a1a3-289d86b736ea ManagedQuery within PT0.035467S
127.0.0.1 - - [26/Jan/2023:18:08:39 +0000] "GET /api/datasets/TableDeletionTest/queries/TableDeletionTest.a30b5069-b267-407f-a1a3-289d86b736ea HTTP/1.1" 200 1470 "-" "Conquery (test client)" 5
[INFO] [2023-01-26 18:08:39]	c.b.c.m.j.JobExecutor		Closing Job Manager fast TableDeletionTest
[INFO] [2023-01-26 18:08:39]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node0	removing worker for Dataset[label=TableDeletionTest, name=TableDeletionTest]
[INFO] [2023-01-26 18:08:39]	c.b.c.m.m.n.s.RemoveWorker	Job Manager slow shard-node1	removing worker for Dataset[label=TableDeletionTest, name=TableDeletionTest]
[INFO] [2023-01-26 18:08:39]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager fast worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56
[INFO] [2023-01-26 18:08:39]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager fast worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52
[INFO] [2023-01-26 18:08:39]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node0	Closing Job Manager slow worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56
[INFO] [2023-01-26 18:08:39]	c.b.c.m.j.JobExecutor	Job Manager slow shard-node1	Closing Job Manager slow worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node1	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52
[INFO] [2023-01-26 18:08:39]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node1	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node1/worker_worker_TableDeletionTest_a6920572-eb55-413f-9fac-cecba2d85f52
[INFO] [2023-01-26 18:08:39]	c.b.c.m.j.JobExecutor		Closing Job Manager slow TableDeletionTest
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56
[INFO] [2023-01-26 18:08:39]	c.b.c.m.w.Namespace		Removing namespace storage of TableDeletionTest
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore		Deleting store DATASET from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore		Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store SECONDARY_IDS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore		Deleting store TABLES from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore		Deleting store DICTIONARIES_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore		Deleting store DICTIONARIES_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore		Deleting store IMPORTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store WORKER from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore		Deleting store CONCEPTS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore		Deleting store ID_MAPPING_META from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore	Job Manager slow shard-node0	Deleting store C_BLOCKS from environment /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore		Deleting store ID_MAPPING_DATA from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest
[INFO] [2023-01-26 18:08:39]	c.b.c.m.c.XodusStoreFactory	Job Manager slow shard-node0	Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/shard-node0/worker_worker_TableDeletionTest_3e70da76-0ed0-40f9-89c8-eb9cb1fd5e56
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore		Deleting store STRUCTURE from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore		Deleting store WORKER_TO_BUCKETS from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest
[DEBUG] [2023-01-26 18:08:39]	c.b.c.i.s.x.s.XodusStore		Deleting store PRIMARY_DICTIONARY from environment /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest
[INFO] [2023-01-26 18:08:39]	c.b.c.m.c.XodusStoreFactory		Removed last XodusStore in Environment. Removing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/dataset_TableDeletionTest
[INFO] [2023-01-26 18:08:39]	c.b.c.u.s.TestConquery		Waiting for jobs to finish
[INFO] [2023-01-26 18:08:39]	c.b.c.i.IntegrationTest$Wrapper	TableDeletionTest	SUCCESS integration test TableDeletionTest
[INFO] [2023-01-26 18:08:39]	c.b.c.u.s.TestConquery	TableDeletionTest	Working in temporary directory /tmp/conqueryIntegrationTest11721327024597521698
INFO  [2023-01-26 18:08:39,744] io.dropwizard.server.DefaultServerFactory: Registering jersey handler with root path prefix: /
INFO  [2023-01-26 18:08:39,744] io.dropwizard.server.DefaultServerFactory: Registering admin handler with root path prefix: /
INFO  [2023-01-26 18:08:39,749] com.bakdata.conquery.commands.ManagerNode: Opening MetaStorage
INFO  [2023-01-26 18:08:39,749] com.bakdata.conquery.commands.ManagerNode: Loading MetaStorage
INFO  [2023-01-26 18:08:39,749] com.bakdata.conquery.commands.ManagerNode: MetaStorage loaded com.bakdata.conquery.io.storage.MetaStorage@10b63d7f
WARN  [2023-01-26 18:08:39,750] com.bakdata.conquery.models.auth.develop.DefaultInitialUserRealm: 
           §§
          §  §
         §    §
        §      §
       §  §§§§  §       You instantiated and are probably using a Shiro realm
      §   §§§§   §      that does not do any permission checks or authentication.
     §     §§     §     Access to all resources is granted to everyone.
    §      §§      §    DO NOT USE THIS REALM IN PRODUCTION
   $                §
  §        §§        §
 §                    §
 §§§§§§§§§§§§§§§§§§§§§§
INFO  [2023-01-26 18:08:39,750] com.bakdata.conquery.models.auth.AuthorizationController: Registering the following realms to Shiro:
	com.bakdata.conquery.models.auth.conquerytoken.ConqueryTokenRealm_33
	com.bakdata.conquery.models.auth.ConqueryAuthorizationRealm_34
	com.bakdata.conquery.models.auth.develop.DefaultInitialUserRealm_35
INFO  [2023-01-26 18:08:39,750] com.bakdata.conquery.commands.ManagerNode: Registering ResourcesProvider
INFO  [2023-01-26 18:08:39,756] com.bakdata.conquery.models.forms.frontendconfiguration.FormScanner: Form[EXPORT_FORM] from `Resource com/bakdata/conquery/frontend/forms/export_form.frontend_conf.json` of Type[com.bakdata.conquery.apiv1.forms.export_form.ExportForm]
INFO  [2023-01-26 18:08:39,756] com.bakdata.conquery.models.forms.frontendconfiguration.FormScanner: Form[FULL_EXPORT_FORM] from `Resource com/bakdata/conquery/frontend/forms/table_export_form.frontend_conf.json` of Type[com.bakdata.conquery.apiv1.forms.export_form.FullExportForm]
INFO  [2023-01-26 18:08:39,797] com.bakdata.conquery.commands.ShardNode: All Worker Storages loaded: 0
INFO  [2023-01-26 18:08:39,797] com.bakdata.conquery.commands.ShardNode: All Worker Storages loaded: 0
INFO  [2023-01-26 18:08:39,797] io.dropwizard.server.ServerFactory: Starting Conquery


 ▄████████  ▄██████▄  ███▄▄▄▄   ████████▄   ███    █▄     ▄████████    ▄████████ ▄██   ▄   
███    ███ ███    ███ ███▀▀▀██▄ ███    ███  ███    ███   ███    ███   ███    ███ ███   ██▄ 
███    █▀  ███    ███ ███   ███ ███    ███  ███    ███   ███    █▀    ███    ███ ███▄▄▄███ 
███        ███    ███ ███   ███ ███    ███  ███    ███  ▄███▄▄▄      ▄███▄▄▄▄██▀ ▀▀▀▀▀▀███ 
███        ███    ███ ███   ███ ███    ███  ███    ███ ▀▀███▀▀▀     ▀▀███▀▀▀▀▀   ▄██   ███ 
███    █▄  ███    ███ ███   ███ ███    ███  ███    ███   ███    █▄  ▀███████████ ███   ███ 
███    ███ ███    ███ ███   ███ ███  ▀ ███  ███    ███   ███    ███   ███    ███ ███   ███ 
████████▀   ▀██████▀   ▀█   █▀   ▀██████▀▄█ ████████▀    ██████████   ███    ███  ▀█████▀  
                                                                      ███    ███           
Version: 0.0.0-SNAPSHOT(${git.commit.id.describe})

           
INFO  [2023-01-26 18:08:39,800] org.eclipse.jetty.setuid.SetUIDListener: Opened application@31f36816{HTTP/1.1, (http/1.1)}{0.0.0.0:37893}
INFO  [2023-01-26 18:08:39,800] org.eclipse.jetty.setuid.SetUIDListener: Opened admin@6e10a039{HTTP/1.1, (http/1.1)}{0.0.0.0:37395}
INFO  [2023-01-26 18:08:39,800] org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.17+8-post-Ubuntu-1ubuntu218.04
INFO  [2023-01-26 18:08:39,802] com.bakdata.conquery.commands.ManagerNode: Started ManagerNode @ /0:0:0:0:0:0:0:0:38861
INFO  [2023-01-26 18:08:39,803] com.bakdata.conquery.commands.ShardNode: Trying to connect to /127.0.0.1:38861
INFO  [2023-01-26 18:08:39,804] com.bakdata.conquery.commands.ManagerNode: New client /127.0.0.1:51066 connected, waiting for identity
INFO  [2023-01-26 18:08:39,804] com.bakdata.conquery.commands.ShardNode: Connected to ManagerNode @ /127.0.0.1:38861
INFO  [2023-01-26 18:08:39,805] com.bakdata.conquery.commands.ShardNode: Trying to connect to /127.0.0.1:38861
INFO  [2023-01-26 18:08:39,817] com.bakdata.conquery.commands.ShardNode: Connected to ManagerNode @ /127.0.0.1:38861
INFO  [2023-01-26 18:08:39,817] com.bakdata.conquery.commands.ManagerNode: New client /127.0.0.1:51068 connected, waiting for identity
INFO  [2023-01-26 18:08:39,821] com.bakdata.conquery.models.messages.network.specific.AddShardNode: ShardNode `/127.0.0.1:51066` registered.
INFO  [2023-01-26 18:08:39,823] com.bakdata.conquery.models.messages.network.specific.AddShardNode: ShardNode `/127.0.0.1:51068` registered.
INFO  [2023-01-26 18:08:39,913] io.dropwizard.jersey.DropwizardResourceConfig: The following paths were found for the configured resources:

    GET     /api/config/frontend (com.bakdata.conquery.resources.api.ConfigResource)
    GET     /api/datasets (com.bakdata.conquery.resources.api.DatasetsResource)
    GET     /api/datasets/{dataset}/concepts (com.bakdata.conquery.resources.api.DatasetResource)
    GET     /api/datasets/{dataset}/concepts/{concept} (com.bakdata.conquery.resources.api.ConceptResource)
    POST    /api/datasets/{dataset}/concepts/{concept}/resolve (com.bakdata.conquery.resources.api.ConceptResource)
    POST    /api/datasets/{dataset}/concepts/{concept}/tables/{table}/filters/{filter}/autocomplete (com.bakdata.conquery.resources.api.FilterResource)
    POST    /api/datasets/{dataset}/concepts/{concept}/tables/{table}/filters/{filter}/resolve (com.bakdata.conquery.resources.api.FilterResource)
    GET     /api/datasets/{dataset}/form-configs (com.bakdata.conquery.resources.api.FormConfigResource)
    POST    /api/datasets/{dataset}/form-configs (com.bakdata.conquery.resources.api.FormConfigResource)
    DELETE  /api/datasets/{dataset}/form-configs/{form-config} (com.bakdata.conquery.resources.api.FormConfigResource)
    GET     /api/datasets/{dataset}/form-configs/{form-config} (com.bakdata.conquery.resources.api.FormConfigResource)
    PATCH   /api/datasets/{dataset}/form-configs/{form-config} (com.bakdata.conquery.resources.api.FormConfigResource)
    GET     /api/datasets/{dataset}/form-queries (com.bakdata.conquery.resources.api.FormResource)
    GET     /api/datasets/{dataset}/queries (com.bakdata.conquery.resources.api.QueryResource)
    POST    /api/datasets/{dataset}/queries (com.bakdata.conquery.resources.api.QueryResource)
    POST    /api/datasets/{dataset}/queries/upload (com.bakdata.conquery.resources.api.QueryResource)
    DELETE  /api/datasets/{dataset}/queries/{query} (com.bakdata.conquery.resources.api.QueryResource)
    GET     /api/datasets/{dataset}/queries/{query} (com.bakdata.conquery.resources.api.QueryResource)
    PATCH   /api/datasets/{dataset}/queries/{query} (com.bakdata.conquery.resources.api.QueryResource)
    POST    /api/datasets/{dataset}/queries/{query}/cancel (com.bakdata.conquery.resources.api.QueryResource)
    POST    /api/datasets/{dataset}/queries/{query}/reexecute (com.bakdata.conquery.resources.api.QueryResource)
    GET     /api/datasets/{dataset}/result/{query}.arrf (com.bakdata.conquery.resources.api.ResultArrowFileResource)
    GET     /api/datasets/{dataset}/result/{query}.arrs (com.bakdata.conquery.resources.api.ResultArrowStreamResource)
    GET     /api/datasets/{dataset}/result/{query}.csv (com.bakdata.conquery.resources.api.ResultCsvResource)
    GET     /api/datasets/{dataset}/result/{query}.xlsx (com.bakdata.conquery.resources.api.ResultExcelResource)
    GET     /api/me (com.bakdata.conquery.resources.api.MeResource)

WARN  [2023-01-26 18:08:39,913] org.glassfish.jersey.internal.Errors: The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.filters.Filter<?> from public void com.bakdata.conquery.resources.hierarchies.HFilters.setFilter(com.bakdata.conquery.models.datasets.concepts.filters.Filter<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public com.bakdata.conquery.apiv1.FullExecutionStatus com.bakdata.conquery.resources.api.QueryResource.getStatus(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) throws java.lang.InterruptedException is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public com.bakdata.conquery.apiv1.FullExecutionStatus com.bakdata.conquery.resources.api.QueryResource.patchQuery(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>,com.bakdata.conquery.apiv1.MetaDataPatch) throws com.bakdata.conquery.models.exceptions.JSONException is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public void com.bakdata.conquery.resources.api.QueryResource.deleteQuery(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>) is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public void com.bakdata.conquery.resources.api.QueryResource.cancel(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>) is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public com.bakdata.conquery.apiv1.FullExecutionStatus com.bakdata.conquery.resources.api.QueryResource.reexecute(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultExcelResource.get(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.identifiable.ids.specific.DatasetId,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultArrowStreamResource.get(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.datasets.Dataset,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultCsvResource.getAsCsv(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.datasets.Dataset,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.lang.String,java.lang.String,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultArrowFileResource.get(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.datasets.Dataset,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.filters.Filter<?> from public void com.bakdata.conquery.resources.hierarchies.HFilters.setFilter(com.bakdata.conquery.models.datasets.concepts.filters.Filter<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.

INFO  [2023-01-26 18:08:39,955] io.dropwizard.jersey.DropwizardResourceConfig: The following paths were found for the configured resources:

    NONE

INFO  [2023-01-26 18:08:39,955] org.eclipse.jetty.server.handler.ContextHandler: Started i.d.j.MutableServletContextHandler@72d630c5{/,null,AVAILABLE}
INFO  [2023-01-26 18:08:39,955] io.dropwizard.setup.AdminEnvironment: tasks = 

    POST    /tasks/permission-cleanup (com.bakdata.conquery.tasks.PermissionCleanupTask)
    POST    /tasks/report-consistency (com.bakdata.conquery.tasks.ReportConsistencyTask)
    POST    /tasks/log-level (io.dropwizard.servlets.tasks.LogConfigurationTask)
    POST    /tasks/form-scanner (com.bakdata.conquery.models.forms.frontendconfiguration.FormScanner)
    POST    /tasks/clear-filter-source-search (com.bakdata.conquery.tasks.ClearFilterSourceSearch)
    POST    /tasks/gc (io.dropwizard.servlets.tasks.GarbageCollectionTask)
    POST    /tasks/query-cleanup (com.bakdata.conquery.tasks.QueryCleanupTask)
    POST    /tasks/shutdown (com.bakdata.conquery.resources.admin.ShutdownTask)

WARN  [2023-01-26 18:08:39,955] io.dropwizard.setup.AdminEnvironment: 
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!    THIS APPLICATION HAS NO HEALTHCHECKS. THIS MEANS YOU WILL NEVER KNOW      !
!     IF IT DIES IN PRODUCTION, WHICH MEANS YOU WILL NEVER KNOW IF YOU'RE      !
!    LETTING YOUR USERS DOWN. YOU SHOULD ADD A HEALTHCHECK FOR EACH OF YOUR    !
!         APPLICATION'S DEPENDENCIES WHICH FULLY (BUT LIGHTLY) TESTS IT.       !
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
INFO  [2023-01-26 18:08:40,039] io.dropwizard.jersey.DropwizardResourceConfig: The following paths were found for the configured resources:

    GET     /admin/auth-overview/csv (com.bakdata.conquery.resources.admin.rest.AuthOverviewResource)
    GET     /admin/auth-overview/csv/group/{groupId} (com.bakdata.conquery.resources.admin.rest.AuthOverviewResource)
    GET     /admin/datasets (com.bakdata.conquery.resources.admin.rest.AdminDatasetsResource)
    POST    /admin/datasets (com.bakdata.conquery.resources.admin.rest.AdminDatasetsResource)
    DELETE  /admin/datasets/{dataset} (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    GET     /admin/datasets/{dataset} (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    GET     /admin/datasets/{dataset}/concepts (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    POST    /admin/datasets/{dataset}/concepts (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    PUT     /admin/datasets/{dataset}/concepts (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    DELETE  /admin/datasets/{dataset}/concepts/{concept} (com.bakdata.conquery.resources.admin.rest.AdminConceptsResource)
    GET     /admin/datasets/{dataset}/concepts/{concept} (com.bakdata.conquery.resources.admin.rest.AdminConceptsResource)
    POST    /admin/datasets/{dataset}/cqpp (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    PUT     /admin/datasets/{dataset}/cqpp (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    POST    /admin/datasets/{dataset}/imports (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    PUT     /admin/datasets/{dataset}/imports (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    POST    /admin/datasets/{dataset}/label (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    GET     /admin/datasets/{dataset}/mapping (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    POST    /admin/datasets/{dataset}/mapping (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    POST    /admin/datasets/{dataset}/secondaryId (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    DELETE  /admin/datasets/{dataset}/secondaryId/{secondaryId} (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    POST    /admin/datasets/{dataset}/structure (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    GET     /admin/datasets/{dataset}/tables (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    POST    /admin/datasets/{dataset}/tables (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    DELETE  /admin/datasets/{dataset}/tables/{table} (com.bakdata.conquery.resources.admin.rest.AdminTablesResource)
    GET     /admin/datasets/{dataset}/tables/{table} (com.bakdata.conquery.resources.admin.rest.AdminTablesResource)
    GET     /admin/datasets/{dataset}/tables/{table}/imports (com.bakdata.conquery.resources.admin.rest.AdminTablesResource)
    DELETE  /admin/datasets/{dataset}/tables/{table}/imports/{importId} (com.bakdata.conquery.resources.admin.rest.AdminTablesResource)
    GET     /admin/datasets/{dataset}/tables/{table}/imports/{importId} (com.bakdata.conquery.resources.admin.rest.AdminTablesResource)
    POST    /admin/datasets/{dataset}/update-matching-stats (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    POST    /admin/datasets/{dataset}/weight (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    GET     /admin/groups (com.bakdata.conquery.resources.admin.rest.GroupResource)
    POST    /admin/groups (com.bakdata.conquery.resources.admin.rest.GroupResource)
    DELETE  /admin/groups/{groupId} (com.bakdata.conquery.resources.admin.rest.GroupResource)
    GET     /admin/groups/{groupId} (com.bakdata.conquery.resources.admin.rest.GroupResource)
    DELETE  /admin/groups/{groupId}/roles/{roleId} (com.bakdata.conquery.resources.admin.rest.GroupResource)
    POST    /admin/groups/{groupId}/roles/{roleId} (com.bakdata.conquery.resources.admin.rest.GroupResource)
    DELETE  /admin/groups/{groupId}/users/{userId} (com.bakdata.conquery.resources.admin.rest.GroupResource)
    POST    /admin/groups/{groupId}/users/{userId} (com.bakdata.conquery.resources.admin.rest.GroupResource)
    GET     /admin/jobs (com.bakdata.conquery.resources.admin.rest.AdminResource)
    POST    /admin/jobs/{jobId}/cancel (com.bakdata.conquery.resources.admin.rest.AdminResource)
    GET     /admin/logout (com.bakdata.conquery.resources.admin.rest.AdminResource)
    DELETE  /admin/permissions/{ownerId} (com.bakdata.conquery.resources.admin.rest.PermissionResource)
    POST    /admin/permissions/{ownerId} (com.bakdata.conquery.resources.admin.rest.PermissionResource)
    GET     /admin/queries (com.bakdata.conquery.resources.admin.rest.AdminResource)
    GET     /admin/roles (com.bakdata.conquery.resources.admin.rest.RoleResource)
    POST    /admin/roles (com.bakdata.conquery.resources.admin.rest.RoleResource)
    DELETE  /admin/roles/{roleId} (com.bakdata.conquery.resources.admin.rest.RoleResource)
    GET     /admin/roles/{roleId} (com.bakdata.conquery.resources.admin.rest.RoleResource)
    POST    /admin/script (com.bakdata.conquery.resources.admin.rest.AdminResource)
    GET     /admin/users (com.bakdata.conquery.resources.admin.rest.UserResource)
    POST    /admin/users (com.bakdata.conquery.resources.admin.rest.UserResource)
    POST    /admin/users/upload (com.bakdata.conquery.resources.admin.rest.UserResource)
    DELETE  /admin/users/{userId} (com.bakdata.conquery.resources.admin.rest.UserResource)
    GET     /admin/users/{userId} (com.bakdata.conquery.resources.admin.rest.UserResource)
    DELETE  /admin/users/{userId}/roles/{roleId} (com.bakdata.conquery.resources.admin.rest.UserResource)
    POST    /admin/users/{userId}/roles/{roleId} (com.bakdata.conquery.resources.admin.rest.UserResource)

WARN  [2023-01-26 18:08:40,039] org.glassfish.jersey.internal.Errors: The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.auth.entities.PermissionOwner<?> from public void com.bakdata.conquery.resources.hierarchies.HPermissions.setOwner(com.bakdata.conquery.models.auth.entities.PermissionOwner<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.auth.entities.PermissionOwner<?> from public void com.bakdata.conquery.resources.hierarchies.HPermissions.setOwner(com.bakdata.conquery.models.auth.entities.PermissionOwner<?>) is not resolvable to a concrete type.

INFO  [2023-01-26 18:08:40,072] io.dropwizard.jersey.DropwizardResourceConfig: The following paths were found for the configured resources:

    GET     /admin-ui/ (com.bakdata.conquery.resources.admin.ui.AdminUIResource)
    GET     /admin-ui/auth-overview (com.bakdata.conquery.resources.admin.ui.AuthOverviewUIResource)
    GET     /admin-ui/datasets (com.bakdata.conquery.resources.admin.ui.DatasetsUIResource)
    GET     /admin-ui/datasets/{dataset} (com.bakdata.conquery.resources.admin.ui.DatasetsUIResource)
    GET     /admin-ui/datasets/{dataset}/concepts/{concept} (com.bakdata.conquery.resources.admin.ui.ConceptsUIResource)
    GET     /admin-ui/datasets/{dataset}/mapping (com.bakdata.conquery.resources.admin.ui.DatasetsUIResource)
    GET     /admin-ui/datasets/{dataset}/tables/{table} (com.bakdata.conquery.resources.admin.ui.TablesUIResource)
    GET     /admin-ui/datasets/{dataset}/tables/{table}/import/{importId} (com.bakdata.conquery.resources.admin.ui.TablesUIResource)
    GET     /admin-ui/groups (com.bakdata.conquery.resources.admin.ui.GroupUIResource)
    GET     /admin-ui/groups/{groupId} (com.bakdata.conquery.resources.admin.ui.GroupUIResource)
    GET     /admin-ui/jobs (com.bakdata.conquery.resources.admin.ui.AdminUIResource)
    GET     /admin-ui/queries (com.bakdata.conquery.resources.admin.ui.AdminUIResource)
    GET     /admin-ui/roles (com.bakdata.conquery.resources.admin.ui.RoleUIResource)
    GET     /admin-ui/roles/{roleId} (com.bakdata.conquery.resources.admin.ui.RoleUIResource)
    GET     /admin-ui/script (com.bakdata.conquery.resources.admin.ui.AdminUIResource)
    GET     /admin-ui/users (com.bakdata.conquery.resources.admin.ui.UserUIResource)
    GET     /admin-ui/users/{userId} (com.bakdata.conquery.resources.admin.ui.UserUIResource)

WARN  [2023-01-26 18:08:40,072] org.glassfish.jersey.internal.Errors: The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter concept of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from protected com.bakdata.conquery.models.datasets.concepts.Concept<?> com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.concept is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter concept of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from protected com.bakdata.conquery.models.datasets.concepts.Concept<?> com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.concept is not resolvable to a concrete type.

INFO  [2023-01-26 18:08:40,117] io.dropwizard.jersey.DropwizardResourceConfig: The following paths were found for the configured resources:

    NONE

INFO  [2023-01-26 18:08:40,117] org.eclipse.jetty.server.handler.ContextHandler: Started i.d.j.MutableServletContextHandler@3904195{/,null,AVAILABLE}
INFO  [2023-01-26 18:08:40,132] org.eclipse.jetty.server.AbstractConnector: Started application@31f36816{HTTP/1.1, (http/1.1)}{0.0.0.0:37893}
INFO  [2023-01-26 18:08:40,135] org.eclipse.jetty.server.AbstractConnector: Started admin@6e10a039{HTTP/1.1, (http/1.1)}{0.0.0.0:37395}
INFO  [2023-01-26 18:08:40,135] org.eclipse.jetty.server.Server: Started @59674ms
INFO  [2023-01-26 18:08:40,276] com.bakdata.conquery.util.support.TestConquery: Working in temporary directory /tmp/conqueryIntegrationTest11721327024597521698
INFO  [2023-01-26 18:08:40,292] io.dropwizard.server.DefaultServerFactory: Registering jersey handler with root path prefix: /
INFO  [2023-01-26 18:08:40,292] io.dropwizard.server.DefaultServerFactory: Registering admin handler with root path prefix: /
INFO  [2023-01-26 18:08:40,297] com.bakdata.conquery.commands.ManagerNode: Opening MetaStorage
INFO  [2023-01-26 18:08:40,297] com.bakdata.conquery.commands.ManagerNode: Loading MetaStorage
INFO  [2023-01-26 18:08:40,297] com.bakdata.conquery.commands.ManagerNode: MetaStorage loaded com.bakdata.conquery.io.storage.MetaStorage@41f12dc1
WARN  [2023-01-26 18:08:40,298] com.bakdata.conquery.models.auth.develop.DefaultInitialUserRealm: 
           §§
          §  §
         §    §
        §      §
       §  §§§§  §       You instantiated and are probably using a Shiro realm
      §   §§§§   §      that does not do any permission checks or authentication.
     §     §§     §     Access to all resources is granted to everyone.
    §      §§      §    DO NOT USE THIS REALM IN PRODUCTION
   $                §
  §        §§        §
 §                    §
 §§§§§§§§§§§§§§§§§§§§§§
INFO  [2023-01-26 18:08:40,298] com.bakdata.conquery.models.auth.AuthorizationController: Registering the following realms to Shiro:
	com.bakdata.conquery.models.auth.conquerytoken.ConqueryTokenRealm_36
	com.bakdata.conquery.models.auth.ConqueryAuthorizationRealm_37
	com.bakdata.conquery.models.auth.develop.DefaultInitialUserRealm_38
INFO  [2023-01-26 18:08:40,298] com.bakdata.conquery.commands.ManagerNode: Registering ResourcesProvider
INFO  [2023-01-26 18:08:40,304] com.bakdata.conquery.models.forms.frontendconfiguration.FormScanner: Form[EXPORT_FORM] from `Resource com/bakdata/conquery/frontend/forms/export_form.frontend_conf.json` of Type[com.bakdata.conquery.apiv1.forms.export_form.ExportForm]
INFO  [2023-01-26 18:08:40,304] com.bakdata.conquery.models.forms.frontendconfiguration.FormScanner: Form[FULL_EXPORT_FORM] from `Resource com/bakdata/conquery/frontend/forms/table_export_form.frontend_conf.json` of Type[com.bakdata.conquery.apiv1.forms.export_form.FullExportForm]
INFO  [2023-01-26 18:08:40,475] com.bakdata.conquery.commands.ShardNode: All Worker Storages loaded: 0
INFO  [2023-01-26 18:08:40,479] com.bakdata.conquery.commands.ShardNode: All Worker Storages loaded: 0
INFO  [2023-01-26 18:08:40,479] io.dropwizard.server.ServerFactory: Starting Conquery


 ▄████████  ▄██████▄  ███▄▄▄▄   ████████▄   ███    █▄     ▄████████    ▄████████ ▄██   ▄   
███    ███ ███    ███ ███▀▀▀██▄ ███    ███  ███    ███   ███    ███   ███    ███ ███   ██▄ 
███    █▀  ███    ███ ███   ███ ███    ███  ███    ███   ███    █▀    ███    ███ ███▄▄▄███ 
███        ███    ███ ███   ███ ███    ███  ███    ███  ▄███▄▄▄      ▄███▄▄▄▄██▀ ▀▀▀▀▀▀███ 
███        ███    ███ ███   ███ ███    ███  ███    ███ ▀▀███▀▀▀     ▀▀███▀▀▀▀▀   ▄██   ███ 
███    █▄  ███    ███ ███   ███ ███    ███  ███    ███   ███    █▄  ▀███████████ ███   ███ 
███    ███ ███    ███ ███   ███ ███  ▀ ███  ███    ███   ███    ███   ███    ███ ███   ███ 
████████▀   ▀██████▀   ▀█   █▀   ▀██████▀▄█ ████████▀    ██████████   ███    ███  ▀█████▀  
                                                                      ███    ███           
Version: 0.0.0-SNAPSHOT(${git.commit.id.describe})

           
INFO  [2023-01-26 18:08:40,484] org.eclipse.jetty.setuid.SetUIDListener: Opened application@58fbfd4d{HTTP/1.1, (http/1.1)}{0.0.0.0:45505}
INFO  [2023-01-26 18:08:40,484] org.eclipse.jetty.setuid.SetUIDListener: Opened admin@449d3375{HTTP/1.1, (http/1.1)}{0.0.0.0:35531}
INFO  [2023-01-26 18:08:40,484] org.eclipse.jetty.server.Server: jetty-9.4.43.v20210629; built: 2021-06-30T11:07:22.254Z; git: 526006ecfa3af7f1a27ef3a288e2bef7ea9dd7e8; jvm 11.0.17+8-post-Ubuntu-1ubuntu218.04
INFO  [2023-01-26 18:08:40,486] com.bakdata.conquery.commands.ManagerNode: Started ManagerNode @ /0:0:0:0:0:0:0:0:42009
INFO  [2023-01-26 18:08:40,487] com.bakdata.conquery.commands.ShardNode: Trying to connect to /127.0.0.1:42009
INFO  [2023-01-26 18:08:40,489] com.bakdata.conquery.commands.ManagerNode: New client /127.0.0.1:56772 connected, waiting for identity
INFO  [2023-01-26 18:08:40,490] com.bakdata.conquery.commands.ShardNode: Connected to ManagerNode @ /127.0.0.1:42009
INFO  [2023-01-26 18:08:40,491] com.bakdata.conquery.commands.ShardNode: Trying to connect to /127.0.0.1:42009
INFO  [2023-01-26 18:08:40,494] com.bakdata.conquery.models.messages.network.specific.AddShardNode: ShardNode `/127.0.0.1:56772` registered.
INFO  [2023-01-26 18:08:40,499] com.bakdata.conquery.commands.ManagerNode: New client /127.0.0.1:56774 connected, waiting for identity
INFO  [2023-01-26 18:08:40,515] com.bakdata.conquery.commands.ShardNode: Connected to ManagerNode @ /127.0.0.1:42009
INFO  [2023-01-26 18:08:40,521] com.bakdata.conquery.models.messages.network.specific.AddShardNode: ShardNode `/127.0.0.1:56774` registered.
INFO  [2023-01-26 18:08:40,598] io.dropwizard.jersey.DropwizardResourceConfig: The following paths were found for the configured resources:

    GET     /api/config/frontend (com.bakdata.conquery.resources.api.ConfigResource)
    GET     /api/datasets (com.bakdata.conquery.resources.api.DatasetsResource)
    GET     /api/datasets/{dataset}/concepts (com.bakdata.conquery.resources.api.DatasetResource)
    GET     /api/datasets/{dataset}/concepts/{concept} (com.bakdata.conquery.resources.api.ConceptResource)
    POST    /api/datasets/{dataset}/concepts/{concept}/resolve (com.bakdata.conquery.resources.api.ConceptResource)
    POST    /api/datasets/{dataset}/concepts/{concept}/tables/{table}/filters/{filter}/autocomplete (com.bakdata.conquery.resources.api.FilterResource)
    POST    /api/datasets/{dataset}/concepts/{concept}/tables/{table}/filters/{filter}/resolve (com.bakdata.conquery.resources.api.FilterResource)
    GET     /api/datasets/{dataset}/form-configs (com.bakdata.conquery.resources.api.FormConfigResource)
    POST    /api/datasets/{dataset}/form-configs (com.bakdata.conquery.resources.api.FormConfigResource)
    DELETE  /api/datasets/{dataset}/form-configs/{form-config} (com.bakdata.conquery.resources.api.FormConfigResource)
    GET     /api/datasets/{dataset}/form-configs/{form-config} (com.bakdata.conquery.resources.api.FormConfigResource)
    PATCH   /api/datasets/{dataset}/form-configs/{form-config} (com.bakdata.conquery.resources.api.FormConfigResource)
    GET     /api/datasets/{dataset}/form-queries (com.bakdata.conquery.resources.api.FormResource)
    GET     /api/datasets/{dataset}/queries (com.bakdata.conquery.resources.api.QueryResource)
    POST    /api/datasets/{dataset}/queries (com.bakdata.conquery.resources.api.QueryResource)
    POST    /api/datasets/{dataset}/queries/upload (com.bakdata.conquery.resources.api.QueryResource)
    DELETE  /api/datasets/{dataset}/queries/{query} (com.bakdata.conquery.resources.api.QueryResource)
    GET     /api/datasets/{dataset}/queries/{query} (com.bakdata.conquery.resources.api.QueryResource)
    PATCH   /api/datasets/{dataset}/queries/{query} (com.bakdata.conquery.resources.api.QueryResource)
    POST    /api/datasets/{dataset}/queries/{query}/cancel (com.bakdata.conquery.resources.api.QueryResource)
    POST    /api/datasets/{dataset}/queries/{query}/reexecute (com.bakdata.conquery.resources.api.QueryResource)
    GET     /api/datasets/{dataset}/result/{query}.arrf (com.bakdata.conquery.resources.api.ResultArrowFileResource)
    GET     /api/datasets/{dataset}/result/{query}.arrs (com.bakdata.conquery.resources.api.ResultArrowStreamResource)
    GET     /api/datasets/{dataset}/result/{query}.csv (com.bakdata.conquery.resources.api.ResultCsvResource)
    GET     /api/datasets/{dataset}/result/{query}.xlsx (com.bakdata.conquery.resources.api.ResultExcelResource)
    GET     /api/me (com.bakdata.conquery.resources.api.MeResource)

WARN  [2023-01-26 18:08:40,598] org.glassfish.jersey.internal.Errors: The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.filters.Filter<?> from public void com.bakdata.conquery.resources.hierarchies.HFilters.setFilter(com.bakdata.conquery.models.datasets.concepts.filters.Filter<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public com.bakdata.conquery.apiv1.FullExecutionStatus com.bakdata.conquery.resources.api.QueryResource.getStatus(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) throws java.lang.InterruptedException is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public com.bakdata.conquery.apiv1.FullExecutionStatus com.bakdata.conquery.resources.api.QueryResource.patchQuery(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>,com.bakdata.conquery.apiv1.MetaDataPatch) throws com.bakdata.conquery.models.exceptions.JSONException is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public void com.bakdata.conquery.resources.api.QueryResource.deleteQuery(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>) is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public void com.bakdata.conquery.resources.api.QueryResource.cancel(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>) is not resolvable to a concrete type.
WARNING: Parameter 2 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public com.bakdata.conquery.apiv1.FullExecutionStatus com.bakdata.conquery.resources.api.QueryResource.reexecute(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultExcelResource.get(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.identifiable.ids.specific.DatasetId,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultArrowStreamResource.get(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.datasets.Dataset,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultCsvResource.getAsCsv(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.datasets.Dataset,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.lang.String,java.lang.String,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 3 of type com.bakdata.conquery.models.execution.ManagedExecution<?> from public javax.ws.rs.core.Response com.bakdata.conquery.resources.api.ResultArrowFileResource.get(com.bakdata.conquery.models.auth.entities.Subject,com.bakdata.conquery.models.datasets.Dataset,com.bakdata.conquery.models.execution.ManagedExecution<?>,java.util.Optional<java.lang.Boolean>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.filters.Filter<?> from public void com.bakdata.conquery.resources.hierarchies.HFilters.setFilter(com.bakdata.conquery.models.datasets.concepts.filters.Filter<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.hierarchies.HConcepts.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.

INFO  [2023-01-26 18:08:40,671] io.dropwizard.jersey.DropwizardResourceConfig: The following paths were found for the configured resources:

    NONE

INFO  [2023-01-26 18:08:40,671] org.eclipse.jetty.server.handler.ContextHandler: Started i.d.j.MutableServletContextHandler@34365908{/,null,AVAILABLE}
INFO  [2023-01-26 18:08:40,671] io.dropwizard.setup.AdminEnvironment: tasks = 

    POST    /tasks/permission-cleanup (com.bakdata.conquery.tasks.PermissionCleanupTask)
    POST    /tasks/report-consistency (com.bakdata.conquery.tasks.ReportConsistencyTask)
    POST    /tasks/log-level (io.dropwizard.servlets.tasks.LogConfigurationTask)
    POST    /tasks/form-scanner (com.bakdata.conquery.models.forms.frontendconfiguration.FormScanner)
    POST    /tasks/clear-filter-source-search (com.bakdata.conquery.tasks.ClearFilterSourceSearch)
    POST    /tasks/gc (io.dropwizard.servlets.tasks.GarbageCollectionTask)
    POST    /tasks/query-cleanup (com.bakdata.conquery.tasks.QueryCleanupTask)
    POST    /tasks/shutdown (com.bakdata.conquery.resources.admin.ShutdownTask)

WARN  [2023-01-26 18:08:40,671] io.dropwizard.setup.AdminEnvironment: 
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!    THIS APPLICATION HAS NO HEALTHCHECKS. THIS MEANS YOU WILL NEVER KNOW      !
!     IF IT DIES IN PRODUCTION, WHICH MEANS YOU WILL NEVER KNOW IF YOU'RE      !
!    LETTING YOUR USERS DOWN. YOU SHOULD ADD A HEALTHCHECK FOR EACH OF YOUR    !
!         APPLICATION'S DEPENDENCIES WHICH FULLY (BUT LIGHTLY) TESTS IT.       !
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
INFO  [2023-01-26 18:08:40,739] io.dropwizard.jersey.DropwizardResourceConfig: The following paths were found for the configured resources:

    GET     /admin/auth-overview/csv (com.bakdata.conquery.resources.admin.rest.AuthOverviewResource)
    GET     /admin/auth-overview/csv/group/{groupId} (com.bakdata.conquery.resources.admin.rest.AuthOverviewResource)
    GET     /admin/datasets (com.bakdata.conquery.resources.admin.rest.AdminDatasetsResource)
    POST    /admin/datasets (com.bakdata.conquery.resources.admin.rest.AdminDatasetsResource)
    DELETE  /admin/datasets/{dataset} (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    GET     /admin/datasets/{dataset} (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    GET     /admin/datasets/{dataset}/concepts (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    POST    /admin/datasets/{dataset}/concepts (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    PUT     /admin/datasets/{dataset}/concepts (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    DELETE  /admin/datasets/{dataset}/concepts/{concept} (com.bakdata.conquery.resources.admin.rest.AdminConceptsResource)
    GET     /admin/datasets/{dataset}/concepts/{concept} (com.bakdata.conquery.resources.admin.rest.AdminConceptsResource)
    POST    /admin/datasets/{dataset}/cqpp (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    PUT     /admin/datasets/{dataset}/cqpp (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    POST    /admin/datasets/{dataset}/imports (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    PUT     /admin/datasets/{dataset}/imports (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    POST    /admin/datasets/{dataset}/label (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    GET     /admin/datasets/{dataset}/mapping (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    POST    /admin/datasets/{dataset}/mapping (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    POST    /admin/datasets/{dataset}/secondaryId (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    DELETE  /admin/datasets/{dataset}/secondaryId/{secondaryId} (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    POST    /admin/datasets/{dataset}/structure (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    GET     /admin/datasets/{dataset}/tables (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    POST    /admin/datasets/{dataset}/tables (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    DELETE  /admin/datasets/{dataset}/tables/{table} (com.bakdata.conquery.resources.admin.rest.AdminTablesResource)
    GET     /admin/datasets/{dataset}/tables/{table} (com.bakdata.conquery.resources.admin.rest.AdminTablesResource)
    GET     /admin/datasets/{dataset}/tables/{table}/imports (com.bakdata.conquery.resources.admin.rest.AdminTablesResource)
    DELETE  /admin/datasets/{dataset}/tables/{table}/imports/{importId} (com.bakdata.conquery.resources.admin.rest.AdminTablesResource)
    GET     /admin/datasets/{dataset}/tables/{table}/imports/{importId} (com.bakdata.conquery.resources.admin.rest.AdminTablesResource)
    POST    /admin/datasets/{dataset}/update-matching-stats (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    POST    /admin/datasets/{dataset}/weight (com.bakdata.conquery.resources.admin.rest.AdminDatasetResource)
    GET     /admin/groups (com.bakdata.conquery.resources.admin.rest.GroupResource)
    POST    /admin/groups (com.bakdata.conquery.resources.admin.rest.GroupResource)
    DELETE  /admin/groups/{groupId} (com.bakdata.conquery.resources.admin.rest.GroupResource)
    GET     /admin/groups/{groupId} (com.bakdata.conquery.resources.admin.rest.GroupResource)
    DELETE  /admin/groups/{groupId}/roles/{roleId} (com.bakdata.conquery.resources.admin.rest.GroupResource)
    POST    /admin/groups/{groupId}/roles/{roleId} (com.bakdata.conquery.resources.admin.rest.GroupResource)
    DELETE  /admin/groups/{groupId}/users/{userId} (com.bakdata.conquery.resources.admin.rest.GroupResource)
    POST    /admin/groups/{groupId}/users/{userId} (com.bakdata.conquery.resources.admin.rest.GroupResource)
    GET     /admin/jobs (com.bakdata.conquery.resources.admin.rest.AdminResource)
    POST    /admin/jobs/{jobId}/cancel (com.bakdata.conquery.resources.admin.rest.AdminResource)
    GET     /admin/logout (com.bakdata.conquery.resources.admin.rest.AdminResource)
    DELETE  /admin/permissions/{ownerId} (com.bakdata.conquery.resources.admin.rest.PermissionResource)
    POST    /admin/permissions/{ownerId} (com.bakdata.conquery.resources.admin.rest.PermissionResource)
    GET     /admin/queries (com.bakdata.conquery.resources.admin.rest.AdminResource)
    GET     /admin/roles (com.bakdata.conquery.resources.admin.rest.RoleResource)
    POST    /admin/roles (com.bakdata.conquery.resources.admin.rest.RoleResource)
    DELETE  /admin/roles/{roleId} (com.bakdata.conquery.resources.admin.rest.RoleResource)
    GET     /admin/roles/{roleId} (com.bakdata.conquery.resources.admin.rest.RoleResource)
    POST    /admin/script (com.bakdata.conquery.resources.admin.rest.AdminResource)
    GET     /admin/users (com.bakdata.conquery.resources.admin.rest.UserResource)
    POST    /admin/users (com.bakdata.conquery.resources.admin.rest.UserResource)
    POST    /admin/users/upload (com.bakdata.conquery.resources.admin.rest.UserResource)
    DELETE  /admin/users/{userId} (com.bakdata.conquery.resources.admin.rest.UserResource)
    GET     /admin/users/{userId} (com.bakdata.conquery.resources.admin.rest.UserResource)
    DELETE  /admin/users/{userId}/roles/{roleId} (com.bakdata.conquery.resources.admin.rest.UserResource)
    POST    /admin/users/{userId}/roles/{roleId} (com.bakdata.conquery.resources.admin.rest.UserResource)

WARN  [2023-01-26 18:08:40,740] org.glassfish.jersey.internal.Errors: The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.auth.entities.PermissionOwner<?> from public void com.bakdata.conquery.resources.hierarchies.HPermissions.setOwner(com.bakdata.conquery.models.auth.entities.PermissionOwner<?>) is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.auth.entities.PermissionOwner<?> from public void com.bakdata.conquery.resources.hierarchies.HPermissions.setOwner(com.bakdata.conquery.models.auth.entities.PermissionOwner<?>) is not resolvable to a concrete type.

INFO  [2023-01-26 18:08:40,789] io.dropwizard.jersey.DropwizardResourceConfig: The following paths were found for the configured resources:

    GET     /admin-ui/ (com.bakdata.conquery.resources.admin.ui.AdminUIResource)
    GET     /admin-ui/auth-overview (com.bakdata.conquery.resources.admin.ui.AuthOverviewUIResource)
    GET     /admin-ui/datasets (com.bakdata.conquery.resources.admin.ui.DatasetsUIResource)
    GET     /admin-ui/datasets/{dataset} (com.bakdata.conquery.resources.admin.ui.DatasetsUIResource)
    GET     /admin-ui/datasets/{dataset}/concepts/{concept} (com.bakdata.conquery.resources.admin.ui.ConceptsUIResource)
    GET     /admin-ui/datasets/{dataset}/mapping (com.bakdata.conquery.resources.admin.ui.DatasetsUIResource)
    GET     /admin-ui/datasets/{dataset}/tables/{table} (com.bakdata.conquery.resources.admin.ui.TablesUIResource)
    GET     /admin-ui/datasets/{dataset}/tables/{table}/import/{importId} (com.bakdata.conquery.resources.admin.ui.TablesUIResource)
    GET     /admin-ui/groups (com.bakdata.conquery.resources.admin.ui.GroupUIResource)
    GET     /admin-ui/groups/{groupId} (com.bakdata.conquery.resources.admin.ui.GroupUIResource)
    GET     /admin-ui/jobs (com.bakdata.conquery.resources.admin.ui.AdminUIResource)
    GET     /admin-ui/queries (com.bakdata.conquery.resources.admin.ui.AdminUIResource)
    GET     /admin-ui/roles (com.bakdata.conquery.resources.admin.ui.RoleUIResource)
    GET     /admin-ui/roles/{roleId} (com.bakdata.conquery.resources.admin.ui.RoleUIResource)
    GET     /admin-ui/script (com.bakdata.conquery.resources.admin.ui.AdminUIResource)
    GET     /admin-ui/users (com.bakdata.conquery.resources.admin.ui.UserUIResource)
    GET     /admin-ui/users/{userId} (com.bakdata.conquery.resources.admin.ui.UserUIResource)

WARN  [2023-01-26 18:08:40,789] org.glassfish.jersey.internal.Errors: The following warnings have been detected: WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter concept of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from protected com.bakdata.conquery.models.datasets.concepts.Concept<?> com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.concept is not resolvable to a concrete type.
WARNING: Parameter 1 of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from public void com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.setConcept(com.bakdata.conquery.models.datasets.concepts.Concept<?>) is not resolvable to a concrete type.
WARNING: Parameter concept of type com.bakdata.conquery.models.datasets.concepts.Concept<?> from protected com.bakdata.conquery.models.datasets.concepts.Concept<?> com.bakdata.conquery.resources.admin.ui.ConceptsUIResource.concept is not resolvable to a concrete type.

INFO  [2023-01-26 18:08:40,890] io.dropwizard.jersey.DropwizardResourceConfig: The following paths were found for the configured resources:

    NONE

INFO  [2023-01-26 18:08:40,890] org.eclipse.jetty.server.handler.ContextHandler: Started i.d.j.MutableServletContextHandler@37215f46{/,null,AVAILABLE}
INFO  [2023-01-26 18:08:40,939] org.eclipse.jetty.server.AbstractConnector: Started application@58fbfd4d{HTTP/1.1, (http/1.1)}{0.0.0.0:45505}
INFO  [2023-01-26 18:08:40,960] org.eclipse.jetty.server.AbstractConnector: Started admin@449d3375{HTTP/1.1, (http/1.1)}{0.0.0.0:35531}
INFO  [2023-01-26 18:08:40,960] org.eclipse.jetty.server.Server: Started @60500ms
INFO  [2023-01-26 18:08:41,081] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test BIG_MULTI_SELECT Test
INFO  [2023-01-26 18:08:41,081] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:41,081] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:41,101] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=BIG_MULTI_SELECT Test, name=BIG_MULTI_SELECT Test]
INFO  [2023-01-26 18:08:41,101] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:41,104] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=BIG_MULTI_SELECT Test, name=BIG_MULTI_SELECT Test]
INFO  [2023-01-26 18:08:41,104] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:41,110] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:41,112] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker BIG_MULTI_SELECT$20Test.worker_BIG_MULTI_SELECT$20Test_95ca0e47-3984-410e-9f8d-91d48ccafdef are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:41,112] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker BIG_MULTI_SELECT$20Test.worker_BIG_MULTI_SELECT$20Test_95ca0e47-3984-410e-9f8d-91d48ccafdef are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:41,112] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:41,112] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker BIG_MULTI_SELECT$20Test.worker_BIG_MULTI_SELECT$20Test_78f15f44-c5fd-4233-97bd-68db80cf0b6b are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:41,112] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker BIG_MULTI_SELECT$20Test.worker_BIG_MULTI_SELECT$20Test_78f15f44-c5fd-4233-97bd-68db80cf0b6b are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:41,112] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:41,226] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:41,228] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table BIG_MULTI_SELECT$20Test.table
INFO  [2023-01-26 18:08:41,228] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table BIG_MULTI_SELECT$20Test.table
INFO  [2023-01-26 18:08:41,362] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:41,485] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:41,490] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:41,490] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 76 B in total
INFO  [2023-01-26 18:08:41,491] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_BIG_MULTI_SELECT Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000405452sINFO  [2023-01-26 18:08:41,532] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=4, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:08:41,532] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with StringParser(super=Parser(lines=4, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:08:41,532] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=4, nullLines=0), subType=IntegerParser(super=Parser(lines=4, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@76a1cf1b)
INFO  [2023-01-26 18:08:41,536] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_BIG_MULTI_SELECT Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:41,536] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:41,536] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_BIG_MULTI_SELECT Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:41,558] com.bakdata.conquery.models.jobs.ImportJob: Importing table into BIG_MULTI_SELECT$20Test.table
127.0.0.1 - - [26/Jan/2023:18:08:41 +0000] "POST /admin/datasets/BIG_MULTI_SELECT%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_BIG_MULTI_SELECT+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 12
INFO  [2023-01-26 18:08:41,560] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:41,561] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:41,562] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:41,562] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:41,565] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
WARN  [2023-01-26 18:08:41,567] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:41,571] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[BIG_MULTI_SELECT$20Test.table.table], containing 4 entries.
INFO  [2023-01-26 18:08:41,571] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[BIG_MULTI_SELECT$20Test.table.table], containing 4 entries.
INFO  [2023-01-26 18:08:41,572] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received BIG_MULTI_SELECT$20Test.table.table.0
INFO  [2023-01-26 18:08:41,572] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received BIG_MULTI_SELECT$20Test.table.table.1
INFO  [2023-01-26 18:08:41,681] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: BIG_MULTI_SELECT Test QUERY INIT
INFO  [2023-01-26 18:08:41,699] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[BIG_MULTI_SELECT$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:08:41,699] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[8ae3e976-4624-444e-a598-d2f985d604b6] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_BIG_MULTI_SELECT Test))]]
127.0.0.1 - - [26/Jan/2023:18:08:41 +0000] "POST /api/datasets/BIG_MULTI_SELECT$20Test/queries HTTP/1.1" 201 1197 "-" "Conquery (test client)" 11
INFO  [2023-01-26 18:08:41,708] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery BIG_MULTI_SELECT$20Test.8ae3e976-4624-444e-a598-d2f985d604b6
INFO  [2023-01-26 18:08:41,708] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery BIG_MULTI_SELECT$20Test.8ae3e976-4624-444e-a598-d2f985d604b6
INFO  [2023-01-26 18:08:41,710] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[BIG_MULTI_SELECT$20Test.8ae3e976-4624-444e-a598-d2f985d604b6] with 0 results within PT0.001247S
INFO  [2023-01-26 18:08:41,710] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[BIG_MULTI_SELECT$20Test.8ae3e976-4624-444e-a598-d2f985d604b6] with 2 results within PT0.001423S
INFO  [2023-01-26 18:08:41,712] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=BIG_MULTI_SELECT$20Test.8ae3e976-4624-444e-a598-d2f985d604b6, workerId=BIG_MULTI_SELECT$20Test.worker_BIG_MULTI_SELECT$20Test_95ca0e47-3984-410e-9f8d-91d48ccafdef, startTime=2023-01-26T18:08:41.708888, finishTime=2023-01-26T18:08:41.710135) of size 0
INFO  [2023-01-26 18:08:41,713] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=BIG_MULTI_SELECT$20Test.8ae3e976-4624-444e-a598-d2f985d604b6, workerId=BIG_MULTI_SELECT$20Test.worker_BIG_MULTI_SELECT$20Test_78f15f44-c5fd-4233-97bd-68db80cf0b6b, startTime=2023-01-26T18:08:41.708874, finishTime=2023-01-26T18:08:41.710297) of size 2
INFO  [2023-01-26 18:08:41,714] com.bakdata.conquery.models.execution.ManagedExecution: DONE 8ae3e976-4624-444e-a598-d2f985d604b6 ManagedQuery within PT0.01442S
127.0.0.1 - - [26/Jan/2023:18:08:41 +0000] "GET /api/datasets/BIG_MULTI_SELECT$20Test/queries/BIG_MULTI_SELECT$20Test.8ae3e976-4624-444e-a598-d2f985d604b6 HTTP/1.1" 200 1481 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:08:41,736] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=BIG_MULTI_SELECT Test], queryId=8ae3e976-4624-444e-a598-d2f985d604b6, label=concept	@§$, creationTime=2023-01-26T18:08:41.699688, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@7f97c797[Count = 0], startTime=2023-01-26T18:08:41.699867, finishTime=2023-01-26T18:08:41.714287, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@131c05d5), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_BIG_MULTI_SELECT Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@25f929dd, com.bakdata.conquery.models.query.ColumnDescriptor@6493e98a]) download on dataset Dataset[label=null, name=BIG_MULTI_SELECT Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:08:41,736] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=BIG_MULTI_SELECT Test], queryId=8ae3e976-4624-444e-a598-d2f985d604b6, label=concept	@§$, creationTime=2023-01-26T18:08:41.699688, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@7f97c797[Count = 0], startTime=2023-01-26T18:08:41.699867, finishTime=2023-01-26T18:08:41.714287, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@131c05d5), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_BIG_MULTI_SELECT Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@25f929dd, com.bakdata.conquery.models.query.ColumnDescriptor@6493e98a]) on dataset Dataset[label=null, name=BIG_MULTI_SELECT Test]
127.0.0.1 - - [26/Jan/2023:18:08:41 +0000] "GET /api/datasets/BIG_MULTI_SELECT%20Test/result/BIG_MULTI_SELECT$20Test.8ae3e976-4624-444e-a598-d2f985d604b6.csv?pretty=false HTTP/1.1" 200 65 "-" "Conquery (test client)" 24
INFO  [2023-01-26 18:08:41,759] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest BIG_MULTI_SELECT Test on 3 rows
INFO  [2023-01-26 18:08:41,760] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast BIG_MULTI_SELECT Test
INFO  [2023-01-26 18:08:41,761] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=BIG_MULTI_SELECT Test, name=BIG_MULTI_SELECT Test]
INFO  [2023-01-26 18:08:41,761] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_BIG_MULTI_SELECT Test_78f15f44-c5fd-4233-97bd-68db80cf0b6b
INFO  [2023-01-26 18:08:41,761] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=BIG_MULTI_SELECT Test, name=BIG_MULTI_SELECT Test]
INFO  [2023-01-26 18:08:41,761] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_BIG_MULTI_SELECT Test_95ca0e47-3984-410e-9f8d-91d48ccafdef
INFO  [2023-01-26 18:08:41,782] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow BIG_MULTI_SELECT Test
INFO  [2023-01-26 18:08:41,805] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_BIG_MULTI_SELECT Test_95ca0e47-3984-410e-9f8d-91d48ccafdef
INFO  [2023-01-26 18:08:41,805] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_BIG_MULTI_SELECT Test_78f15f44-c5fd-4233-97bd-68db80cf0b6b
INFO  [2023-01-26 18:08:41,868] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of BIG_MULTI_SELECT$20Test
INFO  [2023-01-26 18:08:41,868] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:41,977] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test BIG_MULTI_SELECT Test
INFO  [2023-01-26 18:08:41,978] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test BIG_MULTI_SELECT_2VALUES Test
INFO  [2023-01-26 18:08:41,978] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:41,978] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:41,980] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=BIG_MULTI_SELECT_2VALUES Test, name=BIG_MULTI_SELECT_2VALUES Test]
INFO  [2023-01-26 18:08:41,980] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=BIG_MULTI_SELECT_2VALUES Test, name=BIG_MULTI_SELECT_2VALUES Test]
INFO  [2023-01-26 18:08:41,980] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:41,980] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:41,982] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker BIG_MULTI_SELECT_2VALUES$20Test.worker_BIG_MULTI_SELECT_2VALUES$20Test_61201fbb-6646-454d-97ea-0e6b98e6f6dc are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:41,982] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker BIG_MULTI_SELECT_2VALUES$20Test.worker_BIG_MULTI_SELECT_2VALUES$20Test_61201fbb-6646-454d-97ea-0e6b98e6f6dc are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:41,982] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:41,982] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker BIG_MULTI_SELECT_2VALUES$20Test.worker_BIG_MULTI_SELECT_2VALUES$20Test_dcc96c76-9e0c-42ee-b897-bc0b156d7943 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:41,982] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker BIG_MULTI_SELECT_2VALUES$20Test.worker_BIG_MULTI_SELECT_2VALUES$20Test_dcc96c76-9e0c-42ee-b897-bc0b156d7943 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:41,982] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:41,986] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:42,088] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:42,089] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table BIG_MULTI_SELECT_2VALUES$20Test.table
INFO  [2023-01-26 18:08:42,089] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table BIG_MULTI_SELECT_2VALUES$20Test.table
INFO  [2023-01-26 18:08:42,205] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:42,314] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:42,314] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:42,314] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 91 B in total
INFO  [2023-01-26 18:08:42,314] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_BIG_MULTI_SELECT_2VALUES Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000273581sINFO  [2023-01-26 18:08:42,342] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=5, min=1, average=1.250000, max=2}
INFO  [2023-01-26 18:08:42,343] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=5, nullLines=0), subType=IntegerParser(super=Parser(lines=5, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@3bcd7f82)
INFO  [2023-01-26 18:08:42,343] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with StringParser(super=Parser(lines=5, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:08:42,347] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_BIG_MULTI_SELECT_2VALUES Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:42,347] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:42,347] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_BIG_MULTI_SELECT_2VALUES Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:42,365] com.bakdata.conquery.models.jobs.ImportJob: Importing table into BIG_MULTI_SELECT_2VALUES$20Test.table
127.0.0.1 - - [26/Jan/2023:18:08:42 +0000] "POST /admin/datasets/BIG_MULTI_SELECT_2VALUES%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_BIG_MULTI_SELECT_2VALUES+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:08:42,367] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:42,367] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:42,367] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:42,369] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:42,369] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:08:42,370] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[BIG_MULTI_SELECT_2VALUES$20Test.table.table], containing 5 entries.
INFO  [2023-01-26 18:08:42,370] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[BIG_MULTI_SELECT_2VALUES$20Test.table.table], containing 5 entries.
WARN  [2023-01-26 18:08:42,371] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:42,371] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received BIG_MULTI_SELECT_2VALUES$20Test.table.table.0
INFO  [2023-01-26 18:08:42,371] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received BIG_MULTI_SELECT_2VALUES$20Test.table.table.1
INFO  [2023-01-26 18:08:42,476] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: BIG_MULTI_SELECT_2VALUES Test QUERY INIT
INFO  [2023-01-26 18:08:42,504] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[BIG_MULTI_SELECT_2VALUES$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:08:42,505] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[729561f8-a21d-45aa-8edd-121ff8656680] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_BIG_MULTI_SELECT_2VALUES Test))]]
INFO  [2023-01-26 18:08:42,509] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery BIG_MULTI_SELECT_2VALUES$20Test.729561f8-a21d-45aa-8edd-121ff8656680
INFO  [2023-01-26 18:08:42,509] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery BIG_MULTI_SELECT_2VALUES$20Test.729561f8-a21d-45aa-8edd-121ff8656680
INFO  [2023-01-26 18:08:42,510] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[BIG_MULTI_SELECT_2VALUES$20Test.729561f8-a21d-45aa-8edd-121ff8656680] with 0 results within PT0.000574S
INFO  [2023-01-26 18:08:42,510] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[BIG_MULTI_SELECT_2VALUES$20Test.729561f8-a21d-45aa-8edd-121ff8656680] with 3 results within PT0.000869S
INFO  [2023-01-26 18:08:42,510] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=BIG_MULTI_SELECT_2VALUES$20Test.729561f8-a21d-45aa-8edd-121ff8656680, workerId=BIG_MULTI_SELECT_2VALUES$20Test.worker_BIG_MULTI_SELECT_2VALUES$20Test_61201fbb-6646-454d-97ea-0e6b98e6f6dc, startTime=2023-01-26T18:08:42.509595, finishTime=2023-01-26T18:08:42.510169) of size 0
INFO  [2023-01-26 18:08:42,511] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=BIG_MULTI_SELECT_2VALUES$20Test.729561f8-a21d-45aa-8edd-121ff8656680, workerId=BIG_MULTI_SELECT_2VALUES$20Test.worker_BIG_MULTI_SELECT_2VALUES$20Test_dcc96c76-9e0c-42ee-b897-bc0b156d7943, startTime=2023-01-26T18:08:42.509556, finishTime=2023-01-26T18:08:42.510425) of size 3
INFO  [2023-01-26 18:08:42,511] com.bakdata.conquery.models.execution.ManagedExecution: DONE 729561f8-a21d-45aa-8edd-121ff8656680 ManagedQuery within PT0.00638S
127.0.0.1 - - [26/Jan/2023:18:08:42 +0000] "POST /api/datasets/BIG_MULTI_SELECT_2VALUES$20Test/queries HTTP/1.1" 201 1233 "-" "Conquery (test client)" 12
127.0.0.1 - - [26/Jan/2023:18:08:42 +0000] "GET /api/datasets/BIG_MULTI_SELECT_2VALUES$20Test/queries/BIG_MULTI_SELECT_2VALUES$20Test.729561f8-a21d-45aa-8edd-121ff8656680 HTTP/1.1" 200 1548 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:08:42,544] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=BIG_MULTI_SELECT_2VALUES Test], queryId=729561f8-a21d-45aa-8edd-121ff8656680, label=concept	@§$, creationTime=2023-01-26T18:08:42.505137, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@3259a3b5[Count = 0], startTime=2023-01-26T18:08:42.505412, finishTime=2023-01-26T18:08:42.511792, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@555f5cac), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_BIG_MULTI_SELECT_2VALUES Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=3, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@321b750, com.bakdata.conquery.models.query.ColumnDescriptor@2dcd16fd]) download on dataset Dataset[label=null, name=BIG_MULTI_SELECT_2VALUES Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:08:42,544] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=BIG_MULTI_SELECT_2VALUES Test], queryId=729561f8-a21d-45aa-8edd-121ff8656680, label=concept	@§$, creationTime=2023-01-26T18:08:42.505137, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@3259a3b5[Count = 0], startTime=2023-01-26T18:08:42.505412, finishTime=2023-01-26T18:08:42.511792, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@555f5cac), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_BIG_MULTI_SELECT_2VALUES Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=3, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@321b750, com.bakdata.conquery.models.query.ColumnDescriptor@2dcd16fd]) on dataset Dataset[label=null, name=BIG_MULTI_SELECT_2VALUES Test]
127.0.0.1 - - [26/Jan/2023:18:08:42 +0000] "GET /api/datasets/BIG_MULTI_SELECT_2VALUES%20Test/result/BIG_MULTI_SELECT_2VALUES$20Test.729561f8-a21d-45aa-8edd-121ff8656680.csv?pretty=false HTTP/1.1" 200 115 "-" "Conquery (test client)" 29
INFO  [2023-01-26 18:08:42,573] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest BIG_MULTI_SELECT_2VALUES Test on 4 rows
INFO  [2023-01-26 18:08:42,573] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast BIG_MULTI_SELECT_2VALUES Test
INFO  [2023-01-26 18:08:42,573] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=BIG_MULTI_SELECT_2VALUES Test, name=BIG_MULTI_SELECT_2VALUES Test]
INFO  [2023-01-26 18:08:42,573] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=BIG_MULTI_SELECT_2VALUES Test, name=BIG_MULTI_SELECT_2VALUES Test]
INFO  [2023-01-26 18:08:42,574] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_BIG_MULTI_SELECT_2VALUES Test_61201fbb-6646-454d-97ea-0e6b98e6f6dc
INFO  [2023-01-26 18:08:42,575] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_BIG_MULTI_SELECT_2VALUES Test_dcc96c76-9e0c-42ee-b897-bc0b156d7943
INFO  [2023-01-26 18:08:42,579] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow BIG_MULTI_SELECT_2VALUES Test
INFO  [2023-01-26 18:08:42,593] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_BIG_MULTI_SELECT_2VALUES Test_dcc96c76-9e0c-42ee-b897-bc0b156d7943
INFO  [2023-01-26 18:08:42,593] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_BIG_MULTI_SELECT_2VALUES Test_61201fbb-6646-454d-97ea-0e6b98e6f6dc
INFO  [2023-01-26 18:08:42,671] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of BIG_MULTI_SELECT_2VALUES$20Test
INFO  [2023-01-26 18:08:42,671] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:42,778] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test BIG_MULTI_SELECT_2VALUES Test
INFO  [2023-01-26 18:08:42,779] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test BIG_MULTI_SELECT_EMPTY_VALUES Test
INFO  [2023-01-26 18:08:42,779] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:42,779] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:42,780] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=BIG_MULTI_SELECT_EMPTY_VALUES Test, name=BIG_MULTI_SELECT_EMPTY_VALUES Test]
INFO  [2023-01-26 18:08:42,780] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=BIG_MULTI_SELECT_EMPTY_VALUES Test, name=BIG_MULTI_SELECT_EMPTY_VALUES Test]
INFO  [2023-01-26 18:08:42,780] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:42,780] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:42,796] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker BIG_MULTI_SELECT_EMPTY_VALUES$20Test.worker_BIG_MULTI_SELECT_EMPTY_VALUES$20Test_fb788645-4f78-4850-9db3-d7efd1a0a67c are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:42,797] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker BIG_MULTI_SELECT_EMPTY_VALUES$20Test.worker_BIG_MULTI_SELECT_EMPTY_VALUES$20Test_fb788645-4f78-4850-9db3-d7efd1a0a67c are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:42,797] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:42,797] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker BIG_MULTI_SELECT_EMPTY_VALUES$20Test.worker_BIG_MULTI_SELECT_EMPTY_VALUES$20Test_13f01d79-0665-49f0-9d9e-633795926546 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:42,797] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker BIG_MULTI_SELECT_EMPTY_VALUES$20Test.worker_BIG_MULTI_SELECT_EMPTY_VALUES$20Test_13f01d79-0665-49f0-9d9e-633795926546 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:42,797] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:42,801] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:42,903] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:42,903] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table BIG_MULTI_SELECT_EMPTY_VALUES$20Test.table
INFO  [2023-01-26 18:08:42,903] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table BIG_MULTI_SELECT_EMPTY_VALUES$20Test.table
INFO  [2023-01-26 18:08:43,015] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:43,165] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:43,165] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:43,165] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 90 B in total
INFO  [2023-01-26 18:08:43,165] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_BIG_MULTI_SELECT_EMPTY_VALUES Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000837749sINFO  [2023-01-26 18:08:43,250] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=5, min=1, average=1.250000, max=2}
INFO  [2023-01-26 18:08:43,250] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=5, nullLines=0), subType=IntegerParser(super=Parser(lines=5, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@40938c14)
INFO  [2023-01-26 18:08:43,251] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with StringParser(super=Parser(lines=5, nullLines=1), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:08:43,261] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_BIG_MULTI_SELECT_EMPTY_VALUES Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:43,261] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:43,261] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_BIG_MULTI_SELECT_EMPTY_VALUES Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:43,302] com.bakdata.conquery.models.jobs.ImportJob: Importing table into BIG_MULTI_SELECT_EMPTY_VALUES$20Test.table
127.0.0.1 - - [26/Jan/2023:18:08:43 +0000] "POST /admin/datasets/BIG_MULTI_SELECT_EMPTY_VALUES%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_BIG_MULTI_SELECT_EMPTY_VALUES+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 15
INFO  [2023-01-26 18:08:43,305] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:43,305] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:43,306] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:43,306] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:43,307] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:08:43,307] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[BIG_MULTI_SELECT_EMPTY_VALUES$20Test.table.table], containing 5 entries.
INFO  [2023-01-26 18:08:43,307] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[BIG_MULTI_SELECT_EMPTY_VALUES$20Test.table.table], containing 5 entries.
WARN  [2023-01-26 18:08:43,308] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:43,308] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received BIG_MULTI_SELECT_EMPTY_VALUES$20Test.table.table.0
INFO  [2023-01-26 18:08:43,309] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received BIG_MULTI_SELECT_EMPTY_VALUES$20Test.table.table.1
INFO  [2023-01-26 18:08:43,414] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: BIG_MULTI_SELECT_EMPTY_VALUES Test QUERY INIT
INFO  [2023-01-26 18:08:43,425] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[BIG_MULTI_SELECT_EMPTY_VALUES$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:08:43,426] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[fbee39b9-2a91-4eda-a194-cdc0b5d025ab] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_BIG_MULTI_SELECT_EMPTY_VALUES Test))]]
INFO  [2023-01-26 18:08:43,428] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery BIG_MULTI_SELECT_EMPTY_VALUES$20Test.fbee39b9-2a91-4eda-a194-cdc0b5d025ab
INFO  [2023-01-26 18:08:43,428] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery BIG_MULTI_SELECT_EMPTY_VALUES$20Test.fbee39b9-2a91-4eda-a194-cdc0b5d025ab
INFO  [2023-01-26 18:08:43,428] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[BIG_MULTI_SELECT_EMPTY_VALUES$20Test.fbee39b9-2a91-4eda-a194-cdc0b5d025ab] with 0 results within PT0.00055S
127.0.0.1 - - [26/Jan/2023:18:08:43 +0000] "POST /api/datasets/BIG_MULTI_SELECT_EMPTY_VALUES$20Test/queries HTTP/1.1" 201 1249 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:08:43,429] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=BIG_MULTI_SELECT_EMPTY_VALUES$20Test.fbee39b9-2a91-4eda-a194-cdc0b5d025ab, workerId=BIG_MULTI_SELECT_EMPTY_VALUES$20Test.worker_BIG_MULTI_SELECT_EMPTY_VALUES$20Test_fb788645-4f78-4850-9db3-d7efd1a0a67c, startTime=2023-01-26T18:08:43.428103, finishTime=2023-01-26T18:08:43.428653) of size 0
INFO  [2023-01-26 18:08:43,430] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[BIG_MULTI_SELECT_EMPTY_VALUES$20Test.fbee39b9-2a91-4eda-a194-cdc0b5d025ab] with 2 results within PT0.001904S
INFO  [2023-01-26 18:08:43,430] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=BIG_MULTI_SELECT_EMPTY_VALUES$20Test.fbee39b9-2a91-4eda-a194-cdc0b5d025ab, workerId=BIG_MULTI_SELECT_EMPTY_VALUES$20Test.worker_BIG_MULTI_SELECT_EMPTY_VALUES$20Test_13f01d79-0665-49f0-9d9e-633795926546, startTime=2023-01-26T18:08:43.428236, finishTime=2023-01-26T18:08:43.430140) of size 2
INFO  [2023-01-26 18:08:43,431] com.bakdata.conquery.models.execution.ManagedExecution: DONE fbee39b9-2a91-4eda-a194-cdc0b5d025ab ManagedQuery within PT0.005431S
127.0.0.1 - - [26/Jan/2023:18:08:43 +0000] "GET /api/datasets/BIG_MULTI_SELECT_EMPTY_VALUES$20Test/queries/BIG_MULTI_SELECT_EMPTY_VALUES$20Test.fbee39b9-2a91-4eda-a194-cdc0b5d025ab HTTP/1.1" 200 1583 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:08:43,450] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=BIG_MULTI_SELECT_EMPTY_VALUES Test], queryId=fbee39b9-2a91-4eda-a194-cdc0b5d025ab, label=concept	@§$, creationTime=2023-01-26T18:08:43.425958, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@43b6e2e2[Count = 0], startTime=2023-01-26T18:08:43.426129, finishTime=2023-01-26T18:08:43.431560, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2f2f18a3), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_BIG_MULTI_SELECT_EMPTY_VALUES Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@723fe0bf, com.bakdata.conquery.models.query.ColumnDescriptor@574c4454]) download on dataset Dataset[label=null, name=BIG_MULTI_SELECT_EMPTY_VALUES Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:08:43,450] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=BIG_MULTI_SELECT_EMPTY_VALUES Test], queryId=fbee39b9-2a91-4eda-a194-cdc0b5d025ab, label=concept	@§$, creationTime=2023-01-26T18:08:43.425958, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@43b6e2e2[Count = 0], startTime=2023-01-26T18:08:43.426129, finishTime=2023-01-26T18:08:43.431560, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2f2f18a3), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_BIG_MULTI_SELECT_EMPTY_VALUES Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@723fe0bf, com.bakdata.conquery.models.query.ColumnDescriptor@574c4454]) on dataset Dataset[label=null, name=BIG_MULTI_SELECT_EMPTY_VALUES Test]
127.0.0.1 - - [26/Jan/2023:18:08:43 +0000] "GET /api/datasets/BIG_MULTI_SELECT_EMPTY_VALUES%20Test/result/BIG_MULTI_SELECT_EMPTY_VALUES$20Test.fbee39b9-2a91-4eda-a194-cdc0b5d025ab.csv?pretty=false HTTP/1.1" 200 65 "-" "Conquery (test client)" 17
INFO  [2023-01-26 18:08:43,467] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest BIG_MULTI_SELECT_EMPTY_VALUES Test on 3 rows
INFO  [2023-01-26 18:08:43,467] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast BIG_MULTI_SELECT_EMPTY_VALUES Test
INFO  [2023-01-26 18:08:43,467] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=BIG_MULTI_SELECT_EMPTY_VALUES Test, name=BIG_MULTI_SELECT_EMPTY_VALUES Test]
INFO  [2023-01-26 18:08:43,467] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=BIG_MULTI_SELECT_EMPTY_VALUES Test, name=BIG_MULTI_SELECT_EMPTY_VALUES Test]
INFO  [2023-01-26 18:08:43,467] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_BIG_MULTI_SELECT_EMPTY_VALUES Test_fb788645-4f78-4850-9db3-d7efd1a0a67c
INFO  [2023-01-26 18:08:43,467] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_BIG_MULTI_SELECT_EMPTY_VALUES Test_13f01d79-0665-49f0-9d9e-633795926546
INFO  [2023-01-26 18:08:43,480] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow BIG_MULTI_SELECT_EMPTY_VALUES Test
INFO  [2023-01-26 18:08:43,497] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_BIG_MULTI_SELECT_EMPTY_VALUES Test_13f01d79-0665-49f0-9d9e-633795926546
INFO  [2023-01-26 18:08:43,497] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_BIG_MULTI_SELECT_EMPTY_VALUES Test_fb788645-4f78-4850-9db3-d7efd1a0a67c
INFO  [2023-01-26 18:08:43,509] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of BIG_MULTI_SELECT_EMPTY_VALUES$20Test
INFO  [2023-01-26 18:08:43,509] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:43,614] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test BIG_MULTI_SELECT_EMPTY_VALUES Test
INFO  [2023-01-26 18:08:43,615] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test BIG_MULTI_SELECT_SPEZIAL_CHARACTER Test
INFO  [2023-01-26 18:08:43,615] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:43,615] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:43,616] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=BIG_MULTI_SELECT_SPEZIAL_CHARACTER Test, name=BIG_MULTI_SELECT_SPEZIAL_CHARACTER Test]
INFO  [2023-01-26 18:08:43,616] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=BIG_MULTI_SELECT_SPEZIAL_CHARACTER Test, name=BIG_MULTI_SELECT_SPEZIAL_CHARACTER Test]
INFO  [2023-01-26 18:08:43,616] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:43,616] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:43,617] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker BIG_MULTI_SELECT_SPEZIAL_CHARACTER$20Test.worker_BIG_MULTI_SELECT_SPEZIAL_CHARACTER$20Test_e12d8431-8e05-4387-b8f5-908ba629428f are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:43,617] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker BIG_MULTI_SELECT_SPEZIAL_CHARACTER$20Test.worker_BIG_MULTI_SELECT_SPEZIAL_CHARACTER$20Test_e12d8431-8e05-4387-b8f5-908ba629428f are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:43,617] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:43,617] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker BIG_MULTI_SELECT_SPEZIAL_CHARACTER$20Test.worker_BIG_MULTI_SELECT_SPEZIAL_CHARACTER$20Test_43ff983f-21d0-4c81-894b-4bdffae6e60d are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:43,617] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker BIG_MULTI_SELECT_SPEZIAL_CHARACTER$20Test.worker_BIG_MULTI_SELECT_SPEZIAL_CHARACTER$20Test_43ff983f-21d0-4c81-894b-4bdffae6e60d are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:43,617] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:43,622] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:43,731] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:43,732] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table BIG_MULTI_SELECT_SPEZIAL_CHARACTER$20Test.table
INFO  [2023-01-26 18:08:43,732] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table BIG_MULTI_SELECT_SPEZIAL_CHARACTER$20Test.table
INFO  [2023-01-26 18:08:43,847] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:43,960] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:43,960] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:43,960] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 92 B in total
INFO  [2023-01-26 18:08:43,960] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_BIG_MULTI_SELECT_SPEZIAL_CHARACTER Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.00047552sINFO  [2023-01-26 18:08:44,008] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=5, min=1, average=1.250000, max=2}
INFO  [2023-01-26 18:08:44,009] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=5, nullLines=0), subType=IntegerParser(super=Parser(lines=5, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@70d49f73)
INFO  [2023-01-26 18:08:44,009] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with StringParser(super=Parser(lines=5, nullLines=1), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:08:44,013] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_BIG_MULTI_SELECT_SPEZIAL_CHARACTER Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:44,013] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:44,013] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_BIG_MULTI_SELECT_SPEZIAL_CHARACTER Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:44,032] com.bakdata.conquery.models.jobs.ImportJob: Importing table into BIG_MULTI_SELECT_SPEZIAL_CHARACTER$20Test.table
127.0.0.1 - - [26/Jan/2023:18:08:44 +0000] "POST /admin/datasets/BIG_MULTI_SELECT_SPEZIAL_CHARACTER%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_BIG_MULTI_SELECT_SPEZIAL_CHARACTER+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 10
INFO  [2023-01-26 18:08:44,034] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:44,034] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:44,035] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:44,035] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:44,037] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:08:44,037] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[BIG_MULTI_SELECT_SPEZIAL_CHARACTER$20Test.table.table], containing 5 entries.
INFO  [2023-01-26 18:08:44,037] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[BIG_MULTI_SELECT_SPEZIAL_CHARACTER$20Test.table.table], containing 5 entries.
WARN  [2023-01-26 18:08:44,038] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:44,038] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received BIG_MULTI_SELECT_SPEZIAL_CHARACTER$20Test.table.table.0
INFO  [2023-01-26 18:08:44,038] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received BIG_MULTI_SELECT_SPEZIAL_CHARACTER$20Test.table.table.1
INFO  [2023-01-26 18:08:44,144] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: BIG_MULTI_SELECT_SPEZIAL_CHARACTER Test QUERY INIT
INFO  [2023-01-26 18:08:44,155] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[BIG_MULTI_SELECT_SPEZIAL_CHARACTER$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:08:44,155] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[3bc531b1-075f-4751-a883-ef181d550b81] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_BIG_MULTI_SELECT_SPEZIAL_CHARACTER Test))]]
INFO  [2023-01-26 18:08:44,157] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery BIG_MULTI_SELECT_SPEZIAL_CHARACTER$20Test.3bc531b1-075f-4751-a883-ef181d550b81
INFO  [2023-01-26 18:08:44,157] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery BIG_MULTI_SELECT_SPEZIAL_CHARACTER$20Test.3bc531b1-075f-4751-a883-ef181d550b81
INFO  [2023-01-26 18:08:44,158] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[BIG_MULTI_SELECT_SPEZIAL_CHARACTER$20Test.3bc531b1-075f-4751-a883-ef181d550b81] with 0 results within PT0.000887S
INFO  [2023-01-26 18:08:44,158] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[BIG_MULTI_SELECT_SPEZIAL_CHARACTER$20Test.3bc531b1-075f-4751-a883-ef181d550b81] with 1 results within PT0.001109S
INFO  [2023-01-26 18:08:44,159] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=BIG_MULTI_SELECT_SPEZIAL_CHARACTER$20Test.3bc531b1-075f-4751-a883-ef181d550b81, workerId=BIG_MULTI_SELECT_SPEZIAL_CHARACTER$20Test.worker_BIG_MULTI_SELECT_SPEZIAL_CHARACTER$20Test_43ff983f-21d0-4c81-894b-4bdffae6e60d, startTime=2023-01-26T18:08:44.157841, finishTime=2023-01-26T18:08:44.158728) of size 0
INFO  [2023-01-26 18:08:44,159] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=BIG_MULTI_SELECT_SPEZIAL_CHARACTER$20Test.3bc531b1-075f-4751-a883-ef181d550b81, workerId=BIG_MULTI_SELECT_SPEZIAL_CHARACTER$20Test.worker_BIG_MULTI_SELECT_SPEZIAL_CHARACTER$20Test_e12d8431-8e05-4387-b8f5-908ba629428f, startTime=2023-01-26T18:08:44.157856, finishTime=2023-01-26T18:08:44.158965) of size 1
INFO  [2023-01-26 18:08:44,160] com.bakdata.conquery.models.execution.ManagedExecution: DONE 3bc531b1-075f-4751-a883-ef181d550b81 ManagedQuery within PT0.004529S
127.0.0.1 - - [26/Jan/2023:18:08:44 +0000] "POST /api/datasets/BIG_MULTI_SELECT_SPEZIAL_CHARACTER$20Test/queries HTTP/1.1" 201 1269 "-" "Conquery (test client)" 6
127.0.0.1 - - [26/Jan/2023:18:08:44 +0000] "GET /api/datasets/BIG_MULTI_SELECT_SPEZIAL_CHARACTER$20Test/queries/BIG_MULTI_SELECT_SPEZIAL_CHARACTER$20Test.3bc531b1-075f-4751-a883-ef181d550b81 HTTP/1.1" 200 1624 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:08:44,185] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=BIG_MULTI_SELECT_SPEZIAL_CHARACTER Test], queryId=3bc531b1-075f-4751-a883-ef181d550b81, label=concept	@§$, creationTime=2023-01-26T18:08:44.155501, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@221020a2[Count = 0], startTime=2023-01-26T18:08:44.155709, finishTime=2023-01-26T18:08:44.160238, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@190b6dcd), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_BIG_MULTI_SELECT_SPEZIAL_CHARACTER Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@13f8e597, com.bakdata.conquery.models.query.ColumnDescriptor@6109f65e]) download on dataset Dataset[label=null, name=BIG_MULTI_SELECT_SPEZIAL_CHARACTER Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:08:44,185] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=BIG_MULTI_SELECT_SPEZIAL_CHARACTER Test], queryId=3bc531b1-075f-4751-a883-ef181d550b81, label=concept	@§$, creationTime=2023-01-26T18:08:44.155501, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@221020a2[Count = 0], startTime=2023-01-26T18:08:44.155709, finishTime=2023-01-26T18:08:44.160238, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@190b6dcd), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_BIG_MULTI_SELECT_SPEZIAL_CHARACTER Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@13f8e597, com.bakdata.conquery.models.query.ColumnDescriptor@6109f65e]) on dataset Dataset[label=null, name=BIG_MULTI_SELECT_SPEZIAL_CHARACTER Test]
127.0.0.1 - - [26/Jan/2023:18:08:44 +0000] "GET /api/datasets/BIG_MULTI_SELECT_SPEZIAL_CHARACTER%20Test/result/BIG_MULTI_SELECT_SPEZIAL_CHARACTER$20Test.3bc531b1-075f-4751-a883-ef181d550b81.csv?pretty=false HTTP/1.1" 200 39 "-" "Conquery (test client)" 18
INFO  [2023-01-26 18:08:44,202] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest BIG_MULTI_SELECT_SPEZIAL_CHARACTER Test on 2 rows
INFO  [2023-01-26 18:08:44,202] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast BIG_MULTI_SELECT_SPEZIAL_CHARACTER Test
INFO  [2023-01-26 18:08:44,202] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=BIG_MULTI_SELECT_SPEZIAL_CHARACTER Test, name=BIG_MULTI_SELECT_SPEZIAL_CHARACTER Test]
INFO  [2023-01-26 18:08:44,202] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=BIG_MULTI_SELECT_SPEZIAL_CHARACTER Test, name=BIG_MULTI_SELECT_SPEZIAL_CHARACTER Test]
INFO  [2023-01-26 18:08:44,202] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_BIG_MULTI_SELECT_SPEZIAL_CHARACTER Test_43ff983f-21d0-4c81-894b-4bdffae6e60d
INFO  [2023-01-26 18:08:44,202] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_BIG_MULTI_SELECT_SPEZIAL_CHARACTER Test_e12d8431-8e05-4387-b8f5-908ba629428f
INFO  [2023-01-26 18:08:44,216] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow BIG_MULTI_SELECT_SPEZIAL_CHARACTER Test
INFO  [2023-01-26 18:08:44,216] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_BIG_MULTI_SELECT_SPEZIAL_CHARACTER Test_e12d8431-8e05-4387-b8f5-908ba629428f
INFO  [2023-01-26 18:08:44,217] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_BIG_MULTI_SELECT_SPEZIAL_CHARACTER Test_43ff983f-21d0-4c81-894b-4bdffae6e60d
INFO  [2023-01-26 18:08:44,238] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of BIG_MULTI_SELECT_SPEZIAL_CHARACTER$20Test
INFO  [2023-01-26 18:08:44,238] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:44,344] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test BIG_MULTI_SELECT_SPEZIAL_CHARACTER Test
INFO  [2023-01-26 18:08:44,345] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test BIG_MULTI_SELECT_SPEZIAL_CHARACTER2 Test
INFO  [2023-01-26 18:08:44,345] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:44,345] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:44,346] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=BIG_MULTI_SELECT_SPEZIAL_CHARACTER2 Test, name=BIG_MULTI_SELECT_SPEZIAL_CHARACTER2 Test]
INFO  [2023-01-26 18:08:44,346] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=BIG_MULTI_SELECT_SPEZIAL_CHARACTER2 Test, name=BIG_MULTI_SELECT_SPEZIAL_CHARACTER2 Test]
INFO  [2023-01-26 18:08:44,346] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:44,346] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:44,347] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker BIG_MULTI_SELECT_SPEZIAL_CHARACTER2$20Test.worker_BIG_MULTI_SELECT_SPEZIAL_CHARACTER2$20Test_c828fa7c-bf71-41db-aec5-485e26366e91 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:44,348] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker BIG_MULTI_SELECT_SPEZIAL_CHARACTER2$20Test.worker_BIG_MULTI_SELECT_SPEZIAL_CHARACTER2$20Test_c828fa7c-bf71-41db-aec5-485e26366e91 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:44,348] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:44,348] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker BIG_MULTI_SELECT_SPEZIAL_CHARACTER2$20Test.worker_BIG_MULTI_SELECT_SPEZIAL_CHARACTER2$20Test_1d63748e-016f-4dc1-ae02-443ab04d86cb are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:44,348] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker BIG_MULTI_SELECT_SPEZIAL_CHARACTER2$20Test.worker_BIG_MULTI_SELECT_SPEZIAL_CHARACTER2$20Test_1d63748e-016f-4dc1-ae02-443ab04d86cb are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:44,348] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:44,352] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:44,453] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:44,454] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table BIG_MULTI_SELECT_SPEZIAL_CHARACTER2$20Test.table
INFO  [2023-01-26 18:08:44,454] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table BIG_MULTI_SELECT_SPEZIAL_CHARACTER2$20Test.table
INFO  [2023-01-26 18:08:44,565] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:44,676] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:44,677] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:44,677] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 90 B in total
INFO  [2023-01-26 18:08:44,677] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_BIG_MULTI_SELECT_SPEZIAL_CHARACTER2 Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000378608sINFO  [2023-01-26 18:08:44,716] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=5, min=1, average=1.250000, max=2}
INFO  [2023-01-26 18:08:44,716] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=5, nullLines=0), subType=IntegerParser(super=Parser(lines=5, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@2c8a17c3)
INFO  [2023-01-26 18:08:44,716] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with StringParser(super=Parser(lines=5, nullLines=1), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:08:44,720] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_BIG_MULTI_SELECT_SPEZIAL_CHARACTER2 Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:44,720] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:44,720] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_BIG_MULTI_SELECT_SPEZIAL_CHARACTER2 Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:44,739] com.bakdata.conquery.models.jobs.ImportJob: Importing table into BIG_MULTI_SELECT_SPEZIAL_CHARACTER2$20Test.table
127.0.0.1 - - [26/Jan/2023:18:08:44 +0000] "POST /admin/datasets/BIG_MULTI_SELECT_SPEZIAL_CHARACTER2%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_BIG_MULTI_SELECT_SPEZIAL_CHARACTER2+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 14
INFO  [2023-01-26 18:08:44,745] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:44,746] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:44,746] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:44,748] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:08:44,748] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[BIG_MULTI_SELECT_SPEZIAL_CHARACTER2$20Test.table.table], containing 5 entries.
INFO  [2023-01-26 18:08:44,751] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received BIG_MULTI_SELECT_SPEZIAL_CHARACTER2$20Test.table.table.0
INFO  [2023-01-26 18:08:44,752] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:44,752] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[BIG_MULTI_SELECT_SPEZIAL_CHARACTER2$20Test.table.table], containing 5 entries.
WARN  [2023-01-26 18:08:44,752] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:44,752] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:08:44,752] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received BIG_MULTI_SELECT_SPEZIAL_CHARACTER2$20Test.table.table.1
INFO  [2023-01-26 18:08:44,862] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: BIG_MULTI_SELECT_SPEZIAL_CHARACTER2 Test QUERY INIT
INFO  [2023-01-26 18:08:44,873] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[BIG_MULTI_SELECT_SPEZIAL_CHARACTER2$20Test] by User[{user.SUPERUSER@SUPERUSER].
127.0.0.1 - - [26/Jan/2023:18:08:44 +0000] "POST /api/datasets/BIG_MULTI_SELECT_SPEZIAL_CHARACTER2$20Test/queries HTTP/1.1" 201 1272 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:08:44,873] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[b3cc00fb-0ce7-4f5d-896f-185ba8323f4b] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_BIG_MULTI_SELECT_SPEZIAL_CHARACTER2 Test))]]
INFO  [2023-01-26 18:08:44,875] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery BIG_MULTI_SELECT_SPEZIAL_CHARACTER2$20Test.b3cc00fb-0ce7-4f5d-896f-185ba8323f4b
INFO  [2023-01-26 18:08:44,876] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery BIG_MULTI_SELECT_SPEZIAL_CHARACTER2$20Test.b3cc00fb-0ce7-4f5d-896f-185ba8323f4b
INFO  [2023-01-26 18:08:44,877] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[BIG_MULTI_SELECT_SPEZIAL_CHARACTER2$20Test.b3cc00fb-0ce7-4f5d-896f-185ba8323f4b] with 0 results within PT0.001779S
INFO  [2023-01-26 18:08:44,878] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=BIG_MULTI_SELECT_SPEZIAL_CHARACTER2$20Test.b3cc00fb-0ce7-4f5d-896f-185ba8323f4b, workerId=BIG_MULTI_SELECT_SPEZIAL_CHARACTER2$20Test.worker_BIG_MULTI_SELECT_SPEZIAL_CHARACTER2$20Test_1d63748e-016f-4dc1-ae02-443ab04d86cb, startTime=2023-01-26T18:08:44.876006, finishTime=2023-01-26T18:08:44.877785) of size 0
INFO  [2023-01-26 18:08:44,879] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[BIG_MULTI_SELECT_SPEZIAL_CHARACTER2$20Test.b3cc00fb-0ce7-4f5d-896f-185ba8323f4b] with 1 results within PT0.003869S
INFO  [2023-01-26 18:08:44,880] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=BIG_MULTI_SELECT_SPEZIAL_CHARACTER2$20Test.b3cc00fb-0ce7-4f5d-896f-185ba8323f4b, workerId=BIG_MULTI_SELECT_SPEZIAL_CHARACTER2$20Test.worker_BIG_MULTI_SELECT_SPEZIAL_CHARACTER2$20Test_c828fa7c-bf71-41db-aec5-485e26366e91, startTime=2023-01-26T18:08:44.876037, finishTime=2023-01-26T18:08:44.879906) of size 1
INFO  [2023-01-26 18:08:44,881] com.bakdata.conquery.models.execution.ManagedExecution: DONE b3cc00fb-0ce7-4f5d-896f-185ba8323f4b ManagedQuery within PT0.007684S
127.0.0.1 - - [26/Jan/2023:18:08:44 +0000] "GET /api/datasets/BIG_MULTI_SELECT_SPEZIAL_CHARACTER2$20Test/queries/BIG_MULTI_SELECT_SPEZIAL_CHARACTER2$20Test.b3cc00fb-0ce7-4f5d-896f-185ba8323f4b HTTP/1.1" 200 1631 "-" "Conquery (test client)" 5
INFO  [2023-01-26 18:08:44,899] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=BIG_MULTI_SELECT_SPEZIAL_CHARACTER2 Test], queryId=b3cc00fb-0ce7-4f5d-896f-185ba8323f4b, label=concept	@§$, creationTime=2023-01-26T18:08:44.873479, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@31cb52a7[Count = 0], startTime=2023-01-26T18:08:44.873680, finishTime=2023-01-26T18:08:44.881364, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@4240c54d), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_BIG_MULTI_SELECT_SPEZIAL_CHARACTER2 Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@304721, com.bakdata.conquery.models.query.ColumnDescriptor@3a518e6f]) download on dataset Dataset[label=null, name=BIG_MULTI_SELECT_SPEZIAL_CHARACTER2 Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:08:44,899] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=BIG_MULTI_SELECT_SPEZIAL_CHARACTER2 Test], queryId=b3cc00fb-0ce7-4f5d-896f-185ba8323f4b, label=concept	@§$, creationTime=2023-01-26T18:08:44.873479, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@31cb52a7[Count = 0], startTime=2023-01-26T18:08:44.873680, finishTime=2023-01-26T18:08:44.881364, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@4240c54d), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_BIG_MULTI_SELECT_SPEZIAL_CHARACTER2 Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@304721, com.bakdata.conquery.models.query.ColumnDescriptor@3a518e6f]) on dataset Dataset[label=null, name=BIG_MULTI_SELECT_SPEZIAL_CHARACTER2 Test]
127.0.0.1 - - [26/Jan/2023:18:08:44 +0000] "GET /api/datasets/BIG_MULTI_SELECT_SPEZIAL_CHARACTER2%20Test/result/BIG_MULTI_SELECT_SPEZIAL_CHARACTER2$20Test.b3cc00fb-0ce7-4f5d-896f-185ba8323f4b.csv?pretty=false HTTP/1.1" 200 39 "-" "Conquery (test client)" 13
INFO  [2023-01-26 18:08:44,911] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest BIG_MULTI_SELECT_SPEZIAL_CHARACTER2 Test on 2 rows
INFO  [2023-01-26 18:08:44,911] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast BIG_MULTI_SELECT_SPEZIAL_CHARACTER2 Test
INFO  [2023-01-26 18:08:44,911] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=BIG_MULTI_SELECT_SPEZIAL_CHARACTER2 Test, name=BIG_MULTI_SELECT_SPEZIAL_CHARACTER2 Test]
INFO  [2023-01-26 18:08:44,911] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=BIG_MULTI_SELECT_SPEZIAL_CHARACTER2 Test, name=BIG_MULTI_SELECT_SPEZIAL_CHARACTER2 Test]
INFO  [2023-01-26 18:08:44,912] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_BIG_MULTI_SELECT_SPEZIAL_CHARACTER2 Test_1d63748e-016f-4dc1-ae02-443ab04d86cb
INFO  [2023-01-26 18:08:44,912] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_BIG_MULTI_SELECT_SPEZIAL_CHARACTER2 Test_c828fa7c-bf71-41db-aec5-485e26366e91
INFO  [2023-01-26 18:08:44,946] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow BIG_MULTI_SELECT_SPEZIAL_CHARACTER2 Test
INFO  [2023-01-26 18:08:44,947] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_BIG_MULTI_SELECT_SPEZIAL_CHARACTER2 Test_c828fa7c-bf71-41db-aec5-485e26366e91
INFO  [2023-01-26 18:08:44,947] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_BIG_MULTI_SELECT_SPEZIAL_CHARACTER2 Test_1d63748e-016f-4dc1-ae02-443ab04d86cb
INFO  [2023-01-26 18:08:44,952] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of BIG_MULTI_SELECT_SPEZIAL_CHARACTER2$20Test
INFO  [2023-01-26 18:08:44,952] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:45,059] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test BIG_MULTI_SELECT_SPEZIAL_CHARACTER2 Test
INFO  [2023-01-26 18:08:45,059] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test COUNT Test
INFO  [2023-01-26 18:08:45,059] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:45,059] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:45,060] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=COUNT Test, name=COUNT Test]
INFO  [2023-01-26 18:08:45,060] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:45,060] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=COUNT Test, name=COUNT Test]
INFO  [2023-01-26 18:08:45,060] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:45,062] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker COUNT$20Test.worker_COUNT$20Test_90671a20-6858-4638-9bb0-4dbbda2f2304 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:45,062] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker COUNT$20Test.worker_COUNT$20Test_90671a20-6858-4638-9bb0-4dbbda2f2304 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:45,062] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:45,062] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker COUNT$20Test.worker_COUNT$20Test_52c1762c-4306-4ea9-b89f-f74313b98065 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:45,062] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker COUNT$20Test.worker_COUNT$20Test_52c1762c-4306-4ea9-b89f-f74313b98065 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:45,062] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:45,066] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:45,171] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:45,171] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table COUNT$20Test.table
INFO  [2023-01-26 18:08:45,172] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table COUNT$20Test.table
INFO  [2023-01-26 18:08:45,289] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:45,404] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:45,404] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:45,404] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 1 KiB in total
INFO  [2023-01-26 18:08:45,404] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COUNT Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000314983sINFO  [2023-01-26 18:08:45,437] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=5, sum=36, min=1, average=7.200000, max=13}
INFO  [2023-01-26 18:08:45,437] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[nr] with IntegerParser(super=Parser(lines=36, nullLines=0), minValue=1, maxValue=23)
INFO  [2023-01-26 18:08:45,437] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=36, nullLines=0), minParser=DateParser(super=Parser(lines=36, nullLines=0), subType=IntegerParser(super=Parser(lines=36, nullLines=0), minValue=14610, maxValue=14610), dateReader=com.bakdata.conquery.util.DateReader@2e90cb11), maxParser=DateParser(super=Parser(lines=36, nullLines=0), subType=IntegerParser(super=Parser(lines=36, nullLines=0), minValue=14640, maxValue=14640), dateReader=com.bakdata.conquery.util.DateReader@6019bcac), dateReader=com.bakdata.conquery.util.DateReader@1eb9a7a5, onlyQuarters=false, maxValue=14640, minValue=14610, anyOpen=false)
INFO  [2023-01-26 18:08:45,440] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COUNT Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:45,440] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:45,440] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COUNT Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:45,477] com.bakdata.conquery.models.jobs.ImportJob: Importing table into COUNT$20Test.table
127.0.0.1 - - [26/Jan/2023:18:08:45 +0000] "POST /admin/datasets/COUNT%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_COUNT+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 28
INFO  [2023-01-26 18:08:45,481] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:45,481] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:45,481] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:45,481] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:45,483] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:08:45,484] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[COUNT$20Test.table.table], containing 36 entries.
INFO  [2023-01-26 18:08:45,484] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[COUNT$20Test.table.table], containing 36 entries.
WARN  [2023-01-26 18:08:45,484] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:45,484] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received COUNT$20Test.table.table.0
INFO  [2023-01-26 18:08:45,484] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received COUNT$20Test.table.table.1
INFO  [2023-01-26 18:08:45,590] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: COUNT Test QUERY INIT
INFO  [2023-01-26 18:08:45,609] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[COUNT$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:08:45,609] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[bb8e2eab-8482-4932-aeca-51055bce7de9] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_COUNT Test))]]
INFO  [2023-01-26 18:08:45,614] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery COUNT$20Test.bb8e2eab-8482-4932-aeca-51055bce7de9
INFO  [2023-01-26 18:08:45,614] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery COUNT$20Test.bb8e2eab-8482-4932-aeca-51055bce7de9
INFO  [2023-01-26 18:08:45,615] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[COUNT$20Test.bb8e2eab-8482-4932-aeca-51055bce7de9] with 1 results within PT0.001145S
INFO  [2023-01-26 18:08:45,615] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[COUNT$20Test.bb8e2eab-8482-4932-aeca-51055bce7de9] with 1 results within PT0.001336S
127.0.0.1 - - [26/Jan/2023:18:08:45 +0000] "POST /api/datasets/COUNT$20Test/queries HTTP/1.1" 201 1166 "-" "Conquery (test client)" 12
INFO  [2023-01-26 18:08:45,616] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=COUNT$20Test.bb8e2eab-8482-4932-aeca-51055bce7de9, workerId=COUNT$20Test.worker_COUNT$20Test_90671a20-6858-4638-9bb0-4dbbda2f2304, startTime=2023-01-26T18:08:45.614502, finishTime=2023-01-26T18:08:45.615647) of size 1
INFO  [2023-01-26 18:08:45,616] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=COUNT$20Test.bb8e2eab-8482-4932-aeca-51055bce7de9, workerId=COUNT$20Test.worker_COUNT$20Test_52c1762c-4306-4ea9-b89f-f74313b98065, startTime=2023-01-26T18:08:45.614529, finishTime=2023-01-26T18:08:45.615865) of size 1
INFO  [2023-01-26 18:08:45,617] com.bakdata.conquery.models.execution.ManagedExecution: DONE bb8e2eab-8482-4932-aeca-51055bce7de9 ManagedQuery within PT0.007642S
127.0.0.1 - - [26/Jan/2023:18:08:45 +0000] "GET /api/datasets/COUNT$20Test/queries/COUNT$20Test.bb8e2eab-8482-4932-aeca-51055bce7de9 HTTP/1.1" 200 1405 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:08:45,651] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=COUNT Test], queryId=bb8e2eab-8482-4932-aeca-51055bce7de9, label=concept	@§$, creationTime=2023-01-26T18:08:45.609544, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@72ccf5d0[Count = 0], startTime=2023-01-26T18:08:45.609851, finishTime=2023-01-26T18:08:45.617493, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@7f46824a), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_COUNT Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@43f424ee, com.bakdata.conquery.models.query.ColumnDescriptor@7940dc8]) download on dataset Dataset[label=null, name=COUNT Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:08:45,651] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=COUNT Test], queryId=bb8e2eab-8482-4932-aeca-51055bce7de9, label=concept	@§$, creationTime=2023-01-26T18:08:45.609544, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@72ccf5d0[Count = 0], startTime=2023-01-26T18:08:45.609851, finishTime=2023-01-26T18:08:45.617493, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@7f46824a), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_COUNT Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@43f424ee, com.bakdata.conquery.models.query.ColumnDescriptor@7940dc8]) on dataset Dataset[label=null, name=COUNT Test]
127.0.0.1 - - [26/Jan/2023:18:08:45 +0000] "GET /api/datasets/COUNT%20Test/result/COUNT$20Test.bb8e2eab-8482-4932-aeca-51055bce7de9.csv?pretty=false HTTP/1.1" 200 65 "-" "Conquery (test client)" 18
INFO  [2023-01-26 18:08:45,668] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest COUNT Test on 3 rows
INFO  [2023-01-26 18:08:45,668] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast COUNT Test
INFO  [2023-01-26 18:08:45,669] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=COUNT Test, name=COUNT Test]
INFO  [2023-01-26 18:08:45,669] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=COUNT Test, name=COUNT Test]
INFO  [2023-01-26 18:08:45,669] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_COUNT Test_52c1762c-4306-4ea9-b89f-f74313b98065
INFO  [2023-01-26 18:08:45,669] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_COUNT Test_90671a20-6858-4638-9bb0-4dbbda2f2304
INFO  [2023-01-26 18:08:45,672] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow COUNT Test
INFO  [2023-01-26 18:08:45,672] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_COUNT Test_52c1762c-4306-4ea9-b89f-f74313b98065
INFO  [2023-01-26 18:08:45,672] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_COUNT Test_90671a20-6858-4638-9bb0-4dbbda2f2304
INFO  [2023-01-26 18:08:45,684] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of COUNT$20Test
INFO  [2023-01-26 18:08:45,684] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:45,790] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test COUNT Test
INFO  [2023-01-26 18:08:45,791] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test COUNT distinct Test
INFO  [2023-01-26 18:08:45,791] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:45,791] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:45,796] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=COUNT distinct Test, name=COUNT distinct Test]
INFO  [2023-01-26 18:08:45,796] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=COUNT distinct Test, name=COUNT distinct Test]
INFO  [2023-01-26 18:08:45,796] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:45,796] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:45,804] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker COUNT$20distinct$20Test.worker_COUNT$20distinct$20Test_867ae561-8a07-4acf-80a0-94bbe130ac40 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:45,804] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker COUNT$20distinct$20Test.worker_COUNT$20distinct$20Test_867ae561-8a07-4acf-80a0-94bbe130ac40 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:45,804] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:45,804] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker COUNT$20distinct$20Test.worker_COUNT$20distinct$20Test_117aa2e3-a9f9-4ae9-b01f-3a5ba2e214d3 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:45,804] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker COUNT$20distinct$20Test.worker_COUNT$20distinct$20Test_117aa2e3-a9f9-4ae9-b01f-3a5ba2e214d3 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:45,804] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:45,808] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:45,911] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:45,912] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table COUNT$20distinct$20Test.table
INFO  [2023-01-26 18:08:45,912] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table COUNT$20distinct$20Test.table
INFO  [2023-01-26 18:08:46,023] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:46,134] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:46,135] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:46,135] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 1 KiB in total
INFO  [2023-01-26 18:08:46,135] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COUNT distinct Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000294942sINFO  [2023-01-26 18:08:46,166] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=5, sum=36, min=1, average=7.200000, max=13}
INFO  [2023-01-26 18:08:46,166] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=36, nullLines=0), minParser=DateParser(super=Parser(lines=36, nullLines=0), subType=IntegerParser(super=Parser(lines=36, nullLines=0), minValue=14610, maxValue=14610), dateReader=com.bakdata.conquery.util.DateReader@36baf748), maxParser=DateParser(super=Parser(lines=36, nullLines=0), subType=IntegerParser(super=Parser(lines=36, nullLines=0), minValue=14640, maxValue=14640), dateReader=com.bakdata.conquery.util.DateReader@41fa1926), dateReader=com.bakdata.conquery.util.DateReader@4d65fdb0, onlyQuarters=false, maxValue=14640, minValue=14610, anyOpen=false)
INFO  [2023-01-26 18:08:46,166] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[nr] with IntegerParser(super=Parser(lines=36, nullLines=0), minValue=1, maxValue=23)
INFO  [2023-01-26 18:08:46,170] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COUNT distinct Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:46,170] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:46,170] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COUNT distinct Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:46,190] com.bakdata.conquery.models.jobs.ImportJob: Importing table into COUNT$20distinct$20Test.table
127.0.0.1 - - [26/Jan/2023:18:08:46 +0000] "POST /admin/datasets/COUNT%20distinct%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_COUNT+distinct+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 11
INFO  [2023-01-26 18:08:46,193] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:46,194] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:46,194] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:46,194] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:46,195] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:08:46,196] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[COUNT$20distinct$20Test.table.table], containing 36 entries.
INFO  [2023-01-26 18:08:46,196] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[COUNT$20distinct$20Test.table.table], containing 36 entries.
WARN  [2023-01-26 18:08:46,197] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:46,197] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received COUNT$20distinct$20Test.table.table.0
INFO  [2023-01-26 18:08:46,197] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received COUNT$20distinct$20Test.table.table.1
INFO  [2023-01-26 18:08:46,301] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: COUNT distinct Test QUERY INIT
INFO  [2023-01-26 18:08:46,317] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[COUNT$20distinct$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:08:46,318] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[0d8046c2-818a-4847-b9cc-ac4e0390ab89] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_COUNT distinct Test))]]
INFO  [2023-01-26 18:08:46,321] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery COUNT$20distinct$20Test.0d8046c2-818a-4847-b9cc-ac4e0390ab89
INFO  [2023-01-26 18:08:46,321] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery COUNT$20distinct$20Test.0d8046c2-818a-4847-b9cc-ac4e0390ab89
INFO  [2023-01-26 18:08:46,322] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[COUNT$20distinct$20Test.0d8046c2-818a-4847-b9cc-ac4e0390ab89] with 2 results within PT0.001137S
INFO  [2023-01-26 18:08:46,322] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[COUNT$20distinct$20Test.0d8046c2-818a-4847-b9cc-ac4e0390ab89] with 0 results within PT0.000969S
127.0.0.1 - - [26/Jan/2023:18:08:46 +0000] "POST /api/datasets/COUNT$20distinct$20Test/queries HTTP/1.1" 201 1210 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:08:46,322] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=COUNT$20distinct$20Test.0d8046c2-818a-4847-b9cc-ac4e0390ab89, workerId=COUNT$20distinct$20Test.worker_COUNT$20distinct$20Test_117aa2e3-a9f9-4ae9-b01f-3a5ba2e214d3, startTime=2023-01-26T18:08:46.321141, finishTime=2023-01-26T18:08:46.322278) of size 2
INFO  [2023-01-26 18:08:46,323] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=COUNT$20distinct$20Test.0d8046c2-818a-4847-b9cc-ac4e0390ab89, workerId=COUNT$20distinct$20Test.worker_COUNT$20distinct$20Test_867ae561-8a07-4acf-80a0-94bbe130ac40, startTime=2023-01-26T18:08:46.321305, finishTime=2023-01-26T18:08:46.322274) of size 0
INFO  [2023-01-26 18:08:46,323] com.bakdata.conquery.models.execution.ManagedExecution: DONE 0d8046c2-818a-4847-b9cc-ac4e0390ab89 ManagedQuery within PT0.005485S
127.0.0.1 - - [26/Jan/2023:18:08:46 +0000] "GET /api/datasets/COUNT$20distinct$20Test/queries/COUNT$20distinct$20Test.0d8046c2-818a-4847-b9cc-ac4e0390ab89 HTTP/1.1" 200 1493 "-" "Conquery (test client)" 4
INFO  [2023-01-26 18:08:46,354] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=COUNT distinct Test], queryId=0d8046c2-818a-4847-b9cc-ac4e0390ab89, label=concept	@§$, creationTime=2023-01-26T18:08:46.318113, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@420f7fd6[Count = 0], startTime=2023-01-26T18:08:46.318351, finishTime=2023-01-26T18:08:46.323836, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@41e79c8f), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_COUNT distinct Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@58b782fe, com.bakdata.conquery.models.query.ColumnDescriptor@752444cb]) download on dataset Dataset[label=null, name=COUNT distinct Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:08:46,355] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=COUNT distinct Test], queryId=0d8046c2-818a-4847-b9cc-ac4e0390ab89, label=concept	@§$, creationTime=2023-01-26T18:08:46.318113, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@420f7fd6[Count = 0], startTime=2023-01-26T18:08:46.318351, finishTime=2023-01-26T18:08:46.323836, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@41e79c8f), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_COUNT distinct Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@58b782fe, com.bakdata.conquery.models.query.ColumnDescriptor@752444cb]) on dataset Dataset[label=null, name=COUNT distinct Test]
127.0.0.1 - - [26/Jan/2023:18:08:46 +0000] "GET /api/datasets/COUNT%20distinct%20Test/result/COUNT$20distinct$20Test.0d8046c2-818a-4847-b9cc-ac4e0390ab89.csv?pretty=false HTTP/1.1" 200 65 "-" "Conquery (test client)" 22
INFO  [2023-01-26 18:08:46,375] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest COUNT distinct Test on 3 rows
INFO  [2023-01-26 18:08:46,375] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast COUNT distinct Test
INFO  [2023-01-26 18:08:46,376] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=COUNT distinct Test, name=COUNT distinct Test]
INFO  [2023-01-26 18:08:46,376] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=COUNT distinct Test, name=COUNT distinct Test]
INFO  [2023-01-26 18:08:46,376] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_COUNT distinct Test_867ae561-8a07-4acf-80a0-94bbe130ac40
INFO  [2023-01-26 18:08:46,376] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_COUNT distinct Test_117aa2e3-a9f9-4ae9-b01f-3a5ba2e214d3
INFO  [2023-01-26 18:08:46,396] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow COUNT distinct Test
INFO  [2023-01-26 18:08:46,397] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of COUNT$20distinct$20Test
INFO  [2023-01-26 18:08:46,397] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:46,402] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_COUNT distinct Test_867ae561-8a07-4acf-80a0-94bbe130ac40
INFO  [2023-01-26 18:08:46,402] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_COUNT distinct Test_117aa2e3-a9f9-4ae9-b01f-3a5ba2e214d3
INFO  [2023-01-26 18:08:46,602] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test COUNT distinct Test
INFO  [2023-01-26 18:08:46,602] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test COUNT multi distinct Test
INFO  [2023-01-26 18:08:46,602] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:46,603] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:46,604] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=COUNT multi distinct Test, name=COUNT multi distinct Test]
INFO  [2023-01-26 18:08:46,604] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:46,604] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=COUNT multi distinct Test, name=COUNT multi distinct Test]
INFO  [2023-01-26 18:08:46,604] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:46,607] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker COUNT$20multi$20distinct$20Test.worker_COUNT$20multi$20distinct$20Test_da585b9c-1ba8-4979-b029-70fef6311504 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:46,607] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker COUNT$20multi$20distinct$20Test.worker_COUNT$20multi$20distinct$20Test_da585b9c-1ba8-4979-b029-70fef6311504 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:46,607] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:46,607] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker COUNT$20multi$20distinct$20Test.worker_COUNT$20multi$20distinct$20Test_0e723480-4582-4d5c-b702-d57e5ef3f577 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:46,607] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker COUNT$20multi$20distinct$20Test.worker_COUNT$20multi$20distinct$20Test_0e723480-4582-4d5c-b702-d57e5ef3f577 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:46,607] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:46,610] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:46,714] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:46,714] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table COUNT$20multi$20distinct$20Test.table
INFO  [2023-01-26 18:08:46,714] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table COUNT$20multi$20distinct$20Test.table
INFO  [2023-01-26 18:08:46,824] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:46,936] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:46,936] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:46,936] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 1.2 KiB in total
INFO  [2023-01-26 18:08:46,936] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COUNT multi distinct Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000261791sINFO  [2023-01-26 18:08:46,964] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=5, sum=34, min=1, average=6.800000, max=13}
INFO  [2023-01-26 18:08:46,964] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[a] with StringParser(super=Parser(lines=34, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:08:46,964] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[b] with StringParser(super=Parser(lines=34, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:08:46,964] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[nr] with IntegerParser(super=Parser(lines=34, nullLines=0), minValue=1, maxValue=23)
INFO  [2023-01-26 18:08:46,964] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=34, nullLines=0), minParser=DateParser(super=Parser(lines=34, nullLines=0), subType=IntegerParser(super=Parser(lines=34, nullLines=0), minValue=14610, maxValue=14610), dateReader=com.bakdata.conquery.util.DateReader@3c7a076a), maxParser=DateParser(super=Parser(lines=34, nullLines=0), subType=IntegerParser(super=Parser(lines=34, nullLines=0), minValue=14640, maxValue=14640), dateReader=com.bakdata.conquery.util.DateReader@4d63192e), dateReader=com.bakdata.conquery.util.DateReader@390c9de7, onlyQuarters=false, maxValue=14640, minValue=14610, anyOpen=false)
INFO  [2023-01-26 18:08:46,968] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COUNT multi distinct Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:46,968] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:46,968] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COUNT multi distinct Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:46,985] com.bakdata.conquery.models.jobs.ImportJob: Importing table into COUNT$20multi$20distinct$20Test.table
127.0.0.1 - - [26/Jan/2023:18:08:46 +0000] "POST /admin/datasets/COUNT%20multi%20distinct%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_COUNT+multi+distinct+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:08:46,987] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:46,987] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:46,987] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:46,987] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:46,989] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:08:46,990] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[COUNT$20multi$20distinct$20Test.table.table], containing 34 entries.
INFO  [2023-01-26 18:08:46,990] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[COUNT$20multi$20distinct$20Test.table.table], containing 34 entries.
WARN  [2023-01-26 18:08:46,991] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:46,991] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received COUNT$20multi$20distinct$20Test.table.table.0
INFO  [2023-01-26 18:08:46,991] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received COUNT$20multi$20distinct$20Test.table.table.1
INFO  [2023-01-26 18:08:47,109] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: COUNT multi distinct Test QUERY INIT
INFO  [2023-01-26 18:08:47,120] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[COUNT$20multi$20distinct$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:08:47,120] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[6cc7fa24-d9c6-4433-8700-a5f9fd377f8a] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_COUNT multi distinct Test))]]
INFO  [2023-01-26 18:08:47,123] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery COUNT$20multi$20distinct$20Test.6cc7fa24-d9c6-4433-8700-a5f9fd377f8a
INFO  [2023-01-26 18:08:47,123] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery COUNT$20multi$20distinct$20Test.6cc7fa24-d9c6-4433-8700-a5f9fd377f8a
INFO  [2023-01-26 18:08:47,124] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[COUNT$20multi$20distinct$20Test.6cc7fa24-d9c6-4433-8700-a5f9fd377f8a] with 2 results within PT0.000939S
INFO  [2023-01-26 18:08:47,124] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[COUNT$20multi$20distinct$20Test.6cc7fa24-d9c6-4433-8700-a5f9fd377f8a] with 0 results within PT0.001009S
127.0.0.1 - - [26/Jan/2023:18:08:47 +0000] "POST /api/datasets/COUNT$20multi$20distinct$20Test/queries HTTP/1.1" 201 1242 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:08:47,124] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=COUNT$20multi$20distinct$20Test.6cc7fa24-d9c6-4433-8700-a5f9fd377f8a, workerId=COUNT$20multi$20distinct$20Test.worker_COUNT$20multi$20distinct$20Test_da585b9c-1ba8-4979-b029-70fef6311504, startTime=2023-01-26T18:08:47.123307, finishTime=2023-01-26T18:08:47.124246) of size 2
INFO  [2023-01-26 18:08:47,124] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=COUNT$20multi$20distinct$20Test.6cc7fa24-d9c6-4433-8700-a5f9fd377f8a, workerId=COUNT$20multi$20distinct$20Test.worker_COUNT$20multi$20distinct$20Test_0e723480-4582-4d5c-b702-d57e5ef3f577, startTime=2023-01-26T18:08:47.123297, finishTime=2023-01-26T18:08:47.124306) of size 0
INFO  [2023-01-26 18:08:47,125] com.bakdata.conquery.models.execution.ManagedExecution: DONE 6cc7fa24-d9c6-4433-8700-a5f9fd377f8a ManagedQuery within PT0.004705S
127.0.0.1 - - [26/Jan/2023:18:08:47 +0000] "GET /api/datasets/COUNT$20multi$20distinct$20Test/queries/COUNT$20multi$20distinct$20Test.6cc7fa24-d9c6-4433-8700-a5f9fd377f8a HTTP/1.1" 200 1557 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:08:47,145] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=COUNT multi distinct Test], queryId=6cc7fa24-d9c6-4433-8700-a5f9fd377f8a, label=concept	@§$, creationTime=2023-01-26T18:08:47.120646, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@5a34e18c[Count = 0], startTime=2023-01-26T18:08:47.120831, finishTime=2023-01-26T18:08:47.125536, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@23b0ca06), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_COUNT multi distinct Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@22062a00, com.bakdata.conquery.models.query.ColumnDescriptor@7247a065]) download on dataset Dataset[label=null, name=COUNT multi distinct Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:08:47,145] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=COUNT multi distinct Test], queryId=6cc7fa24-d9c6-4433-8700-a5f9fd377f8a, label=concept	@§$, creationTime=2023-01-26T18:08:47.120646, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@5a34e18c[Count = 0], startTime=2023-01-26T18:08:47.120831, finishTime=2023-01-26T18:08:47.125536, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@23b0ca06), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_COUNT multi distinct Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@22062a00, com.bakdata.conquery.models.query.ColumnDescriptor@7247a065]) on dataset Dataset[label=null, name=COUNT multi distinct Test]
127.0.0.1 - - [26/Jan/2023:18:08:47 +0000] "GET /api/datasets/COUNT%20multi%20distinct%20Test/result/COUNT$20multi$20distinct$20Test.6cc7fa24-d9c6-4433-8700-a5f9fd377f8a.csv?pretty=false HTTP/1.1" 200 65 "-" "Conquery (test client)" 14
INFO  [2023-01-26 18:08:47,159] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest COUNT multi distinct Test on 3 rows
INFO  [2023-01-26 18:08:47,159] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast COUNT multi distinct Test
INFO  [2023-01-26 18:08:47,159] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=COUNT multi distinct Test, name=COUNT multi distinct Test]
INFO  [2023-01-26 18:08:47,159] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=COUNT multi distinct Test, name=COUNT multi distinct Test]
INFO  [2023-01-26 18:08:47,159] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_COUNT multi distinct Test_da585b9c-1ba8-4979-b029-70fef6311504
INFO  [2023-01-26 18:08:47,160] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_COUNT multi distinct Test_0e723480-4582-4d5c-b702-d57e5ef3f577
INFO  [2023-01-26 18:08:47,204] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow COUNT multi distinct Test
INFO  [2023-01-26 18:08:47,205] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of COUNT$20multi$20distinct$20Test
INFO  [2023-01-26 18:08:47,205] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:47,205] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_COUNT multi distinct Test_da585b9c-1ba8-4979-b029-70fef6311504
INFO  [2023-01-26 18:08:47,206] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_COUNT multi distinct Test_0e723480-4582-4d5c-b702-d57e5ef3f577
INFO  [2023-01-26 18:08:47,410] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test COUNT multi distinct Test
INFO  [2023-01-26 18:08:47,410] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test COUNT_QUARTERS Test
INFO  [2023-01-26 18:08:47,410] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:47,410] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:47,411] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=COUNT_QUARTERS Test, name=COUNT_QUARTERS Test]
INFO  [2023-01-26 18:08:47,411] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=COUNT_QUARTERS Test, name=COUNT_QUARTERS Test]
INFO  [2023-01-26 18:08:47,411] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:47,411] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:47,419] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:47,419] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker COUNT_QUARTERS$20Test.worker_COUNT_QUARTERS$20Test_cf14448d-8a43-4fd4-88a1-358643e367cd are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:47,419] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker COUNT_QUARTERS$20Test.worker_COUNT_QUARTERS$20Test_cf14448d-8a43-4fd4-88a1-358643e367cd are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:47,419] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:47,419] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker COUNT_QUARTERS$20Test.worker_COUNT_QUARTERS$20Test_8a9de1ab-13ee-4cb1-8f7e-54c83d144626 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:47,419] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker COUNT_QUARTERS$20Test.worker_COUNT_QUARTERS$20Test_8a9de1ab-13ee-4cb1-8f7e-54c83d144626 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:47,419] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:47,522] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:47,522] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table COUNT_QUARTERS$20Test.table
INFO  [2023-01-26 18:08:47,522] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table COUNT_QUARTERS$20Test.table
INFO  [2023-01-26 18:08:47,639] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:47,754] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:47,754] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:47,754] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 1.4 KiB in total
INFO  [2023-01-26 18:08:47,754] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COUNT_QUARTERS Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000180934sINFO  [2023-01-26 18:08:47,773] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=12, sum=38, min=1, average=3.166667, max=6}
INFO  [2023-01-26 18:08:47,773] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[behandlungsdatum] with DateParser(super=Parser(lines=38, nullLines=0), subType=IntegerParser(super=Parser(lines=38, nullLines=0), minValue=16436, maxValue=17117), dateReader=com.bakdata.conquery.util.DateReader@3931c1e3)
INFO  [2023-01-26 18:08:47,773] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=38, nullLines=0), minParser=DateParser(super=Parser(lines=38, nullLines=0), subType=IntegerParser(super=Parser(lines=38, nullLines=0), minValue=16436, maxValue=16436), dateReader=com.bakdata.conquery.util.DateReader@16c2e0bd), maxParser=DateParser(super=Parser(lines=38, nullLines=0), subType=IntegerParser(super=Parser(lines=38, nullLines=0), minValue=17166, maxValue=17166), dateReader=com.bakdata.conquery.util.DateReader@13ab73c7), dateReader=com.bakdata.conquery.util.DateReader@24af552d, onlyQuarters=false, maxValue=17166, minValue=16436, anyOpen=false)
INFO  [2023-01-26 18:08:47,777] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COUNT_QUARTERS Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:47,777] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:47,777] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COUNT_QUARTERS Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:47,791] com.bakdata.conquery.models.jobs.ImportJob: Importing table into COUNT_QUARTERS$20Test.table
127.0.0.1 - - [26/Jan/2023:18:08:47 +0000] "POST /admin/datasets/COUNT_QUARTERS%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_COUNT_QUARTERS+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:08:47,793] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:47,794] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:47,794] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:47,794] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:47,795] com.bakdata.conquery.models.jobs.ImportJob: Start sending 4 Buckets
INFO  [2023-01-26 18:08:47,795] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[COUNT_QUARTERS$20Test.table.table], containing 38 entries.
INFO  [2023-01-26 18:08:47,796] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[COUNT_QUARTERS$20Test.table.table], containing 38 entries.
INFO  [2023-01-26 18:08:47,797] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received COUNT_QUARTERS$20Test.table.table.0
WARN  [2023-01-26 18:08:47,797] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:47,797] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received COUNT_QUARTERS$20Test.table.table.1
INFO  [2023-01-26 18:08:47,797] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received COUNT_QUARTERS$20Test.table.table.2
INFO  [2023-01-26 18:08:47,797] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received COUNT_QUARTERS$20Test.table.table.3
INFO  [2023-01-26 18:08:47,902] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: COUNT_QUARTERS Test QUERY INIT
INFO  [2023-01-26 18:08:47,914] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[COUNT_QUARTERS$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:08:47,914] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[39738867-b0b2-4245-b77e-a7dbc2adaf8c] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_COUNT_QUARTERS Test))]]
INFO  [2023-01-26 18:08:47,917] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery COUNT_QUARTERS$20Test.39738867-b0b2-4245-b77e-a7dbc2adaf8c
INFO  [2023-01-26 18:08:47,917] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery COUNT_QUARTERS$20Test.39738867-b0b2-4245-b77e-a7dbc2adaf8c
127.0.0.1 - - [26/Jan/2023:18:08:47 +0000] "POST /api/datasets/COUNT_QUARTERS$20Test/queries HTTP/1.1" 201 1201 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:08:47,918] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[COUNT_QUARTERS$20Test.39738867-b0b2-4245-b77e-a7dbc2adaf8c] with 4 results within PT0.001425S
INFO  [2023-01-26 18:08:47,919] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=COUNT_QUARTERS$20Test.39738867-b0b2-4245-b77e-a7dbc2adaf8c, workerId=COUNT_QUARTERS$20Test.worker_COUNT_QUARTERS$20Test_cf14448d-8a43-4fd4-88a1-358643e367cd, startTime=2023-01-26T18:08:47.917292, finishTime=2023-01-26T18:08:47.918717) of size 4
INFO  [2023-01-26 18:08:47,922] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[COUNT_QUARTERS$20Test.39738867-b0b2-4245-b77e-a7dbc2adaf8c] with 2 results within PT0.004534S
INFO  [2023-01-26 18:08:47,923] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=COUNT_QUARTERS$20Test.39738867-b0b2-4245-b77e-a7dbc2adaf8c, workerId=COUNT_QUARTERS$20Test.worker_COUNT_QUARTERS$20Test_8a9de1ab-13ee-4cb1-8f7e-54c83d144626, startTime=2023-01-26T18:08:47.917936, finishTime=2023-01-26T18:08:47.922470) of size 2
INFO  [2023-01-26 18:08:47,924] com.bakdata.conquery.models.execution.ManagedExecution: DONE 39738867-b0b2-4245-b77e-a7dbc2adaf8c ManagedQuery within PT0.009517S
127.0.0.1 - - [26/Jan/2023:18:08:47 +0000] "GET /api/datasets/COUNT_QUARTERS$20Test/queries/COUNT_QUARTERS$20Test.39738867-b0b2-4245-b77e-a7dbc2adaf8c HTTP/1.1" 200 1476 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:08:47,961] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=COUNT_QUARTERS Test], queryId=39738867-b0b2-4245-b77e-a7dbc2adaf8c, label=concept	@§$, creationTime=2023-01-26T18:08:47.914680, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@3c3a64c8[Count = 0], startTime=2023-01-26T18:08:47.914865, finishTime=2023-01-26T18:08:47.924382, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@60b3d288), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_COUNT_QUARTERS Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=6, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@2c48d44d, com.bakdata.conquery.models.query.ColumnDescriptor@582adff4]) download on dataset Dataset[label=null, name=COUNT_QUARTERS Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:08:47,962] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=COUNT_QUARTERS Test], queryId=39738867-b0b2-4245-b77e-a7dbc2adaf8c, label=concept	@§$, creationTime=2023-01-26T18:08:47.914680, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@3c3a64c8[Count = 0], startTime=2023-01-26T18:08:47.914865, finishTime=2023-01-26T18:08:47.924382, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@60b3d288), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_COUNT_QUARTERS Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=6, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@2c48d44d, com.bakdata.conquery.models.query.ColumnDescriptor@582adff4]) on dataset Dataset[label=null, name=COUNT_QUARTERS Test]
127.0.0.1 - - [26/Jan/2023:18:08:47 +0000] "GET /api/datasets/COUNT_QUARTERS%20Test/result/COUNT_QUARTERS$20Test.39738867-b0b2-4245-b77e-a7dbc2adaf8c.csv?pretty=false HTTP/1.1" 200 171 "-" "Conquery (test client)" 21
INFO  [2023-01-26 18:08:47,981] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest COUNT_QUARTERS Test on 7 rows
INFO  [2023-01-26 18:08:47,982] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast COUNT_QUARTERS Test
INFO  [2023-01-26 18:08:47,982] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=COUNT_QUARTERS Test, name=COUNT_QUARTERS Test]
INFO  [2023-01-26 18:08:47,982] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=COUNT_QUARTERS Test, name=COUNT_QUARTERS Test]
INFO  [2023-01-26 18:08:47,982] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_COUNT_QUARTERS Test_8a9de1ab-13ee-4cb1-8f7e-54c83d144626
INFO  [2023-01-26 18:08:47,983] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_COUNT_QUARTERS Test_cf14448d-8a43-4fd4-88a1-358643e367cd
INFO  [2023-01-26 18:08:48,011] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow COUNT_QUARTERS Test
INFO  [2023-01-26 18:08:48,013] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_COUNT_QUARTERS Test_cf14448d-8a43-4fd4-88a1-358643e367cd
INFO  [2023-01-26 18:08:48,013] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_COUNT_QUARTERS Test_8a9de1ab-13ee-4cb1-8f7e-54c83d144626
INFO  [2023-01-26 18:08:48,097] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of COUNT_QUARTERS$20Test
INFO  [2023-01-26 18:08:48,097] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:48,203] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test COUNT_QUARTERS Test
INFO  [2023-01-26 18:08:48,204] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test COUNT_QUARTERS Test
INFO  [2023-01-26 18:08:48,204] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:48,204] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:48,208] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=COUNT_QUARTERS Test[1], name=COUNT_QUARTERS Test[1]]
INFO  [2023-01-26 18:08:48,208] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=COUNT_QUARTERS Test[1], name=COUNT_QUARTERS Test[1]]
INFO  [2023-01-26 18:08:48,208] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:48,208] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:48,211] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker COUNT_QUARTERS$20Test[1].worker_COUNT_QUARTERS$20Test[1]_e7c49ef0-1580-4abf-b9df-e2012cd00d3a are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:48,211] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker COUNT_QUARTERS$20Test[1].worker_COUNT_QUARTERS$20Test[1]_e7c49ef0-1580-4abf-b9df-e2012cd00d3a are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:48,211] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:48,211] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker COUNT_QUARTERS$20Test[1].worker_COUNT_QUARTERS$20Test[1]_092c045f-6413-4e07-aa8e-ec8ad990e63d are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:48,211] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker COUNT_QUARTERS$20Test[1].worker_COUNT_QUARTERS$20Test[1]_092c045f-6413-4e07-aa8e-ec8ad990e63d are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:48,211] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:48,214] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:48,316] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:48,317] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table COUNT_QUARTERS$20Test[1].table
INFO  [2023-01-26 18:08:48,317] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table COUNT_QUARTERS$20Test[1].table
INFO  [2023-01-26 18:08:48,428] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:48,538] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:48,538] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:48,538] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 205 B in total
INFO  [2023-01-26 18:08:48,538] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COUNT_QUARTERS Test[1]/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000258914sINFO  [2023-01-26 18:08:48,565] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=5, min=1, average=1.250000, max=2}
INFO  [2023-01-26 18:08:48,565] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=5, nullLines=0), subType=IntegerParser(super=Parser(lines=5, nullLines=0), minValue=16436, maxValue=16436), dateReader=com.bakdata.conquery.util.DateReader@57b605a9)
INFO  [2023-01-26 18:08:48,565] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[behandlungsdatum] with DateRangeParser(super=Parser(lines=5, nullLines=0), minParser=DateParser(super=Parser(lines=5, nullLines=0), subType=IntegerParser(super=Parser(lines=5, nullLines=0), minValue=16436, maxValue=16587), dateReader=com.bakdata.conquery.util.DateReader@1aa6f547), maxParser=DateParser(super=Parser(lines=5, nullLines=0), subType=IntegerParser(super=Parser(lines=5, nullLines=0), minValue=16466, maxValue=16800), dateReader=com.bakdata.conquery.util.DateReader@6ca60cb0), dateReader=com.bakdata.conquery.util.DateReader@d7f7ae6, onlyQuarters=false, maxValue=16800, minValue=16436, anyOpen=false)
INFO  [2023-01-26 18:08:48,568] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COUNT_QUARTERS Test[1]/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:48,568] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:48,568] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COUNT_QUARTERS Test[1]/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:48,592] com.bakdata.conquery.models.jobs.ImportJob: Importing table into COUNT_QUARTERS$20Test[1].table
127.0.0.1 - - [26/Jan/2023:18:08:48 +0000] "POST /admin/datasets/COUNT_QUARTERS%20Test%5B1%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_COUNT_QUARTERS+Test%5B1%5D%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 17
INFO  [2023-01-26 18:08:48,594] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:48,594] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:48,594] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:48,594] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:48,596] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:08:48,596] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[COUNT_QUARTERS$20Test[1].table.table], containing 5 entries.
INFO  [2023-01-26 18:08:48,597] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[COUNT_QUARTERS$20Test[1].table.table], containing 5 entries.
WARN  [2023-01-26 18:08:48,597] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:48,597] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received COUNT_QUARTERS$20Test[1].table.table.0
INFO  [2023-01-26 18:08:48,597] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received COUNT_QUARTERS$20Test[1].table.table.1
INFO  [2023-01-26 18:08:48,702] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: COUNT_QUARTERS Test QUERY INIT
INFO  [2023-01-26 18:08:48,714] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[COUNT_QUARTERS$20Test[1]] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:08:48,714] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[622a8757-945a-429b-b5e7-1c98d8b57334] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_COUNT_QUARTERS Test[1]))]]
INFO  [2023-01-26 18:08:48,717] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery COUNT_QUARTERS$20Test[1].622a8757-945a-429b-b5e7-1c98d8b57334
INFO  [2023-01-26 18:08:48,717] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery COUNT_QUARTERS$20Test[1].622a8757-945a-429b-b5e7-1c98d8b57334
INFO  [2023-01-26 18:08:48,718] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[COUNT_QUARTERS$20Test[1].622a8757-945a-429b-b5e7-1c98d8b57334] with 1 results within PT0.001114S
127.0.0.1 - - [26/Jan/2023:18:08:48 +0000] "POST /api/datasets/COUNT_QUARTERS$20Test%5B1%5D/queries HTTP/1.1" 201 1214 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:08:48,718] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[COUNT_QUARTERS$20Test[1].622a8757-945a-429b-b5e7-1c98d8b57334] with 1 results within PT0.001245S
INFO  [2023-01-26 18:08:48,718] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=COUNT_QUARTERS$20Test[1].622a8757-945a-429b-b5e7-1c98d8b57334, workerId=COUNT_QUARTERS$20Test[1].worker_COUNT_QUARTERS$20Test[1]_092c045f-6413-4e07-aa8e-ec8ad990e63d, startTime=2023-01-26T18:08:48.717103, finishTime=2023-01-26T18:08:48.718217) of size 1
INFO  [2023-01-26 18:08:48,719] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=COUNT_QUARTERS$20Test[1].622a8757-945a-429b-b5e7-1c98d8b57334, workerId=COUNT_QUARTERS$20Test[1].worker_COUNT_QUARTERS$20Test[1]_e7c49ef0-1580-4abf-b9df-e2012cd00d3a, startTime=2023-01-26T18:08:48.717102, finishTime=2023-01-26T18:08:48.718347) of size 1
INFO  [2023-01-26 18:08:48,720] com.bakdata.conquery.models.execution.ManagedExecution: DONE 622a8757-945a-429b-b5e7-1c98d8b57334 ManagedQuery within PT0.005502S
127.0.0.1 - - [26/Jan/2023:18:08:48 +0000] "GET /api/datasets/COUNT_QUARTERS$20Test%5B1%5D/queries/COUNT_QUARTERS$20Test%5B1%5D.622a8757-945a-429b-b5e7-1c98d8b57334 HTTP/1.1" 200 1749 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:08:48,750] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=COUNT_QUARTERS Test[1]], queryId=622a8757-945a-429b-b5e7-1c98d8b57334, label=concept	@§$, creationTime=2023-01-26T18:08:48.714295, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@3cdf3eae[Count = 0], startTime=2023-01-26T18:08:48.714525, finishTime=2023-01-26T18:08:48.720027, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@167df827), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_COUNT_QUARTERS Test[1])), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@4b908068, com.bakdata.conquery.models.query.ColumnDescriptor@7dfe8d8f]) download on dataset Dataset[label=null, name=COUNT_QUARTERS Test[1]] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:08:48,750] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=COUNT_QUARTERS Test[1]], queryId=622a8757-945a-429b-b5e7-1c98d8b57334, label=concept	@§$, creationTime=2023-01-26T18:08:48.714295, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@3cdf3eae[Count = 0], startTime=2023-01-26T18:08:48.714525, finishTime=2023-01-26T18:08:48.720027, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@167df827), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_COUNT_QUARTERS Test[1])), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@4b908068, com.bakdata.conquery.models.query.ColumnDescriptor@7dfe8d8f]) on dataset Dataset[label=null, name=COUNT_QUARTERS Test[1]]
127.0.0.1 - - [26/Jan/2023:18:08:48 +0000] "GET /api/datasets/COUNT_QUARTERS%20Test%5B1%5D/result/COUNT_QUARTERS$20Test%5B1%5D.622a8757-945a-429b-b5e7-1c98d8b57334.csv?pretty=false HTTP/1.1" 200 65 "-" "Conquery (test client)" 17
INFO  [2023-01-26 18:08:48,766] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest COUNT_QUARTERS Test on 3 rows
INFO  [2023-01-26 18:08:48,766] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast COUNT_QUARTERS Test[1]
INFO  [2023-01-26 18:08:48,766] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=COUNT_QUARTERS Test[1], name=COUNT_QUARTERS Test[1]]
INFO  [2023-01-26 18:08:48,766] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=COUNT_QUARTERS Test[1], name=COUNT_QUARTERS Test[1]]
INFO  [2023-01-26 18:08:48,767] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_COUNT_QUARTERS Test[1]_092c045f-6413-4e07-aa8e-ec8ad990e63d
INFO  [2023-01-26 18:08:48,767] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_COUNT_QUARTERS Test[1]_e7c49ef0-1580-4abf-b9df-e2012cd00d3a
INFO  [2023-01-26 18:08:48,808] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow COUNT_QUARTERS Test[1]
INFO  [2023-01-26 18:08:48,816] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_COUNT_QUARTERS Test[1]_092c045f-6413-4e07-aa8e-ec8ad990e63d
INFO  [2023-01-26 18:08:48,816] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_COUNT_QUARTERS Test[1]_e7c49ef0-1580-4abf-b9df-e2012cd00d3a
INFO  [2023-01-26 18:08:48,897] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of COUNT_QUARTERS$20Test[1]
INFO  [2023-01-26 18:08:48,897] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:49,003] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test COUNT_QUARTERS Test
INFO  [2023-01-26 18:08:49,003] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test COUNTfalse Test
INFO  [2023-01-26 18:08:49,003] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:49,003] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:49,004] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=COUNTfalse Test, name=COUNTfalse Test]
INFO  [2023-01-26 18:08:49,004] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=COUNTfalse Test, name=COUNTfalse Test]
INFO  [2023-01-26 18:08:49,004] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:49,004] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:49,009] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker COUNTfalse$20Test.worker_COUNTfalse$20Test_71f4eda6-c18c-49d8-9381-e99c7175fa63 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:49,009] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker COUNTfalse$20Test.worker_COUNTfalse$20Test_71f4eda6-c18c-49d8-9381-e99c7175fa63 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:49,009] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:49,010] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:49,010] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker COUNTfalse$20Test.worker_COUNTfalse$20Test_184d9219-b305-466a-88a3-b85a2f813b9f are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:49,010] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker COUNTfalse$20Test.worker_COUNTfalse$20Test_184d9219-b305-466a-88a3-b85a2f813b9f are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:49,010] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:49,117] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:49,117] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table COUNTfalse$20Test.table
INFO  [2023-01-26 18:08:49,117] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table COUNTfalse$20Test.table
INFO  [2023-01-26 18:08:49,227] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:49,338] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:49,339] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:49,339] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 1 KiB in total
INFO  [2023-01-26 18:08:49,339] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COUNTfalse Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.00049679sINFO  [2023-01-26 18:08:49,389] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=5, sum=36, min=1, average=7.200000, max=13}
INFO  [2023-01-26 18:08:49,389] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[nr] with IntegerParser(super=Parser(lines=36, nullLines=0), minValue=1, maxValue=23)
INFO  [2023-01-26 18:08:49,389] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=36, nullLines=0), minParser=DateParser(super=Parser(lines=36, nullLines=0), subType=IntegerParser(super=Parser(lines=36, nullLines=0), minValue=14610, maxValue=14610), dateReader=com.bakdata.conquery.util.DateReader@7d80c620), maxParser=DateParser(super=Parser(lines=36, nullLines=0), subType=IntegerParser(super=Parser(lines=36, nullLines=0), minValue=14640, maxValue=14640), dateReader=com.bakdata.conquery.util.DateReader@32b76e54), dateReader=com.bakdata.conquery.util.DateReader@5346195c, onlyQuarters=false, maxValue=14640, minValue=14610, anyOpen=false)
INFO  [2023-01-26 18:08:49,393] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COUNTfalse Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:49,393] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:49,393] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COUNTfalse Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:49,414] com.bakdata.conquery.models.jobs.ImportJob: Importing table into COUNTfalse$20Test.table
127.0.0.1 - - [26/Jan/2023:18:08:49 +0000] "POST /admin/datasets/COUNTfalse%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_COUNTfalse+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 11
INFO  [2023-01-26 18:08:49,416] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:49,416] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:49,416] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:49,417] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:49,418] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:08:49,418] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[COUNTfalse$20Test.table.table], containing 36 entries.
INFO  [2023-01-26 18:08:49,418] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[COUNTfalse$20Test.table.table], containing 36 entries.
WARN  [2023-01-26 18:08:49,419] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:49,419] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received COUNTfalse$20Test.table.table.0
INFO  [2023-01-26 18:08:49,420] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received COUNTfalse$20Test.table.table.1
INFO  [2023-01-26 18:08:49,525] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: COUNTfalse Test QUERY INIT
INFO  [2023-01-26 18:08:49,536] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[COUNTfalse$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:08:49,536] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[7a6aa1fa-d6a8-4b1d-9994-6a15ae891f36] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_COUNTfalse Test))]]
INFO  [2023-01-26 18:08:49,538] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery COUNTfalse$20Test.7a6aa1fa-d6a8-4b1d-9994-6a15ae891f36
INFO  [2023-01-26 18:08:49,538] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery COUNTfalse$20Test.7a6aa1fa-d6a8-4b1d-9994-6a15ae891f36
127.0.0.1 - - [26/Jan/2023:18:08:49 +0000] "POST /api/datasets/COUNTfalse$20Test/queries HTTP/1.1" 201 1186 "-" "Conquery (test client)" 5
INFO  [2023-01-26 18:08:49,556] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[COUNTfalse$20Test.7a6aa1fa-d6a8-4b1d-9994-6a15ae891f36] with 1 results within PT0.017244S
INFO  [2023-01-26 18:08:49,556] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=COUNTfalse$20Test.7a6aa1fa-d6a8-4b1d-9994-6a15ae891f36, workerId=COUNTfalse$20Test.worker_COUNTfalse$20Test_71f4eda6-c18c-49d8-9381-e99c7175fa63, startTime=2023-01-26T18:08:49.538979, finishTime=2023-01-26T18:08:49.556223) of size 1
INFO  [2023-01-26 18:08:49,560] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[COUNTfalse$20Test.7a6aa1fa-d6a8-4b1d-9994-6a15ae891f36] with 1 results within PT0.021107S
INFO  [2023-01-26 18:08:49,560] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=COUNTfalse$20Test.7a6aa1fa-d6a8-4b1d-9994-6a15ae891f36, workerId=COUNTfalse$20Test.worker_COUNTfalse$20Test_184d9219-b305-466a-88a3-b85a2f813b9f, startTime=2023-01-26T18:08:49.538979, finishTime=2023-01-26T18:08:49.560086) of size 1
INFO  [2023-01-26 18:08:49,561] com.bakdata.conquery.models.execution.ManagedExecution: DONE 7a6aa1fa-d6a8-4b1d-9994-6a15ae891f36 ManagedQuery within PT0.024769S
127.0.0.1 - - [26/Jan/2023:18:08:49 +0000] "GET /api/datasets/COUNTfalse$20Test/queries/COUNTfalse$20Test.7a6aa1fa-d6a8-4b1d-9994-6a15ae891f36 HTTP/1.1" 200 1445 "-" "Conquery (test client)" 13
INFO  [2023-01-26 18:08:49,573] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=COUNTfalse Test], queryId=7a6aa1fa-d6a8-4b1d-9994-6a15ae891f36, label=concept	@§$, creationTime=2023-01-26T18:08:49.536548, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@251919e9[Count = 0], startTime=2023-01-26T18:08:49.536761, finishTime=2023-01-26T18:08:49.561530, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@34c0d55f), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_COUNTfalse Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@64f73123, com.bakdata.conquery.models.query.ColumnDescriptor@6cf498fd]) download on dataset Dataset[label=null, name=COUNTfalse Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:08:49,574] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=COUNTfalse Test], queryId=7a6aa1fa-d6a8-4b1d-9994-6a15ae891f36, label=concept	@§$, creationTime=2023-01-26T18:08:49.536548, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@251919e9[Count = 0], startTime=2023-01-26T18:08:49.536761, finishTime=2023-01-26T18:08:49.561530, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@34c0d55f), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_COUNTfalse Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@64f73123, com.bakdata.conquery.models.query.ColumnDescriptor@6cf498fd]) on dataset Dataset[label=null, name=COUNTfalse Test]
127.0.0.1 - - [26/Jan/2023:18:08:49 +0000] "GET /api/datasets/COUNTfalse%20Test/result/COUNTfalse$20Test.7a6aa1fa-d6a8-4b1d-9994-6a15ae891f36.csv?pretty=false HTTP/1.1" 200 65 "-" "Conquery (test client)" 20
INFO  [2023-01-26 18:08:49,593] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest COUNTfalse Test on 3 rows
INFO  [2023-01-26 18:08:49,593] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast COUNTfalse Test
INFO  [2023-01-26 18:08:49,593] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=COUNTfalse Test, name=COUNTfalse Test]
INFO  [2023-01-26 18:08:49,593] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=COUNTfalse Test, name=COUNTfalse Test]
INFO  [2023-01-26 18:08:49,593] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_COUNTfalse Test_71f4eda6-c18c-49d8-9381-e99c7175fa63
INFO  [2023-01-26 18:08:49,593] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_COUNTfalse Test_184d9219-b305-466a-88a3-b85a2f813b9f
INFO  [2023-01-26 18:08:49,604] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow COUNTfalse Test
INFO  [2023-01-26 18:08:49,610] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_COUNTfalse Test_184d9219-b305-466a-88a3-b85a2f813b9f
INFO  [2023-01-26 18:08:49,614] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_COUNTfalse Test_71f4eda6-c18c-49d8-9381-e99c7175fa63
INFO  [2023-01-26 18:08:49,620] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of COUNTfalse$20Test
INFO  [2023-01-26 18:08:49,620] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:49,725] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test COUNTfalse Test
INFO  [2023-01-26 18:08:49,725] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test NUMBER_REAL Test
INFO  [2023-01-26 18:08:49,726] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:49,726] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:49,730] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=NUMBER_REAL Test, name=NUMBER_REAL Test]
INFO  [2023-01-26 18:08:49,730] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=NUMBER_REAL Test, name=NUMBER_REAL Test]
INFO  [2023-01-26 18:08:49,730] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:49,730] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:49,733] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker NUMBER_REAL$20Test.worker_NUMBER_REAL$20Test_30467e17-7e87-4f49-8be5-01d121684243 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:49,733] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker NUMBER_REAL$20Test.worker_NUMBER_REAL$20Test_30467e17-7e87-4f49-8be5-01d121684243 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:49,733] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:49,733] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker NUMBER_REAL$20Test.worker_NUMBER_REAL$20Test_d447272d-73f7-49f4-913f-cf42da2dd550 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:49,733] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker NUMBER_REAL$20Test.worker_NUMBER_REAL$20Test_d447272d-73f7-49f4-913f-cf42da2dd550 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:49,733] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:49,736] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:49,840] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:49,840] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table NUMBER_REAL$20Test.table
INFO  [2023-01-26 18:08:49,840] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table NUMBER_REAL$20Test.table
INFO  [2023-01-26 18:08:49,954] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:50,066] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:50,067] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:50,067] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 147 B in total
INFO  [2023-01-26 18:08:50,067] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_REAL Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000268998sINFO  [2023-01-26 18:08:50,094] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=6, min=1, average=1.500000, max=2}
INFO  [2023-01-26 18:08:50,094] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[validity] with DateParser(super=Parser(lines=6, nullLines=1), subType=IntegerParser(super=Parser(lines=6, nullLines=1), minValue=10986, maxValue=10988), dateReader=com.bakdata.conquery.util.DateReader@1c3f7328)
INFO  [2023-01-26 18:08:50,094] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=6, nullLines=1), subType=IntegerParser(super=Parser(lines=6, nullLines=1), minValue=10977, maxValue=10997), dateReader=com.bakdata.conquery.util.DateReader@3af69c73)
INFO  [2023-01-26 18:08:50,097] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_REAL Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:50,097] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:50,097] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_REAL Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:50,111] com.bakdata.conquery.models.jobs.ImportJob: Importing table into NUMBER_REAL$20Test.table
127.0.0.1 - - [26/Jan/2023:18:08:50 +0000] "POST /admin/datasets/NUMBER_REAL%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_NUMBER_REAL+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:08:50,113] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:50,113] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:50,113] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:50,113] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:50,115] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:08:50,115] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[NUMBER_REAL$20Test.table.table], containing 6 entries.
INFO  [2023-01-26 18:08:50,116] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[NUMBER_REAL$20Test.table.table], containing 6 entries.
WARN  [2023-01-26 18:08:50,116] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:50,116] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_REAL$20Test.table.table.0
INFO  [2023-01-26 18:08:50,116] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_REAL$20Test.table.table.1
INFO  [2023-01-26 18:08:50,223] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: NUMBER_REAL Test QUERY INIT
INFO  [2023-01-26 18:08:50,243] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[NUMBER_REAL$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:08:50,244] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[5fa5ca9b-58c2-4081-9425-157da12fc1ea] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_REAL Test))]]
INFO  [2023-01-26 18:08:50,253] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery NUMBER_REAL$20Test.5fa5ca9b-58c2-4081-9425-157da12fc1ea
INFO  [2023-01-26 18:08:50,253] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery NUMBER_REAL$20Test.5fa5ca9b-58c2-4081-9425-157da12fc1ea
127.0.0.1 - - [26/Jan/2023:18:08:50 +0000] "POST /api/datasets/NUMBER_REAL$20Test/queries HTTP/1.1" 201 1293 "-" "Conquery (test client)" 15
INFO  [2023-01-26 18:08:50,255] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[NUMBER_REAL$20Test.5fa5ca9b-58c2-4081-9425-157da12fc1ea] with 0 results within PT0.002657S
INFO  [2023-01-26 18:08:50,255] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[NUMBER_REAL$20Test.5fa5ca9b-58c2-4081-9425-157da12fc1ea] with 2 results within PT0.002756S
INFO  [2023-01-26 18:08:50,256] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=NUMBER_REAL$20Test.5fa5ca9b-58c2-4081-9425-157da12fc1ea, workerId=NUMBER_REAL$20Test.worker_NUMBER_REAL$20Test_30467e17-7e87-4f49-8be5-01d121684243, startTime=2023-01-26T18:08:50.253032, finishTime=2023-01-26T18:08:50.255689) of size 0
INFO  [2023-01-26 18:08:50,256] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=NUMBER_REAL$20Test.5fa5ca9b-58c2-4081-9425-157da12fc1ea, workerId=NUMBER_REAL$20Test.worker_NUMBER_REAL$20Test_d447272d-73f7-49f4-913f-cf42da2dd550, startTime=2023-01-26T18:08:50.253032, finishTime=2023-01-26T18:08:50.255788) of size 2
INFO  [2023-01-26 18:08:50,257] com.bakdata.conquery.models.execution.ManagedExecution: DONE 5fa5ca9b-58c2-4081-9425-157da12fc1ea ManagedQuery within PT0.01249S
127.0.0.1 - - [26/Jan/2023:18:08:50 +0000] "GET /api/datasets/NUMBER_REAL$20Test/queries/NUMBER_REAL$20Test.5fa5ca9b-58c2-4081-9425-157da12fc1ea HTTP/1.1" 200 1557 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:08:50,280] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=NUMBER_REAL Test], queryId=5fa5ca9b-58c2-4081-9425-157da12fc1ea, label=concept	@§$, creationTime=2023-01-26T18:08:50.244382, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@501280a4[Count = 0], startTime=2023-01-26T18:08:50.244931, finishTime=2023-01-26T18:08:50.257421, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@fe14d5f), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_REAL Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@3d4dc80b, com.bakdata.conquery.models.query.ColumnDescriptor@487d85d5]) download on dataset Dataset[label=null, name=NUMBER_REAL Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:08:50,280] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=NUMBER_REAL Test], queryId=5fa5ca9b-58c2-4081-9425-157da12fc1ea, label=concept	@§$, creationTime=2023-01-26T18:08:50.244382, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@501280a4[Count = 0], startTime=2023-01-26T18:08:50.244931, finishTime=2023-01-26T18:08:50.257421, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@fe14d5f), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_REAL Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@3d4dc80b, com.bakdata.conquery.models.query.ColumnDescriptor@487d85d5]) on dataset Dataset[label=null, name=NUMBER_REAL Test]
127.0.0.1 - - [26/Jan/2023:18:08:50 +0000] "GET /api/datasets/NUMBER_REAL%20Test/result/NUMBER_REAL$20Test.5fa5ca9b-58c2-4081-9425-157da12fc1ea.csv?pretty=false HTTP/1.1" 200 65 "-" "Conquery (test client)" 24
INFO  [2023-01-26 18:08:50,302] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest NUMBER_REAL Test on 3 rows
INFO  [2023-01-26 18:08:50,302] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast NUMBER_REAL Test
INFO  [2023-01-26 18:08:50,303] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=NUMBER_REAL Test, name=NUMBER_REAL Test]
INFO  [2023-01-26 18:08:50,303] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=NUMBER_REAL Test, name=NUMBER_REAL Test]
INFO  [2023-01-26 18:08:50,303] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_NUMBER_REAL Test_30467e17-7e87-4f49-8be5-01d121684243
INFO  [2023-01-26 18:08:50,303] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_NUMBER_REAL Test_d447272d-73f7-49f4-913f-cf42da2dd550
INFO  [2023-01-26 18:08:50,331] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow NUMBER_REAL Test
INFO  [2023-01-26 18:08:50,332] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_NUMBER_REAL Test_30467e17-7e87-4f49-8be5-01d121684243
INFO  [2023-01-26 18:08:50,332] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_NUMBER_REAL Test_d447272d-73f7-49f4-913f-cf42da2dd550
INFO  [2023-01-26 18:08:50,417] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of NUMBER_REAL$20Test
INFO  [2023-01-26 18:08:50,417] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:50,522] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test NUMBER_REAL Test
INFO  [2023-01-26 18:08:50,522] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test DIFFSUM_INTEGER Test
INFO  [2023-01-26 18:08:50,522] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:50,522] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:50,523] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DIFFSUM_INTEGER Test, name=DIFFSUM_INTEGER Test]
INFO  [2023-01-26 18:08:50,523] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:50,523] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DIFFSUM_INTEGER Test, name=DIFFSUM_INTEGER Test]
INFO  [2023-01-26 18:08:50,524] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:50,527] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DIFFSUM_INTEGER$20Test.worker_DIFFSUM_INTEGER$20Test_30ec2707-1409-4b77-8226-b60018a3f19f are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:50,527] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DIFFSUM_INTEGER$20Test.worker_DIFFSUM_INTEGER$20Test_30ec2707-1409-4b77-8226-b60018a3f19f are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:50,527] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:50,528] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DIFFSUM_INTEGER$20Test.worker_DIFFSUM_INTEGER$20Test_55b47dbe-57a2-40a9-ad2f-ee85e7eeb206 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:50,528] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DIFFSUM_INTEGER$20Test.worker_DIFFSUM_INTEGER$20Test_55b47dbe-57a2-40a9-ad2f-ee85e7eeb206 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:50,528] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:50,529] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:50,635] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:50,635] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DIFFSUM_INTEGER$20Test.table
INFO  [2023-01-26 18:08:50,635] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DIFFSUM_INTEGER$20Test.table
INFO  [2023-01-26 18:08:50,750] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:50,865] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:50,865] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:50,865] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 439 B in total
INFO  [2023-01-26 18:08:50,865] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DIFFSUM_INTEGER Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000362333sINFO  [2023-01-26 18:08:50,902] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=12, sum=21, min=1, average=1.750000, max=3}
INFO  [2023-01-26 18:08:50,902] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[minus] with IntegerParser(super=Parser(lines=21, nullLines=0), minValue=0, maxValue=200)
INFO  [2023-01-26 18:08:50,902] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=21, nullLines=0), subType=IntegerParser(super=Parser(lines=21, nullLines=0), minValue=14835, maxValue=17614), dateReader=com.bakdata.conquery.util.DateReader@690de5b)
INFO  [2023-01-26 18:08:50,902] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[plus] with IntegerParser(super=Parser(lines=21, nullLines=0), minValue=50, maxValue=250)
INFO  [2023-01-26 18:08:50,906] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DIFFSUM_INTEGER Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:50,906] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:50,906] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DIFFSUM_INTEGER Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:50,930] com.bakdata.conquery.models.jobs.ImportJob: Importing table into DIFFSUM_INTEGER$20Test.table
127.0.0.1 - - [26/Jan/2023:18:08:50 +0000] "POST /admin/datasets/DIFFSUM_INTEGER%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_DIFFSUM_INTEGER+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:08:50,932] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:50,932] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:50,932] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:50,932] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:50,934] com.bakdata.conquery.models.jobs.ImportJob: Start sending 4 Buckets
INFO  [2023-01-26 18:08:50,934] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DIFFSUM_INTEGER$20Test.table.table], containing 21 entries.
INFO  [2023-01-26 18:08:50,934] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DIFFSUM_INTEGER$20Test.table.table], containing 21 entries.
INFO  [2023-01-26 18:08:50,935] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DIFFSUM_INTEGER$20Test.table.table.0
INFO  [2023-01-26 18:08:50,935] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DIFFSUM_INTEGER$20Test.table.table.1
WARN  [2023-01-26 18:08:50,935] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:50,935] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DIFFSUM_INTEGER$20Test.table.table.2
INFO  [2023-01-26 18:08:50,935] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DIFFSUM_INTEGER$20Test.table.table.3
INFO  [2023-01-26 18:08:51,040] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: DIFFSUM_INTEGER Test QUERY INIT
INFO  [2023-01-26 18:08:51,052] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[DIFFSUM_INTEGER$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:08:51,053] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[637e9661-8022-44aa-8d00-73a78a170c32] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_DIFFSUM_INTEGER Test))]]
INFO  [2023-01-26 18:08:51,055] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DIFFSUM_INTEGER$20Test.637e9661-8022-44aa-8d00-73a78a170c32
INFO  [2023-01-26 18:08:51,056] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DIFFSUM_INTEGER$20Test.637e9661-8022-44aa-8d00-73a78a170c32
127.0.0.1 - - [26/Jan/2023:18:08:51 +0000] "POST /api/datasets/DIFFSUM_INTEGER$20Test/queries HTTP/1.1" 201 1209 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:08:51,058] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DIFFSUM_INTEGER$20Test.637e9661-8022-44aa-8d00-73a78a170c32] with 4 results within PT0.002213S
INFO  [2023-01-26 18:08:51,058] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DIFFSUM_INTEGER$20Test.637e9661-8022-44aa-8d00-73a78a170c32] with 3 results within PT0.00206S
INFO  [2023-01-26 18:08:51,058] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DIFFSUM_INTEGER$20Test.637e9661-8022-44aa-8d00-73a78a170c32, workerId=DIFFSUM_INTEGER$20Test.worker_DIFFSUM_INTEGER$20Test_55b47dbe-57a2-40a9-ad2f-ee85e7eeb206, startTime=2023-01-26T18:08:51.056004, finishTime=2023-01-26T18:08:51.058217) of size 4
INFO  [2023-01-26 18:08:51,059] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DIFFSUM_INTEGER$20Test.637e9661-8022-44aa-8d00-73a78a170c32, workerId=DIFFSUM_INTEGER$20Test.worker_DIFFSUM_INTEGER$20Test_30ec2707-1409-4b77-8226-b60018a3f19f, startTime=2023-01-26T18:08:51.056186, finishTime=2023-01-26T18:08:51.058246) of size 3
INFO  [2023-01-26 18:08:51,060] com.bakdata.conquery.models.execution.ManagedExecution: DONE 637e9661-8022-44aa-8d00-73a78a170c32 ManagedQuery within PT0.006708S
127.0.0.1 - - [26/Jan/2023:18:08:51 +0000] "GET /api/datasets/DIFFSUM_INTEGER$20Test/queries/DIFFSUM_INTEGER$20Test.637e9661-8022-44aa-8d00-73a78a170c32 HTTP/1.1" 200 1488 "-" "Conquery (test client)" 4
INFO  [2023-01-26 18:08:51,101] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DIFFSUM_INTEGER Test], queryId=637e9661-8022-44aa-8d00-73a78a170c32, label=concept	@§$, creationTime=2023-01-26T18:08:51.053102, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@1b59362f[Count = 0], startTime=2023-01-26T18:08:51.053290, finishTime=2023-01-26T18:08:51.059998, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@70a9e21d), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DIFFSUM_INTEGER Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=7, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@57098ad6, com.bakdata.conquery.models.query.ColumnDescriptor@5c0da0b7]) download on dataset Dataset[label=null, name=DIFFSUM_INTEGER Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:08:51,101] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DIFFSUM_INTEGER Test], queryId=637e9661-8022-44aa-8d00-73a78a170c32, label=concept	@§$, creationTime=2023-01-26T18:08:51.053102, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@1b59362f[Count = 0], startTime=2023-01-26T18:08:51.053290, finishTime=2023-01-26T18:08:51.059998, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@70a9e21d), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DIFFSUM_INTEGER Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=7, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@57098ad6, com.bakdata.conquery.models.query.ColumnDescriptor@5c0da0b7]) on dataset Dataset[label=null, name=DIFFSUM_INTEGER Test]
127.0.0.1 - - [26/Jan/2023:18:08:51 +0000] "GET /api/datasets/DIFFSUM_INTEGER%20Test/result/DIFFSUM_INTEGER$20Test.637e9661-8022-44aa-8d00-73a78a170c32.csv?pretty=false HTTP/1.1" 200 197 "-" "Conquery (test client)" 19
INFO  [2023-01-26 18:08:51,118] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest DIFFSUM_INTEGER Test on 8 rows
INFO  [2023-01-26 18:08:51,118] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast DIFFSUM_INTEGER Test
INFO  [2023-01-26 18:08:51,119] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DIFFSUM_INTEGER Test, name=DIFFSUM_INTEGER Test]
INFO  [2023-01-26 18:08:51,119] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DIFFSUM_INTEGER Test, name=DIFFSUM_INTEGER Test]
INFO  [2023-01-26 18:08:51,119] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DIFFSUM_INTEGER Test_30ec2707-1409-4b77-8226-b60018a3f19f
INFO  [2023-01-26 18:08:51,119] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DIFFSUM_INTEGER Test_55b47dbe-57a2-40a9-ad2f-ee85e7eeb206
INFO  [2023-01-26 18:08:51,123] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow DIFFSUM_INTEGER Test
INFO  [2023-01-26 18:08:51,130] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DIFFSUM_INTEGER Test_55b47dbe-57a2-40a9-ad2f-ee85e7eeb206
INFO  [2023-01-26 18:08:51,130] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DIFFSUM_INTEGER Test_30ec2707-1409-4b77-8226-b60018a3f19f
INFO  [2023-01-26 18:08:51,135] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of DIFFSUM_INTEGER$20Test
INFO  [2023-01-26 18:08:51,135] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:51,241] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test DIFFSUM_INTEGER Test
INFO  [2023-01-26 18:08:51,242] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test SUM_INTEGER Test
INFO  [2023-01-26 18:08:51,242] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:51,242] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:51,242] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SUM_INTEGER Test, name=SUM_INTEGER Test]
INFO  [2023-01-26 18:08:51,242] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SUM_INTEGER Test, name=SUM_INTEGER Test]
INFO  [2023-01-26 18:08:51,243] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:51,243] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:51,244] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:51,244] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SUM_INTEGER$20Test.worker_SUM_INTEGER$20Test_1d186f34-11e0-49c0-84f8-27f087137cfe are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:51,244] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SUM_INTEGER$20Test.worker_SUM_INTEGER$20Test_1d186f34-11e0-49c0-84f8-27f087137cfe are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:51,244] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:51,244] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SUM_INTEGER$20Test.worker_SUM_INTEGER$20Test_b50141a4-2a15-42c2-9019-3260a84b08ce are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:51,244] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SUM_INTEGER$20Test.worker_SUM_INTEGER$20Test_b50141a4-2a15-42c2-9019-3260a84b08ce are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:51,244] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:51,351] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:51,352] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SUM_INTEGER$20Test.table
INFO  [2023-01-26 18:08:51,352] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SUM_INTEGER$20Test.table
INFO  [2023-01-26 18:08:51,463] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:51,576] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:51,576] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:51,576] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 448 B in total
INFO  [2023-01-26 18:08:51,577] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SUM_INTEGER Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.00035621sINFO  [2023-01-26 18:08:51,613] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=12, sum=21, min=1, average=1.750000, max=3}
INFO  [2023-01-26 18:08:51,613] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=21, nullLines=0), subType=IntegerParser(super=Parser(lines=21, nullLines=0), minValue=14835, maxValue=17614), dateReader=com.bakdata.conquery.util.DateReader@17d74aa7)
INFO  [2023-01-26 18:08:51,613] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[minus] with RealParser(super=Parser(lines=21, nullLines=0), requiredPrecision=4.9E-324, floatULP=1.52587890625E-5)
INFO  [2023-01-26 18:08:51,613] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[plus] with RealParser(super=Parser(lines=21, nullLines=0), requiredPrecision=4.9E-324, floatULP=1.52587890625E-5)
INFO  [2023-01-26 18:08:51,617] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SUM_INTEGER Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:51,617] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:51,617] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SUM_INTEGER Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:51,640] com.bakdata.conquery.models.jobs.ImportJob: Importing table into SUM_INTEGER$20Test.table
127.0.0.1 - - [26/Jan/2023:18:08:51 +0000] "POST /admin/datasets/SUM_INTEGER%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_SUM_INTEGER+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 14
INFO  [2023-01-26 18:08:51,642] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:51,642] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:51,642] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:51,642] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:51,643] com.bakdata.conquery.models.jobs.ImportJob: Start sending 4 Buckets
INFO  [2023-01-26 18:08:51,644] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SUM_INTEGER$20Test.table.table], containing 21 entries.
INFO  [2023-01-26 18:08:51,644] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SUM_INTEGER$20Test.table.table], containing 21 entries.
INFO  [2023-01-26 18:08:51,645] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SUM_INTEGER$20Test.table.table.0
WARN  [2023-01-26 18:08:51,645] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:51,645] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SUM_INTEGER$20Test.table.table.1
INFO  [2023-01-26 18:08:51,645] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SUM_INTEGER$20Test.table.table.2
INFO  [2023-01-26 18:08:51,645] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SUM_INTEGER$20Test.table.table.3
INFO  [2023-01-26 18:08:51,750] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: SUM_INTEGER Test QUERY INIT
INFO  [2023-01-26 18:08:51,766] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[SUM_INTEGER$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:08:51,766] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[4486cfd4-441b-4805-ba6c-817d424471c3] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_SUM_INTEGER Test))]]
INFO  [2023-01-26 18:08:51,769] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SUM_INTEGER$20Test.4486cfd4-441b-4805-ba6c-817d424471c3
INFO  [2023-01-26 18:08:51,770] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SUM_INTEGER$20Test.4486cfd4-441b-4805-ba6c-817d424471c3
127.0.0.1 - - [26/Jan/2023:18:08:51 +0000] "POST /api/datasets/SUM_INTEGER$20Test/queries HTTP/1.1" 201 1191 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:08:51,795] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SUM_INTEGER$20Test.4486cfd4-441b-4805-ba6c-817d424471c3] with 3 results within PT0.025611S
INFO  [2023-01-26 18:08:51,795] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SUM_INTEGER$20Test.4486cfd4-441b-4805-ba6c-817d424471c3] with 4 results within PT0.025798S
INFO  [2023-01-26 18:08:51,796] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SUM_INTEGER$20Test.4486cfd4-441b-4805-ba6c-817d424471c3, workerId=SUM_INTEGER$20Test.worker_SUM_INTEGER$20Test_1d186f34-11e0-49c0-84f8-27f087137cfe, startTime=2023-01-26T18:08:51.770051, finishTime=2023-01-26T18:08:51.795662) of size 3
INFO  [2023-01-26 18:08:51,796] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SUM_INTEGER$20Test.4486cfd4-441b-4805-ba6c-817d424471c3, workerId=SUM_INTEGER$20Test.worker_SUM_INTEGER$20Test_b50141a4-2a15-42c2-9019-3260a84b08ce, startTime=2023-01-26T18:08:51.769867, finishTime=2023-01-26T18:08:51.795665) of size 4
INFO  [2023-01-26 18:08:51,800] com.bakdata.conquery.models.execution.ManagedExecution: DONE 4486cfd4-441b-4805-ba6c-817d424471c3 ManagedQuery within PT0.033967S
127.0.0.1 - - [26/Jan/2023:18:08:51 +0000] "GET /api/datasets/SUM_INTEGER$20Test/queries/SUM_INTEGER$20Test.4486cfd4-441b-4805-ba6c-817d424471c3 HTTP/1.1" 200 1455 "-" "Conquery (test client)" 22
INFO  [2023-01-26 18:08:51,815] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SUM_INTEGER Test], queryId=4486cfd4-441b-4805-ba6c-817d424471c3, label=concept	@§$, creationTime=2023-01-26T18:08:51.766446, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@77891e7e[Count = 0], startTime=2023-01-26T18:08:51.766631, finishTime=2023-01-26T18:08:51.800598, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@4454a767), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SUM_INTEGER Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=7, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@4c1c5fda, com.bakdata.conquery.models.query.ColumnDescriptor@27333af6]) download on dataset Dataset[label=null, name=SUM_INTEGER Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:08:51,815] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SUM_INTEGER Test], queryId=4486cfd4-441b-4805-ba6c-817d424471c3, label=concept	@§$, creationTime=2023-01-26T18:08:51.766446, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@77891e7e[Count = 0], startTime=2023-01-26T18:08:51.766631, finishTime=2023-01-26T18:08:51.800598, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@4454a767), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SUM_INTEGER Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=7, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@4c1c5fda, com.bakdata.conquery.models.query.ColumnDescriptor@27333af6]) on dataset Dataset[label=null, name=SUM_INTEGER Test]
127.0.0.1 - - [26/Jan/2023:18:08:51 +0000] "GET /api/datasets/SUM_INTEGER%20Test/result/SUM_INTEGER$20Test.4486cfd4-441b-4805-ba6c-817d424471c3.csv?pretty=false HTTP/1.1" 200 197 "-" "Conquery (test client)" 18
INFO  [2023-01-26 18:08:51,831] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest SUM_INTEGER Test on 8 rows
INFO  [2023-01-26 18:08:51,831] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast SUM_INTEGER Test
INFO  [2023-01-26 18:08:51,832] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SUM_INTEGER Test, name=SUM_INTEGER Test]
INFO  [2023-01-26 18:08:51,832] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SUM_INTEGER Test_1d186f34-11e0-49c0-84f8-27f087137cfe
INFO  [2023-01-26 18:08:51,837] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SUM_INTEGER Test, name=SUM_INTEGER Test]
INFO  [2023-01-26 18:08:51,838] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SUM_INTEGER Test_b50141a4-2a15-42c2-9019-3260a84b08ce
INFO  [2023-01-26 18:08:51,843] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow SUM_INTEGER Test
INFO  [2023-01-26 18:08:51,843] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SUM_INTEGER Test_1d186f34-11e0-49c0-84f8-27f087137cfe
INFO  [2023-01-26 18:08:51,843] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SUM_INTEGER Test_b50141a4-2a15-42c2-9019-3260a84b08ce
INFO  [2023-01-26 18:08:51,845] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of SUM_INTEGER$20Test
INFO  [2023-01-26 18:08:51,845] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:51,955] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test SUM_INTEGER Test
INFO  [2023-01-26 18:08:51,955] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test DURATION_SUM Test
INFO  [2023-01-26 18:08:51,956] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:51,956] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:51,957] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DURATION_SUM Test, name=DURATION_SUM Test]
INFO  [2023-01-26 18:08:51,957] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DURATION_SUM Test, name=DURATION_SUM Test]
INFO  [2023-01-26 18:08:51,957] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:51,957] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:51,959] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DURATION_SUM$20Test.worker_DURATION_SUM$20Test_ed068f2c-7212-4f8c-bd4d-1fb1c00fa538 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:51,959] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DURATION_SUM$20Test.worker_DURATION_SUM$20Test_ed068f2c-7212-4f8c-bd4d-1fb1c00fa538 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:51,959] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:51,973] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DURATION_SUM$20Test.worker_DURATION_SUM$20Test_2f6ce949-50a5-4640-a751-dd8f721562e2 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:51,973] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:51,973] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DURATION_SUM$20Test.worker_DURATION_SUM$20Test_2f6ce949-50a5-4640-a751-dd8f721562e2 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:51,973] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:52,067] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:52,067] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DURATION_SUM$20Test.table
INFO  [2023-01-26 18:08:52,067] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DURATION_SUM$20Test.table
INFO  [2023-01-26 18:08:52,181] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:52,298] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:52,298] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:52,298] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 166 B in total
INFO  [2023-01-26 18:08:52,298] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DURATION_SUM Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000320708sINFO  [2023-01-26 18:08:52,331] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=6, min=1, average=1.500000, max=2}
INFO  [2023-01-26 18:08:52,331] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=6, nullLines=0), minParser=DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=14610, maxValue=15927), dateReader=com.bakdata.conquery.util.DateReader@1ddaab12), maxParser=DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=14640, maxValue=15928), dateReader=com.bakdata.conquery.util.DateReader@47a1b219), dateReader=com.bakdata.conquery.util.DateReader@11f0015b, onlyQuarters=false, maxValue=15928, minValue=14610, anyOpen=false)
INFO  [2023-01-26 18:08:52,334] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DURATION_SUM Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:52,334] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:52,334] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DURATION_SUM Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:52,352] com.bakdata.conquery.models.jobs.ImportJob: Importing table into DURATION_SUM$20Test.table
127.0.0.1 - - [26/Jan/2023:18:08:52 +0000] "POST /admin/datasets/DURATION_SUM%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_DURATION_SUM+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:08:52,354] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:52,354] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:52,354] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:52,354] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:52,355] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:08:52,356] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DURATION_SUM$20Test.table.table], containing 6 entries.
INFO  [2023-01-26 18:08:52,356] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DURATION_SUM$20Test.table.table], containing 6 entries.
WARN  [2023-01-26 18:08:52,357] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:52,357] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DURATION_SUM$20Test.table.table.1
INFO  [2023-01-26 18:08:52,357] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DURATION_SUM$20Test.table.table.0
INFO  [2023-01-26 18:08:52,462] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: DURATION_SUM Test QUERY INIT
INFO  [2023-01-26 18:08:52,473] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[DURATION_SUM$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:08:52,473] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[5957a5e0-ca66-4cab-8bea-110762dcbba8] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_DURATION_SUM Test))]]
INFO  [2023-01-26 18:08:52,478] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DURATION_SUM$20Test.5957a5e0-ca66-4cab-8bea-110762dcbba8
INFO  [2023-01-26 18:08:52,478] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DURATION_SUM$20Test.5957a5e0-ca66-4cab-8bea-110762dcbba8
INFO  [2023-01-26 18:08:52,478] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DURATION_SUM$20Test.5957a5e0-ca66-4cab-8bea-110762dcbba8] with 1 results within PT0.00081S
127.0.0.1 - - [26/Jan/2023:18:08:52 +0000] "POST /api/datasets/DURATION_SUM$20Test/queries HTTP/1.1" 201 1197 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:08:52,479] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DURATION_SUM$20Test.5957a5e0-ca66-4cab-8bea-110762dcbba8, workerId=DURATION_SUM$20Test.worker_DURATION_SUM$20Test_2f6ce949-50a5-4640-a751-dd8f721562e2, startTime=2023-01-26T18:08:52.478074, finishTime=2023-01-26T18:08:52.478884) of size 1
INFO  [2023-01-26 18:08:52,492] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DURATION_SUM$20Test.5957a5e0-ca66-4cab-8bea-110762dcbba8] with 2 results within PT0.014212S
INFO  [2023-01-26 18:08:52,493] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DURATION_SUM$20Test.5957a5e0-ca66-4cab-8bea-110762dcbba8, workerId=DURATION_SUM$20Test.worker_DURATION_SUM$20Test_ed068f2c-7212-4f8c-bd4d-1fb1c00fa538, startTime=2023-01-26T18:08:52.478080, finishTime=2023-01-26T18:08:52.492292) of size 2
INFO  [2023-01-26 18:08:52,493] com.bakdata.conquery.models.execution.ManagedExecution: DONE 5957a5e0-ca66-4cab-8bea-110762dcbba8 ManagedQuery within PT0.019554S
127.0.0.1 - - [26/Jan/2023:18:08:52 +0000] "GET /api/datasets/DURATION_SUM$20Test/queries/DURATION_SUM$20Test.5957a5e0-ca66-4cab-8bea-110762dcbba8 HTTP/1.1" 200 1465 "-" "Conquery (test client)" 5
INFO  [2023-01-26 18:08:52,506] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DURATION_SUM Test], queryId=5957a5e0-ca66-4cab-8bea-110762dcbba8, label=concept	@§$, creationTime=2023-01-26T18:08:52.473496, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@7609be93[Count = 0], startTime=2023-01-26T18:08:52.473682, finishTime=2023-01-26T18:08:52.493236, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@69ad8c65), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DURATION_SUM Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=3, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@7b99db00, com.bakdata.conquery.models.query.ColumnDescriptor@511b69b8]) download on dataset Dataset[label=null, name=DURATION_SUM Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:08:52,506] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DURATION_SUM Test], queryId=5957a5e0-ca66-4cab-8bea-110762dcbba8, label=concept	@§$, creationTime=2023-01-26T18:08:52.473496, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@7609be93[Count = 0], startTime=2023-01-26T18:08:52.473682, finishTime=2023-01-26T18:08:52.493236, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@69ad8c65), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DURATION_SUM Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=3, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@7b99db00, com.bakdata.conquery.models.query.ColumnDescriptor@511b69b8]) on dataset Dataset[label=null, name=DURATION_SUM Test]
127.0.0.1 - - [26/Jan/2023:18:08:52 +0000] "GET /api/datasets/DURATION_SUM%20Test/result/DURATION_SUM$20Test.5957a5e0-ca66-4cab-8bea-110762dcbba8.csv?pretty=false HTTP/1.1" 200 91 "-" "Conquery (test client)" 22
INFO  [2023-01-26 18:08:52,526] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest DURATION_SUM Test on 4 rows
INFO  [2023-01-26 18:08:52,526] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast DURATION_SUM Test
INFO  [2023-01-26 18:08:52,526] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DURATION_SUM Test, name=DURATION_SUM Test]
INFO  [2023-01-26 18:08:52,526] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DURATION_SUM Test, name=DURATION_SUM Test]
INFO  [2023-01-26 18:08:52,527] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DURATION_SUM Test_ed068f2c-7212-4f8c-bd4d-1fb1c00fa538
INFO  [2023-01-26 18:08:52,527] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DURATION_SUM Test_2f6ce949-50a5-4640-a751-dd8f721562e2
INFO  [2023-01-26 18:08:52,557] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow DURATION_SUM Test
INFO  [2023-01-26 18:08:52,557] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of DURATION_SUM$20Test
INFO  [2023-01-26 18:08:52,557] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:52,558] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DURATION_SUM Test_ed068f2c-7212-4f8c-bd4d-1fb1c00fa538
INFO  [2023-01-26 18:08:52,559] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DURATION_SUM Test_2f6ce949-50a5-4640-a751-dd8f721562e2
INFO  [2023-01-26 18:08:52,762] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test DURATION_SUM Test
INFO  [2023-01-26 18:08:52,763] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test DURATION_SUM_2 Test
INFO  [2023-01-26 18:08:52,763] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:52,763] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:52,765] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DURATION_SUM_2 Test, name=DURATION_SUM_2 Test]
INFO  [2023-01-26 18:08:52,765] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DURATION_SUM_2 Test, name=DURATION_SUM_2 Test]
INFO  [2023-01-26 18:08:52,765] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:52,765] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:52,766] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DURATION_SUM_2$20Test.worker_DURATION_SUM_2$20Test_1b3062e6-8205-417a-abc1-df6daefdff0d are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:52,766] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DURATION_SUM_2$20Test.worker_DURATION_SUM_2$20Test_1b3062e6-8205-417a-abc1-df6daefdff0d are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:52,766] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:52,766] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DURATION_SUM_2$20Test.worker_DURATION_SUM_2$20Test_d61e8363-1e1c-4a5e-b14a-1e23fe212957 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:52,766] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DURATION_SUM_2$20Test.worker_DURATION_SUM_2$20Test_d61e8363-1e1c-4a5e-b14a-1e23fe212957 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:52,766] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:52,771] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:52,873] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:52,873] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DURATION_SUM_2$20Test.table
INFO  [2023-01-26 18:08:52,873] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DURATION_SUM_2$20Test.table
INFO  [2023-01-26 18:08:52,990] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:53,101] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:53,101] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:53,101] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 170 B in total
INFO  [2023-01-26 18:08:53,102] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DURATION_SUM_2 Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000208804sINFO  [2023-01-26 18:08:53,123] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=5, sum=7, min=1, average=1.400000, max=2}
INFO  [2023-01-26 18:08:53,123] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=7, nullLines=1), minParser=DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=14610, maxValue=15927), dateReader=com.bakdata.conquery.util.DateReader@70d9fe17), maxParser=DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=14640, maxValue=15927), dateReader=com.bakdata.conquery.util.DateReader@5da3aece), dateReader=com.bakdata.conquery.util.DateReader@37bfde99, onlyQuarters=false, maxValue=15927, minValue=14610, anyOpen=false)
INFO  [2023-01-26 18:08:53,125] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DURATION_SUM_2 Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:53,125] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:53,125] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DURATION_SUM_2 Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:53,149] com.bakdata.conquery.models.jobs.ImportJob: Importing table into DURATION_SUM_2$20Test.table
127.0.0.1 - - [26/Jan/2023:18:08:53 +0000] "POST /admin/datasets/DURATION_SUM_2%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_DURATION_SUM_2+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:08:53,151] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:53,152] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:53,152] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:53,152] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:53,153] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:08:53,153] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DURATION_SUM_2$20Test.table.table], containing 7 entries.
INFO  [2023-01-26 18:08:53,153] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DURATION_SUM_2$20Test.table.table], containing 7 entries.
WARN  [2023-01-26 18:08:53,154] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:53,154] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DURATION_SUM_2$20Test.table.table.0
INFO  [2023-01-26 18:08:53,154] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DURATION_SUM_2$20Test.table.table.1
INFO  [2023-01-26 18:08:53,259] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: DURATION_SUM_2 Test QUERY INIT
INFO  [2023-01-26 18:08:53,271] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[DURATION_SUM_2$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:08:53,271] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[d5665870-39bc-4d77-b3f1-585f11d201db] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_DURATION_SUM_2 Test))]]
INFO  [2023-01-26 18:08:53,274] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DURATION_SUM_2$20Test.d5665870-39bc-4d77-b3f1-585f11d201db
INFO  [2023-01-26 18:08:53,274] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DURATION_SUM_2$20Test.d5665870-39bc-4d77-b3f1-585f11d201db
127.0.0.1 - - [26/Jan/2023:18:08:53 +0000] "POST /api/datasets/DURATION_SUM_2$20Test/queries HTTP/1.1" 201 1205 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:08:53,296] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DURATION_SUM_2$20Test.d5665870-39bc-4d77-b3f1-585f11d201db] with 1 results within PT0.022616S
INFO  [2023-01-26 18:08:53,297] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DURATION_SUM_2$20Test.d5665870-39bc-4d77-b3f1-585f11d201db] with 3 results within PT0.02345S
INFO  [2023-01-26 18:08:53,297] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DURATION_SUM_2$20Test.d5665870-39bc-4d77-b3f1-585f11d201db, workerId=DURATION_SUM_2$20Test.worker_DURATION_SUM_2$20Test_d61e8363-1e1c-4a5e-b14a-1e23fe212957, startTime=2023-01-26T18:08:53.274040, finishTime=2023-01-26T18:08:53.296656) of size 1
INFO  [2023-01-26 18:08:53,298] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DURATION_SUM_2$20Test.d5665870-39bc-4d77-b3f1-585f11d201db, workerId=DURATION_SUM_2$20Test.worker_DURATION_SUM_2$20Test_1b3062e6-8205-417a-abc1-df6daefdff0d, startTime=2023-01-26T18:08:53.274041, finishTime=2023-01-26T18:08:53.297491) of size 3
INFO  [2023-01-26 18:08:53,298] com.bakdata.conquery.models.execution.ManagedExecution: DONE d5665870-39bc-4d77-b3f1-585f11d201db ManagedQuery within PT0.026725S
127.0.0.1 - - [26/Jan/2023:18:08:53 +0000] "GET /api/datasets/DURATION_SUM_2$20Test/queries/DURATION_SUM_2$20Test.d5665870-39bc-4d77-b3f1-585f11d201db HTTP/1.1" 200 1481 "-" "Conquery (test client)" 12
INFO  [2023-01-26 18:08:53,318] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DURATION_SUM_2 Test], queryId=d5665870-39bc-4d77-b3f1-585f11d201db, label=concept	@§$, creationTime=2023-01-26T18:08:53.271527, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@713a00c[Count = 0], startTime=2023-01-26T18:08:53.271734, finishTime=2023-01-26T18:08:53.298459, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@30036158), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DURATION_SUM_2 Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@555bffc8, com.bakdata.conquery.models.query.ColumnDescriptor@1d2e36ba]) download on dataset Dataset[label=null, name=DURATION_SUM_2 Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:08:53,318] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DURATION_SUM_2 Test], queryId=d5665870-39bc-4d77-b3f1-585f11d201db, label=concept	@§$, creationTime=2023-01-26T18:08:53.271527, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@713a00c[Count = 0], startTime=2023-01-26T18:08:53.271734, finishTime=2023-01-26T18:08:53.298459, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@30036158), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DURATION_SUM_2 Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@555bffc8, com.bakdata.conquery.models.query.ColumnDescriptor@1d2e36ba]) on dataset Dataset[label=null, name=DURATION_SUM_2 Test]
127.0.0.1 - - [26/Jan/2023:18:08:53 +0000] "GET /api/datasets/DURATION_SUM_2%20Test/result/DURATION_SUM_2$20Test.d5665870-39bc-4d77-b3f1-585f11d201db.csv?pretty=false HTTP/1.1" 200 117 "-" "Conquery (test client)" 37
INFO  [2023-01-26 18:08:53,354] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest DURATION_SUM_2 Test on 5 rows
INFO  [2023-01-26 18:08:53,354] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast DURATION_SUM_2 Test
INFO  [2023-01-26 18:08:53,354] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DURATION_SUM_2 Test, name=DURATION_SUM_2 Test]
INFO  [2023-01-26 18:08:53,354] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DURATION_SUM_2 Test, name=DURATION_SUM_2 Test]
INFO  [2023-01-26 18:08:53,354] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DURATION_SUM_2 Test_d61e8363-1e1c-4a5e-b14a-1e23fe212957
INFO  [2023-01-26 18:08:53,354] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DURATION_SUM_2 Test_1b3062e6-8205-417a-abc1-df6daefdff0d
INFO  [2023-01-26 18:08:53,365] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow DURATION_SUM_2 Test
INFO  [2023-01-26 18:08:53,365] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DURATION_SUM_2 Test_1b3062e6-8205-417a-abc1-df6daefdff0d
INFO  [2023-01-26 18:08:53,365] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DURATION_SUM_2 Test_d61e8363-1e1c-4a5e-b14a-1e23fe212957
INFO  [2023-01-26 18:08:53,455] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of DURATION_SUM_2$20Test
INFO  [2023-01-26 18:08:53,455] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:53,560] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test DURATION_SUM_2 Test
INFO  [2023-01-26 18:08:53,561] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test MULTI_SELECT Test
INFO  [2023-01-26 18:08:53,561] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:53,561] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:53,567] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=MULTI_SELECT Test, name=MULTI_SELECT Test]
INFO  [2023-01-26 18:08:53,567] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:53,567] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=MULTI_SELECT Test, name=MULTI_SELECT Test]
INFO  [2023-01-26 18:08:53,567] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:53,568] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker MULTI_SELECT$20Test.worker_MULTI_SELECT$20Test_5107b106-a682-4496-bd52-c9f5d2994636 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:53,568] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker MULTI_SELECT$20Test.worker_MULTI_SELECT$20Test_5107b106-a682-4496-bd52-c9f5d2994636 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:53,568] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:53,574] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker MULTI_SELECT$20Test.worker_MULTI_SELECT$20Test_db987996-8810-400e-8582-28f514ea8a12 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:53,574] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker MULTI_SELECT$20Test.worker_MULTI_SELECT$20Test_db987996-8810-400e-8582-28f514ea8a12 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:53,574] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:53,578] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:53,681] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:53,681] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table MULTI_SELECT$20Test.table
INFO  [2023-01-26 18:08:53,681] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table MULTI_SELECT$20Test.table
INFO  [2023-01-26 18:08:53,793] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:53,905] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:53,905] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:53,905] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 139 B in total
INFO  [2023-01-26 18:08:53,905] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTI_SELECT Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000297698sINFO  [2023-01-26 18:08:53,936] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=5, sum=8, min=1, average=1.600000, max=3}
INFO  [2023-01-26 18:08:53,936] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=8, nullLines=0), subType=IntegerParser(super=Parser(lines=8, nullLines=0), minValue=15340, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@fd4452)
INFO  [2023-01-26 18:08:53,936] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with StringParser(super=Parser(lines=8, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:08:53,940] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTI_SELECT Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:53,940] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:53,940] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTI_SELECT Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:53,960] com.bakdata.conquery.models.jobs.ImportJob: Importing table into MULTI_SELECT$20Test.table
127.0.0.1 - - [26/Jan/2023:18:08:53 +0000] "POST /admin/datasets/MULTI_SELECT%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_MULTI_SELECT+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 11
INFO  [2023-01-26 18:08:53,962] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:53,962] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:53,963] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:53,963] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:53,965] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:08:53,965] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[MULTI_SELECT$20Test.table.table], containing 8 entries.
INFO  [2023-01-26 18:08:53,966] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[MULTI_SELECT$20Test.table.table], containing 8 entries.
WARN  [2023-01-26 18:08:53,967] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:53,967] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTI_SELECT$20Test.table.table.0
INFO  [2023-01-26 18:08:53,967] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTI_SELECT$20Test.table.table.1
INFO  [2023-01-26 18:08:54,072] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: MULTI_SELECT Test QUERY INIT
INFO  [2023-01-26 18:08:54,086] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[MULTI_SELECT$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:08:54,087] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[5e080e50-486d-424b-acd3-316581499b70] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_MULTI_SELECT Test))]]
INFO  [2023-01-26 18:08:54,089] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery MULTI_SELECT$20Test.5e080e50-486d-424b-acd3-316581499b70
INFO  [2023-01-26 18:08:54,089] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery MULTI_SELECT$20Test.5e080e50-486d-424b-acd3-316581499b70
127.0.0.1 - - [26/Jan/2023:18:08:54 +0000] "POST /api/datasets/MULTI_SELECT$20Test/queries HTTP/1.1" 201 1185 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:08:54,098] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[MULTI_SELECT$20Test.5e080e50-486d-424b-acd3-316581499b70] with 1 results within PT0.008267S
INFO  [2023-01-26 18:08:54,098] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[MULTI_SELECT$20Test.5e080e50-486d-424b-acd3-316581499b70] with 2 results within PT0.008335S
INFO  [2023-01-26 18:08:54,098] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=MULTI_SELECT$20Test.5e080e50-486d-424b-acd3-316581499b70, workerId=MULTI_SELECT$20Test.worker_MULTI_SELECT$20Test_5107b106-a682-4496-bd52-c9f5d2994636, startTime=2023-01-26T18:08:54.090017, finishTime=2023-01-26T18:08:54.098352) of size 2
INFO  [2023-01-26 18:08:54,099] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=MULTI_SELECT$20Test.5e080e50-486d-424b-acd3-316581499b70, workerId=MULTI_SELECT$20Test.worker_MULTI_SELECT$20Test_db987996-8810-400e-8582-28f514ea8a12, startTime=2023-01-26T18:08:54.090016, finishTime=2023-01-26T18:08:54.098283) of size 1
INFO  [2023-01-26 18:08:54,099] com.bakdata.conquery.models.execution.ManagedExecution: DONE 5e080e50-486d-424b-acd3-316581499b70 ManagedQuery within PT0.011651S
127.0.0.1 - - [26/Jan/2023:18:08:54 +0000] "GET /api/datasets/MULTI_SELECT$20Test/queries/MULTI_SELECT$20Test.5e080e50-486d-424b-acd3-316581499b70 HTTP/1.1" 200 1453 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:08:54,110] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=MULTI_SELECT Test], queryId=5e080e50-486d-424b-acd3-316581499b70, label=concept	@§$, creationTime=2023-01-26T18:08:54.087249, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@2d5baec6[Count = 0], startTime=2023-01-26T18:08:54.087448, finishTime=2023-01-26T18:08:54.099099, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@559a1664), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_MULTI_SELECT Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=3, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@1eae4c04, com.bakdata.conquery.models.query.ColumnDescriptor@3d8c3694]) download on dataset Dataset[label=null, name=MULTI_SELECT Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:08:54,110] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=MULTI_SELECT Test], queryId=5e080e50-486d-424b-acd3-316581499b70, label=concept	@§$, creationTime=2023-01-26T18:08:54.087249, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@2d5baec6[Count = 0], startTime=2023-01-26T18:08:54.087448, finishTime=2023-01-26T18:08:54.099099, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@559a1664), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_MULTI_SELECT Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=3, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@1eae4c04, com.bakdata.conquery.models.query.ColumnDescriptor@3d8c3694]) on dataset Dataset[label=null, name=MULTI_SELECT Test]
127.0.0.1 - - [26/Jan/2023:18:08:54 +0000] "GET /api/datasets/MULTI_SELECT%20Test/result/MULTI_SELECT$20Test.5e080e50-486d-424b-acd3-316581499b70.csv?pretty=false HTTP/1.1" 200 91 "-" "Conquery (test client)" 21
INFO  [2023-01-26 18:08:54,130] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest MULTI_SELECT Test on 4 rows
INFO  [2023-01-26 18:08:54,130] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast MULTI_SELECT Test
INFO  [2023-01-26 18:08:54,130] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=MULTI_SELECT Test, name=MULTI_SELECT Test]
INFO  [2023-01-26 18:08:54,130] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=MULTI_SELECT Test, name=MULTI_SELECT Test]
INFO  [2023-01-26 18:08:54,130] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_MULTI_SELECT Test_db987996-8810-400e-8582-28f514ea8a12
INFO  [2023-01-26 18:08:54,130] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_MULTI_SELECT Test_5107b106-a682-4496-bd52-c9f5d2994636
INFO  [2023-01-26 18:08:54,167] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow MULTI_SELECT Test
INFO  [2023-01-26 18:08:54,167] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of MULTI_SELECT$20Test
INFO  [2023-01-26 18:08:54,167] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:54,168] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_MULTI_SELECT Test_5107b106-a682-4496-bd52-c9f5d2994636
INFO  [2023-01-26 18:08:54,174] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_MULTI_SELECT Test_db987996-8810-400e-8582-28f514ea8a12
INFO  [2023-01-26 18:08:54,374] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test MULTI_SELECT Test
INFO  [2023-01-26 18:08:54,374] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test NUMBER_DECIMAL Test
INFO  [2023-01-26 18:08:54,374] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:54,375] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:54,376] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=NUMBER_DECIMAL Test, name=NUMBER_DECIMAL Test]
INFO  [2023-01-26 18:08:54,376] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=NUMBER_DECIMAL Test, name=NUMBER_DECIMAL Test]
INFO  [2023-01-26 18:08:54,376] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:54,376] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:54,377] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker NUMBER_DECIMAL$20Test.worker_NUMBER_DECIMAL$20Test_f6eed419-78e7-45d8-b6fc-0c462308ca16 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:54,377] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker NUMBER_DECIMAL$20Test.worker_NUMBER_DECIMAL$20Test_f6eed419-78e7-45d8-b6fc-0c462308ca16 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:54,377] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:54,377] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker NUMBER_DECIMAL$20Test.worker_NUMBER_DECIMAL$20Test_b3145efb-e3bd-4427-8989-a45c8f1c28e6 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:54,377] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker NUMBER_DECIMAL$20Test.worker_NUMBER_DECIMAL$20Test_b3145efb-e3bd-4427-8989-a45c8f1c28e6 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:54,377] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:54,382] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:54,484] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:54,484] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table NUMBER_DECIMAL$20Test.table
INFO  [2023-01-26 18:08:54,484] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table NUMBER_DECIMAL$20Test.table
INFO  [2023-01-26 18:08:54,602] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:54,717] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:54,718] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:54,718] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 355 B in total
INFO  [2023-01-26 18:08:54,718] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_DECIMAL Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000170579sINFO  [2023-01-26 18:08:54,735] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=12, sum=18, min=1, average=1.500000, max=2}
INFO  [2023-01-26 18:08:54,735] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=18, nullLines=0), subType=IntegerParser(super=Parser(lines=18, nullLines=0), minValue=14835, maxValue=17612), dateReader=com.bakdata.conquery.util.DateReader@42db542d)
INFO  [2023-01-26 18:08:54,735] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[nr] with DecimalParser(super=Parser(lines=18, nullLines=3), maxScale=2, maxAbs=300)
INFO  [2023-01-26 18:08:54,742] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_DECIMAL Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:54,742] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:54,742] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_DECIMAL Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:54,755] com.bakdata.conquery.models.jobs.ImportJob: Importing table into NUMBER_DECIMAL$20Test.table
127.0.0.1 - - [26/Jan/2023:18:08:54 +0000] "POST /admin/datasets/NUMBER_DECIMAL%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_NUMBER_DECIMAL+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:08:54,759] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:54,759] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:54,760] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:54,760] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:54,761] com.bakdata.conquery.models.jobs.ImportJob: Start sending 4 Buckets
INFO  [2023-01-26 18:08:54,762] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[NUMBER_DECIMAL$20Test.table.table], containing 18 entries.
INFO  [2023-01-26 18:08:54,762] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[NUMBER_DECIMAL$20Test.table.table], containing 18 entries.
INFO  [2023-01-26 18:08:54,762] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_DECIMAL$20Test.table.table.0
INFO  [2023-01-26 18:08:54,762] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_DECIMAL$20Test.table.table.1
WARN  [2023-01-26 18:08:54,762] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:54,763] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_DECIMAL$20Test.table.table.3
INFO  [2023-01-26 18:08:54,763] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_DECIMAL$20Test.table.table.2
INFO  [2023-01-26 18:08:54,868] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: NUMBER_DECIMAL Test QUERY INIT
INFO  [2023-01-26 18:08:54,902] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[NUMBER_DECIMAL$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:08:54,902] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[8726b10c-8f7b-41ee-9919-4884df49eda6] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_DECIMAL Test))]]
INFO  [2023-01-26 18:08:54,904] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery NUMBER_DECIMAL$20Test.8726b10c-8f7b-41ee-9919-4884df49eda6
INFO  [2023-01-26 18:08:54,904] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery NUMBER_DECIMAL$20Test.8726b10c-8f7b-41ee-9919-4884df49eda6
127.0.0.1 - - [26/Jan/2023:18:08:54 +0000] "POST /api/datasets/NUMBER_DECIMAL$20Test/queries HTTP/1.1" 201 1203 "-" "Conquery (test client)" 26
INFO  [2023-01-26 18:08:54,907] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[NUMBER_DECIMAL$20Test.8726b10c-8f7b-41ee-9919-4884df49eda6] with 3 results within PT0.003023S
INFO  [2023-01-26 18:08:54,907] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[NUMBER_DECIMAL$20Test.8726b10c-8f7b-41ee-9919-4884df49eda6] with 2 results within PT0.003031S
INFO  [2023-01-26 18:08:54,908] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=NUMBER_DECIMAL$20Test.8726b10c-8f7b-41ee-9919-4884df49eda6, workerId=NUMBER_DECIMAL$20Test.worker_NUMBER_DECIMAL$20Test_b3145efb-e3bd-4427-8989-a45c8f1c28e6, startTime=2023-01-26T18:08:54.904955, finishTime=2023-01-26T18:08:54.907986) of size 2
INFO  [2023-01-26 18:08:54,908] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=NUMBER_DECIMAL$20Test.8726b10c-8f7b-41ee-9919-4884df49eda6, workerId=NUMBER_DECIMAL$20Test.worker_NUMBER_DECIMAL$20Test_f6eed419-78e7-45d8-b6fc-0c462308ca16, startTime=2023-01-26T18:08:54.904932, finishTime=2023-01-26T18:08:54.907955) of size 3
INFO  [2023-01-26 18:08:54,908] com.bakdata.conquery.models.execution.ManagedExecution: DONE 8726b10c-8f7b-41ee-9919-4884df49eda6 ManagedQuery within PT0.006143S
127.0.0.1 - - [26/Jan/2023:18:08:54 +0000] "GET /api/datasets/NUMBER_DECIMAL$20Test/queries/NUMBER_DECIMAL$20Test.8726b10c-8f7b-41ee-9919-4884df49eda6 HTTP/1.1" 200 1477 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:08:54,927] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=NUMBER_DECIMAL Test], queryId=8726b10c-8f7b-41ee-9919-4884df49eda6, label=concept	@§$, creationTime=2023-01-26T18:08:54.902428, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@26cf4aa3[Count = 0], startTime=2023-01-26T18:08:54.902617, finishTime=2023-01-26T18:08:54.908760, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@5f6fcd7b), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_DECIMAL Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=5, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@56ddb843, com.bakdata.conquery.models.query.ColumnDescriptor@1880e5a4]) download on dataset Dataset[label=null, name=NUMBER_DECIMAL Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:08:54,927] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=NUMBER_DECIMAL Test], queryId=8726b10c-8f7b-41ee-9919-4884df49eda6, label=concept	@§$, creationTime=2023-01-26T18:08:54.902428, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@26cf4aa3[Count = 0], startTime=2023-01-26T18:08:54.902617, finishTime=2023-01-26T18:08:54.908760, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@5f6fcd7b), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_DECIMAL Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=5, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@56ddb843, com.bakdata.conquery.models.query.ColumnDescriptor@1880e5a4]) on dataset Dataset[label=null, name=NUMBER_DECIMAL Test]
127.0.0.1 - - [26/Jan/2023:18:08:54 +0000] "GET /api/datasets/NUMBER_DECIMAL%20Test/result/NUMBER_DECIMAL$20Test.8726b10c-8f7b-41ee-9919-4884df49eda6.csv?pretty=false HTTP/1.1" 200 144 "-" "Conquery (test client)" 25
INFO  [2023-01-26 18:08:54,952] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest NUMBER_DECIMAL Test on 6 rows
INFO  [2023-01-26 18:08:54,952] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast NUMBER_DECIMAL Test
INFO  [2023-01-26 18:08:54,952] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=NUMBER_DECIMAL Test, name=NUMBER_DECIMAL Test]
INFO  [2023-01-26 18:08:54,952] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=NUMBER_DECIMAL Test, name=NUMBER_DECIMAL Test]
INFO  [2023-01-26 18:08:54,952] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_NUMBER_DECIMAL Test_f6eed419-78e7-45d8-b6fc-0c462308ca16
INFO  [2023-01-26 18:08:54,952] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_NUMBER_DECIMAL Test_b3145efb-e3bd-4427-8989-a45c8f1c28e6
INFO  [2023-01-26 18:08:54,976] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow NUMBER_DECIMAL Test
INFO  [2023-01-26 18:08:54,976] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_NUMBER_DECIMAL Test_b3145efb-e3bd-4427-8989-a45c8f1c28e6
INFO  [2023-01-26 18:08:54,977] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_NUMBER_DECIMAL Test_f6eed419-78e7-45d8-b6fc-0c462308ca16
INFO  [2023-01-26 18:08:55,063] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of NUMBER_DECIMAL$20Test
INFO  [2023-01-26 18:08:55,063] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:55,170] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test NUMBER_DECIMAL Test
INFO  [2023-01-26 18:08:55,170] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test NUMBER_INTEGER Test
INFO  [2023-01-26 18:08:55,170] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:55,170] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:55,184] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=NUMBER_INTEGER Test, name=NUMBER_INTEGER Test]
INFO  [2023-01-26 18:08:55,184] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=NUMBER_INTEGER Test, name=NUMBER_INTEGER Test]
INFO  [2023-01-26 18:08:55,184] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:55,184] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:55,190] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker NUMBER_INTEGER$20Test.worker_NUMBER_INTEGER$20Test_c479d726-d232-4f1f-a1f4-2131f59f38b8 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:55,190] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker NUMBER_INTEGER$20Test.worker_NUMBER_INTEGER$20Test_c479d726-d232-4f1f-a1f4-2131f59f38b8 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:55,190] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:55,190] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker NUMBER_INTEGER$20Test.worker_NUMBER_INTEGER$20Test_22dce583-a100-405f-a8ea-e19c06ec80a1 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:55,190] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker NUMBER_INTEGER$20Test.worker_NUMBER_INTEGER$20Test_22dce583-a100-405f-a8ea-e19c06ec80a1 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:55,190] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:55,195] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:55,296] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:55,296] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table NUMBER_INTEGER$20Test.table
INFO  [2023-01-26 18:08:55,296] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table NUMBER_INTEGER$20Test.table
INFO  [2023-01-26 18:08:55,407] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:55,517] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:55,518] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:55,518] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 255 B in total
INFO  [2023-01-26 18:08:55,518] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_INTEGER Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000250194sINFO  [2023-01-26 18:08:55,543] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=9, sum=15, min=1, average=1.666667, max=2}
INFO  [2023-01-26 18:08:55,543] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=15, nullLines=0), subType=IntegerParser(super=Parser(lines=15, nullLines=0), minValue=14835, maxValue=17351), dateReader=com.bakdata.conquery.util.DateReader@3784e9f)
INFO  [2023-01-26 18:08:55,543] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[nr] with IntegerParser(super=Parser(lines=15, nullLines=3), minValue=50, maxValue=300)
INFO  [2023-01-26 18:08:55,547] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_INTEGER Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:55,547] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:55,547] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_INTEGER Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:55,564] com.bakdata.conquery.models.jobs.ImportJob: Importing table into NUMBER_INTEGER$20Test.table
127.0.0.1 - - [26/Jan/2023:18:08:55 +0000] "POST /admin/datasets/NUMBER_INTEGER%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_NUMBER_INTEGER+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:08:55,566] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:55,566] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:55,566] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:55,566] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:55,567] com.bakdata.conquery.models.jobs.ImportJob: Start sending 3 Buckets
INFO  [2023-01-26 18:08:55,568] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[NUMBER_INTEGER$20Test.table.table], containing 15 entries.
INFO  [2023-01-26 18:08:55,568] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[NUMBER_INTEGER$20Test.table.table], containing 15 entries.
WARN  [2023-01-26 18:08:55,569] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:55,569] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_INTEGER$20Test.table.table.0
INFO  [2023-01-26 18:08:55,569] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_INTEGER$20Test.table.table.1
INFO  [2023-01-26 18:08:55,569] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_INTEGER$20Test.table.table.2
INFO  [2023-01-26 18:08:55,676] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: NUMBER_INTEGER Test QUERY INIT
INFO  [2023-01-26 18:08:55,687] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[NUMBER_INTEGER$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:08:55,688] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[695eabe2-02e9-4755-ae8e-7742064a546f] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_INTEGER Test))]]
INFO  [2023-01-26 18:08:55,690] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery NUMBER_INTEGER$20Test.695eabe2-02e9-4755-ae8e-7742064a546f
INFO  [2023-01-26 18:08:55,690] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery NUMBER_INTEGER$20Test.695eabe2-02e9-4755-ae8e-7742064a546f
127.0.0.1 - - [26/Jan/2023:18:08:55 +0000] "POST /api/datasets/NUMBER_INTEGER$20Test/queries HTTP/1.1" 201 1205 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:08:55,703] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[NUMBER_INTEGER$20Test.695eabe2-02e9-4755-ae8e-7742064a546f] with 2 results within PT0.013359S
INFO  [2023-01-26 18:08:55,704] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=NUMBER_INTEGER$20Test.695eabe2-02e9-4755-ae8e-7742064a546f, workerId=NUMBER_INTEGER$20Test.worker_NUMBER_INTEGER$20Test_c479d726-d232-4f1f-a1f4-2131f59f38b8, startTime=2023-01-26T18:08:55.690367, finishTime=2023-01-26T18:08:55.703726) of size 2
INFO  [2023-01-26 18:08:55,708] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[NUMBER_INTEGER$20Test.695eabe2-02e9-4755-ae8e-7742064a546f] with 2 results within PT0.018147S
INFO  [2023-01-26 18:08:55,709] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=NUMBER_INTEGER$20Test.695eabe2-02e9-4755-ae8e-7742064a546f, workerId=NUMBER_INTEGER$20Test.worker_NUMBER_INTEGER$20Test_22dce583-a100-405f-a8ea-e19c06ec80a1, startTime=2023-01-26T18:08:55.690374, finishTime=2023-01-26T18:08:55.708521) of size 2
INFO  [2023-01-26 18:08:55,709] com.bakdata.conquery.models.execution.ManagedExecution: DONE 695eabe2-02e9-4755-ae8e-7742064a546f ManagedQuery within PT0.021204S
127.0.0.1 - - [26/Jan/2023:18:08:55 +0000] "GET /api/datasets/NUMBER_INTEGER$20Test/queries/NUMBER_INTEGER$20Test.695eabe2-02e9-4755-ae8e-7742064a546f HTTP/1.1" 200 1481 "-" "Conquery (test client)" 12
INFO  [2023-01-26 18:08:55,721] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=NUMBER_INTEGER Test], queryId=695eabe2-02e9-4755-ae8e-7742064a546f, label=concept	@§$, creationTime=2023-01-26T18:08:55.687960, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@1ec6c16b[Count = 0], startTime=2023-01-26T18:08:55.688132, finishTime=2023-01-26T18:08:55.709336, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2a4259e6), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_INTEGER Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@20447d64, com.bakdata.conquery.models.query.ColumnDescriptor@30b98b13]) download on dataset Dataset[label=null, name=NUMBER_INTEGER Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:08:55,721] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=NUMBER_INTEGER Test], queryId=695eabe2-02e9-4755-ae8e-7742064a546f, label=concept	@§$, creationTime=2023-01-26T18:08:55.687960, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@1ec6c16b[Count = 0], startTime=2023-01-26T18:08:55.688132, finishTime=2023-01-26T18:08:55.709336, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2a4259e6), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_INTEGER Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@20447d64, com.bakdata.conquery.models.query.ColumnDescriptor@30b98b13]) on dataset Dataset[label=null, name=NUMBER_INTEGER Test]
127.0.0.1 - - [26/Jan/2023:18:08:55 +0000] "GET /api/datasets/NUMBER_INTEGER%20Test/result/NUMBER_INTEGER$20Test.695eabe2-02e9-4755-ae8e-7742064a546f.csv?pretty=false HTTP/1.1" 200 117 "-" "Conquery (test client)" 25
INFO  [2023-01-26 18:08:55,746] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest NUMBER_INTEGER Test on 5 rows
INFO  [2023-01-26 18:08:55,746] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast NUMBER_INTEGER Test
INFO  [2023-01-26 18:08:55,746] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=NUMBER_INTEGER Test, name=NUMBER_INTEGER Test]
INFO  [2023-01-26 18:08:55,746] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=NUMBER_INTEGER Test, name=NUMBER_INTEGER Test]
INFO  [2023-01-26 18:08:55,746] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_NUMBER_INTEGER Test_c479d726-d232-4f1f-a1f4-2131f59f38b8
INFO  [2023-01-26 18:08:55,765] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_NUMBER_INTEGER Test_22dce583-a100-405f-a8ea-e19c06ec80a1
INFO  [2023-01-26 18:08:55,784] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow NUMBER_INTEGER Test
INFO  [2023-01-26 18:08:55,789] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_NUMBER_INTEGER Test_c479d726-d232-4f1f-a1f4-2131f59f38b8
INFO  [2023-01-26 18:08:55,790] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_NUMBER_INTEGER Test_22dce583-a100-405f-a8ea-e19c06ec80a1
INFO  [2023-01-26 18:08:55,869] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of NUMBER_INTEGER$20Test
INFO  [2023-01-26 18:08:55,869] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:55,975] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test NUMBER_INTEGER Test
INFO  [2023-01-26 18:08:55,976] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test NUMBER_INTEGER Test
INFO  [2023-01-26 18:08:55,976] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:55,976] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:55,977] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=NUMBER_INTEGER Test[1], name=NUMBER_INTEGER Test[1]]
INFO  [2023-01-26 18:08:55,977] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:55,977] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=NUMBER_INTEGER Test[1], name=NUMBER_INTEGER Test[1]]
INFO  [2023-01-26 18:08:55,978] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:55,978] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:55,979] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker NUMBER_INTEGER$20Test[1].worker_NUMBER_INTEGER$20Test[1]_5125dc3c-a9c3-45b2-a25c-ce672ca3b7a1 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:55,979] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker NUMBER_INTEGER$20Test[1].worker_NUMBER_INTEGER$20Test[1]_5125dc3c-a9c3-45b2-a25c-ce672ca3b7a1 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:55,979] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:55,979] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker NUMBER_INTEGER$20Test[1].worker_NUMBER_INTEGER$20Test[1]_491f336a-fc09-4e81-8b43-460ec0e20f1d are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:55,979] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker NUMBER_INTEGER$20Test[1].worker_NUMBER_INTEGER$20Test[1]_491f336a-fc09-4e81-8b43-460ec0e20f1d are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:55,979] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:56,086] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:56,086] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table NUMBER_INTEGER$20Test[1].table
INFO  [2023-01-26 18:08:56,086] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table NUMBER_INTEGER$20Test[1].table
INFO  [2023-01-26 18:08:56,195] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:56,307] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:56,307] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:56,307] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 41 B in total
INFO  [2023-01-26 18:08:56,307] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_INTEGER Test[1]/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.00024949sINFO  [2023-01-26 18:08:56,332] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=1, sum=1, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:08:56,332] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[nr] with IntegerParser(super=Parser(lines=1, nullLines=0), minValue=50, maxValue=50)
INFO  [2023-01-26 18:08:56,332] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=1, nullLines=0), minParser=DateParser(super=Parser(lines=1, nullLines=0), subType=IntegerParser(super=Parser(lines=1, nullLines=0), minValue=16511, maxValue=16511), dateReader=com.bakdata.conquery.util.DateReader@74e64962), maxParser=DateParser(super=Parser(lines=1, nullLines=0), subType=IntegerParser(super=Parser(lines=1, nullLines=0), minValue=16800, maxValue=16800), dateReader=com.bakdata.conquery.util.DateReader@5bca410e), dateReader=com.bakdata.conquery.util.DateReader@3cfe2c46, onlyQuarters=false, maxValue=16800, minValue=16511, anyOpen=false)
INFO  [2023-01-26 18:08:56,335] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_INTEGER Test[1]/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:56,335] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:56,335] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_INTEGER Test[1]/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:56,349] com.bakdata.conquery.models.jobs.ImportJob: Importing table into NUMBER_INTEGER$20Test[1].table
127.0.0.1 - - [26/Jan/2023:18:08:56 +0000] "POST /admin/datasets/NUMBER_INTEGER%20Test%5B1%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_NUMBER_INTEGER+Test%5B1%5D%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:08:56,351] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:56,351] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:56,351] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:56,351] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:56,352] com.bakdata.conquery.models.jobs.ImportJob: Start sending 1 Buckets
INFO  [2023-01-26 18:08:56,359] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[NUMBER_INTEGER$20Test[1].table.table], containing 1 entries.
INFO  [2023-01-26 18:08:56,359] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[NUMBER_INTEGER$20Test[1].table.table], containing 1 entries.
WARN  [2023-01-26 18:08:56,359] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:56,360] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_INTEGER$20Test[1].table.table.0
INFO  [2023-01-26 18:08:56,465] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: NUMBER_INTEGER Test QUERY INIT
INFO  [2023-01-26 18:08:56,480] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[NUMBER_INTEGER$20Test[1]] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:08:56,480] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[6de96de5-400a-42be-a89c-16c1353d50f1] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_INTEGER Test[1]))]]
INFO  [2023-01-26 18:08:56,484] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery NUMBER_INTEGER$20Test[1].6de96de5-400a-42be-a89c-16c1353d50f1
INFO  [2023-01-26 18:08:56,484] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery NUMBER_INTEGER$20Test[1].6de96de5-400a-42be-a89c-16c1353d50f1
WARN  [2023-01-26 18:08:56,484] com.bakdata.conquery.models.query.QueryExecutor: Entities for query are empty
INFO  [2023-01-26 18:08:56,485] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[NUMBER_INTEGER$20Test[1].6de96de5-400a-42be-a89c-16c1353d50f1] with 0 results within PT0.000125S
INFO  [2023-01-26 18:08:56,485] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[NUMBER_INTEGER$20Test[1].6de96de5-400a-42be-a89c-16c1353d50f1] with 1 results within PT0.000705S
INFO  [2023-01-26 18:08:56,485] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=NUMBER_INTEGER$20Test[1].6de96de5-400a-42be-a89c-16c1353d50f1, workerId=NUMBER_INTEGER$20Test[1].worker_NUMBER_INTEGER$20Test[1]_491f336a-fc09-4e81-8b43-460ec0e20f1d, startTime=2023-01-26T18:08:56.484917, finishTime=2023-01-26T18:08:56.485042) of size 0
INFO  [2023-01-26 18:08:56,486] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=NUMBER_INTEGER$20Test[1].6de96de5-400a-42be-a89c-16c1353d50f1, workerId=NUMBER_INTEGER$20Test[1].worker_NUMBER_INTEGER$20Test[1]_5125dc3c-a9c3-45b2-a25c-ce672ca3b7a1, startTime=2023-01-26T18:08:56.484748, finishTime=2023-01-26T18:08:56.485453) of size 1
INFO  [2023-01-26 18:08:56,486] com.bakdata.conquery.models.execution.ManagedExecution: DONE 6de96de5-400a-42be-a89c-16c1353d50f1 ManagedQuery within PT0.005279S
127.0.0.1 - - [26/Jan/2023:18:08:56 +0000] "POST /api/datasets/NUMBER_INTEGER$20Test%5B1%5D/queries HTTP/1.1" 201 1216 "-" "Conquery (test client)" 9
127.0.0.1 - - [26/Jan/2023:18:08:56 +0000] "GET /api/datasets/NUMBER_INTEGER$20Test%5B1%5D/queries/NUMBER_INTEGER$20Test%5B1%5D.6de96de5-400a-42be-a89c-16c1353d50f1 HTTP/1.1" 200 1751 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:08:56,530] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=NUMBER_INTEGER Test[1]], queryId=6de96de5-400a-42be-a89c-16c1353d50f1, label=concept	@§$, creationTime=2023-01-26T18:08:56.480659, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@1bccd9ad[Count = 0], startTime=2023-01-26T18:08:56.480928, finishTime=2023-01-26T18:08:56.486207, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2da72236), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_INTEGER Test[1])), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@1156659b, com.bakdata.conquery.models.query.ColumnDescriptor@15455cd1]) download on dataset Dataset[label=null, name=NUMBER_INTEGER Test[1]] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:08:56,530] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=NUMBER_INTEGER Test[1]], queryId=6de96de5-400a-42be-a89c-16c1353d50f1, label=concept	@§$, creationTime=2023-01-26T18:08:56.480659, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@1bccd9ad[Count = 0], startTime=2023-01-26T18:08:56.480928, finishTime=2023-01-26T18:08:56.486207, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2da72236), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_INTEGER Test[1])), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@1156659b, com.bakdata.conquery.models.query.ColumnDescriptor@15455cd1]) on dataset Dataset[label=null, name=NUMBER_INTEGER Test[1]]
127.0.0.1 - - [26/Jan/2023:18:08:56 +0000] "GET /api/datasets/NUMBER_INTEGER%20Test%5B1%5D/result/NUMBER_INTEGER$20Test%5B1%5D.6de96de5-400a-42be-a89c-16c1353d50f1.csv?pretty=false HTTP/1.1" 200 39 "-" "Conquery (test client)" 17
INFO  [2023-01-26 18:08:56,546] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest NUMBER_INTEGER Test on 2 rows
INFO  [2023-01-26 18:08:56,546] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast NUMBER_INTEGER Test[1]
INFO  [2023-01-26 18:08:56,546] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=NUMBER_INTEGER Test[1], name=NUMBER_INTEGER Test[1]]
INFO  [2023-01-26 18:08:56,546] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=NUMBER_INTEGER Test[1], name=NUMBER_INTEGER Test[1]]
INFO  [2023-01-26 18:08:56,546] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_NUMBER_INTEGER Test[1]_491f336a-fc09-4e81-8b43-460ec0e20f1d
INFO  [2023-01-26 18:08:56,546] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_NUMBER_INTEGER Test[1]_5125dc3c-a9c3-45b2-a25c-ce672ca3b7a1
INFO  [2023-01-26 18:08:56,577] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow NUMBER_INTEGER Test[1]
INFO  [2023-01-26 18:08:56,578] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_NUMBER_INTEGER Test[1]_5125dc3c-a9c3-45b2-a25c-ce672ca3b7a1
INFO  [2023-01-26 18:08:56,578] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_NUMBER_INTEGER Test[1]_491f336a-fc09-4e81-8b43-460ec0e20f1d
INFO  [2023-01-26 18:08:56,660] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of NUMBER_INTEGER$20Test[1]
INFO  [2023-01-26 18:08:56,660] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:56,765] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test NUMBER_INTEGER Test
INFO  [2023-01-26 18:08:56,765] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test NUMBER_MONEY Test
INFO  [2023-01-26 18:08:56,765] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:56,765] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:56,766] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=NUMBER_MONEY Test, name=NUMBER_MONEY Test]
INFO  [2023-01-26 18:08:56,766] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=NUMBER_MONEY Test, name=NUMBER_MONEY Test]
INFO  [2023-01-26 18:08:56,766] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:56,766] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:56,768] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker NUMBER_MONEY$20Test.worker_NUMBER_MONEY$20Test_8a117bf7-bfe4-486f-8a47-98a801a92fb2 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:56,768] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker NUMBER_MONEY$20Test.worker_NUMBER_MONEY$20Test_8a117bf7-bfe4-486f-8a47-98a801a92fb2 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:56,768] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:56,768] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker NUMBER_MONEY$20Test.worker_NUMBER_MONEY$20Test_e3e3dd2b-ead0-42cb-abf2-77b5400896af are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:56,768] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker NUMBER_MONEY$20Test.worker_NUMBER_MONEY$20Test_e3e3dd2b-ead0-42cb-abf2-77b5400896af are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:56,768] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:56,768] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:56,876] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:56,876] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table NUMBER_MONEY$20Test.table
INFO  [2023-01-26 18:08:56,876] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table NUMBER_MONEY$20Test.table
INFO  [2023-01-26 18:08:56,995] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:57,105] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:57,105] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:57,105] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 355 B in total
INFO  [2023-01-26 18:08:57,105] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_MONEY Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000246171sINFO  [2023-01-26 18:08:57,131] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=12, sum=18, min=1, average=1.500000, max=2}
INFO  [2023-01-26 18:08:57,132] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=18, nullLines=0), subType=IntegerParser(super=Parser(lines=18, nullLines=0), minValue=14835, maxValue=17612), dateReader=com.bakdata.conquery.util.DateReader@5e77d3a)
INFO  [2023-01-26 18:08:57,131] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[nr] with MoneyParser(super=Parser(lines=18, nullLines=3), maxValue=30000, minValue=5000, moneyFactor=100)
INFO  [2023-01-26 18:08:57,138] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_MONEY Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:57,138] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:57,138] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_MONEY Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:57,154] com.bakdata.conquery.models.jobs.ImportJob: Importing table into NUMBER_MONEY$20Test.table
127.0.0.1 - - [26/Jan/2023:18:08:57 +0000] "POST /admin/datasets/NUMBER_MONEY%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_NUMBER_MONEY+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:08:57,156] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:57,157] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:57,157] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:57,157] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:57,159] com.bakdata.conquery.models.jobs.ImportJob: Start sending 4 Buckets
INFO  [2023-01-26 18:08:57,159] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[NUMBER_MONEY$20Test.table.table], containing 18 entries.
INFO  [2023-01-26 18:08:57,159] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[NUMBER_MONEY$20Test.table.table], containing 18 entries.
INFO  [2023-01-26 18:08:57,160] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_MONEY$20Test.table.table.0
INFO  [2023-01-26 18:08:57,160] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_MONEY$20Test.table.table.1
WARN  [2023-01-26 18:08:57,160] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:57,161] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_MONEY$20Test.table.table.2
INFO  [2023-01-26 18:08:57,161] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_MONEY$20Test.table.table.3
INFO  [2023-01-26 18:08:57,266] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: NUMBER_MONEY Test QUERY INIT
INFO  [2023-01-26 18:08:57,283] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[NUMBER_MONEY$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:08:57,283] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[625c3c47-d941-4096-8633-54e017659959] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_MONEY Test))]]
INFO  [2023-01-26 18:08:57,286] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery NUMBER_MONEY$20Test.625c3c47-d941-4096-8633-54e017659959
INFO  [2023-01-26 18:08:57,286] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery NUMBER_MONEY$20Test.625c3c47-d941-4096-8633-54e017659959
127.0.0.1 - - [26/Jan/2023:18:08:57 +0000] "POST /api/datasets/NUMBER_MONEY$20Test/queries HTTP/1.1" 201 1202 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:08:57,295] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[NUMBER_MONEY$20Test.625c3c47-d941-4096-8633-54e017659959] with 2 results within PT0.009724S
INFO  [2023-01-26 18:08:57,296] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[NUMBER_MONEY$20Test.625c3c47-d941-4096-8633-54e017659959] with 3 results within PT0.0099S
INFO  [2023-01-26 18:08:57,296] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=NUMBER_MONEY$20Test.625c3c47-d941-4096-8633-54e017659959, workerId=NUMBER_MONEY$20Test.worker_NUMBER_MONEY$20Test_e3e3dd2b-ead0-42cb-abf2-77b5400896af, startTime=2023-01-26T18:08:57.286249, finishTime=2023-01-26T18:08:57.295973) of size 2
INFO  [2023-01-26 18:08:57,297] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=NUMBER_MONEY$20Test.625c3c47-d941-4096-8633-54e017659959, workerId=NUMBER_MONEY$20Test.worker_NUMBER_MONEY$20Test_8a117bf7-bfe4-486f-8a47-98a801a92fb2, startTime=2023-01-26T18:08:57.286249, finishTime=2023-01-26T18:08:57.296149) of size 3
INFO  [2023-01-26 18:08:57,297] com.bakdata.conquery.models.execution.ManagedExecution: DONE 625c3c47-d941-4096-8633-54e017659959 ManagedQuery within PT0.013462S
127.0.0.1 - - [26/Jan/2023:18:08:57 +0000] "GET /api/datasets/NUMBER_MONEY$20Test/queries/NUMBER_MONEY$20Test.625c3c47-d941-4096-8633-54e017659959 HTTP/1.1" 200 1470 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:08:57,337] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=NUMBER_MONEY Test], queryId=625c3c47-d941-4096-8633-54e017659959, label=concept	@§$, creationTime=2023-01-26T18:08:57.283538, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@69ee5f86[Count = 0], startTime=2023-01-26T18:08:57.283741, finishTime=2023-01-26T18:08:57.297203, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@44614a81), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_MONEY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=5, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@7fe99892, com.bakdata.conquery.models.query.ColumnDescriptor@9f3b0a8]) download on dataset Dataset[label=null, name=NUMBER_MONEY Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:08:57,337] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=NUMBER_MONEY Test], queryId=625c3c47-d941-4096-8633-54e017659959, label=concept	@§$, creationTime=2023-01-26T18:08:57.283538, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@69ee5f86[Count = 0], startTime=2023-01-26T18:08:57.283741, finishTime=2023-01-26T18:08:57.297203, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@44614a81), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_MONEY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=5, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@7fe99892, com.bakdata.conquery.models.query.ColumnDescriptor@9f3b0a8]) on dataset Dataset[label=null, name=NUMBER_MONEY Test]
127.0.0.1 - - [26/Jan/2023:18:08:57 +0000] "GET /api/datasets/NUMBER_MONEY%20Test/result/NUMBER_MONEY$20Test.625c3c47-d941-4096-8633-54e017659959.csv?pretty=false HTTP/1.1" 200 144 "-" "Conquery (test client)" 34
INFO  [2023-01-26 18:08:57,349] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest NUMBER_MONEY Test on 6 rows
INFO  [2023-01-26 18:08:57,349] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast NUMBER_MONEY Test
INFO  [2023-01-26 18:08:57,349] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=NUMBER_MONEY Test, name=NUMBER_MONEY Test]
INFO  [2023-01-26 18:08:57,351] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_NUMBER_MONEY Test_8a117bf7-bfe4-486f-8a47-98a801a92fb2
INFO  [2023-01-26 18:08:57,351] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=NUMBER_MONEY Test, name=NUMBER_MONEY Test]
INFO  [2023-01-26 18:08:57,352] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_NUMBER_MONEY Test_e3e3dd2b-ead0-42cb-abf2-77b5400896af
INFO  [2023-01-26 18:08:57,366] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow NUMBER_MONEY Test
INFO  [2023-01-26 18:08:57,367] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_NUMBER_MONEY Test_8a117bf7-bfe4-486f-8a47-98a801a92fb2
INFO  [2023-01-26 18:08:57,367] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_NUMBER_MONEY Test_e3e3dd2b-ead0-42cb-abf2-77b5400896af
INFO  [2023-01-26 18:08:57,461] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of NUMBER_MONEY$20Test
INFO  [2023-01-26 18:08:57,461] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:57,568] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test NUMBER_MONEY Test
INFO  [2023-01-26 18:08:57,568] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test NUMBER_REAL Test
INFO  [2023-01-26 18:08:57,568] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:57,568] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:57,569] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=NUMBER_REAL Test[1], name=NUMBER_REAL Test[1]]
INFO  [2023-01-26 18:08:57,569] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:57,569] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=NUMBER_REAL Test[1], name=NUMBER_REAL Test[1]]
INFO  [2023-01-26 18:08:57,569] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:57,571] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker NUMBER_REAL$20Test[1].worker_NUMBER_REAL$20Test[1]_e6bc93a1-a328-4380-9888-447c3174e237 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:57,571] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker NUMBER_REAL$20Test[1].worker_NUMBER_REAL$20Test[1]_e6bc93a1-a328-4380-9888-447c3174e237 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:57,571] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:57,571] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker NUMBER_REAL$20Test[1].worker_NUMBER_REAL$20Test[1]_b07d3a67-fc49-4b19-a6a6-5e8dd7cb3de0 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:57,571] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker NUMBER_REAL$20Test[1].worker_NUMBER_REAL$20Test[1]_b07d3a67-fc49-4b19-a6a6-5e8dd7cb3de0 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:57,571] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:57,575] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:57,677] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:57,677] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table NUMBER_REAL$20Test[1].table
INFO  [2023-01-26 18:08:57,677] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table NUMBER_REAL$20Test[1].table
INFO  [2023-01-26 18:08:57,788] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:57,901] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:57,901] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:57,901] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 355 B in total
INFO  [2023-01-26 18:08:57,901] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_REAL Test[1]/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000221015sINFO  [2023-01-26 18:08:57,924] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=12, sum=18, min=1, average=1.500000, max=2}
INFO  [2023-01-26 18:08:57,924] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=18, nullLines=0), subType=IntegerParser(super=Parser(lines=18, nullLines=0), minValue=14835, maxValue=17612), dateReader=com.bakdata.conquery.util.DateReader@67b1a829)
INFO  [2023-01-26 18:08:57,924] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[nr] with RealParser(super=Parser(lines=18, nullLines=3), requiredPrecision=4.9E-324, floatULP=3.0517578125E-5)
INFO  [2023-01-26 18:08:57,927] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_REAL Test[1]/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:57,927] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:57,927] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_REAL Test[1]/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:57,944] com.bakdata.conquery.models.jobs.ImportJob: Importing table into NUMBER_REAL$20Test[1].table
127.0.0.1 - - [26/Jan/2023:18:08:57 +0000] "POST /admin/datasets/NUMBER_REAL%20Test%5B1%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_NUMBER_REAL+Test%5B1%5D%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:08:57,946] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:57,946] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:57,946] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:57,946] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:57,948] com.bakdata.conquery.models.jobs.ImportJob: Start sending 4 Buckets
INFO  [2023-01-26 18:08:57,948] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[NUMBER_REAL$20Test[1].table.table], containing 18 entries.
INFO  [2023-01-26 18:08:57,948] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[NUMBER_REAL$20Test[1].table.table], containing 18 entries.
INFO  [2023-01-26 18:08:57,949] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_REAL$20Test[1].table.table.0
INFO  [2023-01-26 18:08:57,949] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_REAL$20Test[1].table.table.1
WARN  [2023-01-26 18:08:57,949] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:57,949] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_REAL$20Test[1].table.table.2
INFO  [2023-01-26 18:08:57,949] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_REAL$20Test[1].table.table.3
INFO  [2023-01-26 18:08:58,055] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: NUMBER_REAL Test QUERY INIT
INFO  [2023-01-26 18:08:58,066] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[NUMBER_REAL$20Test[1]] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:08:58,066] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[fd233899-af94-489b-8ebd-fdb487fa6b9f] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_REAL Test[1]))]]
INFO  [2023-01-26 18:08:58,069] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery NUMBER_REAL$20Test[1].fd233899-af94-489b-8ebd-fdb487fa6b9f
INFO  [2023-01-26 18:08:58,069] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery NUMBER_REAL$20Test[1].fd233899-af94-489b-8ebd-fdb487fa6b9f
127.0.0.1 - - [26/Jan/2023:18:08:58 +0000] "POST /api/datasets/NUMBER_REAL$20Test%5B1%5D/queries HTTP/1.1" 201 1203 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:08:58,078] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[NUMBER_REAL$20Test[1].fd233899-af94-489b-8ebd-fdb487fa6b9f] with 3 results within PT0.008883S
INFO  [2023-01-26 18:08:58,079] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=NUMBER_REAL$20Test[1].fd233899-af94-489b-8ebd-fdb487fa6b9f, workerId=NUMBER_REAL$20Test[1].worker_NUMBER_REAL$20Test[1]_b07d3a67-fc49-4b19-a6a6-5e8dd7cb3de0, startTime=2023-01-26T18:08:58.069794, finishTime=2023-01-26T18:08:58.078677) of size 3
INFO  [2023-01-26 18:08:58,081] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[NUMBER_REAL$20Test[1].fd233899-af94-489b-8ebd-fdb487fa6b9f] with 2 results within PT0.011829S
INFO  [2023-01-26 18:08:58,082] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=NUMBER_REAL$20Test[1].fd233899-af94-489b-8ebd-fdb487fa6b9f, workerId=NUMBER_REAL$20Test[1].worker_NUMBER_REAL$20Test[1]_e6bc93a1-a328-4380-9888-447c3174e237, startTime=2023-01-26T18:08:58.069798, finishTime=2023-01-26T18:08:58.081627) of size 2
INFO  [2023-01-26 18:08:58,082] com.bakdata.conquery.models.execution.ManagedExecution: DONE fd233899-af94-489b-8ebd-fdb487fa6b9f ManagedQuery within PT0.015322S
127.0.0.1 - - [26/Jan/2023:18:08:58 +0000] "GET /api/datasets/NUMBER_REAL$20Test%5B1%5D/queries/NUMBER_REAL$20Test%5B1%5D.fd233899-af94-489b-8ebd-fdb487fa6b9f HTTP/1.1" 200 1714 "-" "Conquery (test client)" 4
INFO  [2023-01-26 18:08:58,095] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=NUMBER_REAL Test[1]], queryId=fd233899-af94-489b-8ebd-fdb487fa6b9f, label=concept	@§$, creationTime=2023-01-26T18:08:58.066806, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@503ebcd0[Count = 0], startTime=2023-01-26T18:08:58.066988, finishTime=2023-01-26T18:08:58.082310, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@57a56221), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_REAL Test[1])), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=5, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@e976c9e, com.bakdata.conquery.models.query.ColumnDescriptor@46f9ebf1]) download on dataset Dataset[label=null, name=NUMBER_REAL Test[1]] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:08:58,095] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=NUMBER_REAL Test[1]], queryId=fd233899-af94-489b-8ebd-fdb487fa6b9f, label=concept	@§$, creationTime=2023-01-26T18:08:58.066806, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@503ebcd0[Count = 0], startTime=2023-01-26T18:08:58.066988, finishTime=2023-01-26T18:08:58.082310, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@57a56221), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_REAL Test[1])), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=5, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@e976c9e, com.bakdata.conquery.models.query.ColumnDescriptor@46f9ebf1]) on dataset Dataset[label=null, name=NUMBER_REAL Test[1]]
127.0.0.1 - - [26/Jan/2023:18:08:58 +0000] "GET /api/datasets/NUMBER_REAL%20Test%5B1%5D/result/NUMBER_REAL$20Test%5B1%5D.fd233899-af94-489b-8ebd-fdb487fa6b9f.csv?pretty=false HTTP/1.1" 200 144 "-" "Conquery (test client)" 19
INFO  [2023-01-26 18:08:58,114] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest NUMBER_REAL Test on 6 rows
INFO  [2023-01-26 18:08:58,114] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast NUMBER_REAL Test[1]
INFO  [2023-01-26 18:08:58,114] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=NUMBER_REAL Test[1], name=NUMBER_REAL Test[1]]
INFO  [2023-01-26 18:08:58,114] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=NUMBER_REAL Test[1], name=NUMBER_REAL Test[1]]
INFO  [2023-01-26 18:08:58,114] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_NUMBER_REAL Test[1]_e6bc93a1-a328-4380-9888-447c3174e237
INFO  [2023-01-26 18:08:58,123] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_NUMBER_REAL Test[1]_b07d3a67-fc49-4b19-a6a6-5e8dd7cb3de0
INFO  [2023-01-26 18:08:58,170] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow NUMBER_REAL Test[1]
INFO  [2023-01-26 18:08:58,177] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_NUMBER_REAL Test[1]_e6bc93a1-a328-4380-9888-447c3174e237
INFO  [2023-01-26 18:08:58,177] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_NUMBER_REAL Test[1]_b07d3a67-fc49-4b19-a6a6-5e8dd7cb3de0
INFO  [2023-01-26 18:08:58,249] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of NUMBER_REAL$20Test[1]
INFO  [2023-01-26 18:08:58,249] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:58,359] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test NUMBER_REAL Test
INFO  [2023-01-26 18:08:58,360] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test NUMBER_MISSING FILTER Test
INFO  [2023-01-26 18:08:58,360] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:58,360] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:58,367] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=NUMBER_MISSING FILTER Test, name=NUMBER_MISSING FILTER Test]
INFO  [2023-01-26 18:08:58,367] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=NUMBER_MISSING FILTER Test, name=NUMBER_MISSING FILTER Test]
INFO  [2023-01-26 18:08:58,367] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:58,367] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:58,371] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker NUMBER_MISSING$20FILTER$20Test.worker_NUMBER_MISSING$20FILTER$20Test_169ddf85-9b0b-4b36-9e03-02d5f7e3a7cb are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:58,371] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker NUMBER_MISSING$20FILTER$20Test.worker_NUMBER_MISSING$20FILTER$20Test_169ddf85-9b0b-4b36-9e03-02d5f7e3a7cb are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:58,371] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:58,371] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker NUMBER_MISSING$20FILTER$20Test.worker_NUMBER_MISSING$20FILTER$20Test_d52aae01-2d51-4541-84d9-50243438ed8d are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:58,371] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker NUMBER_MISSING$20FILTER$20Test.worker_NUMBER_MISSING$20FILTER$20Test_d52aae01-2d51-4541-84d9-50243438ed8d are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:58,371] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:58,373] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:58,477] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:58,477] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table NUMBER_MISSING$20FILTER$20Test.table
INFO  [2023-01-26 18:08:58,477] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table NUMBER_MISSING$20FILTER$20Test.table
INFO  [2023-01-26 18:08:58,594] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:58,704] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:58,704] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:58,704] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 67 B in total
INFO  [2023-01-26 18:08:58,704] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_MISSING FILTER Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000200531sINFO  [2023-01-26 18:08:58,725] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=2, sum=2, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:08:58,725] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[nr] with RealParser(super=Parser(lines=2, nullLines=1), requiredPrecision=4.9E-324, floatULP=1.401298464324817E-45)
INFO  [2023-01-26 18:08:58,725] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=2, nullLines=0), minParser=DateParser(super=Parser(lines=2, nullLines=0), subType=IntegerParser(super=Parser(lines=2, nullLines=0), minValue=16511, maxValue=17292), dateReader=com.bakdata.conquery.util.DateReader@efa8dfa), maxParser=DateParser(super=Parser(lines=2, nullLines=0), subType=IntegerParser(super=Parser(lines=2, nullLines=0), minValue=16525, maxValue=17301), dateReader=com.bakdata.conquery.util.DateReader@59d3e1b9), dateReader=com.bakdata.conquery.util.DateReader@3af22b9f, onlyQuarters=false, maxValue=17301, minValue=16511, anyOpen=false)
INFO  [2023-01-26 18:08:58,728] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_MISSING FILTER Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:58,728] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:58,728] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_MISSING FILTER Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:58,753] com.bakdata.conquery.models.jobs.ImportJob: Importing table into NUMBER_MISSING$20FILTER$20Test.table
127.0.0.1 - - [26/Jan/2023:18:08:58 +0000] "POST /admin/datasets/NUMBER_MISSING%20FILTER%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_NUMBER_MISSING+FILTER+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:08:58,755] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:58,755] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:58,755] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:58,755] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:58,757] com.bakdata.conquery.models.jobs.ImportJob: Start sending 1 Buckets
INFO  [2023-01-26 18:08:58,757] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[NUMBER_MISSING$20FILTER$20Test.table.table], containing 2 entries.
WARN  [2023-01-26 18:08:58,758] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:58,758] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[NUMBER_MISSING$20FILTER$20Test.table.table], containing 2 entries.
INFO  [2023-01-26 18:08:58,759] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_MISSING$20FILTER$20Test.table.table.0
INFO  [2023-01-26 18:08:58,864] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: NUMBER_MISSING FILTER Test QUERY INIT
INFO  [2023-01-26 18:08:58,875] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[NUMBER_MISSING$20FILTER$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:08:58,876] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[472c183f-730a-415a-a92b-ee8229a4327d] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_MISSING FILTER Test))]]
INFO  [2023-01-26 18:08:58,878] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery NUMBER_MISSING$20FILTER$20Test.472c183f-730a-415a-a92b-ee8229a4327d
INFO  [2023-01-26 18:08:58,878] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery NUMBER_MISSING$20FILTER$20Test.472c183f-730a-415a-a92b-ee8229a4327d
WARN  [2023-01-26 18:08:58,879] com.bakdata.conquery.models.query.QueryExecutor: Entities for query are empty
INFO  [2023-01-26 18:08:58,879] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[NUMBER_MISSING$20FILTER$20Test.472c183f-730a-415a-a92b-ee8229a4327d] with 0 results within PT0.000111S
INFO  [2023-01-26 18:08:58,879] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[NUMBER_MISSING$20FILTER$20Test.472c183f-730a-415a-a92b-ee8229a4327d] with 1 results within PT0.000552S
INFO  [2023-01-26 18:08:58,879] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=NUMBER_MISSING$20FILTER$20Test.472c183f-730a-415a-a92b-ee8229a4327d, workerId=NUMBER_MISSING$20FILTER$20Test.worker_NUMBER_MISSING$20FILTER$20Test_169ddf85-9b0b-4b36-9e03-02d5f7e3a7cb, startTime=2023-01-26T18:08:58.878993, finishTime=2023-01-26T18:08:58.879104) of size 0
INFO  [2023-01-26 18:08:58,879] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=NUMBER_MISSING$20FILTER$20Test.472c183f-730a-415a-a92b-ee8229a4327d, workerId=NUMBER_MISSING$20FILTER$20Test.worker_NUMBER_MISSING$20FILTER$20Test_d52aae01-2d51-4541-84d9-50243438ed8d, startTime=2023-01-26T18:08:58.878993, finishTime=2023-01-26T18:08:58.879545) of size 1
INFO  [2023-01-26 18:08:58,880] com.bakdata.conquery.models.execution.ManagedExecution: DONE 472c183f-730a-415a-a92b-ee8229a4327d ManagedQuery within PT0.003999S
127.0.0.1 - - [26/Jan/2023:18:08:58 +0000] "POST /api/datasets/NUMBER_MISSING$20FILTER$20Test/queries HTTP/1.1" 201 1237 "-" "Conquery (test client)" 7
127.0.0.1 - - [26/Jan/2023:18:08:58 +0000] "GET /api/datasets/NUMBER_MISSING$20FILTER$20Test/queries/NUMBER_MISSING$20FILTER$20Test.472c183f-730a-415a-a92b-ee8229a4327d HTTP/1.1" 200 1548 "-" "Conquery (test client)" 4
INFO  [2023-01-26 18:08:58,910] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=NUMBER_MISSING FILTER Test], queryId=472c183f-730a-415a-a92b-ee8229a4327d, label=concept	@§$, creationTime=2023-01-26T18:08:58.875857, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@4a5d38a0[Count = 0], startTime=2023-01-26T18:08:58.876055, finishTime=2023-01-26T18:08:58.880054, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@7274de46), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_MISSING FILTER Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@74819d78, com.bakdata.conquery.models.query.ColumnDescriptor@5629c8]) download on dataset Dataset[label=null, name=NUMBER_MISSING FILTER Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:08:58,910] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=NUMBER_MISSING FILTER Test], queryId=472c183f-730a-415a-a92b-ee8229a4327d, label=concept	@§$, creationTime=2023-01-26T18:08:58.875857, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@4a5d38a0[Count = 0], startTime=2023-01-26T18:08:58.876055, finishTime=2023-01-26T18:08:58.880054, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@7274de46), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_MISSING FILTER Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@74819d78, com.bakdata.conquery.models.query.ColumnDescriptor@5629c8]) on dataset Dataset[label=null, name=NUMBER_MISSING FILTER Test]
127.0.0.1 - - [26/Jan/2023:18:08:58 +0000] "GET /api/datasets/NUMBER_MISSING%20FILTER%20Test/result/NUMBER_MISSING$20FILTER$20Test.472c183f-730a-415a-a92b-ee8229a4327d.csv?pretty=false HTTP/1.1" 200 39 "-" "Conquery (test client)" 18
INFO  [2023-01-26 18:08:58,927] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest NUMBER_MISSING FILTER Test on 2 rows
INFO  [2023-01-26 18:08:58,927] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast NUMBER_MISSING FILTER Test
INFO  [2023-01-26 18:08:58,927] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=NUMBER_MISSING FILTER Test, name=NUMBER_MISSING FILTER Test]
INFO  [2023-01-26 18:08:58,927] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=NUMBER_MISSING FILTER Test, name=NUMBER_MISSING FILTER Test]
INFO  [2023-01-26 18:08:58,927] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_NUMBER_MISSING FILTER Test_169ddf85-9b0b-4b36-9e03-02d5f7e3a7cb
INFO  [2023-01-26 18:08:58,927] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_NUMBER_MISSING FILTER Test_d52aae01-2d51-4541-84d9-50243438ed8d
INFO  [2023-01-26 18:08:58,967] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow NUMBER_MISSING FILTER Test
INFO  [2023-01-26 18:08:58,970] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_NUMBER_MISSING FILTER Test_d52aae01-2d51-4541-84d9-50243438ed8d
INFO  [2023-01-26 18:08:58,970] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_NUMBER_MISSING FILTER Test_169ddf85-9b0b-4b36-9e03-02d5f7e3a7cb
INFO  [2023-01-26 18:08:59,058] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of NUMBER_MISSING$20FILTER$20Test
INFO  [2023-01-26 18:08:59,058] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:59,164] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test NUMBER_MISSING FILTER Test
INFO  [2023-01-26 18:08:59,165] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test Prefix Test
INFO  [2023-01-26 18:08:59,165] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:59,165] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:59,166] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=Prefix Test, name=Prefix Test]
INFO  [2023-01-26 18:08:59,166] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=Prefix Test, name=Prefix Test]
INFO  [2023-01-26 18:08:59,166] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:59,166] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:59,167] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:59,167] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker Prefix$20Test.worker_Prefix$20Test_8b40e8db-cb14-4dad-a530-0118b16646d1 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:59,167] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker Prefix$20Test.worker_Prefix$20Test_8b40e8db-cb14-4dad-a530-0118b16646d1 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:59,167] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:59,167] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker Prefix$20Test.worker_Prefix$20Test_3b4356d8-6464-4821-a3c0-f20e25432117 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:59,168] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker Prefix$20Test.worker_Prefix$20Test_3b4356d8-6464-4821-a3c0-f20e25432117 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:59,168] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:59,275] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:59,275] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table Prefix$20Test.table
INFO  [2023-01-26 18:08:59,275] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table Prefix$20Test.table
INFO  [2023-01-26 18:08:59,393] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:59,515] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:08:59,515] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:08:59,516] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 109 B in total
INFO  [2023-01-26 18:08:59,516] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_Prefix Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000298002sINFO  [2023-01-26 18:08:59,546] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=5, sum=6, min=1, average=1.200000, max=2}
INFO  [2023-01-26 18:08:59,546] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=15340, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@5d0b87f6)
INFO  [2023-01-26 18:08:59,546] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with StringParser(super=Parser(lines=6, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:08:59,550] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_Prefix Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:59,550] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:08:59,550] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_Prefix Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:08:59,571] com.bakdata.conquery.models.jobs.ImportJob: Importing table into Prefix$20Test.table
127.0.0.1 - - [26/Jan/2023:18:08:59 +0000] "POST /admin/datasets/Prefix%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_Prefix+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 11
INFO  [2023-01-26 18:08:59,573] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:59,573] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:08:59,573] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:08:59,573] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:08:59,575] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:08:59,575] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[Prefix$20Test.table.table], containing 6 entries.
INFO  [2023-01-26 18:08:59,575] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[Prefix$20Test.table.table], containing 6 entries.
WARN  [2023-01-26 18:08:59,576] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:08:59,576] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received Prefix$20Test.table.table.0
INFO  [2023-01-26 18:08:59,577] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received Prefix$20Test.table.table.1
INFO  [2023-01-26 18:08:59,681] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: Prefix Test QUERY INIT
INFO  [2023-01-26 18:08:59,694] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[Prefix$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:08:59,694] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[e7cf7029-5cb6-42e6-9d26-aa7b4c1c2b25] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_Prefix Test))]]
INFO  [2023-01-26 18:08:59,697] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery Prefix$20Test.e7cf7029-5cb6-42e6-9d26-aa7b4c1c2b25
127.0.0.1 - - [26/Jan/2023:18:08:59 +0000] "POST /api/datasets/Prefix$20Test/queries HTTP/1.1" 201 1149 "-" "Conquery (test client)" 5
INFO  [2023-01-26 18:08:59,697] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery Prefix$20Test.e7cf7029-5cb6-42e6-9d26-aa7b4c1c2b25
INFO  [2023-01-26 18:08:59,700] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[Prefix$20Test.e7cf7029-5cb6-42e6-9d26-aa7b4c1c2b25] with 2 results within PT0.002743S
INFO  [2023-01-26 18:08:59,700] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[Prefix$20Test.e7cf7029-5cb6-42e6-9d26-aa7b4c1c2b25] with 1 results within PT0.002489S
INFO  [2023-01-26 18:08:59,700] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=Prefix$20Test.e7cf7029-5cb6-42e6-9d26-aa7b4c1c2b25, workerId=Prefix$20Test.worker_Prefix$20Test_8b40e8db-cb14-4dad-a530-0118b16646d1, startTime=2023-01-26T18:08:59.697702, finishTime=2023-01-26T18:08:59.700191) of size 1
INFO  [2023-01-26 18:08:59,700] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=Prefix$20Test.e7cf7029-5cb6-42e6-9d26-aa7b4c1c2b25, workerId=Prefix$20Test.worker_Prefix$20Test_3b4356d8-6464-4821-a3c0-f20e25432117, startTime=2023-01-26T18:08:59.697359, finishTime=2023-01-26T18:08:59.700102) of size 2
INFO  [2023-01-26 18:08:59,700] com.bakdata.conquery.models.execution.ManagedExecution: DONE e7cf7029-5cb6-42e6-9d26-aa7b4c1c2b25 ManagedQuery within PT0.006026S
127.0.0.1 - - [26/Jan/2023:18:08:59 +0000] "GET /api/datasets/Prefix$20Test/queries/Prefix$20Test.e7cf7029-5cb6-42e6-9d26-aa7b4c1c2b25 HTTP/1.1" 200 1392 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:08:59,723] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=Prefix Test], queryId=e7cf7029-5cb6-42e6-9d26-aa7b4c1c2b25, label=concept	@§$, creationTime=2023-01-26T18:08:59.694627, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@783b857b[Count = 0], startTime=2023-01-26T18:08:59.694836, finishTime=2023-01-26T18:08:59.700862, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@3938a27b), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_Prefix Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=3, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@1d45d0f5, com.bakdata.conquery.models.query.ColumnDescriptor@40385c80]) download on dataset Dataset[label=null, name=Prefix Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:08:59,723] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=Prefix Test], queryId=e7cf7029-5cb6-42e6-9d26-aa7b4c1c2b25, label=concept	@§$, creationTime=2023-01-26T18:08:59.694627, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@783b857b[Count = 0], startTime=2023-01-26T18:08:59.694836, finishTime=2023-01-26T18:08:59.700862, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@3938a27b), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_Prefix Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=3, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@1d45d0f5, com.bakdata.conquery.models.query.ColumnDescriptor@40385c80]) on dataset Dataset[label=null, name=Prefix Test]
127.0.0.1 - - [26/Jan/2023:18:08:59 +0000] "GET /api/datasets/Prefix%20Test/result/Prefix$20Test.e7cf7029-5cb6-42e6-9d26-aa7b4c1c2b25.csv?pretty=false HTTP/1.1" 200 91 "-" "Conquery (test client)" 18
INFO  [2023-01-26 18:08:59,740] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest Prefix Test on 4 rows
INFO  [2023-01-26 18:08:59,740] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast Prefix Test
INFO  [2023-01-26 18:08:59,740] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=Prefix Test, name=Prefix Test]
INFO  [2023-01-26 18:08:59,740] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=Prefix Test, name=Prefix Test]
INFO  [2023-01-26 18:08:59,740] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_Prefix Test_8b40e8db-cb14-4dad-a530-0118b16646d1
INFO  [2023-01-26 18:08:59,740] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_Prefix Test_3b4356d8-6464-4821-a3c0-f20e25432117
INFO  [2023-01-26 18:08:59,766] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow Prefix Test
INFO  [2023-01-26 18:08:59,767] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_Prefix Test_3b4356d8-6464-4821-a3c0-f20e25432117
INFO  [2023-01-26 18:08:59,767] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_Prefix Test_8b40e8db-cb14-4dad-a530-0118b16646d1
INFO  [2023-01-26 18:08:59,777] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of Prefix$20Test
INFO  [2023-01-26 18:08:59,777] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:59,882] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test Prefix Test
INFO  [2023-01-26 18:08:59,882] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test QUARTERS_IN_YEAR Test
INFO  [2023-01-26 18:08:59,882] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:08:59,883] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:08:59,883] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=QUARTERS_IN_YEAR Test, name=QUARTERS_IN_YEAR Test]
INFO  [2023-01-26 18:08:59,883] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=QUARTERS_IN_YEAR Test, name=QUARTERS_IN_YEAR Test]
INFO  [2023-01-26 18:08:59,883] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:59,883] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:08:59,885] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker QUARTERS_IN_YEAR$20Test.worker_QUARTERS_IN_YEAR$20Test_cbb50a63-d20d-4fe6-9293-9c935aac3352 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:59,885] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker QUARTERS_IN_YEAR$20Test.worker_QUARTERS_IN_YEAR$20Test_cbb50a63-d20d-4fe6-9293-9c935aac3352 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:59,885] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:59,885] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker QUARTERS_IN_YEAR$20Test.worker_QUARTERS_IN_YEAR$20Test_8e4635e4-a92f-4c21-9416-99f5f7dec73f are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:08:59,885] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker QUARTERS_IN_YEAR$20Test.worker_QUARTERS_IN_YEAR$20Test_8e4635e4-a92f-4c21-9416-99f5f7dec73f are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:08:59,885] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:08:59,889] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:59,992] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:08:59,992] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table QUARTERS_IN_YEAR$20Test.table
INFO  [2023-01-26 18:08:59,993] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table QUARTERS_IN_YEAR$20Test.table
INFO  [2023-01-26 18:09:00,108] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:00,219] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:00,220] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:00,220] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 1.4 KiB in total
INFO  [2023-01-26 18:09:00,220] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_QUARTERS_IN_YEAR Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.00041847sINFO  [2023-01-26 18:09:00,263] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=12, sum=38, min=1, average=3.166667, max=6}
INFO  [2023-01-26 18:09:00,263] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[behandlungsdatum] with DateParser(super=Parser(lines=38, nullLines=0), subType=IntegerParser(super=Parser(lines=38, nullLines=0), minValue=16436, maxValue=17117), dateReader=com.bakdata.conquery.util.DateReader@79af89be)
INFO  [2023-01-26 18:09:00,263] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=38, nullLines=0), minParser=DateParser(super=Parser(lines=38, nullLines=0), subType=IntegerParser(super=Parser(lines=38, nullLines=0), minValue=16436, maxValue=16801), dateReader=com.bakdata.conquery.util.DateReader@7d0d6740), maxParser=DateParser(super=Parser(lines=38, nullLines=0), subType=IntegerParser(super=Parser(lines=38, nullLines=0), minValue=16800, maxValue=17166), dateReader=com.bakdata.conquery.util.DateReader@43d60bd7), dateReader=com.bakdata.conquery.util.DateReader@3ccd86d3, onlyQuarters=false, maxValue=17166, minValue=16436, anyOpen=false)
INFO  [2023-01-26 18:09:00,266] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_QUARTERS_IN_YEAR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:00,266] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:00,266] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_QUARTERS_IN_YEAR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:00,283] com.bakdata.conquery.models.jobs.ImportJob: Importing table into QUARTERS_IN_YEAR$20Test.table
127.0.0.1 - - [26/Jan/2023:18:09:00 +0000] "POST /admin/datasets/QUARTERS_IN_YEAR%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_QUARTERS_IN_YEAR+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 13
INFO  [2023-01-26 18:09:00,289] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:00,290] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:00,290] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:00,290] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:00,291] com.bakdata.conquery.models.jobs.ImportJob: Start sending 4 Buckets
INFO  [2023-01-26 18:09:00,291] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[QUARTERS_IN_YEAR$20Test.table.table], containing 38 entries.
INFO  [2023-01-26 18:09:00,291] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[QUARTERS_IN_YEAR$20Test.table.table], containing 38 entries.
INFO  [2023-01-26 18:09:00,292] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received QUARTERS_IN_YEAR$20Test.table.table.0
WARN  [2023-01-26 18:09:00,292] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:00,292] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received QUARTERS_IN_YEAR$20Test.table.table.1
INFO  [2023-01-26 18:09:00,293] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received QUARTERS_IN_YEAR$20Test.table.table.3
INFO  [2023-01-26 18:09:00,293] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received QUARTERS_IN_YEAR$20Test.table.table.2
INFO  [2023-01-26 18:09:00,398] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: QUARTERS_IN_YEAR Test QUERY INIT
INFO  [2023-01-26 18:09:00,410] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[QUARTERS_IN_YEAR$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:00,411] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[44d59c32-8391-4e4e-ad00-2bc6d00707e6] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_QUARTERS_IN_YEAR Test))]]
INFO  [2023-01-26 18:09:00,414] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery QUARTERS_IN_YEAR$20Test.44d59c32-8391-4e4e-ad00-2bc6d00707e6
INFO  [2023-01-26 18:09:00,414] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery QUARTERS_IN_YEAR$20Test.44d59c32-8391-4e4e-ad00-2bc6d00707e6
127.0.0.1 - - [26/Jan/2023:18:09:00 +0000] "POST /api/datasets/QUARTERS_IN_YEAR$20Test/queries HTTP/1.1" 201 1210 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:09:00,428] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[QUARTERS_IN_YEAR$20Test.44d59c32-8391-4e4e-ad00-2bc6d00707e6] with 4 results within PT0.013809S
INFO  [2023-01-26 18:09:00,428] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[QUARTERS_IN_YEAR$20Test.44d59c32-8391-4e4e-ad00-2bc6d00707e6] with 3 results within PT0.013813S
INFO  [2023-01-26 18:09:00,428] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=QUARTERS_IN_YEAR$20Test.44d59c32-8391-4e4e-ad00-2bc6d00707e6, workerId=QUARTERS_IN_YEAR$20Test.worker_QUARTERS_IN_YEAR$20Test_8e4635e4-a92f-4c21-9416-99f5f7dec73f, startTime=2023-01-26T18:09:00.414310, finishTime=2023-01-26T18:09:00.428123) of size 3
INFO  [2023-01-26 18:09:00,428] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=QUARTERS_IN_YEAR$20Test.44d59c32-8391-4e4e-ad00-2bc6d00707e6, workerId=QUARTERS_IN_YEAR$20Test.worker_QUARTERS_IN_YEAR$20Test_cbb50a63-d20d-4fe6-9293-9c935aac3352, startTime=2023-01-26T18:09:00.414307, finishTime=2023-01-26T18:09:00.428116) of size 4
INFO  [2023-01-26 18:09:00,428] com.bakdata.conquery.models.execution.ManagedExecution: DONE 44d59c32-8391-4e4e-ad00-2bc6d00707e6 ManagedQuery within PT0.017427S
127.0.0.1 - - [26/Jan/2023:18:09:00 +0000] "GET /api/datasets/QUARTERS_IN_YEAR$20Test/queries/QUARTERS_IN_YEAR$20Test.44d59c32-8391-4e4e-ad00-2bc6d00707e6 HTTP/1.1" 200 1494 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:09:00,439] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=QUARTERS_IN_YEAR Test], queryId=44d59c32-8391-4e4e-ad00-2bc6d00707e6, label=concept	@§$, creationTime=2023-01-26T18:09:00.411275, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@4175f755[Count = 0], startTime=2023-01-26T18:09:00.411518, finishTime=2023-01-26T18:09:00.428945, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@34345d28), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_QUARTERS_IN_YEAR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=7, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@48163a22, com.bakdata.conquery.models.query.ColumnDescriptor@2a9427b8]) download on dataset Dataset[label=null, name=QUARTERS_IN_YEAR Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:00,439] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=QUARTERS_IN_YEAR Test], queryId=44d59c32-8391-4e4e-ad00-2bc6d00707e6, label=concept	@§$, creationTime=2023-01-26T18:09:00.411275, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@4175f755[Count = 0], startTime=2023-01-26T18:09:00.411518, finishTime=2023-01-26T18:09:00.428945, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@34345d28), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_QUARTERS_IN_YEAR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=7, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@48163a22, com.bakdata.conquery.models.query.ColumnDescriptor@2a9427b8]) on dataset Dataset[label=null, name=QUARTERS_IN_YEAR Test]
127.0.0.1 - - [26/Jan/2023:18:09:00 +0000] "GET /api/datasets/QUARTERS_IN_YEAR%20Test/result/QUARTERS_IN_YEAR$20Test.44d59c32-8391-4e4e-ad00-2bc6d00707e6.csv?pretty=false HTTP/1.1" 200 197 "-" "Conquery (test client)" 14
INFO  [2023-01-26 18:09:00,451] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest QUARTERS_IN_YEAR Test on 8 rows
INFO  [2023-01-26 18:09:00,451] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast QUARTERS_IN_YEAR Test
INFO  [2023-01-26 18:09:00,451] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=QUARTERS_IN_YEAR Test, name=QUARTERS_IN_YEAR Test]
INFO  [2023-01-26 18:09:00,451] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=QUARTERS_IN_YEAR Test, name=QUARTERS_IN_YEAR Test]
INFO  [2023-01-26 18:09:00,452] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_QUARTERS_IN_YEAR Test_8e4635e4-a92f-4c21-9416-99f5f7dec73f
INFO  [2023-01-26 18:09:00,452] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_QUARTERS_IN_YEAR Test_cbb50a63-d20d-4fe6-9293-9c935aac3352
INFO  [2023-01-26 18:09:00,483] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow QUARTERS_IN_YEAR Test
INFO  [2023-01-26 18:09:00,488] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_QUARTERS_IN_YEAR Test_cbb50a63-d20d-4fe6-9293-9c935aac3352
INFO  [2023-01-26 18:09:00,488] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_QUARTERS_IN_YEAR Test_8e4635e4-a92f-4c21-9416-99f5f7dec73f
INFO  [2023-01-26 18:09:00,493] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of QUARTERS_IN_YEAR$20Test
INFO  [2023-01-26 18:09:00,493] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:00,599] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test QUARTERS_IN_YEAR Test
INFO  [2023-01-26 18:09:00,599] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test SELECT Test
INFO  [2023-01-26 18:09:00,599] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:00,599] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:00,600] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SELECT Test, name=SELECT Test]
INFO  [2023-01-26 18:09:00,600] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:00,600] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SELECT Test, name=SELECT Test]
INFO  [2023-01-26 18:09:00,600] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:00,604] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SELECT$20Test.worker_SELECT$20Test_815e5faf-bdb2-4a6e-9260-64aad5f0921b are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:00,604] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SELECT$20Test.worker_SELECT$20Test_815e5faf-bdb2-4a6e-9260-64aad5f0921b are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:00,604] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:00,604] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SELECT$20Test.worker_SELECT$20Test_786e7ae7-129b-426a-96b4-bf7e5a4bad6d are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:00,604] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SELECT$20Test.worker_SELECT$20Test_786e7ae7-129b-426a-96b4-bf7e5a4bad6d are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:00,604] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:00,606] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:00,717] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:00,717] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SELECT$20Test.table
INFO  [2023-01-26 18:09:00,717] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SELECT$20Test.table
INFO  [2023-01-26 18:09:00,834] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:00,949] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:00,950] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:00,950] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 76 B in total
INFO  [2023-01-26 18:09:00,950] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SELECT Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000225827sINFO  [2023-01-26 18:09:00,973] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=4, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:00,973] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=4, nullLines=0), subType=IntegerParser(super=Parser(lines=4, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@3bdee624)
INFO  [2023-01-26 18:09:00,973] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with StringParser(super=Parser(lines=4, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:00,976] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SELECT Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:00,976] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:00,976] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SELECT Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:00,994] com.bakdata.conquery.models.jobs.ImportJob: Importing table into SELECT$20Test.table
127.0.0.1 - - [26/Jan/2023:18:09:00 +0000] "POST /admin/datasets/SELECT%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_SELECT+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:09:00,995] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:00,995] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:00,996] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:00,996] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:00,998] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:09:00,998] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SELECT$20Test.table.table], containing 4 entries.
INFO  [2023-01-26 18:09:00,998] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SELECT$20Test.table.table], containing 4 entries.
WARN  [2023-01-26 18:09:00,999] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:00,999] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SELECT$20Test.table.table.0
INFO  [2023-01-26 18:09:00,999] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SELECT$20Test.table.table.1
INFO  [2023-01-26 18:09:01,105] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: SELECT Test QUERY INIT
INFO  [2023-01-26 18:09:01,120] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[SELECT$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:01,121] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[0bd3fbba-6a60-4184-aba5-5c382aa21665] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_SELECT Test))]]
INFO  [2023-01-26 18:09:01,124] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SELECT$20Test.0bd3fbba-6a60-4184-aba5-5c382aa21665
INFO  [2023-01-26 18:09:01,124] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SELECT$20Test.0bd3fbba-6a60-4184-aba5-5c382aa21665
127.0.0.1 - - [26/Jan/2023:18:09:01 +0000] "POST /api/datasets/SELECT$20Test/queries HTTP/1.1" 201 1149 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:09:01,125] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SELECT$20Test.0bd3fbba-6a60-4184-aba5-5c382aa21665] with 0 results within PT0.001092S
INFO  [2023-01-26 18:09:01,125] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SELECT$20Test.0bd3fbba-6a60-4184-aba5-5c382aa21665, workerId=SELECT$20Test.worker_SELECT$20Test_786e7ae7-129b-426a-96b4-bf7e5a4bad6d, startTime=2023-01-26T18:09:01.124143, finishTime=2023-01-26T18:09:01.125235) of size 0
INFO  [2023-01-26 18:09:01,137] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SELECT$20Test.0bd3fbba-6a60-4184-aba5-5c382aa21665] with 2 results within PT0.013283S
INFO  [2023-01-26 18:09:01,138] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SELECT$20Test.0bd3fbba-6a60-4184-aba5-5c382aa21665, workerId=SELECT$20Test.worker_SELECT$20Test_815e5faf-bdb2-4a6e-9260-64aad5f0921b, startTime=2023-01-26T18:09:01.124303, finishTime=2023-01-26T18:09:01.137586) of size 2
INFO  [2023-01-26 18:09:01,138] com.bakdata.conquery.models.execution.ManagedExecution: DONE 0bd3fbba-6a60-4184-aba5-5c382aa21665 ManagedQuery within PT0.017416S
127.0.0.1 - - [26/Jan/2023:18:09:01 +0000] "GET /api/datasets/SELECT$20Test/queries/SELECT$20Test.0bd3fbba-6a60-4184-aba5-5c382aa21665 HTTP/1.1" 200 1393 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:09:01,151] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SELECT Test], queryId=0bd3fbba-6a60-4184-aba5-5c382aa21665, label=concept	@§$, creationTime=2023-01-26T18:09:01.120888, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@5fd83e3e[Count = 0], startTime=2023-01-26T18:09:01.121061, finishTime=2023-01-26T18:09:01.138477, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@21b5cf4a), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SELECT Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@48c6ef20, com.bakdata.conquery.models.query.ColumnDescriptor@45cc0906]) download on dataset Dataset[label=null, name=SELECT Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:01,151] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SELECT Test], queryId=0bd3fbba-6a60-4184-aba5-5c382aa21665, label=concept	@§$, creationTime=2023-01-26T18:09:01.120888, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@5fd83e3e[Count = 0], startTime=2023-01-26T18:09:01.121061, finishTime=2023-01-26T18:09:01.138477, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@21b5cf4a), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SELECT Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@48c6ef20, com.bakdata.conquery.models.query.ColumnDescriptor@45cc0906]) on dataset Dataset[label=null, name=SELECT Test]
127.0.0.1 - - [26/Jan/2023:18:09:01 +0000] "GET /api/datasets/SELECT%20Test/result/SELECT$20Test.0bd3fbba-6a60-4184-aba5-5c382aa21665.csv?pretty=false HTTP/1.1" 200 65 "-" "Conquery (test client)" 18
INFO  [2023-01-26 18:09:01,169] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest SELECT Test on 3 rows
INFO  [2023-01-26 18:09:01,169] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast SELECT Test
INFO  [2023-01-26 18:09:01,169] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SELECT Test, name=SELECT Test]
INFO  [2023-01-26 18:09:01,169] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SELECT Test, name=SELECT Test]
INFO  [2023-01-26 18:09:01,169] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SELECT Test_786e7ae7-129b-426a-96b4-bf7e5a4bad6d
INFO  [2023-01-26 18:09:01,169] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SELECT Test_815e5faf-bdb2-4a6e-9260-64aad5f0921b
INFO  [2023-01-26 18:09:01,200] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow SELECT Test
INFO  [2023-01-26 18:09:01,203] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SELECT Test_815e5faf-bdb2-4a6e-9260-64aad5f0921b
INFO  [2023-01-26 18:09:01,207] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SELECT Test_786e7ae7-129b-426a-96b4-bf7e5a4bad6d
INFO  [2023-01-26 18:09:01,299] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of SELECT$20Test
INFO  [2023-01-26 18:09:01,299] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:01,404] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test SELECT Test
INFO  [2023-01-26 18:09:01,404] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test SINGLE_SELECT_EMPTY_VALUES Test
INFO  [2023-01-26 18:09:01,404] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:01,405] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:01,405] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SINGLE_SELECT_EMPTY_VALUES Test, name=SINGLE_SELECT_EMPTY_VALUES Test]
INFO  [2023-01-26 18:09:01,405] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:01,405] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SINGLE_SELECT_EMPTY_VALUES Test, name=SINGLE_SELECT_EMPTY_VALUES Test]
INFO  [2023-01-26 18:09:01,406] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:01,407] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SINGLE_SELECT_EMPTY_VALUES$20Test.worker_SINGLE_SELECT_EMPTY_VALUES$20Test_5ccc640e-ac76-43a0-b203-4c72529268f4 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:01,407] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SINGLE_SELECT_EMPTY_VALUES$20Test.worker_SINGLE_SELECT_EMPTY_VALUES$20Test_5ccc640e-ac76-43a0-b203-4c72529268f4 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:01,407] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:01,407] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SINGLE_SELECT_EMPTY_VALUES$20Test.worker_SINGLE_SELECT_EMPTY_VALUES$20Test_28bfbb28-84f0-49a8-a89d-405edda3c24e are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:01,407] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SINGLE_SELECT_EMPTY_VALUES$20Test.worker_SINGLE_SELECT_EMPTY_VALUES$20Test_28bfbb28-84f0-49a8-a89d-405edda3c24e are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:01,407] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:01,411] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:01,514] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:01,515] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SINGLE_SELECT_EMPTY_VALUES$20Test.table
INFO  [2023-01-26 18:09:01,515] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SINGLE_SELECT_EMPTY_VALUES$20Test.table
INFO  [2023-01-26 18:09:01,625] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:01,735] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:01,735] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:01,735] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 90 B in total
INFO  [2023-01-26 18:09:01,735] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SINGLE_SELECT_EMPTY_VALUES Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000251053sINFO  [2023-01-26 18:09:01,761] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=5, min=1, average=1.250000, max=2}
INFO  [2023-01-26 18:09:01,761] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with StringParser(super=Parser(lines=5, nullLines=1), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:01,761] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=5, nullLines=0), subType=IntegerParser(super=Parser(lines=5, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@4f413846)
INFO  [2023-01-26 18:09:01,769] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SINGLE_SELECT_EMPTY_VALUES Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:01,769] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:01,769] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SINGLE_SELECT_EMPTY_VALUES Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:01,786] com.bakdata.conquery.models.jobs.ImportJob: Importing table into SINGLE_SELECT_EMPTY_VALUES$20Test.table
127.0.0.1 - - [26/Jan/2023:18:09:01 +0000] "POST /admin/datasets/SINGLE_SELECT_EMPTY_VALUES%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_SINGLE_SELECT_EMPTY_VALUES+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:09:01,787] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:01,787] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:01,788] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:01,788] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:01,790] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:09:01,790] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SINGLE_SELECT_EMPTY_VALUES$20Test.table.table], containing 5 entries.
INFO  [2023-01-26 18:09:01,790] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SINGLE_SELECT_EMPTY_VALUES$20Test.table.table], containing 5 entries.
WARN  [2023-01-26 18:09:01,791] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:01,791] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SINGLE_SELECT_EMPTY_VALUES$20Test.table.table.0
INFO  [2023-01-26 18:09:01,791] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SINGLE_SELECT_EMPTY_VALUES$20Test.table.table.1
INFO  [2023-01-26 18:09:01,896] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: SINGLE_SELECT_EMPTY_VALUES Test QUERY INIT
INFO  [2023-01-26 18:09:01,908] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[SINGLE_SELECT_EMPTY_VALUES$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:01,908] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[df0e5f89-2c93-47c0-84d0-02afa83971cc] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_SINGLE_SELECT_EMPTY_VALUES Test))]]
INFO  [2023-01-26 18:09:01,910] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SINGLE_SELECT_EMPTY_VALUES$20Test.df0e5f89-2c93-47c0-84d0-02afa83971cc
INFO  [2023-01-26 18:09:01,910] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SINGLE_SELECT_EMPTY_VALUES$20Test.df0e5f89-2c93-47c0-84d0-02afa83971cc
INFO  [2023-01-26 18:09:01,920] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SINGLE_SELECT_EMPTY_VALUES$20Test.df0e5f89-2c93-47c0-84d0-02afa83971cc] with 0 results within PT0.009656S
INFO  [2023-01-26 18:09:01,920] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SINGLE_SELECT_EMPTY_VALUES$20Test.df0e5f89-2c93-47c0-84d0-02afa83971cc] with 2 results within PT0.009994S
127.0.0.1 - - [26/Jan/2023:18:09:01 +0000] "POST /api/datasets/SINGLE_SELECT_EMPTY_VALUES$20Test/queries HTTP/1.1" 201 1229 "-" "Conquery (test client)" 14
INFO  [2023-01-26 18:09:01,921] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SINGLE_SELECT_EMPTY_VALUES$20Test.df0e5f89-2c93-47c0-84d0-02afa83971cc, workerId=SINGLE_SELECT_EMPTY_VALUES$20Test.worker_SINGLE_SELECT_EMPTY_VALUES$20Test_28bfbb28-84f0-49a8-a89d-405edda3c24e, startTime=2023-01-26T18:09:01.910583, finishTime=2023-01-26T18:09:01.920239) of size 0
INFO  [2023-01-26 18:09:01,921] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SINGLE_SELECT_EMPTY_VALUES$20Test.df0e5f89-2c93-47c0-84d0-02afa83971cc, workerId=SINGLE_SELECT_EMPTY_VALUES$20Test.worker_SINGLE_SELECT_EMPTY_VALUES$20Test_5ccc640e-ac76-43a0-b203-4c72529268f4, startTime=2023-01-26T18:09:01.910583, finishTime=2023-01-26T18:09:01.920577) of size 2
INFO  [2023-01-26 18:09:01,921] com.bakdata.conquery.models.execution.ManagedExecution: DONE df0e5f89-2c93-47c0-84d0-02afa83971cc ManagedQuery within PT0.012704S
127.0.0.1 - - [26/Jan/2023:18:09:01 +0000] "GET /api/datasets/SINGLE_SELECT_EMPTY_VALUES$20Test/queries/SINGLE_SELECT_EMPTY_VALUES$20Test.df0e5f89-2c93-47c0-84d0-02afa83971cc HTTP/1.1" 200 1553 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:09:01,940] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SINGLE_SELECT_EMPTY_VALUES Test], queryId=df0e5f89-2c93-47c0-84d0-02afa83971cc, label=concept	@§$, creationTime=2023-01-26T18:09:01.908316, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@61df63be[Count = 0], startTime=2023-01-26T18:09:01.908503, finishTime=2023-01-26T18:09:01.921207, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@4632f336), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SINGLE_SELECT_EMPTY_VALUES Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@6435a941, com.bakdata.conquery.models.query.ColumnDescriptor@224b1ab3]) download on dataset Dataset[label=null, name=SINGLE_SELECT_EMPTY_VALUES Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:01,941] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SINGLE_SELECT_EMPTY_VALUES Test], queryId=df0e5f89-2c93-47c0-84d0-02afa83971cc, label=concept	@§$, creationTime=2023-01-26T18:09:01.908316, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@61df63be[Count = 0], startTime=2023-01-26T18:09:01.908503, finishTime=2023-01-26T18:09:01.921207, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@4632f336), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SINGLE_SELECT_EMPTY_VALUES Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@6435a941, com.bakdata.conquery.models.query.ColumnDescriptor@224b1ab3]) on dataset Dataset[label=null, name=SINGLE_SELECT_EMPTY_VALUES Test]
127.0.0.1 - - [26/Jan/2023:18:09:01 +0000] "GET /api/datasets/SINGLE_SELECT_EMPTY_VALUES%20Test/result/SINGLE_SELECT_EMPTY_VALUES$20Test.df0e5f89-2c93-47c0-84d0-02afa83971cc.csv?pretty=false HTTP/1.1" 200 65 "-" "Conquery (test client)" 17
INFO  [2023-01-26 18:09:01,957] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest SINGLE_SELECT_EMPTY_VALUES Test on 3 rows
INFO  [2023-01-26 18:09:01,957] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast SINGLE_SELECT_EMPTY_VALUES Test
INFO  [2023-01-26 18:09:01,957] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SINGLE_SELECT_EMPTY_VALUES Test, name=SINGLE_SELECT_EMPTY_VALUES Test]
INFO  [2023-01-26 18:09:01,957] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SINGLE_SELECT_EMPTY_VALUES Test, name=SINGLE_SELECT_EMPTY_VALUES Test]
INFO  [2023-01-26 18:09:01,957] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SINGLE_SELECT_EMPTY_VALUES Test_28bfbb28-84f0-49a8-a89d-405edda3c24e
INFO  [2023-01-26 18:09:01,957] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SINGLE_SELECT_EMPTY_VALUES Test_5ccc640e-ac76-43a0-b203-4c72529268f4
INFO  [2023-01-26 18:09:02,005] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow SINGLE_SELECT_EMPTY_VALUES Test
INFO  [2023-01-26 18:09:02,006] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SINGLE_SELECT_EMPTY_VALUES Test_5ccc640e-ac76-43a0-b203-4c72529268f4
INFO  [2023-01-26 18:09:02,006] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SINGLE_SELECT_EMPTY_VALUES Test_28bfbb28-84f0-49a8-a89d-405edda3c24e
INFO  [2023-01-26 18:09:02,091] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of SINGLE_SELECT_EMPTY_VALUES$20Test
INFO  [2023-01-26 18:09:02,091] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:02,196] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test SINGLE_SELECT_EMPTY_VALUES Test
INFO  [2023-01-26 18:09:02,196] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test SINGLE_SELECT_SPEZIAL_CHARACTER Test
INFO  [2023-01-26 18:09:02,196] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:02,196] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:02,200] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SINGLE_SELECT_SPEZIAL_CHARACTER Test, name=SINGLE_SELECT_SPEZIAL_CHARACTER Test]
INFO  [2023-01-26 18:09:02,200] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SINGLE_SELECT_SPEZIAL_CHARACTER Test, name=SINGLE_SELECT_SPEZIAL_CHARACTER Test]
INFO  [2023-01-26 18:09:02,200] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:02,200] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:02,202] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SINGLE_SELECT_SPEZIAL_CHARACTER$20Test.worker_SINGLE_SELECT_SPEZIAL_CHARACTER$20Test_f1c52b7e-dd99-415d-9fb2-c335d9182507 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:02,202] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SINGLE_SELECT_SPEZIAL_CHARACTER$20Test.worker_SINGLE_SELECT_SPEZIAL_CHARACTER$20Test_f1c52b7e-dd99-415d-9fb2-c335d9182507 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:02,202] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:02,202] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SINGLE_SELECT_SPEZIAL_CHARACTER$20Test.worker_SINGLE_SELECT_SPEZIAL_CHARACTER$20Test_3c9dd29c-adfc-4b88-b18c-ce6ab2894acd are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:02,202] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SINGLE_SELECT_SPEZIAL_CHARACTER$20Test.worker_SINGLE_SELECT_SPEZIAL_CHARACTER$20Test_3c9dd29c-adfc-4b88-b18c-ce6ab2894acd are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:02,202] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:02,206] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:02,307] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:02,308] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SINGLE_SELECT_SPEZIAL_CHARACTER$20Test.table
INFO  [2023-01-26 18:09:02,308] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SINGLE_SELECT_SPEZIAL_CHARACTER$20Test.table
INFO  [2023-01-26 18:09:02,418] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:02,530] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:02,530] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:02,530] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 92 B in total
INFO  [2023-01-26 18:09:02,530] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SINGLE_SELECT_SPEZIAL_CHARACTER Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000455441sINFO  [2023-01-26 18:09:02,577] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=5, min=1, average=1.250000, max=2}
INFO  [2023-01-26 18:09:02,577] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=5, nullLines=0), subType=IntegerParser(super=Parser(lines=5, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@5943df60)
INFO  [2023-01-26 18:09:02,577] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with StringParser(super=Parser(lines=5, nullLines=1), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:02,582] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SINGLE_SELECT_SPEZIAL_CHARACTER Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:02,584] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:02,585] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SINGLE_SELECT_SPEZIAL_CHARACTER Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:02,603] com.bakdata.conquery.models.jobs.ImportJob: Importing table into SINGLE_SELECT_SPEZIAL_CHARACTER$20Test.table
INFO  [2023-01-26 18:09:02,605] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:02,605] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:02,605] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:02,607] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:09:02,608] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SINGLE_SELECT_SPEZIAL_CHARACTER$20Test.table.table], containing 5 entries.
INFO  [2023-01-26 18:09:02,609] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SINGLE_SELECT_SPEZIAL_CHARACTER$20Test.table.table], containing 5 entries.
INFO  [2023-01-26 18:09:02,609] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SINGLE_SELECT_SPEZIAL_CHARACTER$20Test.table.table.0
WARN  [2023-01-26 18:09:02,610] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:02,610] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SINGLE_SELECT_SPEZIAL_CHARACTER$20Test.table.table.1
127.0.0.1 - - [26/Jan/2023:18:09:02 +0000] "POST /admin/datasets/SINGLE_SELECT_SPEZIAL_CHARACTER%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_SINGLE_SELECT_SPEZIAL_CHARACTER+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 16
INFO  [2023-01-26 18:09:02,611] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:02,611] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:02,611] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:02,737] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: SINGLE_SELECT_SPEZIAL_CHARACTER Test QUERY INIT
INFO  [2023-01-26 18:09:02,748] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[SINGLE_SELECT_SPEZIAL_CHARACTER$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:02,748] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[f0407192-5007-4cc6-9d82-62e9d2f105ef] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_SINGLE_SELECT_SPEZIAL_CHARACTER Test))]]
INFO  [2023-01-26 18:09:02,750] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SINGLE_SELECT_SPEZIAL_CHARACTER$20Test.f0407192-5007-4cc6-9d82-62e9d2f105ef
INFO  [2023-01-26 18:09:02,750] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SINGLE_SELECT_SPEZIAL_CHARACTER$20Test.f0407192-5007-4cc6-9d82-62e9d2f105ef
INFO  [2023-01-26 18:09:02,751] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SINGLE_SELECT_SPEZIAL_CHARACTER$20Test.f0407192-5007-4cc6-9d82-62e9d2f105ef] with 0 results within PT0.000668S
INFO  [2023-01-26 18:09:02,751] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SINGLE_SELECT_SPEZIAL_CHARACTER$20Test.f0407192-5007-4cc6-9d82-62e9d2f105ef] with 1 results within PT0.000693S
127.0.0.1 - - [26/Jan/2023:18:09:02 +0000] "POST /api/datasets/SINGLE_SELECT_SPEZIAL_CHARACTER$20Test/queries HTTP/1.1" 201 1249 "-" "Conquery (test client)" 5
INFO  [2023-01-26 18:09:02,751] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SINGLE_SELECT_SPEZIAL_CHARACTER$20Test.f0407192-5007-4cc6-9d82-62e9d2f105ef, workerId=SINGLE_SELECT_SPEZIAL_CHARACTER$20Test.worker_SINGLE_SELECT_SPEZIAL_CHARACTER$20Test_f1c52b7e-dd99-415d-9fb2-c335d9182507, startTime=2023-01-26T18:09:02.750554, finishTime=2023-01-26T18:09:02.751222) of size 0
INFO  [2023-01-26 18:09:02,751] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SINGLE_SELECT_SPEZIAL_CHARACTER$20Test.f0407192-5007-4cc6-9d82-62e9d2f105ef, workerId=SINGLE_SELECT_SPEZIAL_CHARACTER$20Test.worker_SINGLE_SELECT_SPEZIAL_CHARACTER$20Test_3c9dd29c-adfc-4b88-b18c-ce6ab2894acd, startTime=2023-01-26T18:09:02.750577, finishTime=2023-01-26T18:09:02.751270) of size 1
INFO  [2023-01-26 18:09:02,751] com.bakdata.conquery.models.execution.ManagedExecution: DONE f0407192-5007-4cc6-9d82-62e9d2f105ef ManagedQuery within PT0.003413S
127.0.0.1 - - [26/Jan/2023:18:09:02 +0000] "GET /api/datasets/SINGLE_SELECT_SPEZIAL_CHARACTER$20Test/queries/SINGLE_SELECT_SPEZIAL_CHARACTER$20Test.f0407192-5007-4cc6-9d82-62e9d2f105ef HTTP/1.1" 200 1592 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:09:02,768] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SINGLE_SELECT_SPEZIAL_CHARACTER Test], queryId=f0407192-5007-4cc6-9d82-62e9d2f105ef, label=concept	@§$, creationTime=2023-01-26T18:09:02.748401, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@7bfd0c52[Count = 0], startTime=2023-01-26T18:09:02.748569, finishTime=2023-01-26T18:09:02.751982, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@3fa0ae66), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SINGLE_SELECT_SPEZIAL_CHARACTER Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@6ebf56d0, com.bakdata.conquery.models.query.ColumnDescriptor@7d0c3431]) download on dataset Dataset[label=null, name=SINGLE_SELECT_SPEZIAL_CHARACTER Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:02,769] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SINGLE_SELECT_SPEZIAL_CHARACTER Test], queryId=f0407192-5007-4cc6-9d82-62e9d2f105ef, label=concept	@§$, creationTime=2023-01-26T18:09:02.748401, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@7bfd0c52[Count = 0], startTime=2023-01-26T18:09:02.748569, finishTime=2023-01-26T18:09:02.751982, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@3fa0ae66), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SINGLE_SELECT_SPEZIAL_CHARACTER Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@6ebf56d0, com.bakdata.conquery.models.query.ColumnDescriptor@7d0c3431]) on dataset Dataset[label=null, name=SINGLE_SELECT_SPEZIAL_CHARACTER Test]
127.0.0.1 - - [26/Jan/2023:18:09:02 +0000] "GET /api/datasets/SINGLE_SELECT_SPEZIAL_CHARACTER%20Test/result/SINGLE_SELECT_SPEZIAL_CHARACTER$20Test.f0407192-5007-4cc6-9d82-62e9d2f105ef.csv?pretty=false HTTP/1.1" 200 39 "-" "Conquery (test client)" 17
INFO  [2023-01-26 18:09:02,784] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest SINGLE_SELECT_SPEZIAL_CHARACTER Test on 2 rows
INFO  [2023-01-26 18:09:02,784] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast SINGLE_SELECT_SPEZIAL_CHARACTER Test
INFO  [2023-01-26 18:09:02,784] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SINGLE_SELECT_SPEZIAL_CHARACTER Test, name=SINGLE_SELECT_SPEZIAL_CHARACTER Test]
INFO  [2023-01-26 18:09:02,785] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SINGLE_SELECT_SPEZIAL_CHARACTER Test_3c9dd29c-adfc-4b88-b18c-ce6ab2894acd
INFO  [2023-01-26 18:09:02,785] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SINGLE_SELECT_SPEZIAL_CHARACTER Test, name=SINGLE_SELECT_SPEZIAL_CHARACTER Test]
INFO  [2023-01-26 18:09:02,785] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SINGLE_SELECT_SPEZIAL_CHARACTER Test_f1c52b7e-dd99-415d-9fb2-c335d9182507
INFO  [2023-01-26 18:09:02,800] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow SINGLE_SELECT_SPEZIAL_CHARACTER Test
INFO  [2023-01-26 18:09:02,801] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SINGLE_SELECT_SPEZIAL_CHARACTER Test_f1c52b7e-dd99-415d-9fb2-c335d9182507
INFO  [2023-01-26 18:09:02,801] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SINGLE_SELECT_SPEZIAL_CHARACTER Test_3c9dd29c-adfc-4b88-b18c-ce6ab2894acd
INFO  [2023-01-26 18:09:02,810] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of SINGLE_SELECT_SPEZIAL_CHARACTER$20Test
INFO  [2023-01-26 18:09:02,810] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:02,937] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test SINGLE_SELECT_SPEZIAL_CHARACTER Test
INFO  [2023-01-26 18:09:02,938] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test SINGLE_SELECT_SPEZIAL_CHARACTER2 Test
INFO  [2023-01-26 18:09:02,938] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:02,938] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:02,944] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SINGLE_SELECT_SPEZIAL_CHARACTER2 Test, name=SINGLE_SELECT_SPEZIAL_CHARACTER2 Test]
INFO  [2023-01-26 18:09:02,944] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SINGLE_SELECT_SPEZIAL_CHARACTER2 Test, name=SINGLE_SELECT_SPEZIAL_CHARACTER2 Test]
INFO  [2023-01-26 18:09:02,944] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:02,944] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:02,951] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SINGLE_SELECT_SPEZIAL_CHARACTER2$20Test.worker_SINGLE_SELECT_SPEZIAL_CHARACTER2$20Test_c78c9dcf-3c15-4f4e-ba97-003783d6627d are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:02,951] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SINGLE_SELECT_SPEZIAL_CHARACTER2$20Test.worker_SINGLE_SELECT_SPEZIAL_CHARACTER2$20Test_c78c9dcf-3c15-4f4e-ba97-003783d6627d are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:02,951] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:02,951] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SINGLE_SELECT_SPEZIAL_CHARACTER2$20Test.worker_SINGLE_SELECT_SPEZIAL_CHARACTER2$20Test_f6715b89-def1-432f-8cd1-a2fb6a09edfe are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:02,951] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SINGLE_SELECT_SPEZIAL_CHARACTER2$20Test.worker_SINGLE_SELECT_SPEZIAL_CHARACTER2$20Test_f6715b89-def1-432f-8cd1-a2fb6a09edfe are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:02,951] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:02,955] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:03,057] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:03,058] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SINGLE_SELECT_SPEZIAL_CHARACTER2$20Test.table
INFO  [2023-01-26 18:09:03,058] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SINGLE_SELECT_SPEZIAL_CHARACTER2$20Test.table
INFO  [2023-01-26 18:09:03,169] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:03,278] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:03,279] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:03,279] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 105 B in total
INFO  [2023-01-26 18:09:03,279] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SINGLE_SELECT_SPEZIAL_CHARACTER2 Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000555018sINFO  [2023-01-26 18:09:03,335] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=5, sum=6, min=1, average=1.200000, max=2}
INFO  [2023-01-26 18:09:03,335] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with StringParser(super=Parser(lines=6, nullLines=1), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:03,335] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@152ff90e)
INFO  [2023-01-26 18:09:03,342] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SINGLE_SELECT_SPEZIAL_CHARACTER2 Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:03,342] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:03,342] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SINGLE_SELECT_SPEZIAL_CHARACTER2 Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:03,364] com.bakdata.conquery.models.jobs.ImportJob: Importing table into SINGLE_SELECT_SPEZIAL_CHARACTER2$20Test.table
127.0.0.1 - - [26/Jan/2023:18:09:03 +0000] "POST /admin/datasets/SINGLE_SELECT_SPEZIAL_CHARACTER2%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_SINGLE_SELECT_SPEZIAL_CHARACTER2+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:09:03,365] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:03,365] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:03,365] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:03,365] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:03,367] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:09:03,378] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SINGLE_SELECT_SPEZIAL_CHARACTER2$20Test.table.table], containing 6 entries.
INFO  [2023-01-26 18:09:03,378] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SINGLE_SELECT_SPEZIAL_CHARACTER2$20Test.table.table], containing 6 entries.
WARN  [2023-01-26 18:09:03,379] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:03,379] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SINGLE_SELECT_SPEZIAL_CHARACTER2$20Test.table.table.0
INFO  [2023-01-26 18:09:03,379] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SINGLE_SELECT_SPEZIAL_CHARACTER2$20Test.table.table.1
INFO  [2023-01-26 18:09:03,485] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: SINGLE_SELECT_SPEZIAL_CHARACTER2 Test QUERY INIT
INFO  [2023-01-26 18:09:03,497] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[SINGLE_SELECT_SPEZIAL_CHARACTER2$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:03,498] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[7cdf59ec-d648-4f6c-9963-8a5889e679f1] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_SINGLE_SELECT_SPEZIAL_CHARACTER2 Test))]]
INFO  [2023-01-26 18:09:03,501] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SINGLE_SELECT_SPEZIAL_CHARACTER2$20Test.7cdf59ec-d648-4f6c-9963-8a5889e679f1
INFO  [2023-01-26 18:09:03,501] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SINGLE_SELECT_SPEZIAL_CHARACTER2$20Test.7cdf59ec-d648-4f6c-9963-8a5889e679f1
INFO  [2023-01-26 18:09:03,502] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SINGLE_SELECT_SPEZIAL_CHARACTER2$20Test.7cdf59ec-d648-4f6c-9963-8a5889e679f1] with 0 results within PT0.000848S
127.0.0.1 - - [26/Jan/2023:18:09:03 +0000] "POST /api/datasets/SINGLE_SELECT_SPEZIAL_CHARACTER2$20Test/queries HTTP/1.1" 201 1253 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:09:03,502] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SINGLE_SELECT_SPEZIAL_CHARACTER2$20Test.7cdf59ec-d648-4f6c-9963-8a5889e679f1, workerId=SINGLE_SELECT_SPEZIAL_CHARACTER2$20Test.worker_SINGLE_SELECT_SPEZIAL_CHARACTER2$20Test_f6715b89-def1-432f-8cd1-a2fb6a09edfe, startTime=2023-01-26T18:09:03.501364, finishTime=2023-01-26T18:09:03.502212) of size 0
INFO  [2023-01-26 18:09:03,503] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SINGLE_SELECT_SPEZIAL_CHARACTER2$20Test.7cdf59ec-d648-4f6c-9963-8a5889e679f1] with 1 results within PT0.001785S
INFO  [2023-01-26 18:09:03,503] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SINGLE_SELECT_SPEZIAL_CHARACTER2$20Test.7cdf59ec-d648-4f6c-9963-8a5889e679f1, workerId=SINGLE_SELECT_SPEZIAL_CHARACTER2$20Test.worker_SINGLE_SELECT_SPEZIAL_CHARACTER2$20Test_c78c9dcf-3c15-4f4e-ba97-003783d6627d, startTime=2023-01-26T18:09:03.501390, finishTime=2023-01-26T18:09:03.503175) of size 1
INFO  [2023-01-26 18:09:03,503] com.bakdata.conquery.models.execution.ManagedExecution: DONE 7cdf59ec-d648-4f6c-9963-8a5889e679f1 ManagedQuery within PT0.005423S
127.0.0.1 - - [26/Jan/2023:18:09:03 +0000] "GET /api/datasets/SINGLE_SELECT_SPEZIAL_CHARACTER2$20Test/queries/SINGLE_SELECT_SPEZIAL_CHARACTER2$20Test.7cdf59ec-d648-4f6c-9963-8a5889e679f1 HTTP/1.1" 200 1600 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:09:03,532] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SINGLE_SELECT_SPEZIAL_CHARACTER2 Test], queryId=7cdf59ec-d648-4f6c-9963-8a5889e679f1, label=concept	@§$, creationTime=2023-01-26T18:09:03.498237, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@232579c1[Count = 0], startTime=2023-01-26T18:09:03.498451, finishTime=2023-01-26T18:09:03.503874, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@605c4070), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SINGLE_SELECT_SPEZIAL_CHARACTER2 Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@1946a20f, com.bakdata.conquery.models.query.ColumnDescriptor@66fb5a1c]) download on dataset Dataset[label=null, name=SINGLE_SELECT_SPEZIAL_CHARACTER2 Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:03,532] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SINGLE_SELECT_SPEZIAL_CHARACTER2 Test], queryId=7cdf59ec-d648-4f6c-9963-8a5889e679f1, label=concept	@§$, creationTime=2023-01-26T18:09:03.498237, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@232579c1[Count = 0], startTime=2023-01-26T18:09:03.498451, finishTime=2023-01-26T18:09:03.503874, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@605c4070), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SINGLE_SELECT_SPEZIAL_CHARACTER2 Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@1946a20f, com.bakdata.conquery.models.query.ColumnDescriptor@66fb5a1c]) on dataset Dataset[label=null, name=SINGLE_SELECT_SPEZIAL_CHARACTER2 Test]
127.0.0.1 - - [26/Jan/2023:18:09:03 +0000] "GET /api/datasets/SINGLE_SELECT_SPEZIAL_CHARACTER2%20Test/result/SINGLE_SELECT_SPEZIAL_CHARACTER2$20Test.7cdf59ec-d648-4f6c-9963-8a5889e679f1.csv?pretty=false HTTP/1.1" 200 39 "-" "Conquery (test client)" 19
INFO  [2023-01-26 18:09:03,550] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest SINGLE_SELECT_SPEZIAL_CHARACTER2 Test on 2 rows
INFO  [2023-01-26 18:09:03,550] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast SINGLE_SELECT_SPEZIAL_CHARACTER2 Test
INFO  [2023-01-26 18:09:03,551] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SINGLE_SELECT_SPEZIAL_CHARACTER2 Test, name=SINGLE_SELECT_SPEZIAL_CHARACTER2 Test]
INFO  [2023-01-26 18:09:03,551] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SINGLE_SELECT_SPEZIAL_CHARACTER2 Test, name=SINGLE_SELECT_SPEZIAL_CHARACTER2 Test]
INFO  [2023-01-26 18:09:03,551] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SINGLE_SELECT_SPEZIAL_CHARACTER2 Test_f6715b89-def1-432f-8cd1-a2fb6a09edfe
INFO  [2023-01-26 18:09:03,551] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SINGLE_SELECT_SPEZIAL_CHARACTER2 Test_c78c9dcf-3c15-4f4e-ba97-003783d6627d
INFO  [2023-01-26 18:09:03,649] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow SINGLE_SELECT_SPEZIAL_CHARACTER2 Test
INFO  [2023-01-26 18:09:03,650] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SINGLE_SELECT_SPEZIAL_CHARACTER2 Test_c78c9dcf-3c15-4f4e-ba97-003783d6627d
INFO  [2023-01-26 18:09:03,650] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SINGLE_SELECT_SPEZIAL_CHARACTER2 Test_f6715b89-def1-432f-8cd1-a2fb6a09edfe
INFO  [2023-01-26 18:09:03,679] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of SINGLE_SELECT_SPEZIAL_CHARACTER2$20Test
INFO  [2023-01-26 18:09:03,679] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:03,785] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test SINGLE_SELECT_SPEZIAL_CHARACTER2 Test
INFO  [2023-01-26 18:09:03,785] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test SINGLE_SELECT_SPEZIAL_CHARACTER3 Test
INFO  [2023-01-26 18:09:03,785] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:03,785] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:03,788] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SINGLE_SELECT_SPEZIAL_CHARACTER3 Test, name=SINGLE_SELECT_SPEZIAL_CHARACTER3 Test]
INFO  [2023-01-26 18:09:03,788] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SINGLE_SELECT_SPEZIAL_CHARACTER3 Test, name=SINGLE_SELECT_SPEZIAL_CHARACTER3 Test]
INFO  [2023-01-26 18:09:03,788] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:03,788] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:03,865] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SINGLE_SELECT_SPEZIAL_CHARACTER3$20Test.worker_SINGLE_SELECT_SPEZIAL_CHARACTER3$20Test_228f7a2c-6c6f-4838-a57a-52bf52cc01c6 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:03,865] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SINGLE_SELECT_SPEZIAL_CHARACTER3$20Test.worker_SINGLE_SELECT_SPEZIAL_CHARACTER3$20Test_228f7a2c-6c6f-4838-a57a-52bf52cc01c6 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:03,865] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:03,865] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SINGLE_SELECT_SPEZIAL_CHARACTER3$20Test.worker_SINGLE_SELECT_SPEZIAL_CHARACTER3$20Test_c1700109-2eda-4430-b5ec-a0f0b306eaea are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:03,865] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SINGLE_SELECT_SPEZIAL_CHARACTER3$20Test.worker_SINGLE_SELECT_SPEZIAL_CHARACTER3$20Test_c1700109-2eda-4430-b5ec-a0f0b306eaea are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:03,865] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:03,868] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:03,972] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:03,973] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SINGLE_SELECT_SPEZIAL_CHARACTER3$20Test.table
INFO  [2023-01-26 18:09:03,973] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SINGLE_SELECT_SPEZIAL_CHARACTER3$20Test.table
INFO  [2023-01-26 18:09:04,085] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:04,198] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:04,198] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:04,198] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 105 B in total
INFO  [2023-01-26 18:09:04,198] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SINGLE_SELECT_SPEZIAL_CHARACTER3 Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000156651sINFO  [2023-01-26 18:09:04,214] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=5, sum=6, min=1, average=1.200000, max=2}
INFO  [2023-01-26 18:09:04,214] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@1c7a772)
INFO  [2023-01-26 18:09:04,214] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with StringParser(super=Parser(lines=6, nullLines=1), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:04,217] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SINGLE_SELECT_SPEZIAL_CHARACTER3 Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:04,218] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:04,218] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SINGLE_SELECT_SPEZIAL_CHARACTER3 Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:04,235] com.bakdata.conquery.models.jobs.ImportJob: Importing table into SINGLE_SELECT_SPEZIAL_CHARACTER3$20Test.table
127.0.0.1 - - [26/Jan/2023:18:09:04 +0000] "POST /admin/datasets/SINGLE_SELECT_SPEZIAL_CHARACTER3%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_SINGLE_SELECT_SPEZIAL_CHARACTER3+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:09:04,235] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:04,236] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:04,236] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:04,236] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:04,238] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:09:04,238] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SINGLE_SELECT_SPEZIAL_CHARACTER3$20Test.table.table], containing 6 entries.
INFO  [2023-01-26 18:09:04,238] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SINGLE_SELECT_SPEZIAL_CHARACTER3$20Test.table.table], containing 6 entries.
INFO  [2023-01-26 18:09:04,239] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SINGLE_SELECT_SPEZIAL_CHARACTER3$20Test.table.table.0
WARN  [2023-01-26 18:09:04,239] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:04,239] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SINGLE_SELECT_SPEZIAL_CHARACTER3$20Test.table.table.1
INFO  [2023-01-26 18:09:04,344] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: SINGLE_SELECT_SPEZIAL_CHARACTER3 Test QUERY INIT
INFO  [2023-01-26 18:09:04,356] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[SINGLE_SELECT_SPEZIAL_CHARACTER3$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:04,357] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[42fa95d8-fed3-4a87-a0e3-23bcb5cb2ae9] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_SINGLE_SELECT_SPEZIAL_CHARACTER3 Test))]]
INFO  [2023-01-26 18:09:04,359] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SINGLE_SELECT_SPEZIAL_CHARACTER3$20Test.42fa95d8-fed3-4a87-a0e3-23bcb5cb2ae9
INFO  [2023-01-26 18:09:04,359] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SINGLE_SELECT_SPEZIAL_CHARACTER3$20Test.42fa95d8-fed3-4a87-a0e3-23bcb5cb2ae9
127.0.0.1 - - [26/Jan/2023:18:09:04 +0000] "POST /api/datasets/SINGLE_SELECT_SPEZIAL_CHARACTER3$20Test/queries HTTP/1.1" 201 1253 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:09:04,361] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SINGLE_SELECT_SPEZIAL_CHARACTER3$20Test.42fa95d8-fed3-4a87-a0e3-23bcb5cb2ae9] with 1 results within PT0.00137S
INFO  [2023-01-26 18:09:04,361] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SINGLE_SELECT_SPEZIAL_CHARACTER3$20Test.42fa95d8-fed3-4a87-a0e3-23bcb5cb2ae9] with 0 results within PT0.001449S
INFO  [2023-01-26 18:09:04,361] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SINGLE_SELECT_SPEZIAL_CHARACTER3$20Test.42fa95d8-fed3-4a87-a0e3-23bcb5cb2ae9, workerId=SINGLE_SELECT_SPEZIAL_CHARACTER3$20Test.worker_SINGLE_SELECT_SPEZIAL_CHARACTER3$20Test_228f7a2c-6c6f-4838-a57a-52bf52cc01c6, startTime=2023-01-26T18:09:04.359638, finishTime=2023-01-26T18:09:04.361087) of size 0
INFO  [2023-01-26 18:09:04,361] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SINGLE_SELECT_SPEZIAL_CHARACTER3$20Test.42fa95d8-fed3-4a87-a0e3-23bcb5cb2ae9, workerId=SINGLE_SELECT_SPEZIAL_CHARACTER3$20Test.worker_SINGLE_SELECT_SPEZIAL_CHARACTER3$20Test_c1700109-2eda-4430-b5ec-a0f0b306eaea, startTime=2023-01-26T18:09:04.359708, finishTime=2023-01-26T18:09:04.361078) of size 1
INFO  [2023-01-26 18:09:04,361] com.bakdata.conquery.models.execution.ManagedExecution: DONE 42fa95d8-fed3-4a87-a0e3-23bcb5cb2ae9 ManagedQuery within PT0.004603S
127.0.0.1 - - [26/Jan/2023:18:09:04 +0000] "GET /api/datasets/SINGLE_SELECT_SPEZIAL_CHARACTER3$20Test/queries/SINGLE_SELECT_SPEZIAL_CHARACTER3$20Test.42fa95d8-fed3-4a87-a0e3-23bcb5cb2ae9 HTTP/1.1" 200 1600 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:09:04,381] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SINGLE_SELECT_SPEZIAL_CHARACTER3 Test], queryId=42fa95d8-fed3-4a87-a0e3-23bcb5cb2ae9, label=concept	@§$, creationTime=2023-01-26T18:09:04.357044, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@3e04ac09[Count = 0], startTime=2023-01-26T18:09:04.357233, finishTime=2023-01-26T18:09:04.361836, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@71ec55da), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SINGLE_SELECT_SPEZIAL_CHARACTER3 Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@79775575, com.bakdata.conquery.models.query.ColumnDescriptor@18d9b1b2]) download on dataset Dataset[label=null, name=SINGLE_SELECT_SPEZIAL_CHARACTER3 Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:04,382] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SINGLE_SELECT_SPEZIAL_CHARACTER3 Test], queryId=42fa95d8-fed3-4a87-a0e3-23bcb5cb2ae9, label=concept	@§$, creationTime=2023-01-26T18:09:04.357044, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@3e04ac09[Count = 0], startTime=2023-01-26T18:09:04.357233, finishTime=2023-01-26T18:09:04.361836, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@71ec55da), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SINGLE_SELECT_SPEZIAL_CHARACTER3 Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@79775575, com.bakdata.conquery.models.query.ColumnDescriptor@18d9b1b2]) on dataset Dataset[label=null, name=SINGLE_SELECT_SPEZIAL_CHARACTER3 Test]
127.0.0.1 - - [26/Jan/2023:18:09:04 +0000] "GET /api/datasets/SINGLE_SELECT_SPEZIAL_CHARACTER3%20Test/result/SINGLE_SELECT_SPEZIAL_CHARACTER3$20Test.42fa95d8-fed3-4a87-a0e3-23bcb5cb2ae9.csv?pretty=false HTTP/1.1" 200 39 "-" "Conquery (test client)" 23
INFO  [2023-01-26 18:09:04,403] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest SINGLE_SELECT_SPEZIAL_CHARACTER3 Test on 2 rows
INFO  [2023-01-26 18:09:04,403] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast SINGLE_SELECT_SPEZIAL_CHARACTER3 Test
INFO  [2023-01-26 18:09:04,404] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SINGLE_SELECT_SPEZIAL_CHARACTER3 Test, name=SINGLE_SELECT_SPEZIAL_CHARACTER3 Test]
INFO  [2023-01-26 18:09:04,404] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SINGLE_SELECT_SPEZIAL_CHARACTER3 Test, name=SINGLE_SELECT_SPEZIAL_CHARACTER3 Test]
INFO  [2023-01-26 18:09:04,404] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SINGLE_SELECT_SPEZIAL_CHARACTER3 Test_c1700109-2eda-4430-b5ec-a0f0b306eaea
INFO  [2023-01-26 18:09:04,404] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SINGLE_SELECT_SPEZIAL_CHARACTER3 Test_228f7a2c-6c6f-4838-a57a-52bf52cc01c6
INFO  [2023-01-26 18:09:04,468] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SINGLE_SELECT_SPEZIAL_CHARACTER3 Test_c1700109-2eda-4430-b5ec-a0f0b306eaea
INFO  [2023-01-26 18:09:04,468] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SINGLE_SELECT_SPEZIAL_CHARACTER3 Test_228f7a2c-6c6f-4838-a57a-52bf52cc01c6
INFO  [2023-01-26 18:09:04,502] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow SINGLE_SELECT_SPEZIAL_CHARACTER3 Test
INFO  [2023-01-26 18:09:04,539] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of SINGLE_SELECT_SPEZIAL_CHARACTER3$20Test
INFO  [2023-01-26 18:09:04,539] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:04,644] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test SINGLE_SELECT_SPEZIAL_CHARACTER3 Test
INFO  [2023-01-26 18:09:04,645] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test SUM_DECIMAL
INFO  [2023-01-26 18:09:04,645] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:04,645] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:04,650] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SUM_DECIMAL, name=SUM_DECIMAL]
INFO  [2023-01-26 18:09:04,650] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SUM_DECIMAL, name=SUM_DECIMAL]
INFO  [2023-01-26 18:09:04,650] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:04,650] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:04,652] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SUM_DECIMAL.worker_SUM_DECIMAL_6d0037a7-d93a-4fa3-a158-f90d5db52682 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:04,652] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SUM_DECIMAL.worker_SUM_DECIMAL_6d0037a7-d93a-4fa3-a158-f90d5db52682 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:04,652] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:04,652] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SUM_DECIMAL.worker_SUM_DECIMAL_399bd206-aa92-46ec-ba8f-a25843ca8797 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:04,652] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SUM_DECIMAL.worker_SUM_DECIMAL_399bd206-aa92-46ec-ba8f-a25843ca8797 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:04,652] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:04,656] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:04,759] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:04,760] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SUM_DECIMAL.table
INFO  [2023-01-26 18:09:04,760] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SUM_DECIMAL.table
INFO  [2023-01-26 18:09:04,873] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:04,985] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:04,985] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:04,986] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 185 B in total
INFO  [2023-01-26 18:09:04,986] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SUM_DECIMAL/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000457449sINFO  [2023-01-26 18:09:05,032] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=6, sum=10, min=1, average=1.666667, max=4}
INFO  [2023-01-26 18:09:05,032] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[plus] with DecimalParser(super=Parser(lines=10, nullLines=0), maxScale=0, maxAbs=250)
INFO  [2023-01-26 18:09:05,032] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=10, nullLines=0), subType=IntegerParser(super=Parser(lines=10, nullLines=0), minValue=16511, maxValue=16514), dateReader=com.bakdata.conquery.util.DateReader@3f796227)
INFO  [2023-01-26 18:09:05,035] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SUM_DECIMAL/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:05,035] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:05,035] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SUM_DECIMAL/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:05,053] com.bakdata.conquery.models.jobs.ImportJob: Importing table into SUM_DECIMAL.table
127.0.0.1 - - [26/Jan/2023:18:09:05 +0000] "POST /admin/datasets/SUM_DECIMAL/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_SUM_DECIMAL%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:09:05,054] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:05,054] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:05,055] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:05,055] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:05,056] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:09:05,057] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SUM_DECIMAL.table.table], containing 10 entries.
INFO  [2023-01-26 18:09:05,057] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SUM_DECIMAL.table.table], containing 10 entries.
WARN  [2023-01-26 18:09:05,058] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:05,058] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SUM_DECIMAL.table.table.0
INFO  [2023-01-26 18:09:05,058] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SUM_DECIMAL.table.table.1
INFO  [2023-01-26 18:09:05,162] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: SUM_DECIMAL QUERY INIT
INFO  [2023-01-26 18:09:05,173] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[SUM_DECIMAL] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:05,173] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[7df8a08a-c247-4b9a-bc65-5c411a8209f9] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_SUM_DECIMAL))]]
INFO  [2023-01-26 18:09:05,176] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SUM_DECIMAL.7df8a08a-c247-4b9a-bc65-5c411a8209f9
INFO  [2023-01-26 18:09:05,176] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SUM_DECIMAL.7df8a08a-c247-4b9a-bc65-5c411a8209f9
INFO  [2023-01-26 18:09:05,177] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SUM_DECIMAL.7df8a08a-c247-4b9a-bc65-5c411a8209f9] with 3 results within PT0.000926S
INFO  [2023-01-26 18:09:05,177] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SUM_DECIMAL.7df8a08a-c247-4b9a-bc65-5c411a8209f9] with 1 results within PT0.00093S
127.0.0.1 - - [26/Jan/2023:18:09:05 +0000] "POST /api/datasets/SUM_DECIMAL/queries HTTP/1.1" 201 1163 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:09:05,177] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SUM_DECIMAL.7df8a08a-c247-4b9a-bc65-5c411a8209f9, workerId=SUM_DECIMAL.worker_SUM_DECIMAL_399bd206-aa92-46ec-ba8f-a25843ca8797, startTime=2023-01-26T18:09:05.176411, finishTime=2023-01-26T18:09:05.177341) of size 1
INFO  [2023-01-26 18:09:05,178] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SUM_DECIMAL.7df8a08a-c247-4b9a-bc65-5c411a8209f9, workerId=SUM_DECIMAL.worker_SUM_DECIMAL_6d0037a7-d93a-4fa3-a158-f90d5db52682, startTime=2023-01-26T18:09:05.176416, finishTime=2023-01-26T18:09:05.177342) of size 3
INFO  [2023-01-26 18:09:05,178] com.bakdata.conquery.models.execution.ManagedExecution: DONE 7df8a08a-c247-4b9a-bc65-5c411a8209f9 ManagedQuery within PT0.004463S
127.0.0.1 - - [26/Jan/2023:18:09:05 +0000] "GET /api/datasets/SUM_DECIMAL/queries/SUM_DECIMAL.7df8a08a-c247-4b9a-bc65-5c411a8209f9 HTTP/1.1" 200 1398 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:09:05,204] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SUM_DECIMAL], queryId=7df8a08a-c247-4b9a-bc65-5c411a8209f9, label=concept	@§$, creationTime=2023-01-26T18:09:05.173453, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@2974681e[Count = 0], startTime=2023-01-26T18:09:05.173628, finishTime=2023-01-26T18:09:05.178091, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2db1bd80), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SUM_DECIMAL)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@6f098e5b, com.bakdata.conquery.models.query.ColumnDescriptor@133291d8]) download on dataset Dataset[label=null, name=SUM_DECIMAL] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:05,204] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SUM_DECIMAL], queryId=7df8a08a-c247-4b9a-bc65-5c411a8209f9, label=concept	@§$, creationTime=2023-01-26T18:09:05.173453, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@2974681e[Count = 0], startTime=2023-01-26T18:09:05.173628, finishTime=2023-01-26T18:09:05.178091, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2db1bd80), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SUM_DECIMAL)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@6f098e5b, com.bakdata.conquery.models.query.ColumnDescriptor@133291d8]) on dataset Dataset[label=null, name=SUM_DECIMAL]
127.0.0.1 - - [26/Jan/2023:18:09:05 +0000] "GET /api/datasets/SUM_DECIMAL/result/SUM_DECIMAL.7df8a08a-c247-4b9a-bc65-5c411a8209f9.csv?pretty=false HTTP/1.1" 200 117 "-" "Conquery (test client)" 15
INFO  [2023-01-26 18:09:05,219] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest SUM_DECIMAL on 5 rows
INFO  [2023-01-26 18:09:05,219] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast SUM_DECIMAL
INFO  [2023-01-26 18:09:05,219] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SUM_DECIMAL, name=SUM_DECIMAL]
INFO  [2023-01-26 18:09:05,219] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SUM_DECIMAL, name=SUM_DECIMAL]
INFO  [2023-01-26 18:09:05,219] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SUM_DECIMAL_399bd206-aa92-46ec-ba8f-a25843ca8797
INFO  [2023-01-26 18:09:05,219] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SUM_DECIMAL_6d0037a7-d93a-4fa3-a158-f90d5db52682
INFO  [2023-01-26 18:09:05,250] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow SUM_DECIMAL
INFO  [2023-01-26 18:09:05,251] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SUM_DECIMAL_399bd206-aa92-46ec-ba8f-a25843ca8797
INFO  [2023-01-26 18:09:05,251] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SUM_DECIMAL_6d0037a7-d93a-4fa3-a158-f90d5db52682
INFO  [2023-01-26 18:09:05,258] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of SUM_DECIMAL
INFO  [2023-01-26 18:09:05,258] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:05,363] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test SUM_DECIMAL
INFO  [2023-01-26 18:09:05,364] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test SUM_INTEGER Test
INFO  [2023-01-26 18:09:05,364] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:05,364] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:05,368] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SUM_INTEGER Test[1], name=SUM_INTEGER Test[1]]
INFO  [2023-01-26 18:09:05,368] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SUM_INTEGER Test[1], name=SUM_INTEGER Test[1]]
INFO  [2023-01-26 18:09:05,368] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:05,368] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:05,374] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SUM_INTEGER$20Test[1].worker_SUM_INTEGER$20Test[1]_03a4256d-0e6d-46ee-947e-578b9c1e8de9 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:05,374] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SUM_INTEGER$20Test[1].worker_SUM_INTEGER$20Test[1]_03a4256d-0e6d-46ee-947e-578b9c1e8de9 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:05,374] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:05,375] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SUM_INTEGER$20Test[1].worker_SUM_INTEGER$20Test[1]_0fab8fe4-9d95-40a7-a3d8-c6a75935df40 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:05,375] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SUM_INTEGER$20Test[1].worker_SUM_INTEGER$20Test[1]_0fab8fe4-9d95-40a7-a3d8-c6a75935df40 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:05,375] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:05,379] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:05,482] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:05,482] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SUM_INTEGER$20Test[1].table
INFO  [2023-01-26 18:09:05,482] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SUM_INTEGER$20Test[1].table
INFO  [2023-01-26 18:09:05,594] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:05,703] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:05,703] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:05,703] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 185 B in total
INFO  [2023-01-26 18:09:05,704] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SUM_INTEGER Test[1]/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000240978sINFO  [2023-01-26 18:09:05,728] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=6, sum=10, min=1, average=1.666667, max=4}
INFO  [2023-01-26 18:09:05,728] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[plus] with IntegerParser(super=Parser(lines=10, nullLines=0), minValue=-50, maxValue=250)
INFO  [2023-01-26 18:09:05,728] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=10, nullLines=0), subType=IntegerParser(super=Parser(lines=10, nullLines=0), minValue=16511, maxValue=16514), dateReader=com.bakdata.conquery.util.DateReader@550f1908)
INFO  [2023-01-26 18:09:05,731] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SUM_INTEGER Test[1]/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:05,731] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:05,731] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SUM_INTEGER Test[1]/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:05,745] com.bakdata.conquery.models.jobs.ImportJob: Importing table into SUM_INTEGER$20Test[1].table
127.0.0.1 - - [26/Jan/2023:18:09:05 +0000] "POST /admin/datasets/SUM_INTEGER%20Test%5B1%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_SUM_INTEGER+Test%5B1%5D%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:09:05,746] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:05,746] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:05,746] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:05,746] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:05,747] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:09:05,748] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SUM_INTEGER$20Test[1].table.table], containing 10 entries.
INFO  [2023-01-26 18:09:05,748] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SUM_INTEGER$20Test[1].table.table], containing 10 entries.
WARN  [2023-01-26 18:09:05,749] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:05,749] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SUM_INTEGER$20Test[1].table.table.0
INFO  [2023-01-26 18:09:05,749] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SUM_INTEGER$20Test[1].table.table.1
INFO  [2023-01-26 18:09:05,853] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: SUM_INTEGER Test QUERY INIT
INFO  [2023-01-26 18:09:05,870] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[SUM_INTEGER$20Test[1]] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:05,870] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[fe0d2cf0-d903-4a1e-a6c9-5665d3afedfc] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_SUM_INTEGER Test[1]))]]
INFO  [2023-01-26 18:09:05,874] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SUM_INTEGER$20Test[1].fe0d2cf0-d903-4a1e-a6c9-5665d3afedfc
INFO  [2023-01-26 18:09:05,874] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SUM_INTEGER$20Test[1].fe0d2cf0-d903-4a1e-a6c9-5665d3afedfc
INFO  [2023-01-26 18:09:05,875] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SUM_INTEGER$20Test[1].fe0d2cf0-d903-4a1e-a6c9-5665d3afedfc] with 1 results within PT0.000771S
INFO  [2023-01-26 18:09:05,875] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SUM_INTEGER$20Test[1].fe0d2cf0-d903-4a1e-a6c9-5665d3afedfc] with 3 results within PT0.000809S
127.0.0.1 - - [26/Jan/2023:18:09:05 +0000] "POST /api/datasets/SUM_INTEGER$20Test%5B1%5D/queries HTTP/1.1" 201 1206 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:09:05,875] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SUM_INTEGER$20Test[1].fe0d2cf0-d903-4a1e-a6c9-5665d3afedfc, workerId=SUM_INTEGER$20Test[1].worker_SUM_INTEGER$20Test[1]_0fab8fe4-9d95-40a7-a3d8-c6a75935df40, startTime=2023-01-26T18:09:05.874719, finishTime=2023-01-26T18:09:05.875528) of size 3
INFO  [2023-01-26 18:09:05,876] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SUM_INTEGER$20Test[1].fe0d2cf0-d903-4a1e-a6c9-5665d3afedfc, workerId=SUM_INTEGER$20Test[1].worker_SUM_INTEGER$20Test[1]_03a4256d-0e6d-46ee-947e-578b9c1e8de9, startTime=2023-01-26T18:09:05.874718, finishTime=2023-01-26T18:09:05.875489) of size 1
INFO  [2023-01-26 18:09:05,876] com.bakdata.conquery.models.execution.ManagedExecution: DONE fe0d2cf0-d903-4a1e-a6c9-5665d3afedfc ManagedQuery within PT0.005587S
127.0.0.1 - - [26/Jan/2023:18:09:05 +0000] "GET /api/datasets/SUM_INTEGER$20Test%5B1%5D/queries/SUM_INTEGER$20Test%5B1%5D.fe0d2cf0-d903-4a1e-a6c9-5665d3afedfc HTTP/1.1" 200 1717 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:09:05,898] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SUM_INTEGER Test[1]], queryId=fe0d2cf0-d903-4a1e-a6c9-5665d3afedfc, label=concept	@§$, creationTime=2023-01-26T18:09:05.870412, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@20e2c623[Count = 0], startTime=2023-01-26T18:09:05.870558, finishTime=2023-01-26T18:09:05.876145, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@49a9526d), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SUM_INTEGER Test[1])), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@68a40569, com.bakdata.conquery.models.query.ColumnDescriptor@47239dc4]) download on dataset Dataset[label=null, name=SUM_INTEGER Test[1]] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:05,898] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SUM_INTEGER Test[1]], queryId=fe0d2cf0-d903-4a1e-a6c9-5665d3afedfc, label=concept	@§$, creationTime=2023-01-26T18:09:05.870412, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@20e2c623[Count = 0], startTime=2023-01-26T18:09:05.870558, finishTime=2023-01-26T18:09:05.876145, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@49a9526d), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SUM_INTEGER Test[1])), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@68a40569, com.bakdata.conquery.models.query.ColumnDescriptor@47239dc4]) on dataset Dataset[label=null, name=SUM_INTEGER Test[1]]
127.0.0.1 - - [26/Jan/2023:18:09:05 +0000] "GET /api/datasets/SUM_INTEGER%20Test%5B1%5D/result/SUM_INTEGER$20Test%5B1%5D.fe0d2cf0-d903-4a1e-a6c9-5665d3afedfc.csv?pretty=false HTTP/1.1" 200 117 "-" "Conquery (test client)" 14
INFO  [2023-01-26 18:09:05,912] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL FilterTest SUM_INTEGER Test on 5 rows
INFO  [2023-01-26 18:09:05,912] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast SUM_INTEGER Test[1]
INFO  [2023-01-26 18:09:05,913] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SUM_INTEGER Test[1], name=SUM_INTEGER Test[1]]
INFO  [2023-01-26 18:09:05,913] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SUM_INTEGER Test[1], name=SUM_INTEGER Test[1]]
INFO  [2023-01-26 18:09:05,913] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SUM_INTEGER Test[1]_03a4256d-0e6d-46ee-947e-578b9c1e8de9
INFO  [2023-01-26 18:09:05,913] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SUM_INTEGER Test[1]_0fab8fe4-9d95-40a7-a3d8-c6a75935df40
INFO  [2023-01-26 18:09:05,968] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow SUM_INTEGER Test[1]
INFO  [2023-01-26 18:09:05,973] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SUM_INTEGER Test[1]_03a4256d-0e6d-46ee-947e-578b9c1e8de9
INFO  [2023-01-26 18:09:05,974] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SUM_INTEGER Test[1]_0fab8fe4-9d95-40a7-a3d8-c6a75935df40
INFO  [2023-01-26 18:09:06,049] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of SUM_INTEGER$20Test[1]
INFO  [2023-01-26 18:09:06,049] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:06,155] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test SUM_INTEGER Test
INFO  [2023-01-26 18:09:06,155] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test ABS-EXPORT-FORM SECONDARY_ID
INFO  [2023-01-26 18:09:06,155] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:06,155] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:06,159] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=ABS-EXPORT-FORM SECONDARY_ID, name=ABS-EXPORT-FORM SECONDARY_ID]
INFO  [2023-01-26 18:09:06,159] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=ABS-EXPORT-FORM SECONDARY_ID, name=ABS-EXPORT-FORM SECONDARY_ID]
INFO  [2023-01-26 18:09:06,159] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:06,159] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:06,161] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker ABS-EXPORT-FORM$20SECONDARY_ID.worker_ABS-EXPORT-FORM$20SECONDARY_ID_606552c5-fa5c-4377-a4eb-55de71e351bb are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:06,161] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker ABS-EXPORT-FORM$20SECONDARY_ID.worker_ABS-EXPORT-FORM$20SECONDARY_ID_606552c5-fa5c-4377-a4eb-55de71e351bb are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:06,161] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:06,161] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker ABS-EXPORT-FORM$20SECONDARY_ID.worker_ABS-EXPORT-FORM$20SECONDARY_ID_721d12dc-4ff7-443f-a30b-65a1d281e301 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:06,161] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker ABS-EXPORT-FORM$20SECONDARY_ID.worker_ABS-EXPORT-FORM$20SECONDARY_ID_721d12dc-4ff7-443f-a30b-65a1d281e301 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:06,161] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:06,165] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:06,306] com.bakdata.conquery.resources.admin.rest.AdminDatasetProcessor: Received new SecondaryId[ABS-EXPORT-FORM$20SECONDARY_ID.secondary]
INFO  [2023-01-26 18:09:06,306] com.bakdata.conquery.resources.admin.rest.AdminDatasetProcessor: Received new SecondaryId[ABS-EXPORT-FORM$20SECONDARY_ID.ignored]
INFO  [2023-01-26 18:09:06,306] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:06,307] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId ABS-EXPORT-FORM$20SECONDARY_ID.secondary
INFO  [2023-01-26 18:09:06,307] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId ABS-EXPORT-FORM$20SECONDARY_ID.secondary
INFO  [2023-01-26 18:09:06,348] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId ABS-EXPORT-FORM$20SECONDARY_ID.ignored
INFO  [2023-01-26 18:09:06,348] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId ABS-EXPORT-FORM$20SECONDARY_ID.ignored
INFO  [2023-01-26 18:09:06,454] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ABS-EXPORT-FORM$20SECONDARY_ID.vers_stamm
INFO  [2023-01-26 18:09:06,454] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:06,454] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ABS-EXPORT-FORM$20SECONDARY_ID.vers_stamm
INFO  [2023-01-26 18:09:06,454] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ABS-EXPORT-FORM$20SECONDARY_ID.table
INFO  [2023-01-26 18:09:06,454] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ABS-EXPORT-FORM$20SECONDARY_ID.table
INFO  [2023-01-26 18:09:06,563] com.bakdata.conquery.integration.json.FormTest: ABS-EXPORT-FORM SECONDARY_ID IMPORT TABLES
INFO  [2023-01-26 18:09:06,582] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:06,693] com.bakdata.conquery.integration.json.FormTest: ABS-EXPORT-FORM SECONDARY_ID IMPORT CONCEPTS
INFO  [2023-01-26 18:09:06,694] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:06,694] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:06,694] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:06,694] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 1.5 KiB in total
INFO  [2023-01-26 18:09:06,694] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ABS-EXPORT-FORM SECONDARY_ID/vers_stamm.import.json, tag=Optional.empty)
█████████████████████████████████████████████     ▌  90%	est. time remaining: 0.003331018sINFO  [2023-01-26 18:09:06,722] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=22, sum=22, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:06,722] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_end] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15614, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@5f0f77e8)
INFO  [2023-01-26 18:09:06,722] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_start] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15340, maxValue=15706), dateReader=com.bakdata.conquery.util.DateReader@1518b15d)
INFO  [2023-01-26 18:09:06,722] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date] with DateRangeParser(super=Parser(lines=22, nullLines=0), minParser=DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15340, maxValue=15706), dateReader=com.bakdata.conquery.util.DateReader@46bd8aaa), maxParser=DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15614, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@487a7c0d), dateReader=com.bakdata.conquery.util.DateReader@4c45e1da, onlyQuarters=false, maxValue=16070, minValue=15340, anyOpen=false)
INFO  [2023-01-26 18:09:06,723] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geburtsdatum] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=-6759, maxValue=9131), dateReader=com.bakdata.conquery.util.DateReader@6d4f4747)
INFO  [2023-01-26 18:09:06,723] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=22, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:06,727] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ABS-EXPORT-FORM SECONDARY_ID/vers_stamm.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:06,727] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ABS-EXPORT-FORM SECONDARY_ID/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000546473sINFO  [2023-01-26 18:09:06,750] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=1, sum=6, min=6, average=6.000000, max=6}
INFO  [2023-01-26 18:09:06,750] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=15400, maxValue=15405), dateReader=com.bakdata.conquery.util.DateReader@56857af5)
INFO  [2023-01-26 18:09:06,750] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[column] with StringParser(super=Parser(lines=6, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:06,750] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[second_id] with StringParser(super=Parser(lines=6, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:06,756] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ABS-EXPORT-FORM SECONDARY_ID/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:06,756] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 2 Jobs:
INFO  [2023-01-26 18:09:06,756] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ABS-EXPORT-FORM SECONDARY_ID/vers_stamm.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:06,756] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ABS-EXPORT-FORM SECONDARY_ID/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:06,781] com.bakdata.conquery.models.jobs.ImportJob: Importing vers_stamm into ABS-EXPORT-FORM$20SECONDARY_ID.vers_stamm
127.0.0.1 - - [26/Jan/2023:18:09:06 +0000] "POST /admin/datasets/ABS-EXPORT-FORM%20SECONDARY_ID/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_ABS-EXPORT-FORM+SECONDARY_ID%2Fvers_stamm.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 10
INFO  [2023-01-26 18:09:06,782] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:06,783] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:06,783] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:06,785] com.bakdata.conquery.models.jobs.ImportJob: Start sending 8 Buckets
INFO  [2023-01-26 18:09:06,785] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ABS-EXPORT-FORM$20SECONDARY_ID.vers_stamm.vers_stamm], containing 22 entries.
INFO  [2023-01-26 18:09:06,785] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ABS-EXPORT-FORM$20SECONDARY_ID.vers_stamm.vers_stamm], containing 22 entries.
INFO  [2023-01-26 18:09:06,786] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ABS-EXPORT-FORM$20SECONDARY_ID.vers_stamm.vers_stamm.0
INFO  [2023-01-26 18:09:06,787] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ABS-EXPORT-FORM$20SECONDARY_ID.vers_stamm.vers_stamm.2
INFO  [2023-01-26 18:09:06,789] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ABS-EXPORT-FORM$20SECONDARY_ID.vers_stamm.vers_stamm.1
INFO  [2023-01-26 18:09:06,789] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ABS-EXPORT-FORM$20SECONDARY_ID.vers_stamm.vers_stamm.3
INFO  [2023-01-26 18:09:06,789] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ABS-EXPORT-FORM$20SECONDARY_ID.vers_stamm.vers_stamm.4
WARN  [2023-01-26 18:09:06,789] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:06,789] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ABS-EXPORT-FORM$20SECONDARY_ID.vers_stamm.vers_stamm.6
INFO  [2023-01-26 18:09:06,790] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ABS-EXPORT-FORM$20SECONDARY_ID.vers_stamm.vers_stamm.5
INFO  [2023-01-26 18:09:06,790] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ABS-EXPORT-FORM$20SECONDARY_ID.vers_stamm.vers_stamm.7
INFO  [2023-01-26 18:09:06,807] com.bakdata.conquery.models.jobs.ImportJob: Importing table into ABS-EXPORT-FORM$20SECONDARY_ID.table
INFO  [2023-01-26 18:09:06,807] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
127.0.0.1 - - [26/Jan/2023:18:09:06 +0000] "POST /admin/datasets/ABS-EXPORT-FORM%20SECONDARY_ID/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_ABS-EXPORT-FORM+SECONDARY_ID%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:09:06,808] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:06,808] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:06,808] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:06,808] com.bakdata.conquery.models.jobs.ImportJob: Start sending 1 Buckets
WARN  [2023-01-26 18:09:06,808] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:06,808] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ABS-EXPORT-FORM$20SECONDARY_ID.table.table], containing 6 entries.
INFO  [2023-01-26 18:09:06,809] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ABS-EXPORT-FORM$20SECONDARY_ID.table.table], containing 6 entries.
INFO  [2023-01-26 18:09:06,809] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ABS-EXPORT-FORM$20SECONDARY_ID.table.table.0
INFO  [2023-01-26 18:09:06,913] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:06,919] com.bakdata.conquery.integration.json.FormTest: ABS-EXPORT-FORM SECONDARY_ID IMPORT TABLE CONTENTS
INFO  [2023-01-26 18:09:06,923] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:06,929] com.bakdata.conquery.integration.json.FormTest: ABS-EXPORT-FORM SECONDARY_ID PARSE JSON FORM DESCRIPTION
INFO  [2023-01-26 18:09:06,942] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:06,942] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 2 Concepts
INFO  [2023-01-26 18:09:06,942] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 2 Concepts
INFO  [2023-01-26 18:09:07,052] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[778b0039-fead-48ef-99a1-5399af20e799] in Datasets[[]]
INFO  [2023-01-26 18:09:07,063] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteForm: Started Form ABS-EXPORT-FORM$20SECONDARY_ID.778b0039-fead-48ef-99a1-5399af20e799
INFO  [2023-01-26 18:09:07,063] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteForm: Started Form ABS-EXPORT-FORM$20SECONDARY_ID.778b0039-fead-48ef-99a1-5399af20e799
INFO  [2023-01-26 18:09:07,070] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[ABS-EXPORT-FORM$20SECONDARY_ID.778b0039-fead-48ef-99a1-5399af20e799] with 0 results within PT0.0076S
INFO  [2023-01-26 18:09:07,071] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[ABS-EXPORT-FORM$20SECONDARY_ID.778b0039-fead-48ef-99a1-5399af20e799] with 1 results within PT0.008287S
INFO  [2023-01-26 18:09:07,074] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=ABS-EXPORT-FORM$20SECONDARY_ID.778b0039-fead-48ef-99a1-5399af20e799, workerId=ABS-EXPORT-FORM$20SECONDARY_ID.worker_ABS-EXPORT-FORM$20SECONDARY_ID_721d12dc-4ff7-443f-a30b-65a1d281e301, startTime=2023-01-26T18:09:07.063262, finishTime=2023-01-26T18:09:07.070862) of size 0
INFO  [2023-01-26 18:09:07,074] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=ABS-EXPORT-FORM$20SECONDARY_ID.778b0039-fead-48ef-99a1-5399af20e799, workerId=ABS-EXPORT-FORM$20SECONDARY_ID.worker_ABS-EXPORT-FORM$20SECONDARY_ID_606552c5-fa5c-4377-a4eb-55de71e351bb, startTime=2023-01-26T18:09:07.063259, finishTime=2023-01-26T18:09:07.071546) of size 1
INFO  [2023-01-26 18:09:07,074] com.bakdata.conquery.models.execution.ManagedExecution: DONE 3f886752-2c19-4226-991f-64f62c16f7d7 ManagedQuery within PT0.021639S
INFO  [2023-01-26 18:09:07,075] com.bakdata.conquery.models.execution.ManagedExecution: DONE 778b0039-fead-48ef-99a1-5399af20e799 ManagedInternalForm within PT0.022646S
INFO  [2023-01-26 18:09:07,075] com.bakdata.conquery.integration.json.FormTest: ABS-EXPORT-FORM SECONDARY_ID QUERIES EXECUTED
INFO  [2023-01-26 18:09:07,092] com.bakdata.conquery.integration.json.FormTest: ABS-EXPORT-FORM SECONDARY_ID CSV TESTING: results
INFO  [2023-01-26 18:09:07,096] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast ABS-EXPORT-FORM SECONDARY_ID
INFO  [2023-01-26 18:09:07,096] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=ABS-EXPORT-FORM SECONDARY_ID, name=ABS-EXPORT-FORM SECONDARY_ID]
INFO  [2023-01-26 18:09:07,096] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=ABS-EXPORT-FORM SECONDARY_ID, name=ABS-EXPORT-FORM SECONDARY_ID]
INFO  [2023-01-26 18:09:07,097] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_ABS-EXPORT-FORM SECONDARY_ID_721d12dc-4ff7-443f-a30b-65a1d281e301
INFO  [2023-01-26 18:09:07,097] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_ABS-EXPORT-FORM SECONDARY_ID_606552c5-fa5c-4377-a4eb-55de71e351bb
INFO  [2023-01-26 18:09:07,172] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow ABS-EXPORT-FORM SECONDARY_ID
INFO  [2023-01-26 18:09:07,172] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_ABS-EXPORT-FORM SECONDARY_ID_606552c5-fa5c-4377-a4eb-55de71e351bb
INFO  [2023-01-26 18:09:07,172] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_ABS-EXPORT-FORM SECONDARY_ID_721d12dc-4ff7-443f-a30b-65a1d281e301
INFO  [2023-01-26 18:09:07,209] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of ABS-EXPORT-FORM$20SECONDARY_ID
INFO  [2023-01-26 18:09:07,209] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:07,348] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test ABS-EXPORT-FORM SECONDARY_ID
INFO  [2023-01-26 18:09:07,349] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test ABS-EXPORT-FORM ADD DEFAULT SELECT Test
INFO  [2023-01-26 18:09:07,349] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:07,349] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:07,350] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=ABS-EXPORT-FORM ADD DEFAULT SELECT Test, name=ABS-EXPORT-FORM ADD DEFAULT SELECT Test]
INFO  [2023-01-26 18:09:07,350] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:07,351] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=ABS-EXPORT-FORM ADD DEFAULT SELECT Test, name=ABS-EXPORT-FORM ADD DEFAULT SELECT Test]
INFO  [2023-01-26 18:09:07,351] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:07,354] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test.worker_ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test_2bd63f62-2b64-4159-a191-9bac66d85b7f are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:07,354] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test.worker_ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test_2bd63f62-2b64-4159-a191-9bac66d85b7f are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:07,354] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:07,354] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test.worker_ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test_6963259b-7203-47a0-b708-212ed80da60f are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:07,354] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test.worker_ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test_6963259b-7203-47a0-b708-212ed80da60f are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:07,354] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:07,356] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:07,458] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:07,464] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:07,465] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test.vers_stamm
INFO  [2023-01-26 18:09:07,465] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test.vers_stamm
INFO  [2023-01-26 18:09:07,570] com.bakdata.conquery.integration.json.FormTest: ABS-EXPORT-FORM ADD DEFAULT SELECT Test IMPORT TABLES
INFO  [2023-01-26 18:09:07,580] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:07,688] com.bakdata.conquery.integration.json.FormTest: ABS-EXPORT-FORM ADD DEFAULT SELECT Test IMPORT CONCEPTS
INFO  [2023-01-26 18:09:07,689] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:07,689] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:07,689] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 1.3 KiB in total
INFO  [2023-01-26 18:09:07,689] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ABS-EXPORT-FORM ADD DEFAULT SELECT Test/vers_stamm.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000299635sINFO  [2023-01-26 18:09:07,720] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=22, sum=22, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:07,720] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_start] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15340, maxValue=15706), dateReader=com.bakdata.conquery.util.DateReader@6a3dd8b4)
INFO  [2023-01-26 18:09:07,720] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date] with DateRangeParser(super=Parser(lines=22, nullLines=0), minParser=DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15340, maxValue=15706), dateReader=com.bakdata.conquery.util.DateReader@50fef9ac), maxParser=DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15614, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@5e390dc3), dateReader=com.bakdata.conquery.util.DateReader@5a0692dc, onlyQuarters=false, maxValue=16070, minValue=15340, anyOpen=false)
INFO  [2023-01-26 18:09:07,720] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=22, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:07,721] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geburtsdatum] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=-6759, maxValue=9131), dateReader=com.bakdata.conquery.util.DateReader@1f0407f8)
INFO  [2023-01-26 18:09:07,721] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_end] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15614, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@6a17f941)
INFO  [2023-01-26 18:09:07,729] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ABS-EXPORT-FORM ADD DEFAULT SELECT Test/vers_stamm.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:07,729] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:07,729] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ABS-EXPORT-FORM ADD DEFAULT SELECT Test/vers_stamm.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:07,747] com.bakdata.conquery.models.jobs.ImportJob: Importing vers_stamm into ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test.vers_stamm
127.0.0.1 - - [26/Jan/2023:18:09:07 +0000] "POST /admin/datasets/ABS-EXPORT-FORM%20ADD%20DEFAULT%20SELECT%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_ABS-EXPORT-FORM+ADD+DEFAULT+SELECT+Test%2Fvers_stamm.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:09:07,748] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:07,748] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:07,749] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:07,749] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:07,750] com.bakdata.conquery.models.jobs.ImportJob: Start sending 8 Buckets
INFO  [2023-01-26 18:09:07,751] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test.vers_stamm.vers_stamm], containing 22 entries.
INFO  [2023-01-26 18:09:07,751] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test.vers_stamm.vers_stamm], containing 22 entries.
INFO  [2023-01-26 18:09:07,752] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test.vers_stamm.vers_stamm.0
INFO  [2023-01-26 18:09:07,752] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test.vers_stamm.vers_stamm.1
INFO  [2023-01-26 18:09:07,752] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test.vers_stamm.vers_stamm.2
INFO  [2023-01-26 18:09:07,753] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test.vers_stamm.vers_stamm.3
INFO  [2023-01-26 18:09:07,753] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test.vers_stamm.vers_stamm.4
WARN  [2023-01-26 18:09:07,753] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:07,760] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test.vers_stamm.vers_stamm.5
INFO  [2023-01-26 18:09:07,761] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test.vers_stamm.vers_stamm.6
INFO  [2023-01-26 18:09:07,761] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test.vers_stamm.vers_stamm.7
INFO  [2023-01-26 18:09:07,866] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:07,875] com.bakdata.conquery.integration.json.FormTest: ABS-EXPORT-FORM ADD DEFAULT SELECT Test IMPORT TABLE CONTENTS
INFO  [2023-01-26 18:09:07,904] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:07,910] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:07,915] com.bakdata.conquery.integration.json.FormTest: ABS-EXPORT-FORM ADD DEFAULT SELECT Test PARSE JSON FORM DESCRIPTION
INFO  [2023-01-26 18:09:07,922] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:07,922] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:07,922] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:08,031] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[bef9659b-c6b5-458f-b0ff-259fc16b64a5] in Datasets[[]]
INFO  [2023-01-26 18:09:08,049] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteForm: Started Form ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test.bef9659b-c6b5-458f-b0ff-259fc16b64a5
INFO  [2023-01-26 18:09:08,049] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteForm: Started Form ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test.bef9659b-c6b5-458f-b0ff-259fc16b64a5
INFO  [2023-01-26 18:09:08,051] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test.bef9659b-c6b5-458f-b0ff-259fc16b64a5] with 0 results within PT0.002478S
INFO  [2023-01-26 18:09:08,052] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test.bef9659b-c6b5-458f-b0ff-259fc16b64a5] with 1 results within PT0.002827S
INFO  [2023-01-26 18:09:08,052] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test.bef9659b-c6b5-458f-b0ff-259fc16b64a5, workerId=ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test.worker_ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test_2bd63f62-2b64-4159-a191-9bac66d85b7f, startTime=2023-01-26T18:09:08.049092, finishTime=2023-01-26T18:09:08.051570) of size 0
INFO  [2023-01-26 18:09:08,053] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test.bef9659b-c6b5-458f-b0ff-259fc16b64a5, workerId=ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test.worker_ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test_6963259b-7203-47a0-b708-212ed80da60f, startTime=2023-01-26T18:09:08.049259, finishTime=2023-01-26T18:09:08.052086) of size 1
INFO  [2023-01-26 18:09:08,053] com.bakdata.conquery.models.execution.ManagedExecution: DONE b17d40fd-6aa6-4f11-af4b-028bb31766c5 ManagedQuery within PT0.021797S
INFO  [2023-01-26 18:09:08,054] com.bakdata.conquery.integration.json.FormTest: ABS-EXPORT-FORM ADD DEFAULT SELECT Test QUERIES EXECUTED
INFO  [2023-01-26 18:09:08,054] com.bakdata.conquery.models.execution.ManagedExecution: DONE bef9659b-c6b5-458f-b0ff-259fc16b64a5 ManagedInternalForm within PT0.02258S
INFO  [2023-01-26 18:09:08,066] com.bakdata.conquery.integration.json.FormTest: ABS-EXPORT-FORM ADD DEFAULT SELECT Test CSV TESTING: results
INFO  [2023-01-26 18:09:08,068] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast ABS-EXPORT-FORM ADD DEFAULT SELECT Test
INFO  [2023-01-26 18:09:08,068] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=ABS-EXPORT-FORM ADD DEFAULT SELECT Test, name=ABS-EXPORT-FORM ADD DEFAULT SELECT Test]
INFO  [2023-01-26 18:09:08,068] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=ABS-EXPORT-FORM ADD DEFAULT SELECT Test, name=ABS-EXPORT-FORM ADD DEFAULT SELECT Test]
INFO  [2023-01-26 18:09:08,068] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_ABS-EXPORT-FORM ADD DEFAULT SELECT Test_6963259b-7203-47a0-b708-212ed80da60f
INFO  [2023-01-26 18:09:08,069] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_ABS-EXPORT-FORM ADD DEFAULT SELECT Test_2bd63f62-2b64-4159-a191-9bac66d85b7f
INFO  [2023-01-26 18:09:08,151] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow ABS-EXPORT-FORM ADD DEFAULT SELECT Test
INFO  [2023-01-26 18:09:08,161] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of ABS-EXPORT-FORM$20ADD$20DEFAULT$20SELECT$20Test
INFO  [2023-01-26 18:09:08,161] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_ABS-EXPORT-FORM ADD DEFAULT SELECT Test_2bd63f62-2b64-4159-a191-9bac66d85b7f
INFO  [2023-01-26 18:09:08,161] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_ABS-EXPORT-FORM ADD DEFAULT SELECT Test_6963259b-7203-47a0-b708-212ed80da60f
INFO  [2023-01-26 18:09:08,161] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:08,327] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test ABS-EXPORT-FORM ADD DEFAULT SELECT Test
INFO  [2023-01-26 18:09:08,327] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test ABS-EXPORT-FORM WITH SELECT SET Test
INFO  [2023-01-26 18:09:08,327] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:08,327] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:08,328] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=ABS-EXPORT-FORM WITH SELECT SET Test, name=ABS-EXPORT-FORM WITH SELECT SET Test]
INFO  [2023-01-26 18:09:08,328] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=ABS-EXPORT-FORM WITH SELECT SET Test, name=ABS-EXPORT-FORM WITH SELECT SET Test]
INFO  [2023-01-26 18:09:08,328] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:08,328] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:08,330] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:08,331] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test.worker_ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test_f9189921-3792-4b0d-9d56-76b34ff904bf are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:08,331] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test.worker_ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test_f9189921-3792-4b0d-9d56-76b34ff904bf are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:08,331] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:08,331] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test.worker_ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test_5d7cd174-6182-421b-add9-9faf7dd0e053 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:08,331] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test.worker_ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test_5d7cd174-6182-421b-add9-9faf7dd0e053 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:08,331] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:08,434] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:08,441] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:08,442] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test.vers_stamm
INFO  [2023-01-26 18:09:08,442] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test.vers_stamm
INFO  [2023-01-26 18:09:08,547] com.bakdata.conquery.integration.json.FormTest: ABS-EXPORT-FORM WITH SELECT SET Test IMPORT TABLES
INFO  [2023-01-26 18:09:08,560] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:08,672] com.bakdata.conquery.integration.json.FormTest: ABS-EXPORT-FORM WITH SELECT SET Test IMPORT CONCEPTS
INFO  [2023-01-26 18:09:08,672] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:08,672] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:08,673] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 1.3 KiB in total
INFO  [2023-01-26 18:09:08,673] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ABS-EXPORT-FORM WITH SELECT SET Test/vers_stamm.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.00027392sINFO  [2023-01-26 18:09:08,701] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=22, sum=22, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:08,701] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_end] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15614, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@a2e88a6)
INFO  [2023-01-26 18:09:08,701] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=22, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:08,701] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geburtsdatum] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=-6759, maxValue=9131), dateReader=com.bakdata.conquery.util.DateReader@3890be2d)
INFO  [2023-01-26 18:09:08,701] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_start] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15340, maxValue=15706), dateReader=com.bakdata.conquery.util.DateReader@442b2975)
INFO  [2023-01-26 18:09:08,701] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date] with DateRangeParser(super=Parser(lines=22, nullLines=0), minParser=DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15340, maxValue=15706), dateReader=com.bakdata.conquery.util.DateReader@9477636), maxParser=DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15614, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@2305556e), dateReader=com.bakdata.conquery.util.DateReader@3884df17, onlyQuarters=false, maxValue=16070, minValue=15340, anyOpen=false)
INFO  [2023-01-26 18:09:08,705] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ABS-EXPORT-FORM WITH SELECT SET Test/vers_stamm.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:08,705] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:08,705] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ABS-EXPORT-FORM WITH SELECT SET Test/vers_stamm.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:08,723] com.bakdata.conquery.models.jobs.ImportJob: Importing vers_stamm into ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test.vers_stamm
127.0.0.1 - - [26/Jan/2023:18:09:08 +0000] "POST /admin/datasets/ABS-EXPORT-FORM%20WITH%20SELECT%20SET%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_ABS-EXPORT-FORM+WITH+SELECT+SET+Test%2Fvers_stamm.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:09:08,723] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:08,724] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:08,724] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:08,724] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:08,726] com.bakdata.conquery.models.jobs.ImportJob: Start sending 8 Buckets
INFO  [2023-01-26 18:09:08,727] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test.vers_stamm.vers_stamm], containing 22 entries.
INFO  [2023-01-26 18:09:08,727] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test.vers_stamm.vers_stamm], containing 22 entries.
INFO  [2023-01-26 18:09:08,728] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test.vers_stamm.vers_stamm.0
INFO  [2023-01-26 18:09:08,728] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test.vers_stamm.vers_stamm.2
INFO  [2023-01-26 18:09:08,728] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test.vers_stamm.vers_stamm.1
INFO  [2023-01-26 18:09:08,728] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test.vers_stamm.vers_stamm.3
INFO  [2023-01-26 18:09:08,728] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test.vers_stamm.vers_stamm.4
WARN  [2023-01-26 18:09:08,729] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:08,729] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test.vers_stamm.vers_stamm.5
INFO  [2023-01-26 18:09:08,729] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test.vers_stamm.vers_stamm.6
INFO  [2023-01-26 18:09:08,729] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test.vers_stamm.vers_stamm.7
INFO  [2023-01-26 18:09:08,835] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:08,840] com.bakdata.conquery.integration.json.FormTest: ABS-EXPORT-FORM WITH SELECT SET Test IMPORT TABLE CONTENTS
INFO  [2023-01-26 18:09:08,900] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:08,906] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:08,911] com.bakdata.conquery.integration.json.FormTest: ABS-EXPORT-FORM WITH SELECT SET Test PARSE JSON FORM DESCRIPTION
INFO  [2023-01-26 18:09:08,918] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:08,918] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:08,918] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:09,025] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[394cab16-b423-4930-acce-ebffad0b83c1] in Datasets[[]]
INFO  [2023-01-26 18:09:09,029] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteForm: Started Form ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test.394cab16-b423-4930-acce-ebffad0b83c1
INFO  [2023-01-26 18:09:09,029] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteForm: Started Form ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test.394cab16-b423-4930-acce-ebffad0b83c1
INFO  [2023-01-26 18:09:09,048] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test.394cab16-b423-4930-acce-ebffad0b83c1] with 0 results within PT0.018525S
INFO  [2023-01-26 18:09:09,048] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test.394cab16-b423-4930-acce-ebffad0b83c1, workerId=ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test.worker_ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test_5d7cd174-6182-421b-add9-9faf7dd0e053, startTime=2023-01-26T18:09:09.029726, finishTime=2023-01-26T18:09:09.048251) of size 0
INFO  [2023-01-26 18:09:09,052] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test.394cab16-b423-4930-acce-ebffad0b83c1] with 1 results within PT0.022277S
INFO  [2023-01-26 18:09:09,052] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test.394cab16-b423-4930-acce-ebffad0b83c1, workerId=ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test.worker_ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test_f9189921-3792-4b0d-9d56-76b34ff904bf, startTime=2023-01-26T18:09:09.029723, finishTime=2023-01-26T18:09:09.052) of size 1
INFO  [2023-01-26 18:09:09,052] com.bakdata.conquery.models.execution.ManagedExecution: DONE 11b5d76c-acaf-471f-be01-c8165d8dd304 ManagedQuery within PT0.027526S
INFO  [2023-01-26 18:09:09,053] com.bakdata.conquery.integration.json.FormTest: ABS-EXPORT-FORM WITH SELECT SET Test QUERIES EXECUTED
INFO  [2023-01-26 18:09:09,053] com.bakdata.conquery.models.execution.ManagedExecution: DONE 394cab16-b423-4930-acce-ebffad0b83c1 ManagedInternalForm within PT0.028403S
INFO  [2023-01-26 18:09:09,065] com.bakdata.conquery.integration.json.FormTest: ABS-EXPORT-FORM WITH SELECT SET Test CSV TESTING: results
INFO  [2023-01-26 18:09:09,067] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast ABS-EXPORT-FORM WITH SELECT SET Test
INFO  [2023-01-26 18:09:09,067] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=ABS-EXPORT-FORM WITH SELECT SET Test, name=ABS-EXPORT-FORM WITH SELECT SET Test]
INFO  [2023-01-26 18:09:09,067] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=ABS-EXPORT-FORM WITH SELECT SET Test, name=ABS-EXPORT-FORM WITH SELECT SET Test]
INFO  [2023-01-26 18:09:09,067] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_ABS-EXPORT-FORM WITH SELECT SET Test_5d7cd174-6182-421b-add9-9faf7dd0e053
INFO  [2023-01-26 18:09:09,067] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_ABS-EXPORT-FORM WITH SELECT SET Test_f9189921-3792-4b0d-9d56-76b34ff904bf
INFO  [2023-01-26 18:09:09,129] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow ABS-EXPORT-FORM WITH SELECT SET Test
INFO  [2023-01-26 18:09:09,129] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_ABS-EXPORT-FORM WITH SELECT SET Test_f9189921-3792-4b0d-9d56-76b34ff904bf
INFO  [2023-01-26 18:09:09,129] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_ABS-EXPORT-FORM WITH SELECT SET Test_5d7cd174-6182-421b-add9-9faf7dd0e053
INFO  [2023-01-26 18:09:09,129] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of ABS-EXPORT-FORM$20WITH$20SELECT$20SET$20Test
INFO  [2023-01-26 18:09:09,129] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:09,328] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test ABS-EXPORT-FORM WITH SELECT SET Test
INFO  [2023-01-26 18:09:09,329] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test ADD DEFAULT SELECT Test
INFO  [2023-01-26 18:09:09,329] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:09,329] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:09,330] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=ADD DEFAULT SELECT Test, name=ADD DEFAULT SELECT Test]
INFO  [2023-01-26 18:09:09,330] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=ADD DEFAULT SELECT Test, name=ADD DEFAULT SELECT Test]
INFO  [2023-01-26 18:09:09,331] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:09,331] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:09,332] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:09,333] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker ADD$20DEFAULT$20SELECT$20Test.worker_ADD$20DEFAULT$20SELECT$20Test_44044823-a4c8-4e18-b76b-f199aa9b7d09 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:09,333] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker ADD$20DEFAULT$20SELECT$20Test.worker_ADD$20DEFAULT$20SELECT$20Test_44044823-a4c8-4e18-b76b-f199aa9b7d09 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:09,333] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:09,333] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker ADD$20DEFAULT$20SELECT$20Test.worker_ADD$20DEFAULT$20SELECT$20Test_01ef8720-9f7b-4232-ba06-b7dae88e105a are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:09,333] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker ADD$20DEFAULT$20SELECT$20Test.worker_ADD$20DEFAULT$20SELECT$20Test_01ef8720-9f7b-4232-ba06-b7dae88e105a are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:09,333] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:09,437] com.bakdata.conquery.resources.admin.rest.AdminDatasetProcessor: Received new SecondaryId[ADD$20DEFAULT$20SELECT$20Test.secondary]
INFO  [2023-01-26 18:09:09,438] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:09,439] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId ADD$20DEFAULT$20SELECT$20Test.secondary
INFO  [2023-01-26 18:09:09,439] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId ADD$20DEFAULT$20SELECT$20Test.secondary
INFO  [2023-01-26 18:09:09,545] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:09,546] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ADD$20DEFAULT$20SELECT$20Test.vers_stamm
INFO  [2023-01-26 18:09:09,546] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ADD$20DEFAULT$20SELECT$20Test.vers_stamm
INFO  [2023-01-26 18:09:09,546] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ADD$20DEFAULT$20SELECT$20Test.table
INFO  [2023-01-26 18:09:09,546] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ADD$20DEFAULT$20SELECT$20Test.table
INFO  [2023-01-26 18:09:09,651] com.bakdata.conquery.integration.json.FormTest: ADD DEFAULT SELECT Test IMPORT TABLES
INFO  [2023-01-26 18:09:09,678] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:09,788] com.bakdata.conquery.integration.json.FormTest: ADD DEFAULT SELECT Test IMPORT CONCEPTS
INFO  [2023-01-26 18:09:09,788] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:09,788] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:09,788] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:09,788] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 1.5 KiB in total
INFO  [2023-01-26 18:09:09,788] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ADD DEFAULT SELECT Test/vers_stamm.import.json, tag=Optional.empty)
█████████████████████████████████████████████     ▌  90%	est. time remaining: 0.003552675sINFO  [2023-01-26 18:09:09,818] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=22, sum=22, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:09,818] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_end] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15614, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@60bf8373)
INFO  [2023-01-26 18:09:09,818] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=22, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:09,818] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geburtsdatum] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=-6759, maxValue=9131), dateReader=com.bakdata.conquery.util.DateReader@41ccaa37)
INFO  [2023-01-26 18:09:09,818] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_start] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15340, maxValue=15706), dateReader=com.bakdata.conquery.util.DateReader@3fc216b4)
INFO  [2023-01-26 18:09:09,819] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date] with DateRangeParser(super=Parser(lines=22, nullLines=0), minParser=DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15340, maxValue=15706), dateReader=com.bakdata.conquery.util.DateReader@110e790a), maxParser=DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15614, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@6ec6113), dateReader=com.bakdata.conquery.util.DateReader@1b11803a, onlyQuarters=false, maxValue=16070, minValue=15340, anyOpen=false)
INFO  [2023-01-26 18:09:09,822] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ADD DEFAULT SELECT Test/vers_stamm.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:09,823] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ADD DEFAULT SELECT Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000549696sINFO  [2023-01-26 18:09:09,844] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=1, sum=6, min=6, average=6.000000, max=6}
INFO  [2023-01-26 18:09:09,844] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[second_id] with StringParser(super=Parser(lines=6, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:09,844] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=15400, maxValue=15405), dateReader=com.bakdata.conquery.util.DateReader@7fcc4e3b)
INFO  [2023-01-26 18:09:09,844] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[column] with StringParser(super=Parser(lines=6, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:09,847] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ADD DEFAULT SELECT Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:09,847] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 2 Jobs:
INFO  [2023-01-26 18:09:09,847] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ADD DEFAULT SELECT Test/vers_stamm.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:09,847] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ADD DEFAULT SELECT Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:09,865] com.bakdata.conquery.models.jobs.ImportJob: Importing vers_stamm into ADD$20DEFAULT$20SELECT$20Test.vers_stamm
127.0.0.1 - - [26/Jan/2023:18:09:09 +0000] "POST /admin/datasets/ADD%20DEFAULT%20SELECT%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_ADD+DEFAULT+SELECT+Test%2Fvers_stamm.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:09:09,866] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:09,867] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:09,867] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:09,868] com.bakdata.conquery.models.jobs.ImportJob: Start sending 8 Buckets
INFO  [2023-01-26 18:09:09,869] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ADD$20DEFAULT$20SELECT$20Test.vers_stamm.vers_stamm], containing 22 entries.
INFO  [2023-01-26 18:09:09,869] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ADD$20DEFAULT$20SELECT$20Test.vers_stamm.vers_stamm], containing 22 entries.
INFO  [2023-01-26 18:09:09,870] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ADD$20DEFAULT$20SELECT$20Test.vers_stamm.vers_stamm.0
INFO  [2023-01-26 18:09:09,870] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ADD$20DEFAULT$20SELECT$20Test.vers_stamm.vers_stamm.2
INFO  [2023-01-26 18:09:09,870] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ADD$20DEFAULT$20SELECT$20Test.vers_stamm.vers_stamm.1
INFO  [2023-01-26 18:09:09,870] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ADD$20DEFAULT$20SELECT$20Test.vers_stamm.vers_stamm.3
INFO  [2023-01-26 18:09:09,870] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ADD$20DEFAULT$20SELECT$20Test.vers_stamm.vers_stamm.4
INFO  [2023-01-26 18:09:09,870] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ADD$20DEFAULT$20SELECT$20Test.vers_stamm.vers_stamm.5
WARN  [2023-01-26 18:09:09,871] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:09,871] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ADD$20DEFAULT$20SELECT$20Test.vers_stamm.vers_stamm.6
INFO  [2023-01-26 18:09:09,872] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ADD$20DEFAULT$20SELECT$20Test.vers_stamm.vers_stamm.7
INFO  [2023-01-26 18:09:09,886] com.bakdata.conquery.models.jobs.ImportJob: Importing table into ADD$20DEFAULT$20SELECT$20Test.table
INFO  [2023-01-26 18:09:09,886] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:09,887] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:09,887] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
127.0.0.1 - - [26/Jan/2023:18:09:09 +0000] "POST /admin/datasets/ADD%20DEFAULT%20SELECT%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_ADD+DEFAULT+SELECT+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 10
INFO  [2023-01-26 18:09:09,887] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:09,887] com.bakdata.conquery.models.jobs.ImportJob: Start sending 1 Buckets
WARN  [2023-01-26 18:09:09,888] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:09,888] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ADD$20DEFAULT$20SELECT$20Test.table.table], containing 6 entries.
INFO  [2023-01-26 18:09:09,888] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ADD$20DEFAULT$20SELECT$20Test.table.table.0
INFO  [2023-01-26 18:09:09,888] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ADD$20DEFAULT$20SELECT$20Test.table.table], containing 6 entries.
INFO  [2023-01-26 18:09:09,993] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:09,998] com.bakdata.conquery.integration.json.FormTest: ADD DEFAULT SELECT Test IMPORT TABLE CONTENTS
INFO  [2023-01-26 18:09:10,003] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:10,009] com.bakdata.conquery.integration.json.FormTest: ADD DEFAULT SELECT Test PARSE JSON FORM DESCRIPTION
INFO  [2023-01-26 18:09:10,019] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:10,020] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 2 Concepts
INFO  [2023-01-26 18:09:10,020] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 2 Concepts
INFO  [2023-01-26 18:09:10,126] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[d633fe18-a891-453c-943b-01b311867ac1] in Datasets[[]]
INFO  [2023-01-26 18:09:10,134] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteForm: Started Form ADD$20DEFAULT$20SELECT$20Test.d633fe18-a891-453c-943b-01b311867ac1
INFO  [2023-01-26 18:09:10,134] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteForm: Started Form ADD$20DEFAULT$20SELECT$20Test.d633fe18-a891-453c-943b-01b311867ac1
INFO  [2023-01-26 18:09:10,178] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[ADD$20DEFAULT$20SELECT$20Test.d633fe18-a891-453c-943b-01b311867ac1] with 0 results within PT0.044023S
INFO  [2023-01-26 18:09:10,179] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=ADD$20DEFAULT$20SELECT$20Test.d633fe18-a891-453c-943b-01b311867ac1, workerId=ADD$20DEFAULT$20SELECT$20Test.worker_ADD$20DEFAULT$20SELECT$20Test_01ef8720-9f7b-4232-ba06-b7dae88e105a, startTime=2023-01-26T18:09:10.134345, finishTime=2023-01-26T18:09:10.178368) of size 0
INFO  [2023-01-26 18:09:10,184] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[ADD$20DEFAULT$20SELECT$20Test.d633fe18-a891-453c-943b-01b311867ac1] with 1 results within PT0.050286S
INFO  [2023-01-26 18:09:10,185] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=ADD$20DEFAULT$20SELECT$20Test.d633fe18-a891-453c-943b-01b311867ac1, workerId=ADD$20DEFAULT$20SELECT$20Test.worker_ADD$20DEFAULT$20SELECT$20Test_44044823-a4c8-4e18-b76b-f199aa9b7d09, startTime=2023-01-26T18:09:10.134146, finishTime=2023-01-26T18:09:10.184432) of size 1
INFO  [2023-01-26 18:09:10,185] com.bakdata.conquery.models.execution.ManagedExecution: DONE 8939ab77-8043-4cb2-a264-f166ddede7ad ManagedQuery within PT0.058483S
INFO  [2023-01-26 18:09:10,186] com.bakdata.conquery.integration.json.FormTest: ADD DEFAULT SELECT Test QUERIES EXECUTED
INFO  [2023-01-26 18:09:10,186] com.bakdata.conquery.models.execution.ManagedExecution: DONE d633fe18-a891-453c-943b-01b311867ac1 ManagedInternalForm within PT0.059116S
INFO  [2023-01-26 18:09:10,201] com.bakdata.conquery.integration.json.FormTest: ADD DEFAULT SELECT Test CSV TESTING: results
INFO  [2023-01-26 18:09:10,203] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast ADD DEFAULT SELECT Test
INFO  [2023-01-26 18:09:10,203] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=ADD DEFAULT SELECT Test, name=ADD DEFAULT SELECT Test]
INFO  [2023-01-26 18:09:10,203] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=ADD DEFAULT SELECT Test, name=ADD DEFAULT SELECT Test]
INFO  [2023-01-26 18:09:10,207] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_ADD DEFAULT SELECT Test_01ef8720-9f7b-4232-ba06-b7dae88e105a
INFO  [2023-01-26 18:09:10,211] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_ADD DEFAULT SELECT Test_44044823-a4c8-4e18-b76b-f199aa9b7d09
INFO  [2023-01-26 18:09:10,231] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow ADD DEFAULT SELECT Test
INFO  [2023-01-26 18:09:10,231] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_ADD DEFAULT SELECT Test_44044823-a4c8-4e18-b76b-f199aa9b7d09
INFO  [2023-01-26 18:09:10,232] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_ADD DEFAULT SELECT Test_01ef8720-9f7b-4232-ba06-b7dae88e105a
INFO  [2023-01-26 18:09:10,301] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of ADD$20DEFAULT$20SELECT$20Test
INFO  [2023-01-26 18:09:10,301] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:10,426] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test ADD DEFAULT SELECT Test
INFO  [2023-01-26 18:09:10,426] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test ADD DEFAULT SELECT Test
INFO  [2023-01-26 18:09:10,426] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:10,426] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:10,427] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=ADD DEFAULT SELECT Test[1], name=ADD DEFAULT SELECT Test[1]]
INFO  [2023-01-26 18:09:10,427] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=ADD DEFAULT SELECT Test[1], name=ADD DEFAULT SELECT Test[1]]
INFO  [2023-01-26 18:09:10,427] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:10,427] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:10,433] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker ADD$20DEFAULT$20SELECT$20Test[1].worker_ADD$20DEFAULT$20SELECT$20Test[1]_751bbaa8-2bed-4a8a-a44a-4c4598d32d93 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:10,433] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker ADD$20DEFAULT$20SELECT$20Test[1].worker_ADD$20DEFAULT$20SELECT$20Test[1]_751bbaa8-2bed-4a8a-a44a-4c4598d32d93 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:10,433] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:10,435] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker ADD$20DEFAULT$20SELECT$20Test[1].worker_ADD$20DEFAULT$20SELECT$20Test[1]_edbeb98c-dc54-42db-82df-8f658269b58d are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:10,435] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker ADD$20DEFAULT$20SELECT$20Test[1].worker_ADD$20DEFAULT$20SELECT$20Test[1]_edbeb98c-dc54-42db-82df-8f658269b58d are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:10,435] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:10,439] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:10,539] com.bakdata.conquery.resources.admin.rest.AdminDatasetProcessor: Received new SecondaryId[ADD$20DEFAULT$20SELECT$20Test[1].secondary]
INFO  [2023-01-26 18:09:10,540] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:10,541] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId ADD$20DEFAULT$20SELECT$20Test[1].secondary
INFO  [2023-01-26 18:09:10,541] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId ADD$20DEFAULT$20SELECT$20Test[1].secondary
INFO  [2023-01-26 18:09:10,648] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:10,648] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ADD$20DEFAULT$20SELECT$20Test[1].vers_stamm
INFO  [2023-01-26 18:09:10,648] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ADD$20DEFAULT$20SELECT$20Test[1].table
INFO  [2023-01-26 18:09:10,648] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ADD$20DEFAULT$20SELECT$20Test[1].vers_stamm
INFO  [2023-01-26 18:09:10,649] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ADD$20DEFAULT$20SELECT$20Test[1].table
INFO  [2023-01-26 18:09:10,753] com.bakdata.conquery.integration.json.FormTest: ADD DEFAULT SELECT Test IMPORT TABLES
INFO  [2023-01-26 18:09:10,766] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:10,877] com.bakdata.conquery.integration.json.FormTest: ADD DEFAULT SELECT Test IMPORT CONCEPTS
INFO  [2023-01-26 18:09:10,877] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:10,877] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:10,877] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:10,877] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 1.5 KiB in total
INFO  [2023-01-26 18:09:10,878] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ADD DEFAULT SELECT Test[1]/vers_stamm.import.json, tag=Optional.empty)
█████████████████████████████████████████████     ▌  90%	est. time remaining: 0.003628361sINFO  [2023-01-26 18:09:10,908] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=22, sum=22, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:10,908] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_end] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15614, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@76616f51)
INFO  [2023-01-26 18:09:10,908] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=22, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:10,908] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geburtsdatum] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=-6759, maxValue=9131), dateReader=com.bakdata.conquery.util.DateReader@3f281c7d)
INFO  [2023-01-26 18:09:10,908] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_start] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15340, maxValue=15706), dateReader=com.bakdata.conquery.util.DateReader@627c570e)
INFO  [2023-01-26 18:09:10,908] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date] with DateRangeParser(super=Parser(lines=22, nullLines=0), minParser=DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15340, maxValue=15706), dateReader=com.bakdata.conquery.util.DateReader@2ed1fbe9), maxParser=DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15614, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@40af1c9d), dateReader=com.bakdata.conquery.util.DateReader@7f2bf8b7, onlyQuarters=false, maxValue=16070, minValue=15340, anyOpen=false)
INFO  [2023-01-26 18:09:10,912] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ADD DEFAULT SELECT Test[1]/vers_stamm.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:10,912] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ADD DEFAULT SELECT Test[1]/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000564879sINFO  [2023-01-26 18:09:10,935] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=1, sum=6, min=6, average=6.000000, max=6}
INFO  [2023-01-26 18:09:10,935] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[second_id] with StringParser(super=Parser(lines=6, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:10,935] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=15400, maxValue=15405), dateReader=com.bakdata.conquery.util.DateReader@74343c9f)
INFO  [2023-01-26 18:09:10,935] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[column] with StringParser(super=Parser(lines=6, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:10,938] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ADD DEFAULT SELECT Test[1]/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:10,938] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 2 Jobs:
INFO  [2023-01-26 18:09:10,938] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ADD DEFAULT SELECT Test[1]/vers_stamm.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:10,938] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ADD DEFAULT SELECT Test[1]/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:10,958] com.bakdata.conquery.models.jobs.ImportJob: Importing vers_stamm into ADD$20DEFAULT$20SELECT$20Test[1].vers_stamm
127.0.0.1 - - [26/Jan/2023:18:09:10 +0000] "POST /admin/datasets/ADD%20DEFAULT%20SELECT%20Test%5B1%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_ADD+DEFAULT+SELECT+Test%5B1%5D%2Fvers_stamm.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 10
INFO  [2023-01-26 18:09:10,959] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:10,960] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:10,960] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:10,964] com.bakdata.conquery.models.jobs.ImportJob: Start sending 8 Buckets
INFO  [2023-01-26 18:09:10,964] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ADD$20DEFAULT$20SELECT$20Test[1].vers_stamm.vers_stamm], containing 22 entries.
INFO  [2023-01-26 18:09:10,964] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ADD$20DEFAULT$20SELECT$20Test[1].vers_stamm.vers_stamm], containing 22 entries.
INFO  [2023-01-26 18:09:10,966] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ADD$20DEFAULT$20SELECT$20Test[1].vers_stamm.vers_stamm.0
INFO  [2023-01-26 18:09:10,966] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ADD$20DEFAULT$20SELECT$20Test[1].vers_stamm.vers_stamm.1
INFO  [2023-01-26 18:09:10,984] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ADD$20DEFAULT$20SELECT$20Test[1].vers_stamm.vers_stamm.2
INFO  [2023-01-26 18:09:10,984] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ADD$20DEFAULT$20SELECT$20Test[1].vers_stamm.vers_stamm.3
INFO  [2023-01-26 18:09:10,984] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ADD$20DEFAULT$20SELECT$20Test[1].vers_stamm.vers_stamm.4
INFO  [2023-01-26 18:09:10,984] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ADD$20DEFAULT$20SELECT$20Test[1].vers_stamm.vers_stamm.5
WARN  [2023-01-26 18:09:10,984] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:10,984] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ADD$20DEFAULT$20SELECT$20Test[1].vers_stamm.vers_stamm.6
INFO  [2023-01-26 18:09:10,985] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ADD$20DEFAULT$20SELECT$20Test[1].vers_stamm.vers_stamm.7
INFO  [2023-01-26 18:09:10,994] com.bakdata.conquery.models.jobs.ImportJob: Importing table into ADD$20DEFAULT$20SELECT$20Test[1].table
INFO  [2023-01-26 18:09:10,994] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
127.0.0.1 - - [26/Jan/2023:18:09:10 +0000] "POST /admin/datasets/ADD%20DEFAULT%20SELECT%20Test%5B1%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_ADD+DEFAULT+SELECT+Test%5B1%5D%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:09:10,995] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:10,995] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:10,995] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:10,995] com.bakdata.conquery.models.jobs.ImportJob: Start sending 1 Buckets
WARN  [2023-01-26 18:09:10,996] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:10,996] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ADD$20DEFAULT$20SELECT$20Test[1].table.table], containing 6 entries.
INFO  [2023-01-26 18:09:10,996] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ADD$20DEFAULT$20SELECT$20Test[1].table.table], containing 6 entries.
INFO  [2023-01-26 18:09:10,996] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ADD$20DEFAULT$20SELECT$20Test[1].table.table.0
INFO  [2023-01-26 18:09:11,101] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:11,106] com.bakdata.conquery.integration.json.FormTest: ADD DEFAULT SELECT Test IMPORT TABLE CONTENTS
INFO  [2023-01-26 18:09:11,111] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:11,116] com.bakdata.conquery.integration.json.FormTest: ADD DEFAULT SELECT Test PARSE JSON FORM DESCRIPTION
INFO  [2023-01-26 18:09:11,124] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:11,124] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 2 Concepts
INFO  [2023-01-26 18:09:11,124] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 2 Concepts
INFO  [2023-01-26 18:09:11,232] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[f6df7414-db75-4285-a888-0b7e8d593c85] in Datasets[[]]
INFO  [2023-01-26 18:09:11,239] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteForm: Started Form ADD$20DEFAULT$20SELECT$20Test[1].f6df7414-db75-4285-a888-0b7e8d593c85
INFO  [2023-01-26 18:09:11,239] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteForm: Started Form ADD$20DEFAULT$20SELECT$20Test[1].f6df7414-db75-4285-a888-0b7e8d593c85
INFO  [2023-01-26 18:09:11,246] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[ADD$20DEFAULT$20SELECT$20Test[1].f6df7414-db75-4285-a888-0b7e8d593c85] with 0 results within PT0.007224S
INFO  [2023-01-26 18:09:11,246] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[ADD$20DEFAULT$20SELECT$20Test[1].f6df7414-db75-4285-a888-0b7e8d593c85] with 1 results within PT0.007493S
INFO  [2023-01-26 18:09:11,248] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=ADD$20DEFAULT$20SELECT$20Test[1].f6df7414-db75-4285-a888-0b7e8d593c85, workerId=ADD$20DEFAULT$20SELECT$20Test[1].worker_ADD$20DEFAULT$20SELECT$20Test[1]_751bbaa8-2bed-4a8a-a44a-4c4598d32d93, startTime=2023-01-26T18:09:11.239140, finishTime=2023-01-26T18:09:11.246364) of size 0
INFO  [2023-01-26 18:09:11,248] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=ADD$20DEFAULT$20SELECT$20Test[1].f6df7414-db75-4285-a888-0b7e8d593c85, workerId=ADD$20DEFAULT$20SELECT$20Test[1].worker_ADD$20DEFAULT$20SELECT$20Test[1]_edbeb98c-dc54-42db-82df-8f658269b58d, startTime=2023-01-26T18:09:11.239141, finishTime=2023-01-26T18:09:11.246634) of size 1
INFO  [2023-01-26 18:09:11,248] com.bakdata.conquery.models.execution.ManagedExecution: DONE 1fdfe3fa-a103-453a-841e-09e999d240ac ManagedQuery within PT0.016273S
INFO  [2023-01-26 18:09:11,249] com.bakdata.conquery.models.execution.ManagedExecution: DONE f6df7414-db75-4285-a888-0b7e8d593c85 ManagedInternalForm within PT0.01706S
INFO  [2023-01-26 18:09:11,249] com.bakdata.conquery.integration.json.FormTest: ADD DEFAULT SELECT Test QUERIES EXECUTED
INFO  [2023-01-26 18:09:11,264] com.bakdata.conquery.integration.json.FormTest: ADD DEFAULT SELECT Test CSV TESTING: results
INFO  [2023-01-26 18:09:11,266] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast ADD DEFAULT SELECT Test[1]
INFO  [2023-01-26 18:09:11,266] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=ADD DEFAULT SELECT Test[1], name=ADD DEFAULT SELECT Test[1]]
INFO  [2023-01-26 18:09:11,266] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=ADD DEFAULT SELECT Test[1], name=ADD DEFAULT SELECT Test[1]]
INFO  [2023-01-26 18:09:11,266] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_ADD DEFAULT SELECT Test[1]_751bbaa8-2bed-4a8a-a44a-4c4598d32d93
INFO  [2023-01-26 18:09:11,266] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_ADD DEFAULT SELECT Test[1]_edbeb98c-dc54-42db-82df-8f658269b58d
INFO  [2023-01-26 18:09:11,328] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow ADD DEFAULT SELECT Test[1]
INFO  [2023-01-26 18:09:11,366] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_ADD DEFAULT SELECT Test[1]_751bbaa8-2bed-4a8a-a44a-4c4598d32d93
INFO  [2023-01-26 18:09:11,366] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_ADD DEFAULT SELECT Test[1]_edbeb98c-dc54-42db-82df-8f658269b58d
INFO  [2023-01-26 18:09:11,396] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of ADD$20DEFAULT$20SELECT$20Test[1]
INFO  [2023-01-26 18:09:11,396] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:11,534] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test ADD DEFAULT SELECT Test
INFO  [2023-01-26 18:09:11,535] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test ENTITY-DATE-EXPORT-FORM SECONDARY_ID
INFO  [2023-01-26 18:09:11,535] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:11,535] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:11,536] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=ENTITY-DATE-EXPORT-FORM SECONDARY_ID, name=ENTITY-DATE-EXPORT-FORM SECONDARY_ID]
INFO  [2023-01-26 18:09:11,536] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=ENTITY-DATE-EXPORT-FORM SECONDARY_ID, name=ENTITY-DATE-EXPORT-FORM SECONDARY_ID]
INFO  [2023-01-26 18:09:11,536] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:11,536] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:11,538] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:11,539] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.worker_ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID_0b729942-cef8-4fbd-bcdb-1d175d3bc122 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:11,539] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.worker_ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID_0b729942-cef8-4fbd-bcdb-1d175d3bc122 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:11,539] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:11,539] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.worker_ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID_382654cb-118f-4807-9bcb-1caa47ce6c5d are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:11,539] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.worker_ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID_382654cb-118f-4807-9bcb-1caa47ce6c5d are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:11,539] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:11,642] com.bakdata.conquery.resources.admin.rest.AdminDatasetProcessor: Received new SecondaryId[ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.secondary]
INFO  [2023-01-26 18:09:11,644] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:11,644] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.secondary
INFO  [2023-01-26 18:09:11,645] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.secondary
INFO  [2023-01-26 18:09:11,758] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.vers_stamm
INFO  [2023-01-26 18:09:11,758] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.vers_stamm
INFO  [2023-01-26 18:09:11,758] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:11,758] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.table
INFO  [2023-01-26 18:09:11,758] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.table
INFO  [2023-01-26 18:09:11,864] com.bakdata.conquery.integration.json.FormTest: ENTITY-DATE-EXPORT-FORM SECONDARY_ID IMPORT TABLES
INFO  [2023-01-26 18:09:11,874] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:11,984] com.bakdata.conquery.integration.json.FormTest: ENTITY-DATE-EXPORT-FORM SECONDARY_ID IMPORT CONCEPTS
INFO  [2023-01-26 18:09:11,985] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:11,985] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:11,985] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:11,985] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 1.5 KiB in total
INFO  [2023-01-26 18:09:11,985] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ENTITY-DATE-EXPORT-FORM SECONDARY_ID/vers_stamm.import.json, tag=Optional.empty)
█████████████████████████████████████████████     ▌  90%	est. time remaining: 0.003706769sINFO  [2023-01-26 18:09:12,017] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=22, sum=22, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:12,017] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=22, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:12,017] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_end] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15614, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@5ec3184c)
INFO  [2023-01-26 18:09:12,017] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geburtsdatum] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=-6759, maxValue=9131), dateReader=com.bakdata.conquery.util.DateReader@621e3f1c)
INFO  [2023-01-26 18:09:12,017] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date] with DateRangeParser(super=Parser(lines=22, nullLines=0), minParser=DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15340, maxValue=15706), dateReader=com.bakdata.conquery.util.DateReader@5d0cf4bb), maxParser=DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15614, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@388df2f0), dateReader=com.bakdata.conquery.util.DateReader@2f8aa58b, onlyQuarters=false, maxValue=16070, minValue=15340, anyOpen=false)
INFO  [2023-01-26 18:09:12,017] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_start] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15340, maxValue=15706), dateReader=com.bakdata.conquery.util.DateReader@42f740a9)
INFO  [2023-01-26 18:09:12,022] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ENTITY-DATE-EXPORT-FORM SECONDARY_ID/vers_stamm.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:12,022] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ENTITY-DATE-EXPORT-FORM SECONDARY_ID/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000545817sINFO  [2023-01-26 18:09:12,041] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=1, sum=6, min=6, average=6.000000, max=6}
INFO  [2023-01-26 18:09:12,041] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=15400, maxValue=15405), dateReader=com.bakdata.conquery.util.DateReader@77db69bd)
INFO  [2023-01-26 18:09:12,041] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[second_id] with StringParser(super=Parser(lines=6, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:12,041] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[column] with StringParser(super=Parser(lines=6, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:12,044] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ENTITY-DATE-EXPORT-FORM SECONDARY_ID/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:12,045] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 2 Jobs:
INFO  [2023-01-26 18:09:12,045] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ENTITY-DATE-EXPORT-FORM SECONDARY_ID/vers_stamm.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:12,045] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ENTITY-DATE-EXPORT-FORM SECONDARY_ID/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:12,064] com.bakdata.conquery.models.jobs.ImportJob: Importing vers_stamm into ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.vers_stamm
127.0.0.1 - - [26/Jan/2023:18:09:12 +0000] "POST /admin/datasets/ENTITY-DATE-EXPORT-FORM%20SECONDARY_ID/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_ENTITY-DATE-EXPORT-FORM+SECONDARY_ID%2Fvers_stamm.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:09:12,066] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:12,066] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:12,066] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:12,068] com.bakdata.conquery.models.jobs.ImportJob: Start sending 8 Buckets
INFO  [2023-01-26 18:09:12,068] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.vers_stamm.vers_stamm], containing 22 entries.
INFO  [2023-01-26 18:09:12,068] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.vers_stamm.vers_stamm], containing 22 entries.
WARN  [2023-01-26 18:09:12,070] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:12,071] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.vers_stamm.vers_stamm.0
INFO  [2023-01-26 18:09:12,072] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.vers_stamm.vers_stamm.1
INFO  [2023-01-26 18:09:12,072] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.vers_stamm.vers_stamm.4
INFO  [2023-01-26 18:09:12,072] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.vers_stamm.vers_stamm.6
INFO  [2023-01-26 18:09:12,079] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.vers_stamm.vers_stamm.2
INFO  [2023-01-26 18:09:12,080] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.vers_stamm.vers_stamm.3
INFO  [2023-01-26 18:09:12,080] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.vers_stamm.vers_stamm.5
INFO  [2023-01-26 18:09:12,080] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.vers_stamm.vers_stamm.7
INFO  [2023-01-26 18:09:12,088] com.bakdata.conquery.models.jobs.ImportJob: Importing table into ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.table
INFO  [2023-01-26 18:09:12,089] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
127.0.0.1 - - [26/Jan/2023:18:09:12 +0000] "POST /admin/datasets/ENTITY-DATE-EXPORT-FORM%20SECONDARY_ID/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_ENTITY-DATE-EXPORT-FORM+SECONDARY_ID%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 14
INFO  [2023-01-26 18:09:12,089] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:12,089] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:12,089] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:12,089] com.bakdata.conquery.models.jobs.ImportJob: Start sending 1 Buckets
INFO  [2023-01-26 18:09:12,090] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.table.table], containing 6 entries.
WARN  [2023-01-26 18:09:12,090] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:12,090] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.table.table], containing 6 entries.
INFO  [2023-01-26 18:09:12,090] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.table.table.0
INFO  [2023-01-26 18:09:12,195] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:12,200] com.bakdata.conquery.integration.json.FormTest: ENTITY-DATE-EXPORT-FORM SECONDARY_ID IMPORT TABLE CONTENTS
INFO  [2023-01-26 18:09:12,206] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:12,212] com.bakdata.conquery.integration.json.FormTest: ENTITY-DATE-EXPORT-FORM SECONDARY_ID PARSE JSON FORM DESCRIPTION
INFO  [2023-01-26 18:09:12,218] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:12,219] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 2 Concepts
INFO  [2023-01-26 18:09:12,219] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 2 Concepts
INFO  [2023-01-26 18:09:12,336] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[050891c4-d6da-4a2f-992f-c1890d6649ca] in Datasets[[]]
INFO  [2023-01-26 18:09:12,342] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteForm: Started Form ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.050891c4-d6da-4a2f-992f-c1890d6649ca
INFO  [2023-01-26 18:09:12,343] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteForm: Started Form ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.050891c4-d6da-4a2f-992f-c1890d6649ca
INFO  [2023-01-26 18:09:12,371] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.050891c4-d6da-4a2f-992f-c1890d6649ca] with 1 results within PT0.029215S
INFO  [2023-01-26 18:09:12,372] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.050891c4-d6da-4a2f-992f-c1890d6649ca, workerId=ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.worker_ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID_382654cb-118f-4807-9bcb-1caa47ce6c5d, startTime=2023-01-26T18:09:12.342466, finishTime=2023-01-26T18:09:12.371681) of size 1
INFO  [2023-01-26 18:09:12,376] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.050891c4-d6da-4a2f-992f-c1890d6649ca] with 0 results within PT0.033219S
INFO  [2023-01-26 18:09:12,376] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.050891c4-d6da-4a2f-992f-c1890d6649ca, workerId=ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID.worker_ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID_0b729942-cef8-4fbd-bcdb-1d175d3bc122, startTime=2023-01-26T18:09:12.343111, finishTime=2023-01-26T18:09:12.376330) of size 0
INFO  [2023-01-26 18:09:12,377] com.bakdata.conquery.models.execution.ManagedExecution: DONE f6416c6f-a75c-4184-a0e2-9d3a583ba92a ManagedQuery within PT0.040321S
INFO  [2023-01-26 18:09:12,386] com.bakdata.conquery.integration.json.FormTest: ENTITY-DATE-EXPORT-FORM SECONDARY_ID QUERIES EXECUTED
INFO  [2023-01-26 18:09:12,386] com.bakdata.conquery.models.execution.ManagedExecution: DONE 050891c4-d6da-4a2f-992f-c1890d6649ca ManagedInternalForm within PT0.050112S
INFO  [2023-01-26 18:09:12,413] com.bakdata.conquery.integration.json.FormTest: ENTITY-DATE-EXPORT-FORM SECONDARY_ID CSV TESTING: results
INFO  [2023-01-26 18:09:12,414] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast ENTITY-DATE-EXPORT-FORM SECONDARY_ID
INFO  [2023-01-26 18:09:12,414] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=ENTITY-DATE-EXPORT-FORM SECONDARY_ID, name=ENTITY-DATE-EXPORT-FORM SECONDARY_ID]
INFO  [2023-01-26 18:09:12,414] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=ENTITY-DATE-EXPORT-FORM SECONDARY_ID, name=ENTITY-DATE-EXPORT-FORM SECONDARY_ID]
INFO  [2023-01-26 18:09:12,416] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_ENTITY-DATE-EXPORT-FORM SECONDARY_ID_0b729942-cef8-4fbd-bcdb-1d175d3bc122
INFO  [2023-01-26 18:09:12,419] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_ENTITY-DATE-EXPORT-FORM SECONDARY_ID_382654cb-118f-4807-9bcb-1caa47ce6c5d
INFO  [2023-01-26 18:09:12,436] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow ENTITY-DATE-EXPORT-FORM SECONDARY_ID
INFO  [2023-01-26 18:09:12,437] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_ENTITY-DATE-EXPORT-FORM SECONDARY_ID_0b729942-cef8-4fbd-bcdb-1d175d3bc122
INFO  [2023-01-26 18:09:12,437] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_ENTITY-DATE-EXPORT-FORM SECONDARY_ID_382654cb-118f-4807-9bcb-1caa47ce6c5d
INFO  [2023-01-26 18:09:12,530] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of ENTITY-DATE-EXPORT-FORM$20SECONDARY_ID
INFO  [2023-01-26 18:09:12,530] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:12,634] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test ENTITY-DATE-EXPORT-FORM SECONDARY_ID
INFO  [2023-01-26 18:09:12,635] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test ADD DEFAULT SELECT Test
INFO  [2023-01-26 18:09:12,635] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:12,635] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:12,636] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=ADD DEFAULT SELECT Test[2], name=ADD DEFAULT SELECT Test[2]]
INFO  [2023-01-26 18:09:12,636] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=ADD DEFAULT SELECT Test[2], name=ADD DEFAULT SELECT Test[2]]
INFO  [2023-01-26 18:09:12,636] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:12,636] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:12,637] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker ADD$20DEFAULT$20SELECT$20Test[2].worker_ADD$20DEFAULT$20SELECT$20Test[2]_c73e9319-70ef-420e-be1a-02c0d49a26c7 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:12,637] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker ADD$20DEFAULT$20SELECT$20Test[2].worker_ADD$20DEFAULT$20SELECT$20Test[2]_c73e9319-70ef-420e-be1a-02c0d49a26c7 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:12,637] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:12,638] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker ADD$20DEFAULT$20SELECT$20Test[2].worker_ADD$20DEFAULT$20SELECT$20Test[2]_2516588e-db7e-4e0a-a4c9-9c04d0412961 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:12,638] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker ADD$20DEFAULT$20SELECT$20Test[2].worker_ADD$20DEFAULT$20SELECT$20Test[2]_2516588e-db7e-4e0a-a4c9-9c04d0412961 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:12,638] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:12,642] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:12,742] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:12,748] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:12,749] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ADD$20DEFAULT$20SELECT$20Test[2].vers_stamm
INFO  [2023-01-26 18:09:12,749] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ADD$20DEFAULT$20SELECT$20Test[2].vers_stamm
INFO  [2023-01-26 18:09:12,853] com.bakdata.conquery.integration.json.FormTest: ADD DEFAULT SELECT Test IMPORT TABLES
INFO  [2023-01-26 18:09:12,867] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:12,973] com.bakdata.conquery.integration.json.FormTest: ADD DEFAULT SELECT Test IMPORT CONCEPTS
INFO  [2023-01-26 18:09:12,973] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:12,974] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:12,974] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 1.3 KiB in total
INFO  [2023-01-26 18:09:12,974] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ADD DEFAULT SELECT Test[2]/vers_stamm.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000300822sINFO  [2023-01-26 18:09:13,005] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=22, sum=22, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:13,005] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_end] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15614, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@7fb9d0ee)
INFO  [2023-01-26 18:09:13,005] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=22, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:13,005] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_start] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15340, maxValue=15706), dateReader=com.bakdata.conquery.util.DateReader@65da586)
INFO  [2023-01-26 18:09:13,005] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date] with DateRangeParser(super=Parser(lines=22, nullLines=0), minParser=DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15340, maxValue=15706), dateReader=com.bakdata.conquery.util.DateReader@5b2ca2ec), maxParser=DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15614, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@69688979), dateReader=com.bakdata.conquery.util.DateReader@60cf0f1f, onlyQuarters=false, maxValue=16070, minValue=15340, anyOpen=false)
INFO  [2023-01-26 18:09:13,005] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geburtsdatum] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=-6759, maxValue=9131), dateReader=com.bakdata.conquery.util.DateReader@89a4b3d)
INFO  [2023-01-26 18:09:13,009] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ADD DEFAULT SELECT Test[2]/vers_stamm.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:13,009] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:13,009] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ADD DEFAULT SELECT Test[2]/vers_stamm.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:13,027] com.bakdata.conquery.models.jobs.ImportJob: Importing vers_stamm into ADD$20DEFAULT$20SELECT$20Test[2].vers_stamm
127.0.0.1 - - [26/Jan/2023:18:09:13 +0000] "POST /admin/datasets/ADD%20DEFAULT%20SELECT%20Test%5B2%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_ADD+DEFAULT+SELECT+Test%5B2%5D%2Fvers_stamm.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 10
INFO  [2023-01-26 18:09:13,027] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:13,028] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:13,029] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:13,029] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:13,030] com.bakdata.conquery.models.jobs.ImportJob: Start sending 8 Buckets
INFO  [2023-01-26 18:09:13,031] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ADD$20DEFAULT$20SELECT$20Test[2].vers_stamm.vers_stamm], containing 22 entries.
INFO  [2023-01-26 18:09:13,031] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ADD$20DEFAULT$20SELECT$20Test[2].vers_stamm.vers_stamm], containing 22 entries.
INFO  [2023-01-26 18:09:13,032] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ADD$20DEFAULT$20SELECT$20Test[2].vers_stamm.vers_stamm.0
INFO  [2023-01-26 18:09:13,032] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ADD$20DEFAULT$20SELECT$20Test[2].vers_stamm.vers_stamm.1
INFO  [2023-01-26 18:09:13,032] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ADD$20DEFAULT$20SELECT$20Test[2].vers_stamm.vers_stamm.2
INFO  [2023-01-26 18:09:13,032] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ADD$20DEFAULT$20SELECT$20Test[2].vers_stamm.vers_stamm.4
INFO  [2023-01-26 18:09:13,032] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ADD$20DEFAULT$20SELECT$20Test[2].vers_stamm.vers_stamm.3
WARN  [2023-01-26 18:09:13,032] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:13,032] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ADD$20DEFAULT$20SELECT$20Test[2].vers_stamm.vers_stamm.6
INFO  [2023-01-26 18:09:13,032] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ADD$20DEFAULT$20SELECT$20Test[2].vers_stamm.vers_stamm.5
INFO  [2023-01-26 18:09:13,032] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ADD$20DEFAULT$20SELECT$20Test[2].vers_stamm.vers_stamm.7
INFO  [2023-01-26 18:09:13,137] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:13,142] com.bakdata.conquery.integration.json.FormTest: ADD DEFAULT SELECT Test IMPORT TABLE CONTENTS
INFO  [2023-01-26 18:09:13,194] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:13,199] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:13,205] com.bakdata.conquery.integration.json.FormTest: ADD DEFAULT SELECT Test PARSE JSON FORM DESCRIPTION
INFO  [2023-01-26 18:09:13,212] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:13,212] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:13,212] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:13,320] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[0de83731-5b01-4e52-aef4-20031711796e] in Datasets[[]]
INFO  [2023-01-26 18:09:13,326] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteForm: Started Form ADD$20DEFAULT$20SELECT$20Test[2].0de83731-5b01-4e52-aef4-20031711796e
INFO  [2023-01-26 18:09:13,327] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteForm: Started Form ADD$20DEFAULT$20SELECT$20Test[2].0de83731-5b01-4e52-aef4-20031711796e
INFO  [2023-01-26 18:09:13,355] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[ADD$20DEFAULT$20SELECT$20Test[2].0de83731-5b01-4e52-aef4-20031711796e] with 1 results within PT0.029194S
INFO  [2023-01-26 18:09:13,356] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[ADD$20DEFAULT$20SELECT$20Test[2].0de83731-5b01-4e52-aef4-20031711796e] with 0 results within PT0.028437S
INFO  [2023-01-26 18:09:13,356] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=ADD$20DEFAULT$20SELECT$20Test[2].0de83731-5b01-4e52-aef4-20031711796e, workerId=ADD$20DEFAULT$20SELECT$20Test[2].worker_ADD$20DEFAULT$20SELECT$20Test[2]_c73e9319-70ef-420e-be1a-02c0d49a26c7, startTime=2023-01-26T18:09:13.326249, finishTime=2023-01-26T18:09:13.355443) of size 1
INFO  [2023-01-26 18:09:13,356] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=ADD$20DEFAULT$20SELECT$20Test[2].0de83731-5b01-4e52-aef4-20031711796e, workerId=ADD$20DEFAULT$20SELECT$20Test[2].worker_ADD$20DEFAULT$20SELECT$20Test[2]_2516588e-db7e-4e0a-a4c9-9c04d0412961, startTime=2023-01-26T18:09:13.327585, finishTime=2023-01-26T18:09:13.356022) of size 0
INFO  [2023-01-26 18:09:13,356] com.bakdata.conquery.models.execution.ManagedExecution: DONE 7d4922ef-8b9c-4ac6-b3ab-b62fa20af66d ManagedQuery within PT0.036236S
INFO  [2023-01-26 18:09:13,357] com.bakdata.conquery.models.execution.ManagedExecution: DONE 0de83731-5b01-4e52-aef4-20031711796e ManagedInternalForm within PT0.037086S
INFO  [2023-01-26 18:09:13,357] com.bakdata.conquery.integration.json.FormTest: ADD DEFAULT SELECT Test QUERIES EXECUTED
INFO  [2023-01-26 18:09:13,366] com.bakdata.conquery.integration.json.FormTest: ADD DEFAULT SELECT Test CSV TESTING: results
INFO  [2023-01-26 18:09:13,368] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast ADD DEFAULT SELECT Test[2]
INFO  [2023-01-26 18:09:13,368] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=ADD DEFAULT SELECT Test[2], name=ADD DEFAULT SELECT Test[2]]
INFO  [2023-01-26 18:09:13,368] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=ADD DEFAULT SELECT Test[2], name=ADD DEFAULT SELECT Test[2]]
INFO  [2023-01-26 18:09:13,368] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_ADD DEFAULT SELECT Test[2]_2516588e-db7e-4e0a-a4c9-9c04d0412961
INFO  [2023-01-26 18:09:13,368] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_ADD DEFAULT SELECT Test[2]_c73e9319-70ef-420e-be1a-02c0d49a26c7
INFO  [2023-01-26 18:09:13,466] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow ADD DEFAULT SELECT Test[2]
INFO  [2023-01-26 18:09:13,466] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_ADD DEFAULT SELECT Test[2]_2516588e-db7e-4e0a-a4c9-9c04d0412961
INFO  [2023-01-26 18:09:13,466] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_ADD DEFAULT SELECT Test[2]_c73e9319-70ef-420e-be1a-02c0d49a26c7
INFO  [2023-01-26 18:09:13,533] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of ADD$20DEFAULT$20SELECT$20Test[2]
INFO  [2023-01-26 18:09:13,533] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:13,618] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test ADD DEFAULT SELECT Test
INFO  [2023-01-26 18:09:13,618] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test WITH SELECT SET Test
INFO  [2023-01-26 18:09:13,618] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:13,618] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:13,619] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=WITH SELECT SET Test, name=WITH SELECT SET Test]
INFO  [2023-01-26 18:09:13,619] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=WITH SELECT SET Test, name=WITH SELECT SET Test]
INFO  [2023-01-26 18:09:13,619] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:13,619] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:13,621] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker WITH$20SELECT$20SET$20Test.worker_WITH$20SELECT$20SET$20Test_bcf27a17-e451-431c-b92e-2ccab8c7f1cc are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:13,621] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker WITH$20SELECT$20SET$20Test.worker_WITH$20SELECT$20SET$20Test_bcf27a17-e451-431c-b92e-2ccab8c7f1cc are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:13,621] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:13,627] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker WITH$20SELECT$20SET$20Test.worker_WITH$20SELECT$20SET$20Test_0df31fa3-ecb4-4bef-b889-dfc568c3a697 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:13,627] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker WITH$20SELECT$20SET$20Test.worker_WITH$20SELECT$20SET$20Test_0df31fa3-ecb4-4bef-b889-dfc568c3a697 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:13,627] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:13,631] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:13,731] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:13,737] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:13,738] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table WITH$20SELECT$20SET$20Test.vers_stamm
INFO  [2023-01-26 18:09:13,738] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table WITH$20SELECT$20SET$20Test.vers_stamm
INFO  [2023-01-26 18:09:13,842] com.bakdata.conquery.integration.json.FormTest: WITH SELECT SET Test IMPORT TABLES
INFO  [2023-01-26 18:09:13,851] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:13,968] com.bakdata.conquery.integration.json.FormTest: WITH SELECT SET Test IMPORT CONCEPTS
INFO  [2023-01-26 18:09:13,969] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:13,969] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:13,969] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 1.3 KiB in total
INFO  [2023-01-26 18:09:13,969] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_WITH SELECT SET Test/vers_stamm.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000210221sINFO  [2023-01-26 18:09:13,991] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=22, sum=22, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:13,991] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_end] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15614, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@5b993c76)
INFO  [2023-01-26 18:09:13,991] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=22, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:13,991] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_start] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15340, maxValue=15706), dateReader=com.bakdata.conquery.util.DateReader@6358e5ad)
INFO  [2023-01-26 18:09:13,991] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geburtsdatum] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=-6759, maxValue=9131), dateReader=com.bakdata.conquery.util.DateReader@ca5cef6)
INFO  [2023-01-26 18:09:13,991] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date] with DateRangeParser(super=Parser(lines=22, nullLines=0), minParser=DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15340, maxValue=15706), dateReader=com.bakdata.conquery.util.DateReader@503e8ff3), maxParser=DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15614, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@6a2d1063), dateReader=com.bakdata.conquery.util.DateReader@3de075a4, onlyQuarters=false, maxValue=16070, minValue=15340, anyOpen=false)
INFO  [2023-01-26 18:09:13,997] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_WITH SELECT SET Test/vers_stamm.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:13,997] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:13,997] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_WITH SELECT SET Test/vers_stamm.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:14,018] com.bakdata.conquery.models.jobs.ImportJob: Importing vers_stamm into WITH$20SELECT$20SET$20Test.vers_stamm
127.0.0.1 - - [26/Jan/2023:18:09:14 +0000] "POST /admin/datasets/WITH%20SELECT%20SET%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_WITH+SELECT+SET+Test%2Fvers_stamm.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 11
INFO  [2023-01-26 18:09:14,019] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:14,019] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:14,020] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:14,020] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:14,023] com.bakdata.conquery.models.jobs.ImportJob: Start sending 8 Buckets
INFO  [2023-01-26 18:09:14,024] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[WITH$20SELECT$20SET$20Test.vers_stamm.vers_stamm], containing 22 entries.
INFO  [2023-01-26 18:09:14,024] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[WITH$20SELECT$20SET$20Test.vers_stamm.vers_stamm], containing 22 entries.
INFO  [2023-01-26 18:09:14,025] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received WITH$20SELECT$20SET$20Test.vers_stamm.vers_stamm.0
INFO  [2023-01-26 18:09:14,025] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received WITH$20SELECT$20SET$20Test.vers_stamm.vers_stamm.1
INFO  [2023-01-26 18:09:14,025] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received WITH$20SELECT$20SET$20Test.vers_stamm.vers_stamm.2
INFO  [2023-01-26 18:09:14,025] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received WITH$20SELECT$20SET$20Test.vers_stamm.vers_stamm.3
INFO  [2023-01-26 18:09:14,025] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received WITH$20SELECT$20SET$20Test.vers_stamm.vers_stamm.4
WARN  [2023-01-26 18:09:14,025] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:14,025] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received WITH$20SELECT$20SET$20Test.vers_stamm.vers_stamm.5
INFO  [2023-01-26 18:09:14,026] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received WITH$20SELECT$20SET$20Test.vers_stamm.vers_stamm.6
INFO  [2023-01-26 18:09:14,026] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received WITH$20SELECT$20SET$20Test.vers_stamm.vers_stamm.7
INFO  [2023-01-26 18:09:14,143] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:14,148] com.bakdata.conquery.integration.json.FormTest: WITH SELECT SET Test IMPORT TABLE CONTENTS
INFO  [2023-01-26 18:09:14,184] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:14,189] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:14,195] com.bakdata.conquery.integration.json.FormTest: WITH SELECT SET Test PARSE JSON FORM DESCRIPTION
INFO  [2023-01-26 18:09:14,203] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:14,203] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:14,203] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:14,311] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[1b84c104-5cd7-46f5-9d89-8f69de7f7428] in Datasets[[]]
INFO  [2023-01-26 18:09:14,315] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteForm: Started Form WITH$20SELECT$20SET$20Test.1b84c104-5cd7-46f5-9d89-8f69de7f7428
INFO  [2023-01-26 18:09:14,316] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteForm: Started Form WITH$20SELECT$20SET$20Test.1b84c104-5cd7-46f5-9d89-8f69de7f7428
INFO  [2023-01-26 18:09:14,335] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[WITH$20SELECT$20SET$20Test.1b84c104-5cd7-46f5-9d89-8f69de7f7428] with 0 results within PT0.019766S
INFO  [2023-01-26 18:09:14,336] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=WITH$20SELECT$20SET$20Test.1b84c104-5cd7-46f5-9d89-8f69de7f7428, workerId=WITH$20SELECT$20SET$20Test.worker_WITH$20SELECT$20SET$20Test_0df31fa3-ecb4-4bef-b889-dfc568c3a697, startTime=2023-01-26T18:09:14.316139, finishTime=2023-01-26T18:09:14.335905) of size 0
INFO  [2023-01-26 18:09:14,341] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[WITH$20SELECT$20SET$20Test.1b84c104-5cd7-46f5-9d89-8f69de7f7428] with 1 results within PT0.025397S
INFO  [2023-01-26 18:09:14,342] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=WITH$20SELECT$20SET$20Test.1b84c104-5cd7-46f5-9d89-8f69de7f7428, workerId=WITH$20SELECT$20SET$20Test.worker_WITH$20SELECT$20SET$20Test_bcf27a17-e451-431c-b92e-2ccab8c7f1cc, startTime=2023-01-26T18:09:14.315908, finishTime=2023-01-26T18:09:14.341305) of size 1
INFO  [2023-01-26 18:09:14,342] com.bakdata.conquery.models.execution.ManagedExecution: DONE 0f3016a7-d9e1-4299-862d-394c68d2110e ManagedQuery within PT0.031079S
INFO  [2023-01-26 18:09:14,343] com.bakdata.conquery.integration.json.FormTest: WITH SELECT SET Test QUERIES EXECUTED
INFO  [2023-01-26 18:09:14,343] com.bakdata.conquery.models.execution.ManagedExecution: DONE 1b84c104-5cd7-46f5-9d89-8f69de7f7428 ManagedInternalForm within PT0.031735S
INFO  [2023-01-26 18:09:14,355] com.bakdata.conquery.integration.json.FormTest: WITH SELECT SET Test CSV TESTING: results
INFO  [2023-01-26 18:09:14,357] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast WITH SELECT SET Test
INFO  [2023-01-26 18:09:14,357] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=WITH SELECT SET Test, name=WITH SELECT SET Test]
INFO  [2023-01-26 18:09:14,357] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=WITH SELECT SET Test, name=WITH SELECT SET Test]
INFO  [2023-01-26 18:09:14,359] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_WITH SELECT SET Test_0df31fa3-ecb4-4bef-b889-dfc568c3a697
INFO  [2023-01-26 18:09:14,363] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_WITH SELECT SET Test_bcf27a17-e451-431c-b92e-2ccab8c7f1cc
INFO  [2023-01-26 18:09:14,419] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow WITH SELECT SET Test
INFO  [2023-01-26 18:09:14,420] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_WITH SELECT SET Test_bcf27a17-e451-431c-b92e-2ccab8c7f1cc
INFO  [2023-01-26 18:09:14,426] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of WITH$20SELECT$20SET$20Test
INFO  [2023-01-26 18:09:14,426] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:14,427] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_WITH SELECT SET Test_0df31fa3-ecb4-4bef-b889-dfc568c3a697
INFO  [2023-01-26 18:09:14,609] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test WITH SELECT SET Test
INFO  [2023-01-26 18:09:14,610] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test REL-EXPORT-FORM Test
INFO  [2023-01-26 18:09:14,610] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:14,610] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:14,611] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=REL-EXPORT-FORM Test, name=REL-EXPORT-FORM Test]
INFO  [2023-01-26 18:09:14,611] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:14,611] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=REL-EXPORT-FORM Test, name=REL-EXPORT-FORM Test]
INFO  [2023-01-26 18:09:14,611] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:14,613] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker REL-EXPORT-FORM$20Test.worker_REL-EXPORT-FORM$20Test_560fb968-11ee-4793-ab70-f2fb621bfe11 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:14,613] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker REL-EXPORT-FORM$20Test.worker_REL-EXPORT-FORM$20Test_560fb968-11ee-4793-ab70-f2fb621bfe11 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:14,613] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:14,613] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker REL-EXPORT-FORM$20Test.worker_REL-EXPORT-FORM$20Test_c98c302c-ce41-4e71-9438-1a596e16e9bb are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:14,613] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker REL-EXPORT-FORM$20Test.worker_REL-EXPORT-FORM$20Test_c98c302c-ce41-4e71-9438-1a596e16e9bb are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:14,613] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:14,617] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:14,716] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:14,723] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:14,723] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table REL-EXPORT-FORM$20Test.vers_stamm
INFO  [2023-01-26 18:09:14,723] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table REL-EXPORT-FORM$20Test.vers_stamm
INFO  [2023-01-26 18:09:14,723] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table REL-EXPORT-FORM$20Test.vers_tage_range
INFO  [2023-01-26 18:09:14,723] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table REL-EXPORT-FORM$20Test.vers_tage_range
INFO  [2023-01-26 18:09:14,829] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM Test IMPORT TABLES
INFO  [2023-01-26 18:09:14,861] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:14,975] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM Test IMPORT CONCEPTS
INFO  [2023-01-26 18:09:14,975] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:14,976] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:14,976] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:14,976] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 2.3 KiB in total
INFO  [2023-01-26 18:09:14,976] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM Test/vers_stamm.import.json, tag=Optional.empty)
████████████████████████████▌                     ▌  57%	est. time remaining: 0.030703476sINFO  [2023-01-26 18:09:15,017] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=22, sum=22, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:15,017] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_end] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15614, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@374e3734)
INFO  [2023-01-26 18:09:15,017] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geburtsdatum] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=-6759, maxValue=9131), dateReader=com.bakdata.conquery.util.DateReader@49a74106)
INFO  [2023-01-26 18:09:15,017] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=22, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:15,017] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_start] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15340, maxValue=15706), dateReader=com.bakdata.conquery.util.DateReader@7ead1876)
INFO  [2023-01-26 18:09:15,017] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date] with DateRangeParser(super=Parser(lines=22, nullLines=0), minParser=DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15340, maxValue=15706), dateReader=com.bakdata.conquery.util.DateReader@4028ee8d), maxParser=DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15614, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@6d2694b0), dateReader=com.bakdata.conquery.util.DateReader@7589c9fc, onlyQuarters=false, maxValue=16070, minValue=15340, anyOpen=false)
INFO  [2023-01-26 18:09:15,021] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM Test/vers_stamm.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:15,021] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM Test/vers_tage_range.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000697812sINFO  [2023-01-26 18:09:15,047] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=21, sum=21, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:15,047] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_start] with DateParser(super=Parser(lines=21, nullLines=0), subType=IntegerParser(super=Parser(lines=21, nullLines=0), minValue=14975, maxValue=15522), dateReader=com.bakdata.conquery.util.DateReader@562c6140)
INFO  [2023-01-26 18:09:15,047] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_end] with DateParser(super=Parser(lines=21, nullLines=0), subType=IntegerParser(super=Parser(lines=21, nullLines=0), minValue=15614, maxValue=15705), dateReader=com.bakdata.conquery.util.DateReader@63f11193)
INFO  [2023-01-26 18:09:15,047] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date] with DateRangeParser(super=Parser(lines=21, nullLines=0), minParser=DateParser(super=Parser(lines=21, nullLines=0), subType=IntegerParser(super=Parser(lines=21, nullLines=0), minValue=14975, maxValue=15522), dateReader=com.bakdata.conquery.util.DateReader@47bc396e), maxParser=DateParser(super=Parser(lines=21, nullLines=0), subType=IntegerParser(super=Parser(lines=21, nullLines=0), minValue=15614, maxValue=15705), dateReader=com.bakdata.conquery.util.DateReader@63d9677d), dateReader=com.bakdata.conquery.util.DateReader@6175cd6d, onlyQuarters=false, maxValue=15705, minValue=14975, anyOpen=false)
INFO  [2023-01-26 18:09:15,054] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM Test/vers_tage_range.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:15,054] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 2 Jobs:
INFO  [2023-01-26 18:09:15,054] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM Test/vers_stamm.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:15,054] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM Test/vers_tage_range.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:15,075] com.bakdata.conquery.models.jobs.ImportJob: Importing vers_stamm into REL-EXPORT-FORM$20Test.vers_stamm
INFO  [2023-01-26 18:09:15,076] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
127.0.0.1 - - [26/Jan/2023:18:09:15 +0000] "POST /admin/datasets/REL-EXPORT-FORM%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_REL-EXPORT-FORM+Test%2Fvers_stamm.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 17
INFO  [2023-01-26 18:09:15,083] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:15,084] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:15,086] com.bakdata.conquery.models.jobs.ImportJob: Start sending 8 Buckets
INFO  [2023-01-26 18:09:15,086] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[REL-EXPORT-FORM$20Test.vers_stamm.vers_stamm], containing 22 entries.
INFO  [2023-01-26 18:09:15,086] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[REL-EXPORT-FORM$20Test.vers_stamm.vers_stamm], containing 22 entries.
INFO  [2023-01-26 18:09:15,087] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test.vers_stamm.vers_stamm.0
INFO  [2023-01-26 18:09:15,087] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test.vers_stamm.vers_stamm.1
INFO  [2023-01-26 18:09:15,087] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test.vers_stamm.vers_stamm.2
INFO  [2023-01-26 18:09:15,087] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test.vers_stamm.vers_stamm.3
INFO  [2023-01-26 18:09:15,087] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test.vers_stamm.vers_stamm.4
WARN  [2023-01-26 18:09:15,087] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:15,087] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test.vers_stamm.vers_stamm.5
INFO  [2023-01-26 18:09:15,091] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test.vers_stamm.vers_stamm.6
INFO  [2023-01-26 18:09:15,091] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test.vers_stamm.vers_stamm.7
INFO  [2023-01-26 18:09:15,101] com.bakdata.conquery.models.jobs.ImportJob: Importing vers_tage_range into REL-EXPORT-FORM$20Test.vers_tage_range
INFO  [2023-01-26 18:09:15,101] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:15,101] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:15,101] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:15,101] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:09:15 +0000] "POST /admin/datasets/REL-EXPORT-FORM%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_REL-EXPORT-FORM+Test%2Fvers_tage_range.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:09:15,102] com.bakdata.conquery.models.jobs.ImportJob: Start sending 8 Buckets
INFO  [2023-01-26 18:09:15,102] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[REL-EXPORT-FORM$20Test.vers_tage_range.vers_tage_range], containing 21 entries.
INFO  [2023-01-26 18:09:15,102] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[REL-EXPORT-FORM$20Test.vers_tage_range.vers_tage_range], containing 21 entries.
INFO  [2023-01-26 18:09:15,102] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test.vers_tage_range.vers_tage_range.0
INFO  [2023-01-26 18:09:15,102] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test.vers_tage_range.vers_tage_range.1
INFO  [2023-01-26 18:09:15,102] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test.vers_tage_range.vers_tage_range.2
INFO  [2023-01-26 18:09:15,102] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test.vers_tage_range.vers_tage_range.3
INFO  [2023-01-26 18:09:15,102] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test.vers_tage_range.vers_tage_range.4
INFO  [2023-01-26 18:09:15,103] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test.vers_tage_range.vers_tage_range.5
WARN  [2023-01-26 18:09:15,103] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:15,103] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test.vers_tage_range.vers_tage_range.6
INFO  [2023-01-26 18:09:15,103] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test.vers_tage_range.vers_tage_range.7
INFO  [2023-01-26 18:09:15,208] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:15,213] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM Test IMPORT TABLE CONTENTS
INFO  [2023-01-26 18:09:15,256] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:15,262] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:15,267] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM Test PARSE JSON FORM DESCRIPTION
INFO  [2023-01-26 18:09:15,277] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:15,277] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 3 Concepts
INFO  [2023-01-26 18:09:15,278] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 3 Concepts
INFO  [2023-01-26 18:09:15,386] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[771c2240-cac9-4c5e-9acc-dcbde8ee6b10] in Datasets[[]]
INFO  [2023-01-26 18:09:15,403] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteForm: Started Form REL-EXPORT-FORM$20Test.771c2240-cac9-4c5e-9acc-dcbde8ee6b10
INFO  [2023-01-26 18:09:15,403] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteForm: Started Form REL-EXPORT-FORM$20Test.771c2240-cac9-4c5e-9acc-dcbde8ee6b10
INFO  [2023-01-26 18:09:15,411] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[REL-EXPORT-FORM$20Test.771c2240-cac9-4c5e-9acc-dcbde8ee6b10] with 1 results within PT0.007133S
INFO  [2023-01-26 18:09:15,411] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[REL-EXPORT-FORM$20Test.771c2240-cac9-4c5e-9acc-dcbde8ee6b10] with 1 results within PT0.007438S
INFO  [2023-01-26 18:09:15,411] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=REL-EXPORT-FORM$20Test.771c2240-cac9-4c5e-9acc-dcbde8ee6b10, workerId=REL-EXPORT-FORM$20Test.worker_REL-EXPORT-FORM$20Test_c98c302c-ce41-4e71-9438-1a596e16e9bb, startTime=2023-01-26T18:09:15.403885, finishTime=2023-01-26T18:09:15.411018) of size 1
INFO  [2023-01-26 18:09:15,411] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=REL-EXPORT-FORM$20Test.771c2240-cac9-4c5e-9acc-dcbde8ee6b10, workerId=REL-EXPORT-FORM$20Test.worker_REL-EXPORT-FORM$20Test_560fb968-11ee-4793-ab70-f2fb621bfe11, startTime=2023-01-26T18:09:15.403866, finishTime=2023-01-26T18:09:15.411304) of size 1
INFO  [2023-01-26 18:09:15,411] com.bakdata.conquery.models.execution.ManagedExecution: DONE 612d5e19-a5c9-42db-8005-276afce8214a ManagedQuery within PT0.025432S
INFO  [2023-01-26 18:09:15,412] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM Test QUERIES EXECUTED
INFO  [2023-01-26 18:09:15,412] com.bakdata.conquery.models.execution.ManagedExecution: DONE 771c2240-cac9-4c5e-9acc-dcbde8ee6b10 ManagedInternalForm within PT0.026174S
INFO  [2023-01-26 18:09:15,423] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM Test CSV TESTING: results
INFO  [2023-01-26 18:09:15,425] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast REL-EXPORT-FORM Test
INFO  [2023-01-26 18:09:15,425] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=REL-EXPORT-FORM Test, name=REL-EXPORT-FORM Test]
INFO  [2023-01-26 18:09:15,426] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=REL-EXPORT-FORM Test, name=REL-EXPORT-FORM Test]
INFO  [2023-01-26 18:09:15,426] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_REL-EXPORT-FORM Test_560fb968-11ee-4793-ab70-f2fb621bfe11
INFO  [2023-01-26 18:09:15,426] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_REL-EXPORT-FORM Test_c98c302c-ce41-4e71-9438-1a596e16e9bb
INFO  [2023-01-26 18:09:15,515] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow REL-EXPORT-FORM Test
INFO  [2023-01-26 18:09:15,515] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_REL-EXPORT-FORM Test_560fb968-11ee-4793-ab70-f2fb621bfe11
INFO  [2023-01-26 18:09:15,515] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_REL-EXPORT-FORM Test_c98c302c-ce41-4e71-9438-1a596e16e9bb
INFO  [2023-01-26 18:09:15,615] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of REL-EXPORT-FORM$20Test
INFO  [2023-01-26 18:09:15,615] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:15,683] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test REL-EXPORT-FORM Test
INFO  [2023-01-26 18:09:15,683] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test REL-EXPORT-FORM Test
INFO  [2023-01-26 18:09:15,683] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:15,684] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:15,741] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=REL-EXPORT-FORM Test[1], name=REL-EXPORT-FORM Test[1]]
INFO  [2023-01-26 18:09:15,741] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=REL-EXPORT-FORM Test[1], name=REL-EXPORT-FORM Test[1]]
INFO  [2023-01-26 18:09:15,741] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:15,741] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:15,749] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker REL-EXPORT-FORM$20Test[1].worker_REL-EXPORT-FORM$20Test[1]_c87b5dca-c3ed-45f8-aced-283ad7de346f are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:15,749] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker REL-EXPORT-FORM$20Test[1].worker_REL-EXPORT-FORM$20Test[1]_c87b5dca-c3ed-45f8-aced-283ad7de346f are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:15,749] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:15,749] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker REL-EXPORT-FORM$20Test[1].worker_REL-EXPORT-FORM$20Test[1]_aa32176e-40d1-47e1-a629-166548f353d6 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:15,749] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker REL-EXPORT-FORM$20Test[1].worker_REL-EXPORT-FORM$20Test[1]_aa32176e-40d1-47e1-a629-166548f353d6 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:15,749] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:15,753] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:15,854] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:15,862] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:15,862] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table REL-EXPORT-FORM$20Test[1].vers_stamm
INFO  [2023-01-26 18:09:15,862] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table REL-EXPORT-FORM$20Test[1].vers_stamm
INFO  [2023-01-26 18:09:15,863] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table REL-EXPORT-FORM$20Test[1].vers_tage_range
INFO  [2023-01-26 18:09:15,863] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table REL-EXPORT-FORM$20Test[1].vers_tage_range
INFO  [2023-01-26 18:09:15,967] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM Test IMPORT TABLES
INFO  [2023-01-26 18:09:15,992] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:16,102] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM Test IMPORT CONCEPTS
INFO  [2023-01-26 18:09:16,103] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:16,104] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:16,104] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:16,104] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 2.3 KiB in total
INFO  [2023-01-26 18:09:16,104] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM Test[1]/vers_stamm.import.json, tag=Optional.empty)
████████████████████████████▌                     ▌  57%	est. time remaining: 0.028778504sINFO  [2023-01-26 18:09:16,143] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=22, sum=22, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:16,143] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_end] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15614, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@2c55f778)
INFO  [2023-01-26 18:09:16,143] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=22, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:16,143] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_start] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15340, maxValue=15706), dateReader=com.bakdata.conquery.util.DateReader@5f86d9b2)
INFO  [2023-01-26 18:09:16,143] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geburtsdatum] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=-6759, maxValue=9131), dateReader=com.bakdata.conquery.util.DateReader@22bdac21)
INFO  [2023-01-26 18:09:16,143] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date] with DateRangeParser(super=Parser(lines=22, nullLines=0), minParser=DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15340, maxValue=15706), dateReader=com.bakdata.conquery.util.DateReader@78a4c8e8), maxParser=DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15614, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@5a547b74), dateReader=com.bakdata.conquery.util.DateReader@2988be49, onlyQuarters=false, maxValue=16070, minValue=15340, anyOpen=false)
INFO  [2023-01-26 18:09:16,148] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM Test[1]/vers_stamm.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:16,148] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM Test[1]/vers_tage_range.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.00071695sINFO  [2023-01-26 18:09:16,177] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=21, sum=21, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:16,177] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_start] with DateParser(super=Parser(lines=21, nullLines=0), subType=IntegerParser(super=Parser(lines=21, nullLines=0), minValue=14975, maxValue=15522), dateReader=com.bakdata.conquery.util.DateReader@36b293cc)
INFO  [2023-01-26 18:09:16,177] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_end] with DateParser(super=Parser(lines=21, nullLines=0), subType=IntegerParser(super=Parser(lines=21, nullLines=0), minValue=15614, maxValue=15705), dateReader=com.bakdata.conquery.util.DateReader@669bd3fd)
INFO  [2023-01-26 18:09:16,177] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date] with DateRangeParser(super=Parser(lines=21, nullLines=0), minParser=DateParser(super=Parser(lines=21, nullLines=0), subType=IntegerParser(super=Parser(lines=21, nullLines=0), minValue=14975, maxValue=15522), dateReader=com.bakdata.conquery.util.DateReader@642ad7e6), maxParser=DateParser(super=Parser(lines=21, nullLines=0), subType=IntegerParser(super=Parser(lines=21, nullLines=0), minValue=15614, maxValue=15705), dateReader=com.bakdata.conquery.util.DateReader@3d704cc7), dateReader=com.bakdata.conquery.util.DateReader@60db4bc, onlyQuarters=false, maxValue=15705, minValue=14975, anyOpen=false)
INFO  [2023-01-26 18:09:16,180] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM Test[1]/vers_tage_range.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:16,180] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 2 Jobs:
INFO  [2023-01-26 18:09:16,180] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM Test[1]/vers_stamm.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:16,180] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM Test[1]/vers_tage_range.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:16,200] com.bakdata.conquery.models.jobs.ImportJob: Importing vers_stamm into REL-EXPORT-FORM$20Test[1].vers_stamm
127.0.0.1 - - [26/Jan/2023:18:09:16 +0000] "POST /admin/datasets/REL-EXPORT-FORM%20Test%5B1%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_REL-EXPORT-FORM+Test%5B1%5D%2Fvers_stamm.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 11
INFO  [2023-01-26 18:09:16,201] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:16,202] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:16,202] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:16,204] com.bakdata.conquery.models.jobs.ImportJob: Start sending 8 Buckets
INFO  [2023-01-26 18:09:16,204] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[REL-EXPORT-FORM$20Test[1].vers_stamm.vers_stamm], containing 22 entries.
INFO  [2023-01-26 18:09:16,204] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[REL-EXPORT-FORM$20Test[1].vers_stamm.vers_stamm], containing 22 entries.
INFO  [2023-01-26 18:09:16,205] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[1].vers_stamm.vers_stamm.0
INFO  [2023-01-26 18:09:16,205] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[1].vers_stamm.vers_stamm.1
INFO  [2023-01-26 18:09:16,206] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[1].vers_stamm.vers_stamm.2
INFO  [2023-01-26 18:09:16,207] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[1].vers_stamm.vers_stamm.4
INFO  [2023-01-26 18:09:16,207] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[1].vers_stamm.vers_stamm.3
WARN  [2023-01-26 18:09:16,207] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:16,207] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[1].vers_stamm.vers_stamm.5
INFO  [2023-01-26 18:09:16,207] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[1].vers_stamm.vers_stamm.6
INFO  [2023-01-26 18:09:16,207] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[1].vers_stamm.vers_stamm.7
INFO  [2023-01-26 18:09:16,226] com.bakdata.conquery.models.jobs.ImportJob: Importing vers_tage_range into REL-EXPORT-FORM$20Test[1].vers_tage_range
INFO  [2023-01-26 18:09:16,227] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:16,227] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:16,227] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:16,227] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:09:16 +0000] "POST /admin/datasets/REL-EXPORT-FORM%20Test%5B1%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_REL-EXPORT-FORM+Test%5B1%5D%2Fvers_tage_range.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:09:16,227] com.bakdata.conquery.models.jobs.ImportJob: Start sending 8 Buckets
INFO  [2023-01-26 18:09:16,227] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[REL-EXPORT-FORM$20Test[1].vers_tage_range.vers_tage_range], containing 21 entries.
INFO  [2023-01-26 18:09:16,228] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[REL-EXPORT-FORM$20Test[1].vers_tage_range.vers_tage_range], containing 21 entries.
INFO  [2023-01-26 18:09:16,228] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[1].vers_tage_range.vers_tage_range.0
INFO  [2023-01-26 18:09:16,228] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[1].vers_tage_range.vers_tage_range.1
INFO  [2023-01-26 18:09:16,228] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[1].vers_tage_range.vers_tage_range.2
INFO  [2023-01-26 18:09:16,228] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[1].vers_tage_range.vers_tage_range.3
WARN  [2023-01-26 18:09:16,228] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:16,276] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[1].vers_tage_range.vers_tage_range.4
INFO  [2023-01-26 18:09:16,276] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[1].vers_tage_range.vers_tage_range.5
INFO  [2023-01-26 18:09:16,276] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[1].vers_tage_range.vers_tage_range.6
INFO  [2023-01-26 18:09:16,276] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[1].vers_tage_range.vers_tage_range.7
INFO  [2023-01-26 18:09:16,392] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:16,397] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM Test IMPORT TABLE CONTENTS
INFO  [2023-01-26 18:09:16,433] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:16,439] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:16,444] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM Test PARSE JSON FORM DESCRIPTION
INFO  [2023-01-26 18:09:16,451] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:16,451] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 3 Concepts
INFO  [2023-01-26 18:09:16,452] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 3 Concepts
INFO  [2023-01-26 18:09:16,559] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[f789fd37-e2d7-4930-816d-103b16754fe7] in Datasets[[]]
INFO  [2023-01-26 18:09:16,564] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteForm: Started Form REL-EXPORT-FORM$20Test[1].f789fd37-e2d7-4930-816d-103b16754fe7
INFO  [2023-01-26 18:09:16,566] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteForm: Started Form REL-EXPORT-FORM$20Test[1].f789fd37-e2d7-4930-816d-103b16754fe7
INFO  [2023-01-26 18:09:16,593] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[REL-EXPORT-FORM$20Test[1].f789fd37-e2d7-4930-816d-103b16754fe7] with 1 results within PT0.027113S
INFO  [2023-01-26 18:09:16,593] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[REL-EXPORT-FORM$20Test[1].f789fd37-e2d7-4930-816d-103b16754fe7] with 1 results within PT0.028757S
INFO  [2023-01-26 18:09:16,594] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=REL-EXPORT-FORM$20Test[1].f789fd37-e2d7-4930-816d-103b16754fe7, workerId=REL-EXPORT-FORM$20Test[1].worker_REL-EXPORT-FORM$20Test[1]_aa32176e-40d1-47e1-a629-166548f353d6, startTime=2023-01-26T18:09:16.564747, finishTime=2023-01-26T18:09:16.593504) of size 1
INFO  [2023-01-26 18:09:16,594] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=REL-EXPORT-FORM$20Test[1].f789fd37-e2d7-4930-816d-103b16754fe7, workerId=REL-EXPORT-FORM$20Test[1].worker_REL-EXPORT-FORM$20Test[1]_c87b5dca-c3ed-45f8-aced-283ad7de346f, startTime=2023-01-26T18:09:16.566046, finishTime=2023-01-26T18:09:16.593159) of size 1
INFO  [2023-01-26 18:09:16,594] com.bakdata.conquery.models.execution.ManagedExecution: DONE 1d2cca3a-0415-48c2-9a5f-0691b6de3c43 ManagedQuery within PT0.034603S
INFO  [2023-01-26 18:09:16,594] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM Test QUERIES EXECUTED
INFO  [2023-01-26 18:09:16,594] com.bakdata.conquery.models.execution.ManagedExecution: DONE f789fd37-e2d7-4930-816d-103b16754fe7 ManagedInternalForm within PT0.035249S
INFO  [2023-01-26 18:09:16,602] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM Test CSV TESTING: results
INFO  [2023-01-26 18:09:16,603] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast REL-EXPORT-FORM Test[1]
INFO  [2023-01-26 18:09:16,603] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=REL-EXPORT-FORM Test[1], name=REL-EXPORT-FORM Test[1]]
INFO  [2023-01-26 18:09:16,603] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=REL-EXPORT-FORM Test[1], name=REL-EXPORT-FORM Test[1]]
INFO  [2023-01-26 18:09:16,604] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_REL-EXPORT-FORM Test[1]_c87b5dca-c3ed-45f8-aced-283ad7de346f
INFO  [2023-01-26 18:09:16,604] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_REL-EXPORT-FORM Test[1]_aa32176e-40d1-47e1-a629-166548f353d6
INFO  [2023-01-26 18:09:16,641] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow REL-EXPORT-FORM Test[1]
INFO  [2023-01-26 18:09:16,642] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_REL-EXPORT-FORM Test[1]_c87b5dca-c3ed-45f8-aced-283ad7de346f
INFO  [2023-01-26 18:09:16,649] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_REL-EXPORT-FORM Test[1]_aa32176e-40d1-47e1-a629-166548f353d6
INFO  [2023-01-26 18:09:16,728] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of REL-EXPORT-FORM$20Test[1]
INFO  [2023-01-26 18:09:16,729] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:16,757] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test REL-EXPORT-FORM Test
INFO  [2023-01-26 18:09:16,758] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test REL-EXPORT-FORM Test
INFO  [2023-01-26 18:09:16,758] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:16,758] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:16,758] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=REL-EXPORT-FORM Test[2], name=REL-EXPORT-FORM Test[2]]
INFO  [2023-01-26 18:09:16,758] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=REL-EXPORT-FORM Test[2], name=REL-EXPORT-FORM Test[2]]
INFO  [2023-01-26 18:09:16,759] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:16,759] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:16,760] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker REL-EXPORT-FORM$20Test[2].worker_REL-EXPORT-FORM$20Test[2]_01d7194d-bec0-41d9-8a47-d2ffd6d5ecb7 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:16,760] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker REL-EXPORT-FORM$20Test[2].worker_REL-EXPORT-FORM$20Test[2]_01d7194d-bec0-41d9-8a47-d2ffd6d5ecb7 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:16,760] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:16,760] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker REL-EXPORT-FORM$20Test[2].worker_REL-EXPORT-FORM$20Test[2]_e568111e-da26-474f-b4f0-8b3e25ac1739 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:16,760] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker REL-EXPORT-FORM$20Test[2].worker_REL-EXPORT-FORM$20Test[2]_e568111e-da26-474f-b4f0-8b3e25ac1739 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:16,760] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:16,764] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:16,864] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:16,878] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:16,878] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table REL-EXPORT-FORM$20Test[2].vers_stamm
INFO  [2023-01-26 18:09:16,878] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table REL-EXPORT-FORM$20Test[2].vers_stamm
INFO  [2023-01-26 18:09:16,878] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table REL-EXPORT-FORM$20Test[2].vers_tage_range
INFO  [2023-01-26 18:09:16,878] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table REL-EXPORT-FORM$20Test[2].vers_tage_range
INFO  [2023-01-26 18:09:16,982] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM Test IMPORT TABLES
INFO  [2023-01-26 18:09:16,998] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:17,125] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM Test IMPORT CONCEPTS
INFO  [2023-01-26 18:09:17,126] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:17,126] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:17,126] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:17,126] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 2.3 KiB in total
INFO  [2023-01-26 18:09:17,126] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM Test[2]/vers_stamm.import.json, tag=Optional.empty)
████████████████████████████▌                     ▌  57%	est. time remaining: 0.015041726sINFO  [2023-01-26 18:09:17,146] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=22, sum=22, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:17,147] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_end] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15614, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@32e503fa)
INFO  [2023-01-26 18:09:17,147] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=22, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:17,147] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geburtsdatum] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=-6759, maxValue=9131), dateReader=com.bakdata.conquery.util.DateReader@7957fc65)
INFO  [2023-01-26 18:09:17,147] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_start] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15340, maxValue=15706), dateReader=com.bakdata.conquery.util.DateReader@6d1b4067)
INFO  [2023-01-26 18:09:17,147] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date] with DateRangeParser(super=Parser(lines=22, nullLines=0), minParser=DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15340, maxValue=15706), dateReader=com.bakdata.conquery.util.DateReader@5fbc3fc5), maxParser=DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15614, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@60955681), dateReader=com.bakdata.conquery.util.DateReader@b56a67b, onlyQuarters=false, maxValue=16070, minValue=15340, anyOpen=false)
INFO  [2023-01-26 18:09:17,150] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM Test[2]/vers_stamm.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:17,150] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM Test[2]/vers_tage_range.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000431159sINFO  [2023-01-26 18:09:17,170] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=21, sum=21, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:17,170] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_start] with DateParser(super=Parser(lines=21, nullLines=0), subType=IntegerParser(super=Parser(lines=21, nullLines=0), minValue=14975, maxValue=15522), dateReader=com.bakdata.conquery.util.DateReader@30d3f796)
INFO  [2023-01-26 18:09:17,170] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_end] with DateParser(super=Parser(lines=21, nullLines=0), subType=IntegerParser(super=Parser(lines=21, nullLines=0), minValue=15614, maxValue=15705), dateReader=com.bakdata.conquery.util.DateReader@3cf9c70e)
INFO  [2023-01-26 18:09:17,170] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date] with DateRangeParser(super=Parser(lines=21, nullLines=0), minParser=DateParser(super=Parser(lines=21, nullLines=0), subType=IntegerParser(super=Parser(lines=21, nullLines=0), minValue=14975, maxValue=15522), dateReader=com.bakdata.conquery.util.DateReader@38a6b44e), maxParser=DateParser(super=Parser(lines=21, nullLines=0), subType=IntegerParser(super=Parser(lines=21, nullLines=0), minValue=15614, maxValue=15705), dateReader=com.bakdata.conquery.util.DateReader@4150f7f5), dateReader=com.bakdata.conquery.util.DateReader@2dc66360, onlyQuarters=false, maxValue=15705, minValue=14975, anyOpen=false)
INFO  [2023-01-26 18:09:17,174] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM Test[2]/vers_tage_range.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:17,174] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 2 Jobs:
INFO  [2023-01-26 18:09:17,174] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM Test[2]/vers_stamm.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:17,174] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM Test[2]/vers_tage_range.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:17,195] com.bakdata.conquery.models.jobs.ImportJob: Importing vers_stamm into REL-EXPORT-FORM$20Test[2].vers_stamm
127.0.0.1 - - [26/Jan/2023:18:09:17 +0000] "POST /admin/datasets/REL-EXPORT-FORM%20Test%5B2%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_REL-EXPORT-FORM+Test%5B2%5D%2Fvers_stamm.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:09:17,196] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:17,197] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:17,197] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:17,199] com.bakdata.conquery.models.jobs.ImportJob: Start sending 8 Buckets
INFO  [2023-01-26 18:09:17,199] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[REL-EXPORT-FORM$20Test[2].vers_stamm.vers_stamm], containing 22 entries.
INFO  [2023-01-26 18:09:17,199] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[REL-EXPORT-FORM$20Test[2].vers_stamm.vers_stamm], containing 22 entries.
INFO  [2023-01-26 18:09:17,200] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[2].vers_stamm.vers_stamm.0
INFO  [2023-01-26 18:09:17,201] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[2].vers_stamm.vers_stamm.2
INFO  [2023-01-26 18:09:17,201] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[2].vers_stamm.vers_stamm.1
INFO  [2023-01-26 18:09:17,202] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[2].vers_stamm.vers_stamm.3
INFO  [2023-01-26 18:09:17,202] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[2].vers_stamm.vers_stamm.4
INFO  [2023-01-26 18:09:17,202] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[2].vers_stamm.vers_stamm.5
WARN  [2023-01-26 18:09:17,202] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:17,202] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[2].vers_stamm.vers_stamm.6
INFO  [2023-01-26 18:09:17,202] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[2].vers_stamm.vers_stamm.7
INFO  [2023-01-26 18:09:17,211] com.bakdata.conquery.models.jobs.ImportJob: Importing vers_tage_range into REL-EXPORT-FORM$20Test[2].vers_tage_range
INFO  [2023-01-26 18:09:17,212] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:17,212] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:17,212] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
127.0.0.1 - - [26/Jan/2023:18:09:17 +0000] "POST /admin/datasets/REL-EXPORT-FORM%20Test%5B2%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_REL-EXPORT-FORM+Test%5B2%5D%2Fvers_tage_range.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:09:17,212] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:17,212] com.bakdata.conquery.models.jobs.ImportJob: Start sending 8 Buckets
INFO  [2023-01-26 18:09:17,212] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[REL-EXPORT-FORM$20Test[2].vers_tage_range.vers_tage_range], containing 21 entries.
INFO  [2023-01-26 18:09:17,212] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[REL-EXPORT-FORM$20Test[2].vers_tage_range.vers_tage_range], containing 21 entries.
INFO  [2023-01-26 18:09:17,213] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[2].vers_tage_range.vers_tage_range.0
INFO  [2023-01-26 18:09:17,213] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[2].vers_tage_range.vers_tage_range.1
INFO  [2023-01-26 18:09:17,213] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[2].vers_tage_range.vers_tage_range.2
WARN  [2023-01-26 18:09:17,213] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:17,213] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[2].vers_tage_range.vers_tage_range.3
INFO  [2023-01-26 18:09:17,256] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[2].vers_tage_range.vers_tage_range.5
INFO  [2023-01-26 18:09:17,256] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[2].vers_tage_range.vers_tage_range.7
INFO  [2023-01-26 18:09:17,256] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[2].vers_tage_range.vers_tage_range.4
INFO  [2023-01-26 18:09:17,256] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[2].vers_tage_range.vers_tage_range.6
INFO  [2023-01-26 18:09:17,361] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:17,367] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM Test IMPORT TABLE CONTENTS
INFO  [2023-01-26 18:09:17,407] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:17,412] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:17,418] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM Test PARSE JSON FORM DESCRIPTION
INFO  [2023-01-26 18:09:17,425] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:17,425] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 3 Concepts
INFO  [2023-01-26 18:09:17,425] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 3 Concepts
INFO  [2023-01-26 18:09:17,533] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[76240093-bffb-4383-9ff8-de5ce726d32b] in Datasets[[]]
INFO  [2023-01-26 18:09:17,539] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteForm: Started Form REL-EXPORT-FORM$20Test[2].76240093-bffb-4383-9ff8-de5ce726d32b
INFO  [2023-01-26 18:09:17,539] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteForm: Started Form REL-EXPORT-FORM$20Test[2].76240093-bffb-4383-9ff8-de5ce726d32b
INFO  [2023-01-26 18:09:17,548] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[REL-EXPORT-FORM$20Test[2].76240093-bffb-4383-9ff8-de5ce726d32b] with 1 results within PT0.008361S
INFO  [2023-01-26 18:09:17,548] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[REL-EXPORT-FORM$20Test[2].76240093-bffb-4383-9ff8-de5ce726d32b] with 1 results within PT0.008753S
INFO  [2023-01-26 18:09:17,548] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=REL-EXPORT-FORM$20Test[2].76240093-bffb-4383-9ff8-de5ce726d32b, workerId=REL-EXPORT-FORM$20Test[2].worker_REL-EXPORT-FORM$20Test[2]_e568111e-da26-474f-b4f0-8b3e25ac1739, startTime=2023-01-26T18:09:17.539627, finishTime=2023-01-26T18:09:17.547988) of size 1
INFO  [2023-01-26 18:09:17,548] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=REL-EXPORT-FORM$20Test[2].76240093-bffb-4383-9ff8-de5ce726d32b, workerId=REL-EXPORT-FORM$20Test[2].worker_REL-EXPORT-FORM$20Test[2]_01d7194d-bec0-41d9-8a47-d2ffd6d5ecb7, startTime=2023-01-26T18:09:17.539633, finishTime=2023-01-26T18:09:17.548386) of size 1
INFO  [2023-01-26 18:09:17,549] com.bakdata.conquery.models.execution.ManagedExecution: DONE 47823d91-89a4-403f-b4f1-7b4ab0179544 ManagedQuery within PT0.015882S
INFO  [2023-01-26 18:09:17,550] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM Test QUERIES EXECUTED
INFO  [2023-01-26 18:09:17,550] com.bakdata.conquery.models.execution.ManagedExecution: DONE 76240093-bffb-4383-9ff8-de5ce726d32b ManagedInternalForm within PT0.016873S
INFO  [2023-01-26 18:09:17,552] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM Test CSV TESTING: results
INFO  [2023-01-26 18:09:17,555] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast REL-EXPORT-FORM Test[2]
INFO  [2023-01-26 18:09:17,555] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=REL-EXPORT-FORM Test[2], name=REL-EXPORT-FORM Test[2]]
INFO  [2023-01-26 18:09:17,555] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=REL-EXPORT-FORM Test[2], name=REL-EXPORT-FORM Test[2]]
INFO  [2023-01-26 18:09:17,555] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_REL-EXPORT-FORM Test[2]_e568111e-da26-474f-b4f0-8b3e25ac1739
INFO  [2023-01-26 18:09:17,555] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_REL-EXPORT-FORM Test[2]_01d7194d-bec0-41d9-8a47-d2ffd6d5ecb7
INFO  [2023-01-26 18:09:17,587] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow REL-EXPORT-FORM Test[2]
INFO  [2023-01-26 18:09:17,587] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_REL-EXPORT-FORM Test[2]_01d7194d-bec0-41d9-8a47-d2ffd6d5ecb7
INFO  [2023-01-26 18:09:17,587] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_REL-EXPORT-FORM Test[2]_e568111e-da26-474f-b4f0-8b3e25ac1739
INFO  [2023-01-26 18:09:17,613] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of REL-EXPORT-FORM$20Test[2]
INFO  [2023-01-26 18:09:17,613] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:17,730] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test REL-EXPORT-FORM Test
INFO  [2023-01-26 18:09:17,731] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test REL-EXPORT-FORM Test
INFO  [2023-01-26 18:09:17,731] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:17,731] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:17,732] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=REL-EXPORT-FORM Test[3], name=REL-EXPORT-FORM Test[3]]
INFO  [2023-01-26 18:09:17,732] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=REL-EXPORT-FORM Test[3], name=REL-EXPORT-FORM Test[3]]
INFO  [2023-01-26 18:09:17,732] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:17,732] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:17,734] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker REL-EXPORT-FORM$20Test[3].worker_REL-EXPORT-FORM$20Test[3]_60fc3a44-1bba-4baa-8f37-ae84674d0002 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:17,734] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker REL-EXPORT-FORM$20Test[3].worker_REL-EXPORT-FORM$20Test[3]_60fc3a44-1bba-4baa-8f37-ae84674d0002 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:17,734] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:17,734] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker REL-EXPORT-FORM$20Test[3].worker_REL-EXPORT-FORM$20Test[3]_f0ab22b3-8730-4cf3-be56-bf526f12f248 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:17,734] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker REL-EXPORT-FORM$20Test[3].worker_REL-EXPORT-FORM$20Test[3]_f0ab22b3-8730-4cf3-be56-bf526f12f248 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:17,734] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:17,738] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:17,849] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:17,856] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:17,856] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table REL-EXPORT-FORM$20Test[3].vers_stamm
INFO  [2023-01-26 18:09:17,856] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table REL-EXPORT-FORM$20Test[3].vers_stamm
INFO  [2023-01-26 18:09:17,856] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table REL-EXPORT-FORM$20Test[3].vers_tage_range
INFO  [2023-01-26 18:09:17,856] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table REL-EXPORT-FORM$20Test[3].vers_tage_range
INFO  [2023-01-26 18:09:17,962] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM Test IMPORT TABLES
INFO  [2023-01-26 18:09:17,977] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:18,087] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM Test IMPORT CONCEPTS
INFO  [2023-01-26 18:09:18,087] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:18,088] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:18,088] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:18,088] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 2.3 KiB in total
INFO  [2023-01-26 18:09:18,088] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM Test[3]/vers_stamm.import.json, tag=Optional.empty)
████████████████████████████▌                     ▌  57%	est. time remaining: 0.024043782sINFO  [2023-01-26 18:09:18,120] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=22, sum=22, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:18,120] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_end] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15614, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@1b5b3ba1)
INFO  [2023-01-26 18:09:18,120] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=22, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:18,120] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_start] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15340, maxValue=15706), dateReader=com.bakdata.conquery.util.DateReader@157a591e)
INFO  [2023-01-26 18:09:18,120] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geburtsdatum] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=-6759, maxValue=9131), dateReader=com.bakdata.conquery.util.DateReader@5bab56af)
INFO  [2023-01-26 18:09:18,120] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date] with DateRangeParser(super=Parser(lines=22, nullLines=0), minParser=DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15340, maxValue=15706), dateReader=com.bakdata.conquery.util.DateReader@511d9ebd), maxParser=DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15614, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@1ecc3f56), dateReader=com.bakdata.conquery.util.DateReader@776e3e74, onlyQuarters=false, maxValue=16070, minValue=15340, anyOpen=false)
INFO  [2023-01-26 18:09:18,125] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM Test[3]/vers_stamm.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:18,125] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM Test[3]/vers_tage_range.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000617663sINFO  [2023-01-26 18:09:18,151] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=21, sum=21, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:18,151] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_start] with DateParser(super=Parser(lines=21, nullLines=0), subType=IntegerParser(super=Parser(lines=21, nullLines=0), minValue=14975, maxValue=15522), dateReader=com.bakdata.conquery.util.DateReader@15b2bdd9)
INFO  [2023-01-26 18:09:18,151] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_end] with DateParser(super=Parser(lines=21, nullLines=0), subType=IntegerParser(super=Parser(lines=21, nullLines=0), minValue=15614, maxValue=15705), dateReader=com.bakdata.conquery.util.DateReader@311c4028)
INFO  [2023-01-26 18:09:18,151] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date] with DateRangeParser(super=Parser(lines=21, nullLines=0), minParser=DateParser(super=Parser(lines=21, nullLines=0), subType=IntegerParser(super=Parser(lines=21, nullLines=0), minValue=14975, maxValue=15522), dateReader=com.bakdata.conquery.util.DateReader@2058543), maxParser=DateParser(super=Parser(lines=21, nullLines=0), subType=IntegerParser(super=Parser(lines=21, nullLines=0), minValue=15614, maxValue=15705), dateReader=com.bakdata.conquery.util.DateReader@48eefadc), dateReader=com.bakdata.conquery.util.DateReader@7635f8c4, onlyQuarters=false, maxValue=15705, minValue=14975, anyOpen=false)
INFO  [2023-01-26 18:09:18,154] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM Test[3]/vers_tage_range.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:18,154] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 2 Jobs:
INFO  [2023-01-26 18:09:18,154] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM Test[3]/vers_stamm.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:18,154] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM Test[3]/vers_tage_range.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:18,174] com.bakdata.conquery.models.jobs.ImportJob: Importing vers_stamm into REL-EXPORT-FORM$20Test[3].vers_stamm
INFO  [2023-01-26 18:09:18,175] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:18,176] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:18,176] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:18,178] com.bakdata.conquery.models.jobs.ImportJob: Start sending 8 Buckets
INFO  [2023-01-26 18:09:18,178] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[REL-EXPORT-FORM$20Test[3].vers_stamm.vers_stamm], containing 22 entries.
INFO  [2023-01-26 18:09:18,179] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[3].vers_stamm.vers_stamm.0
INFO  [2023-01-26 18:09:18,182] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[3].vers_stamm.vers_stamm.1
INFO  [2023-01-26 18:09:18,182] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[3].vers_stamm.vers_stamm.4
127.0.0.1 - - [26/Jan/2023:18:09:18 +0000] "POST /admin/datasets/REL-EXPORT-FORM%20Test%5B3%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_REL-EXPORT-FORM+Test%5B3%5D%2Fvers_stamm.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 17
INFO  [2023-01-26 18:09:18,182] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[REL-EXPORT-FORM$20Test[3].vers_stamm.vers_stamm], containing 22 entries.
WARN  [2023-01-26 18:09:18,182] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:18,182] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[3].vers_stamm.vers_stamm.2
INFO  [2023-01-26 18:09:18,183] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[3].vers_stamm.vers_stamm.6
INFO  [2023-01-26 18:09:18,183] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[3].vers_stamm.vers_stamm.3
INFO  [2023-01-26 18:09:18,209] com.bakdata.conquery.models.jobs.ImportJob: Importing vers_tage_range into REL-EXPORT-FORM$20Test[3].vers_tage_range
INFO  [2023-01-26 18:09:18,209] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:18,209] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:18,209] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
127.0.0.1 - - [26/Jan/2023:18:09:18 +0000] "POST /admin/datasets/REL-EXPORT-FORM%20Test%5B3%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_REL-EXPORT-FORM+Test%5B3%5D%2Fvers_tage_range.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 16
INFO  [2023-01-26 18:09:18,210] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:18,210] com.bakdata.conquery.models.jobs.ImportJob: Start sending 8 Buckets
INFO  [2023-01-26 18:09:18,210] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[REL-EXPORT-FORM$20Test[3].vers_tage_range.vers_tage_range], containing 21 entries.
INFO  [2023-01-26 18:09:18,210] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[3].vers_tage_range.vers_tage_range.0
WARN  [2023-01-26 18:09:18,210] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:18,211] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[3].vers_tage_range.vers_tage_range.1
INFO  [2023-01-26 18:09:18,224] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[3].vers_stamm.vers_stamm.5
INFO  [2023-01-26 18:09:18,224] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[3].vers_stamm.vers_stamm.7
INFO  [2023-01-26 18:09:18,224] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[REL-EXPORT-FORM$20Test[3].vers_tage_range.vers_tage_range], containing 21 entries.
INFO  [2023-01-26 18:09:18,224] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[3].vers_tage_range.vers_tage_range.2
INFO  [2023-01-26 18:09:18,224] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[3].vers_tage_range.vers_tage_range.3
INFO  [2023-01-26 18:09:18,225] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[3].vers_tage_range.vers_tage_range.5
INFO  [2023-01-26 18:09:18,225] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[3].vers_tage_range.vers_tage_range.7
INFO  [2023-01-26 18:09:18,252] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[3].vers_tage_range.vers_tage_range.4
INFO  [2023-01-26 18:09:18,252] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[3].vers_tage_range.vers_tage_range.6
INFO  [2023-01-26 18:09:18,357] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:18,362] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM Test IMPORT TABLE CONTENTS
INFO  [2023-01-26 18:09:18,410] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:18,416] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:18,421] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM Test PARSE JSON FORM DESCRIPTION
INFO  [2023-01-26 18:09:18,428] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:18,428] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 3 Concepts
INFO  [2023-01-26 18:09:18,428] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 3 Concepts
INFO  [2023-01-26 18:09:18,536] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[519dd65b-5077-4bf8-b02c-80b5c9188a87] in Datasets[[]]
INFO  [2023-01-26 18:09:18,542] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteForm: Started Form REL-EXPORT-FORM$20Test[3].519dd65b-5077-4bf8-b02c-80b5c9188a87
INFO  [2023-01-26 18:09:18,543] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteForm: Started Form REL-EXPORT-FORM$20Test[3].519dd65b-5077-4bf8-b02c-80b5c9188a87
INFO  [2023-01-26 18:09:18,551] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[REL-EXPORT-FORM$20Test[3].519dd65b-5077-4bf8-b02c-80b5c9188a87] with 1 results within PT0.008415S
INFO  [2023-01-26 18:09:18,551] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[REL-EXPORT-FORM$20Test[3].519dd65b-5077-4bf8-b02c-80b5c9188a87] with 1 results within PT0.008388S
INFO  [2023-01-26 18:09:18,552] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=REL-EXPORT-FORM$20Test[3].519dd65b-5077-4bf8-b02c-80b5c9188a87, workerId=REL-EXPORT-FORM$20Test[3].worker_REL-EXPORT-FORM$20Test[3]_f0ab22b3-8730-4cf3-be56-bf526f12f248, startTime=2023-01-26T18:09:18.542855, finishTime=2023-01-26T18:09:18.551270) of size 1
INFO  [2023-01-26 18:09:18,552] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=REL-EXPORT-FORM$20Test[3].519dd65b-5077-4bf8-b02c-80b5c9188a87, workerId=REL-EXPORT-FORM$20Test[3].worker_REL-EXPORT-FORM$20Test[3]_60fc3a44-1bba-4baa-8f37-ae84674d0002, startTime=2023-01-26T18:09:18.543142, finishTime=2023-01-26T18:09:18.551530) of size 1
INFO  [2023-01-26 18:09:18,552] com.bakdata.conquery.models.execution.ManagedExecution: DONE f7a350d8-38ba-4d58-9b37-c862a905dc82 ManagedQuery within PT0.015165S
INFO  [2023-01-26 18:09:18,552] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM Test QUERIES EXECUTED
INFO  [2023-01-26 18:09:18,552] com.bakdata.conquery.models.execution.ManagedExecution: DONE 519dd65b-5077-4bf8-b02c-80b5c9188a87 ManagedInternalForm within PT0.015876S
INFO  [2023-01-26 18:09:18,567] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM Test CSV TESTING: results
INFO  [2023-01-26 18:09:18,569] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=REL-EXPORT-FORM Test[3], name=REL-EXPORT-FORM Test[3]]
INFO  [2023-01-26 18:09:18,569] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast REL-EXPORT-FORM Test[3]
INFO  [2023-01-26 18:09:18,569] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=REL-EXPORT-FORM Test[3], name=REL-EXPORT-FORM Test[3]]
INFO  [2023-01-26 18:09:18,571] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_REL-EXPORT-FORM Test[3]_60fc3a44-1bba-4baa-8f37-ae84674d0002
INFO  [2023-01-26 18:09:18,571] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_REL-EXPORT-FORM Test[3]_f0ab22b3-8730-4cf3-be56-bf526f12f248
INFO  [2023-01-26 18:09:18,632] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow REL-EXPORT-FORM Test[3]
INFO  [2023-01-26 18:09:18,633] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_REL-EXPORT-FORM Test[3]_60fc3a44-1bba-4baa-8f37-ae84674d0002
INFO  [2023-01-26 18:09:18,633] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_REL-EXPORT-FORM Test[3]_f0ab22b3-8730-4cf3-be56-bf526f12f248
INFO  [2023-01-26 18:09:18,713] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of REL-EXPORT-FORM$20Test[3]
INFO  [2023-01-26 18:09:18,713] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:18,834] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test REL-EXPORT-FORM Test
INFO  [2023-01-26 18:09:18,834] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test REL-EXPORT-FORM SECONDARY_ID
INFO  [2023-01-26 18:09:18,834] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:18,834] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:18,835] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=REL-EXPORT-FORM SECONDARY_ID, name=REL-EXPORT-FORM SECONDARY_ID]
INFO  [2023-01-26 18:09:18,835] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=REL-EXPORT-FORM SECONDARY_ID, name=REL-EXPORT-FORM SECONDARY_ID]
INFO  [2023-01-26 18:09:18,835] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:18,835] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:18,837] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker REL-EXPORT-FORM$20SECONDARY_ID.worker_REL-EXPORT-FORM$20SECONDARY_ID_98e8069c-6bf3-48f3-9fc1-d6cd68df2f55 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:18,837] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker REL-EXPORT-FORM$20SECONDARY_ID.worker_REL-EXPORT-FORM$20SECONDARY_ID_98e8069c-6bf3-48f3-9fc1-d6cd68df2f55 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:18,837] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:18,837] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker REL-EXPORT-FORM$20SECONDARY_ID.worker_REL-EXPORT-FORM$20SECONDARY_ID_ce24b35f-c526-4a03-a96d-d830ab0a8c5b are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:18,837] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker REL-EXPORT-FORM$20SECONDARY_ID.worker_REL-EXPORT-FORM$20SECONDARY_ID_ce24b35f-c526-4a03-a96d-d830ab0a8c5b are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:18,837] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:18,841] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:18,941] com.bakdata.conquery.resources.admin.rest.AdminDatasetProcessor: Received new SecondaryId[REL-EXPORT-FORM$20SECONDARY_ID.secondary]
INFO  [2023-01-26 18:09:18,942] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:18,942] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId REL-EXPORT-FORM$20SECONDARY_ID.secondary
INFO  [2023-01-26 18:09:18,942] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId REL-EXPORT-FORM$20SECONDARY_ID.secondary
INFO  [2023-01-26 18:09:19,049] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:19,049] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table REL-EXPORT-FORM$20SECONDARY_ID.vers_stamm
INFO  [2023-01-26 18:09:19,049] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table REL-EXPORT-FORM$20SECONDARY_ID.vers_stamm
INFO  [2023-01-26 18:09:19,049] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table REL-EXPORT-FORM$20SECONDARY_ID.table
INFO  [2023-01-26 18:09:19,049] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table REL-EXPORT-FORM$20SECONDARY_ID.table
INFO  [2023-01-26 18:09:19,154] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM SECONDARY_ID IMPORT TABLES
INFO  [2023-01-26 18:09:19,165] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:19,277] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM SECONDARY_ID IMPORT CONCEPTS
INFO  [2023-01-26 18:09:19,277] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:19,278] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:19,278] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:19,278] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 1.5 KiB in total
INFO  [2023-01-26 18:09:19,278] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM SECONDARY_ID/vers_stamm.import.json, tag=Optional.empty)
█████████████████████████████████████████████     ▌  90%	est. time remaining: 0.003634054sINFO  [2023-01-26 18:09:19,308] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=22, sum=22, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:19,308] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_end] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15614, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@5e0e5b40)
INFO  [2023-01-26 18:09:19,309] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_start] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15340, maxValue=15706), dateReader=com.bakdata.conquery.util.DateReader@48680bb)
INFO  [2023-01-26 18:09:19,309] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=22, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:19,309] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date] with DateRangeParser(super=Parser(lines=22, nullLines=0), minParser=DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15340, maxValue=15706), dateReader=com.bakdata.conquery.util.DateReader@7b65e32d), maxParser=DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15614, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@3ef06e0), dateReader=com.bakdata.conquery.util.DateReader@273eeebd, onlyQuarters=false, maxValue=16070, minValue=15340, anyOpen=false)
INFO  [2023-01-26 18:09:19,309] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geburtsdatum] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=-6759, maxValue=9131), dateReader=com.bakdata.conquery.util.DateReader@18f38b3b)
INFO  [2023-01-26 18:09:19,312] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM SECONDARY_ID/vers_stamm.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:19,313] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM SECONDARY_ID/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000579678sINFO  [2023-01-26 18:09:19,337] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=1, sum=6, min=6, average=6.000000, max=6}
INFO  [2023-01-26 18:09:19,337] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=15400, maxValue=15405), dateReader=com.bakdata.conquery.util.DateReader@6e271a7d)
INFO  [2023-01-26 18:09:19,337] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[second_id] with StringParser(super=Parser(lines=6, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:19,337] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[column] with StringParser(super=Parser(lines=6, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:19,340] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM SECONDARY_ID/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:19,340] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 2 Jobs:
INFO  [2023-01-26 18:09:19,340] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM SECONDARY_ID/vers_stamm.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:19,340] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM SECONDARY_ID/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:19,359] com.bakdata.conquery.models.jobs.ImportJob: Importing vers_stamm into REL-EXPORT-FORM$20SECONDARY_ID.vers_stamm
127.0.0.1 - - [26/Jan/2023:18:09:19 +0000] "POST /admin/datasets/REL-EXPORT-FORM%20SECONDARY_ID/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_REL-EXPORT-FORM+SECONDARY_ID%2Fvers_stamm.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:09:19,360] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:19,361] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:19,361] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:19,363] com.bakdata.conquery.models.jobs.ImportJob: Start sending 8 Buckets
INFO  [2023-01-26 18:09:19,363] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[REL-EXPORT-FORM$20SECONDARY_ID.vers_stamm.vers_stamm], containing 22 entries.
INFO  [2023-01-26 18:09:19,363] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[REL-EXPORT-FORM$20SECONDARY_ID.vers_stamm.vers_stamm], containing 22 entries.
INFO  [2023-01-26 18:09:19,364] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20SECONDARY_ID.vers_stamm.vers_stamm.0
INFO  [2023-01-26 18:09:19,364] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20SECONDARY_ID.vers_stamm.vers_stamm.2
INFO  [2023-01-26 18:09:19,364] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20SECONDARY_ID.vers_stamm.vers_stamm.1
INFO  [2023-01-26 18:09:19,365] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20SECONDARY_ID.vers_stamm.vers_stamm.4
INFO  [2023-01-26 18:09:19,365] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20SECONDARY_ID.vers_stamm.vers_stamm.3
WARN  [2023-01-26 18:09:19,365] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:19,365] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20SECONDARY_ID.vers_stamm.vers_stamm.5
INFO  [2023-01-26 18:09:19,365] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20SECONDARY_ID.vers_stamm.vers_stamm.6
INFO  [2023-01-26 18:09:19,365] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20SECONDARY_ID.vers_stamm.vers_stamm.7
INFO  [2023-01-26 18:09:19,377] com.bakdata.conquery.models.jobs.ImportJob: Importing table into REL-EXPORT-FORM$20SECONDARY_ID.table
INFO  [2023-01-26 18:09:19,378] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:19,378] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:19,378] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
127.0.0.1 - - [26/Jan/2023:18:09:19 +0000] "POST /admin/datasets/REL-EXPORT-FORM%20SECONDARY_ID/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_REL-EXPORT-FORM+SECONDARY_ID%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 10
INFO  [2023-01-26 18:09:19,378] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:19,378] com.bakdata.conquery.models.jobs.ImportJob: Start sending 1 Buckets
INFO  [2023-01-26 18:09:19,379] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[REL-EXPORT-FORM$20SECONDARY_ID.table.table], containing 6 entries.
WARN  [2023-01-26 18:09:19,379] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:19,379] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[REL-EXPORT-FORM$20SECONDARY_ID.table.table], containing 6 entries.
INFO  [2023-01-26 18:09:19,380] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20SECONDARY_ID.table.table.0
INFO  [2023-01-26 18:09:19,485] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:19,490] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM SECONDARY_ID IMPORT TABLE CONTENTS
INFO  [2023-01-26 18:09:19,497] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:19,527] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM SECONDARY_ID PARSE JSON FORM DESCRIPTION
INFO  [2023-01-26 18:09:19,534] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:19,534] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 2 Concepts
INFO  [2023-01-26 18:09:19,534] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 2 Concepts
INFO  [2023-01-26 18:09:19,640] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[c3dd9940-a9fd-468c-95f9-04f69b69642d] in Datasets[[]]
INFO  [2023-01-26 18:09:19,649] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteForm: Started Form REL-EXPORT-FORM$20SECONDARY_ID.c3dd9940-a9fd-468c-95f9-04f69b69642d
INFO  [2023-01-26 18:09:19,649] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteForm: Started Form REL-EXPORT-FORM$20SECONDARY_ID.c3dd9940-a9fd-468c-95f9-04f69b69642d
INFO  [2023-01-26 18:09:19,655] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[REL-EXPORT-FORM$20SECONDARY_ID.c3dd9940-a9fd-468c-95f9-04f69b69642d] with 0 results within PT0.006234S
INFO  [2023-01-26 18:09:19,656] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[REL-EXPORT-FORM$20SECONDARY_ID.c3dd9940-a9fd-468c-95f9-04f69b69642d] with 1 results within PT0.006535S
INFO  [2023-01-26 18:09:19,656] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=REL-EXPORT-FORM$20SECONDARY_ID.c3dd9940-a9fd-468c-95f9-04f69b69642d, workerId=REL-EXPORT-FORM$20SECONDARY_ID.worker_REL-EXPORT-FORM$20SECONDARY_ID_98e8069c-6bf3-48f3-9fc1-d6cd68df2f55, startTime=2023-01-26T18:09:19.649500, finishTime=2023-01-26T18:09:19.656035) of size 1
INFO  [2023-01-26 18:09:19,656] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=REL-EXPORT-FORM$20SECONDARY_ID.c3dd9940-a9fd-468c-95f9-04f69b69642d, workerId=REL-EXPORT-FORM$20SECONDARY_ID.worker_REL-EXPORT-FORM$20SECONDARY_ID_ce24b35f-c526-4a03-a96d-d830ab0a8c5b, startTime=2023-01-26T18:09:19.649728, finishTime=2023-01-26T18:09:19.655962) of size 0
INFO  [2023-01-26 18:09:19,656] com.bakdata.conquery.models.execution.ManagedExecution: DONE 05bd0c1d-4ec5-4334-8e32-49fd4c1e51ea ManagedQuery within PT0.015841S
INFO  [2023-01-26 18:09:19,657] com.bakdata.conquery.models.execution.ManagedExecution: DONE c3dd9940-a9fd-468c-95f9-04f69b69642d ManagedInternalForm within PT0.016619S
INFO  [2023-01-26 18:09:19,657] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM SECONDARY_ID QUERIES EXECUTED
INFO  [2023-01-26 18:09:19,674] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM SECONDARY_ID CSV TESTING: results
INFO  [2023-01-26 18:09:19,676] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast REL-EXPORT-FORM SECONDARY_ID
INFO  [2023-01-26 18:09:19,677] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=REL-EXPORT-FORM SECONDARY_ID, name=REL-EXPORT-FORM SECONDARY_ID]
INFO  [2023-01-26 18:09:19,677] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=REL-EXPORT-FORM SECONDARY_ID, name=REL-EXPORT-FORM SECONDARY_ID]
INFO  [2023-01-26 18:09:19,679] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_REL-EXPORT-FORM SECONDARY_ID_98e8069c-6bf3-48f3-9fc1-d6cd68df2f55
INFO  [2023-01-26 18:09:19,682] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_REL-EXPORT-FORM SECONDARY_ID_ce24b35f-c526-4a03-a96d-d830ab0a8c5b
INFO  [2023-01-26 18:09:19,740] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_REL-EXPORT-FORM SECONDARY_ID_98e8069c-6bf3-48f3-9fc1-d6cd68df2f55
INFO  [2023-01-26 18:09:19,740] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow REL-EXPORT-FORM SECONDARY_ID
INFO  [2023-01-26 18:09:19,740] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_REL-EXPORT-FORM SECONDARY_ID_ce24b35f-c526-4a03-a96d-d830ab0a8c5b
INFO  [2023-01-26 18:09:19,779] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of REL-EXPORT-FORM$20SECONDARY_ID
INFO  [2023-01-26 18:09:19,779] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:19,940] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test REL-EXPORT-FORM SECONDARY_ID
INFO  [2023-01-26 18:09:19,940] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test REL-EXPORT-FORM Test
INFO  [2023-01-26 18:09:19,940] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:19,940] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:19,941] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=REL-EXPORT-FORM Test[4], name=REL-EXPORT-FORM Test[4]]
INFO  [2023-01-26 18:09:19,941] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=REL-EXPORT-FORM Test[4], name=REL-EXPORT-FORM Test[4]]
INFO  [2023-01-26 18:09:19,941] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:19,941] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:19,943] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker REL-EXPORT-FORM$20Test[4].worker_REL-EXPORT-FORM$20Test[4]_cdf93e53-b643-4f8a-9cd0-2295a1f26b20 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:19,943] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker REL-EXPORT-FORM$20Test[4].worker_REL-EXPORT-FORM$20Test[4]_cdf93e53-b643-4f8a-9cd0-2295a1f26b20 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:19,943] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:19,943] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:19,943] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker REL-EXPORT-FORM$20Test[4].worker_REL-EXPORT-FORM$20Test[4]_44b76cfc-18c0-4f39-811a-86c36ee5d2dc are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:19,943] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker REL-EXPORT-FORM$20Test[4].worker_REL-EXPORT-FORM$20Test[4]_44b76cfc-18c0-4f39-811a-86c36ee5d2dc are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:19,943] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:20,047] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:20,053] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:20,054] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table REL-EXPORT-FORM$20Test[4].vers_stamm
INFO  [2023-01-26 18:09:20,054] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table REL-EXPORT-FORM$20Test[4].vers_stamm
INFO  [2023-01-26 18:09:20,054] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table REL-EXPORT-FORM$20Test[4].vers_tage_range
INFO  [2023-01-26 18:09:20,054] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table REL-EXPORT-FORM$20Test[4].vers_tage_range
INFO  [2023-01-26 18:09:20,159] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM Test IMPORT TABLES
INFO  [2023-01-26 18:09:20,175] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:20,294] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM Test IMPORT CONCEPTS
INFO  [2023-01-26 18:09:20,295] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:20,295] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:20,295] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:20,295] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 2.3 KiB in total
INFO  [2023-01-26 18:09:20,295] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM Test[4]/vers_stamm.import.json, tag=Optional.empty)
████████████████████████████▌                     ▌  57%	est. time remaining: 0.027470161sINFO  [2023-01-26 18:09:20,332] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=22, sum=22, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:20,332] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_end] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15614, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@451cf79e)
INFO  [2023-01-26 18:09:20,332] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=22, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:20,332] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_start] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15340, maxValue=15706), dateReader=com.bakdata.conquery.util.DateReader@26a1dadb)
INFO  [2023-01-26 18:09:20,332] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geburtsdatum] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=-6759, maxValue=9131), dateReader=com.bakdata.conquery.util.DateReader@2a8732f5)
INFO  [2023-01-26 18:09:20,332] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date] with DateRangeParser(super=Parser(lines=22, nullLines=0), minParser=DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15340, maxValue=15706), dateReader=com.bakdata.conquery.util.DateReader@5e5a388f), maxParser=DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15614, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@40998d47), dateReader=com.bakdata.conquery.util.DateReader@76c9ee3, onlyQuarters=false, maxValue=16070, minValue=15340, anyOpen=false)
INFO  [2023-01-26 18:09:20,336] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM Test[4]/vers_stamm.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:20,336] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM Test[4]/vers_tage_range.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000690115sINFO  [2023-01-26 18:09:20,365] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=21, sum=21, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:20,365] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_start] with DateParser(super=Parser(lines=21, nullLines=0), subType=IntegerParser(super=Parser(lines=21, nullLines=0), minValue=14975, maxValue=15522), dateReader=com.bakdata.conquery.util.DateReader@5c43c458)
INFO  [2023-01-26 18:09:20,365] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_end] with DateParser(super=Parser(lines=21, nullLines=0), subType=IntegerParser(super=Parser(lines=21, nullLines=0), minValue=15614, maxValue=15705), dateReader=com.bakdata.conquery.util.DateReader@720939a9)
INFO  [2023-01-26 18:09:20,365] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date] with DateRangeParser(super=Parser(lines=21, nullLines=0), minParser=DateParser(super=Parser(lines=21, nullLines=0), subType=IntegerParser(super=Parser(lines=21, nullLines=0), minValue=14975, maxValue=15522), dateReader=com.bakdata.conquery.util.DateReader@cc9d8c0), maxParser=DateParser(super=Parser(lines=21, nullLines=0), subType=IntegerParser(super=Parser(lines=21, nullLines=0), minValue=15614, maxValue=15705), dateReader=com.bakdata.conquery.util.DateReader@73806080), dateReader=com.bakdata.conquery.util.DateReader@759b6d1a, onlyQuarters=false, maxValue=15705, minValue=14975, anyOpen=false)
INFO  [2023-01-26 18:09:20,368] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM Test[4]/vers_tage_range.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:20,368] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 2 Jobs:
INFO  [2023-01-26 18:09:20,368] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM Test[4]/vers_stamm.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:20,368] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL-EXPORT-FORM Test[4]/vers_tage_range.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:20,388] com.bakdata.conquery.models.jobs.ImportJob: Importing vers_stamm into REL-EXPORT-FORM$20Test[4].vers_stamm
127.0.0.1 - - [26/Jan/2023:18:09:20 +0000] "POST /admin/datasets/REL-EXPORT-FORM%20Test%5B4%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_REL-EXPORT-FORM+Test%5B4%5D%2Fvers_stamm.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 11
INFO  [2023-01-26 18:09:20,389] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:20,390] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:20,390] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:20,391] com.bakdata.conquery.models.jobs.ImportJob: Start sending 8 Buckets
INFO  [2023-01-26 18:09:20,399] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[REL-EXPORT-FORM$20Test[4].vers_stamm.vers_stamm], containing 22 entries.
INFO  [2023-01-26 18:09:20,399] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[REL-EXPORT-FORM$20Test[4].vers_stamm.vers_stamm], containing 22 entries.
INFO  [2023-01-26 18:09:20,401] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[4].vers_stamm.vers_stamm.0
INFO  [2023-01-26 18:09:20,401] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[4].vers_stamm.vers_stamm.2
INFO  [2023-01-26 18:09:20,401] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[4].vers_stamm.vers_stamm.1
WARN  [2023-01-26 18:09:20,401] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:20,401] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[4].vers_stamm.vers_stamm.4
INFO  [2023-01-26 18:09:20,401] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[4].vers_stamm.vers_stamm.3
INFO  [2023-01-26 18:09:20,401] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[4].vers_stamm.vers_stamm.6
INFO  [2023-01-26 18:09:20,401] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[4].vers_stamm.vers_stamm.5
INFO  [2023-01-26 18:09:20,403] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[4].vers_stamm.vers_stamm.7
INFO  [2023-01-26 18:09:20,414] com.bakdata.conquery.models.jobs.ImportJob: Importing vers_tage_range into REL-EXPORT-FORM$20Test[4].vers_tage_range
127.0.0.1 - - [26/Jan/2023:18:09:20 +0000] "POST /admin/datasets/REL-EXPORT-FORM%20Test%5B4%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_REL-EXPORT-FORM+Test%5B4%5D%2Fvers_tage_range.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:09:20,415] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:20,415] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:20,415] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:20,415] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:20,415] com.bakdata.conquery.models.jobs.ImportJob: Start sending 8 Buckets
INFO  [2023-01-26 18:09:20,415] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[REL-EXPORT-FORM$20Test[4].vers_tage_range.vers_tage_range], containing 21 entries.
INFO  [2023-01-26 18:09:20,415] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[REL-EXPORT-FORM$20Test[4].vers_tage_range.vers_tage_range], containing 21 entries.
INFO  [2023-01-26 18:09:20,416] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[4].vers_tage_range.vers_tage_range.0
INFO  [2023-01-26 18:09:20,416] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[4].vers_tage_range.vers_tage_range.2
INFO  [2023-01-26 18:09:20,416] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[4].vers_tage_range.vers_tage_range.1
WARN  [2023-01-26 18:09:20,416] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:20,416] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[4].vers_tage_range.vers_tage_range.3
INFO  [2023-01-26 18:09:20,460] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[4].vers_tage_range.vers_tage_range.4
INFO  [2023-01-26 18:09:20,460] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[4].vers_tage_range.vers_tage_range.6
INFO  [2023-01-26 18:09:20,467] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[4].vers_tage_range.vers_tage_range.5
INFO  [2023-01-26 18:09:20,468] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL-EXPORT-FORM$20Test[4].vers_tage_range.vers_tage_range.7
INFO  [2023-01-26 18:09:20,573] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:20,579] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM Test IMPORT TABLE CONTENTS
INFO  [2023-01-26 18:09:20,740] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:20,746] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:20,753] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM Test PARSE JSON FORM DESCRIPTION
INFO  [2023-01-26 18:09:20,766] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:20,766] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 3 Concepts
INFO  [2023-01-26 18:09:20,766] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 3 Concepts
INFO  [2023-01-26 18:09:20,874] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[c471c1eb-9ec2-447a-83f9-7013246be946] in Datasets[[]]
INFO  [2023-01-26 18:09:20,881] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteForm: Started Form REL-EXPORT-FORM$20Test[4].c471c1eb-9ec2-447a-83f9-7013246be946
INFO  [2023-01-26 18:09:20,881] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteForm: Started Form REL-EXPORT-FORM$20Test[4].c471c1eb-9ec2-447a-83f9-7013246be946
INFO  [2023-01-26 18:09:20,901] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[REL-EXPORT-FORM$20Test[4].c471c1eb-9ec2-447a-83f9-7013246be946] with 1 results within PT0.020178S
INFO  [2023-01-26 18:09:20,902] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=REL-EXPORT-FORM$20Test[4].c471c1eb-9ec2-447a-83f9-7013246be946, workerId=REL-EXPORT-FORM$20Test[4].worker_REL-EXPORT-FORM$20Test[4]_44b76cfc-18c0-4f39-811a-86c36ee5d2dc, startTime=2023-01-26T18:09:20.881335, finishTime=2023-01-26T18:09:20.901513) of size 1
INFO  [2023-01-26 18:09:20,920] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[REL-EXPORT-FORM$20Test[4].c471c1eb-9ec2-447a-83f9-7013246be946] with 1 results within PT0.039188S
INFO  [2023-01-26 18:09:20,921] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=REL-EXPORT-FORM$20Test[4].c471c1eb-9ec2-447a-83f9-7013246be946, workerId=REL-EXPORT-FORM$20Test[4].worker_REL-EXPORT-FORM$20Test[4]_cdf93e53-b643-4f8a-9cd0-2295a1f26b20, startTime=2023-01-26T18:09:20.881785, finishTime=2023-01-26T18:09:20.920973) of size 1
INFO  [2023-01-26 18:09:20,921] com.bakdata.conquery.models.execution.ManagedExecution: DONE f138b719-7c7e-4f7e-813e-568fbb47439c ManagedQuery within PT0.046826S
INFO  [2023-01-26 18:09:20,922] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM Test QUERIES EXECUTED
INFO  [2023-01-26 18:09:20,922] com.bakdata.conquery.models.execution.ManagedExecution: DONE c471c1eb-9ec2-447a-83f9-7013246be946 ManagedInternalForm within PT0.047869S
INFO  [2023-01-26 18:09:20,923] com.bakdata.conquery.integration.json.FormTest: REL-EXPORT-FORM Test CSV TESTING: results
INFO  [2023-01-26 18:09:20,925] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast REL-EXPORT-FORM Test[4]
INFO  [2023-01-26 18:09:20,925] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=REL-EXPORT-FORM Test[4], name=REL-EXPORT-FORM Test[4]]
INFO  [2023-01-26 18:09:20,925] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=REL-EXPORT-FORM Test[4], name=REL-EXPORT-FORM Test[4]]
INFO  [2023-01-26 18:09:20,925] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_REL-EXPORT-FORM Test[4]_44b76cfc-18c0-4f39-811a-86c36ee5d2dc
INFO  [2023-01-26 18:09:20,926] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_REL-EXPORT-FORM Test[4]_cdf93e53-b643-4f8a-9cd0-2295a1f26b20
INFO  [2023-01-26 18:09:20,964] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow REL-EXPORT-FORM Test[4]
INFO  [2023-01-26 18:09:20,964] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_REL-EXPORT-FORM Test[4]_44b76cfc-18c0-4f39-811a-86c36ee5d2dc
INFO  [2023-01-26 18:09:20,964] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_REL-EXPORT-FORM Test[4]_cdf93e53-b643-4f8a-9cd0-2295a1f26b20
INFO  [2023-01-26 18:09:21,064] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of REL-EXPORT-FORM$20Test[4]
INFO  [2023-01-26 18:09:21,064] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:21,072] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test REL-EXPORT-FORM Test
INFO  [2023-01-26 18:09:21,072] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test FULL_EXPORT_FORM
INFO  [2023-01-26 18:09:21,072] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:21,072] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:21,073] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=FULL_EXPORT_FORM, name=FULL_EXPORT_FORM]
INFO  [2023-01-26 18:09:21,073] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=FULL_EXPORT_FORM, name=FULL_EXPORT_FORM]
INFO  [2023-01-26 18:09:21,073] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:21,074] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:21,077] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker FULL_EXPORT_FORM.worker_FULL_EXPORT_FORM_7904e3c6-3237-4002-95f8-ef73d619fb05 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:21,077] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker FULL_EXPORT_FORM.worker_FULL_EXPORT_FORM_7904e3c6-3237-4002-95f8-ef73d619fb05 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:21,077] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:21,077] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker FULL_EXPORT_FORM.worker_FULL_EXPORT_FORM_51761377-49f1-43c6-9f02-9ab9f84c60bd are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:21,077] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker FULL_EXPORT_FORM.worker_FULL_EXPORT_FORM_51761377-49f1-43c6-9f02-9ab9f84c60bd are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:21,077] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:21,080] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:21,181] com.bakdata.conquery.resources.admin.rest.AdminDatasetProcessor: Received new SecondaryId[FULL_EXPORT_FORM.secondary]
INFO  [2023-01-26 18:09:21,182] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:21,182] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId FULL_EXPORT_FORM.secondary
INFO  [2023-01-26 18:09:21,182] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId FULL_EXPORT_FORM.secondary
INFO  [2023-01-26 18:09:21,288] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:21,288] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table FULL_EXPORT_FORM.vers_stamm
INFO  [2023-01-26 18:09:21,288] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table FULL_EXPORT_FORM.vers_stamm
INFO  [2023-01-26 18:09:21,289] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table FULL_EXPORT_FORM.table
INFO  [2023-01-26 18:09:21,289] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table FULL_EXPORT_FORM.table
INFO  [2023-01-26 18:09:21,393] com.bakdata.conquery.integration.json.FormTest: FULL_EXPORT_FORM IMPORT TABLES
INFO  [2023-01-26 18:09:21,407] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:21,518] com.bakdata.conquery.integration.json.FormTest: FULL_EXPORT_FORM IMPORT CONCEPTS
INFO  [2023-01-26 18:09:21,519] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:21,519] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:21,519] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:21,519] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 1.5 KiB in total
INFO  [2023-01-26 18:09:21,519] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_FULL_EXPORT_FORM/vers_stamm.import.json, tag=Optional.empty)
█████████████████████████████████████████████     ▌  90%	est. time remaining: 0.003132218sINFO  [2023-01-26 18:09:21,546] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=22, sum=22, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:21,546] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_end] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15614, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@7d3800bc)
INFO  [2023-01-26 18:09:21,546] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=22, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:21,546] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geburtsdatum] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=-6759, maxValue=9131), dateReader=com.bakdata.conquery.util.DateReader@3426766)
INFO  [2023-01-26 18:09:21,546] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date_start] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15340, maxValue=15706), dateReader=com.bakdata.conquery.util.DateReader@26556e81)
INFO  [2023-01-26 18:09:21,546] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[date] with DateRangeParser(super=Parser(lines=22, nullLines=0), minParser=DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15340, maxValue=15706), dateReader=com.bakdata.conquery.util.DateReader@15001563), maxParser=DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=15614, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@4c2a2cdf), dateReader=com.bakdata.conquery.util.DateReader@7c99feb9, onlyQuarters=false, maxValue=16070, minValue=15340, anyOpen=false)
INFO  [2023-01-26 18:09:21,550] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_FULL_EXPORT_FORM/vers_stamm.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:21,550] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_FULL_EXPORT_FORM/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000515637sINFO  [2023-01-26 18:09:21,571] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=1, sum=6, min=6, average=6.000000, max=6}
INFO  [2023-01-26 18:09:21,572] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=15400, maxValue=15405), dateReader=com.bakdata.conquery.util.DateReader@2d170ce8)
INFO  [2023-01-26 18:09:21,572] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[column] with StringParser(super=Parser(lines=6, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:21,572] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[second_id] with StringParser(super=Parser(lines=6, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:21,575] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_FULL_EXPORT_FORM/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:21,575] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 2 Jobs:
INFO  [2023-01-26 18:09:21,575] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_FULL_EXPORT_FORM/vers_stamm.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:21,575] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_FULL_EXPORT_FORM/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:21,595] com.bakdata.conquery.models.jobs.ImportJob: Importing vers_stamm into FULL_EXPORT_FORM.vers_stamm
127.0.0.1 - - [26/Jan/2023:18:09:21 +0000] "POST /admin/datasets/FULL_EXPORT_FORM/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_FULL_EXPORT_FORM%2Fvers_stamm.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:09:21,596] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:21,597] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:21,597] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:21,599] com.bakdata.conquery.models.jobs.ImportJob: Start sending 8 Buckets
INFO  [2023-01-26 18:09:21,599] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[FULL_EXPORT_FORM.vers_stamm.vers_stamm], containing 22 entries.
INFO  [2023-01-26 18:09:21,599] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[FULL_EXPORT_FORM.vers_stamm.vers_stamm], containing 22 entries.
INFO  [2023-01-26 18:09:21,600] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received FULL_EXPORT_FORM.vers_stamm.vers_stamm.0
INFO  [2023-01-26 18:09:21,600] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received FULL_EXPORT_FORM.vers_stamm.vers_stamm.1
INFO  [2023-01-26 18:09:21,600] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received FULL_EXPORT_FORM.vers_stamm.vers_stamm.2
WARN  [2023-01-26 18:09:21,600] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:21,601] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received FULL_EXPORT_FORM.vers_stamm.vers_stamm.3
INFO  [2023-01-26 18:09:21,601] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received FULL_EXPORT_FORM.vers_stamm.vers_stamm.4
INFO  [2023-01-26 18:09:21,601] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received FULL_EXPORT_FORM.vers_stamm.vers_stamm.6
INFO  [2023-01-26 18:09:21,601] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received FULL_EXPORT_FORM.vers_stamm.vers_stamm.5
INFO  [2023-01-26 18:09:21,601] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received FULL_EXPORT_FORM.vers_stamm.vers_stamm.7
INFO  [2023-01-26 18:09:21,612] com.bakdata.conquery.models.jobs.ImportJob: Importing table into FULL_EXPORT_FORM.table
INFO  [2023-01-26 18:09:21,612] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:21,612] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:21,612] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
127.0.0.1 - - [26/Jan/2023:18:09:21 +0000] "POST /admin/datasets/FULL_EXPORT_FORM/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_FULL_EXPORT_FORM%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:09:21,612] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:21,613] com.bakdata.conquery.models.jobs.ImportJob: Start sending 1 Buckets
WARN  [2023-01-26 18:09:21,613] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:21,613] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[FULL_EXPORT_FORM.table.table], containing 6 entries.
INFO  [2023-01-26 18:09:21,613] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[FULL_EXPORT_FORM.table.table], containing 6 entries.
INFO  [2023-01-26 18:09:21,613] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received FULL_EXPORT_FORM.table.table.0
INFO  [2023-01-26 18:09:21,718] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:21,724] com.bakdata.conquery.integration.json.FormTest: FULL_EXPORT_FORM IMPORT TABLE CONTENTS
INFO  [2023-01-26 18:09:21,732] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:21,737] com.bakdata.conquery.integration.json.FormTest: FULL_EXPORT_FORM PARSE JSON FORM DESCRIPTION
INFO  [2023-01-26 18:09:21,747] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:21,748] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 2 Concepts
INFO  [2023-01-26 18:09:21,748] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 2 Concepts
INFO  [2023-01-26 18:09:21,861] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[a95be4fd-f268-4c51-9f46-73c0ab4a2e02] in Datasets[[]]
INFO  [2023-01-26 18:09:21,872] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteForm: Started Form FULL_EXPORT_FORM.a95be4fd-f268-4c51-9f46-73c0ab4a2e02
INFO  [2023-01-26 18:09:21,872] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteForm: Started Form FULL_EXPORT_FORM.a95be4fd-f268-4c51-9f46-73c0ab4a2e02
INFO  [2023-01-26 18:09:21,887] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[FULL_EXPORT_FORM.a95be4fd-f268-4c51-9f46-73c0ab4a2e02] with 1 results within PT0.014443S
INFO  [2023-01-26 18:09:21,887] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[FULL_EXPORT_FORM.a95be4fd-f268-4c51-9f46-73c0ab4a2e02] with 0 results within PT0.014593S
INFO  [2023-01-26 18:09:21,888] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=FULL_EXPORT_FORM.a95be4fd-f268-4c51-9f46-73c0ab4a2e02, workerId=FULL_EXPORT_FORM.worker_FULL_EXPORT_FORM_51761377-49f1-43c6-9f02-9ab9f84c60bd, startTime=2023-01-26T18:09:21.873012, finishTime=2023-01-26T18:09:21.887605) of size 0
INFO  [2023-01-26 18:09:21,888] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=FULL_EXPORT_FORM.a95be4fd-f268-4c51-9f46-73c0ab4a2e02, workerId=FULL_EXPORT_FORM.worker_FULL_EXPORT_FORM_7904e3c6-3237-4002-95f8-ef73d619fb05, startTime=2023-01-26T18:09:21.873006, finishTime=2023-01-26T18:09:21.887449) of size 1
INFO  [2023-01-26 18:09:21,888] com.bakdata.conquery.models.execution.ManagedExecution: DONE c79cab93-323a-48a4-91c3-101173dd3b5f ManagedQuery within PT0.027136S
INFO  [2023-01-26 18:09:21,889] com.bakdata.conquery.models.execution.ManagedExecution: DONE a95be4fd-f268-4c51-9f46-73c0ab4a2e02 ManagedInternalForm within PT0.027846S
INFO  [2023-01-26 18:09:21,889] com.bakdata.conquery.integration.json.FormTest: FULL_EXPORT_FORM QUERIES EXECUTED
INFO  [2023-01-26 18:09:21,899] com.bakdata.conquery.integration.json.FormTest: FULL_EXPORT_FORM CSV TESTING: results
INFO  [2023-01-26 18:09:21,901] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast FULL_EXPORT_FORM
INFO  [2023-01-26 18:09:21,901] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=FULL_EXPORT_FORM, name=FULL_EXPORT_FORM]
INFO  [2023-01-26 18:09:21,901] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=FULL_EXPORT_FORM, name=FULL_EXPORT_FORM]
INFO  [2023-01-26 18:09:21,901] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_FULL_EXPORT_FORM_7904e3c6-3237-4002-95f8-ef73d619fb05
INFO  [2023-01-26 18:09:21,903] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_FULL_EXPORT_FORM_51761377-49f1-43c6-9f02-9ab9f84c60bd
INFO  [2023-01-26 18:09:21,998] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_FULL_EXPORT_FORM_7904e3c6-3237-4002-95f8-ef73d619fb05
INFO  [2023-01-26 18:09:21,998] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow FULL_EXPORT_FORM
INFO  [2023-01-26 18:09:21,998] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_FULL_EXPORT_FORM_51761377-49f1-43c6-9f02-9ab9f84c60bd
INFO  [2023-01-26 18:09:22,013] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of FULL_EXPORT_FORM
INFO  [2023-01-26 18:09:22,013] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:22,158] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test FULL_EXPORT_FORM
INFO  [2023-01-26 18:09:22,159] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test ABS_EXPORT Test
INFO  [2023-01-26 18:09:22,159] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:22,159] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:22,180] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=ABS_EXPORT Test, name=ABS_EXPORT Test]
INFO  [2023-01-26 18:09:22,180] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=ABS_EXPORT Test, name=ABS_EXPORT Test]
INFO  [2023-01-26 18:09:22,180] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:22,180] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:22,183] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker ABS_EXPORT$20Test.worker_ABS_EXPORT$20Test_3dd671be-f8c3-4f3d-ac2e-25d2f7e1bea6 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:22,183] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker ABS_EXPORT$20Test.worker_ABS_EXPORT$20Test_3dd671be-f8c3-4f3d-ac2e-25d2f7e1bea6 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:22,183] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:22,183] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker ABS_EXPORT$20Test.worker_ABS_EXPORT$20Test_124c5d66-9c7c-41f5-b6de-dad7b3e03526 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:22,183] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker ABS_EXPORT$20Test.worker_ABS_EXPORT$20Test_124c5d66-9c7c-41f5-b6de-dad7b3e03526 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:22,183] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:22,186] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:22,288] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:22,294] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:22,295] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ABS_EXPORT$20Test.test_table
INFO  [2023-01-26 18:09:22,295] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ABS_EXPORT$20Test.test_table
INFO  [2023-01-26 18:09:22,405] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:22,515] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:22,516] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:22,516] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 183 B in total
INFO  [2023-01-26 18:09:22,516] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ABS_EXPORT Test/test_table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.00023345sINFO  [2023-01-26 18:09:22,540] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=2, sum=9, min=1, average=4.500000, max=8}
INFO  [2023-01-26 18:09:22,540] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=9, nullLines=0), encoding=null, prefix=A, suffix=)
INFO  [2023-01-26 18:09:22,540] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=9, nullLines=0), subType=IntegerParser(super=Parser(lines=9, nullLines=0), minValue=11109, maxValue=12935), dateReader=com.bakdata.conquery.util.DateReader@92ae90e)
INFO  [2023-01-26 18:09:22,543] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ABS_EXPORT Test/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:22,543] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:22,543] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ABS_EXPORT Test/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:22,561] com.bakdata.conquery.models.jobs.ImportJob: Importing test_table into ABS_EXPORT$20Test.test_table
127.0.0.1 - - [26/Jan/2023:18:09:22 +0000] "POST /admin/datasets/ABS_EXPORT%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_ABS_EXPORT+Test%2Ftest_table.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 10
INFO  [2023-01-26 18:09:22,562] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:22,563] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:22,563] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:22,563] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:22,565] com.bakdata.conquery.models.jobs.ImportJob: Start sending 1 Buckets
INFO  [2023-01-26 18:09:22,566] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ABS_EXPORT$20Test.test_table.test_table], containing 9 entries.
INFO  [2023-01-26 18:09:22,566] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ABS_EXPORT$20Test.test_table.test_table], containing 9 entries.
WARN  [2023-01-26 18:09:22,566] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:22,566] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ABS_EXPORT$20Test.test_table.test_table.0
INFO  [2023-01-26 18:09:22,671] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:22,677] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:22,694] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:22,695] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:22,800] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: ABS_EXPORT Test QUERY INIT
INFO  [2023-01-26 18:09:22,817] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[ABS_EXPORT$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:22,818] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[1a31b2b7-2091-41f0-8557-202d4f669512] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_ABS_EXPORT Test))]]
INFO  [2023-01-26 18:09:22,821] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started AbsoluteFormQuery ABS_EXPORT$20Test.1a31b2b7-2091-41f0-8557-202d4f669512
INFO  [2023-01-26 18:09:22,821] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started AbsoluteFormQuery ABS_EXPORT$20Test.1a31b2b7-2091-41f0-8557-202d4f669512
WARN  [2023-01-26 18:09:22,822] com.bakdata.conquery.models.query.QueryExecutor: Entities for query are empty
INFO  [2023-01-26 18:09:22,822] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[ABS_EXPORT$20Test.1a31b2b7-2091-41f0-8557-202d4f669512] with 0 results within PT0.000618S
INFO  [2023-01-26 18:09:22,822] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=ABS_EXPORT$20Test.1a31b2b7-2091-41f0-8557-202d4f669512, workerId=ABS_EXPORT$20Test.worker_ABS_EXPORT$20Test_124c5d66-9c7c-41f5-b6de-dad7b3e03526, startTime=2023-01-26T18:09:22.821587, finishTime=2023-01-26T18:09:22.822205) of size 0
127.0.0.1 - - [26/Jan/2023:18:09:22 +0000] "POST /api/datasets/ABS_EXPORT$20Test/queries HTTP/1.1" 201 2262 "-" "Conquery (test client)" 10
INFO  [2023-01-26 18:09:22,823] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[ABS_EXPORT$20Test.1a31b2b7-2091-41f0-8557-202d4f669512] with 1 results within PT0.002125S
INFO  [2023-01-26 18:09:22,824] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=ABS_EXPORT$20Test.1a31b2b7-2091-41f0-8557-202d4f669512, workerId=ABS_EXPORT$20Test.worker_ABS_EXPORT$20Test_3dd671be-f8c3-4f3d-ac2e-25d2f7e1bea6, startTime=2023-01-26T18:09:22.821438, finishTime=2023-01-26T18:09:22.823563) of size 1
INFO  [2023-01-26 18:09:22,824] com.bakdata.conquery.models.execution.ManagedExecution: DONE 1a31b2b7-2091-41f0-8557-202d4f669512 ManagedQuery within PT0.006095S
127.0.0.1 - - [26/Jan/2023:18:09:22 +0000] "GET /api/datasets/ABS_EXPORT$20Test/queries/ABS_EXPORT$20Test.1a31b2b7-2091-41f0-8557-202d4f669512 HTTP/1.1" 200 2521 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:09:22,844] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=ABS_EXPORT Test], queryId=1a31b2b7-2091-41f0-8557-202d4f669512, label=test_tree---test_child1	@§$, creationTime=2023-01-26T18:09:22.817958, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@5a3b7b57[Count = 0], startTime=2023-01-26T18:09:22.818174, finishTime=2023-01-26T18:09:22.824269, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@7874fa30), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_ABS_EXPORT Test)), query=com.bakdata.conquery.models.forms.managed.AbsoluteFormQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@5cbc392e, com.bakdata.conquery.models.query.ColumnDescriptor@7a3ed5f, com.bakdata.conquery.models.query.ColumnDescriptor@643cf3f, com.bakdata.conquery.models.query.ColumnDescriptor@59b910bd, com.bakdata.conquery.models.query.ColumnDescriptor@647127ed]) download on dataset Dataset[label=null, name=ABS_EXPORT Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:22,844] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=ABS_EXPORT Test], queryId=1a31b2b7-2091-41f0-8557-202d4f669512, label=test_tree---test_child1	@§$, creationTime=2023-01-26T18:09:22.817958, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@5a3b7b57[Count = 0], startTime=2023-01-26T18:09:22.818174, finishTime=2023-01-26T18:09:22.824269, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@7874fa30), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_ABS_EXPORT Test)), query=com.bakdata.conquery.models.forms.managed.AbsoluteFormQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@5cbc392e, com.bakdata.conquery.models.query.ColumnDescriptor@7a3ed5f, com.bakdata.conquery.models.query.ColumnDescriptor@643cf3f, com.bakdata.conquery.models.query.ColumnDescriptor@59b910bd, com.bakdata.conquery.models.query.ColumnDescriptor@647127ed]) on dataset Dataset[label=null, name=ABS_EXPORT Test]
127.0.0.1 - - [26/Jan/2023:18:09:22 +0000] "GET /api/datasets/ABS_EXPORT%20Test/result/ABS_EXPORT$20Test.1a31b2b7-2091-41f0-8557-202d4f669512.csv?pretty=false HTTP/1.1" 200 203 "-" "Conquery (test client)" 24
INFO  [2023-01-26 18:09:22,867] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest ABS_EXPORT Test on 5 rows
INFO  [2023-01-26 18:09:22,867] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast ABS_EXPORT Test
INFO  [2023-01-26 18:09:22,867] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=ABS_EXPORT Test, name=ABS_EXPORT Test]
INFO  [2023-01-26 18:09:22,867] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=ABS_EXPORT Test, name=ABS_EXPORT Test]
INFO  [2023-01-26 18:09:22,867] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_ABS_EXPORT Test_124c5d66-9c7c-41f5-b6de-dad7b3e03526
INFO  [2023-01-26 18:09:22,868] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_ABS_EXPORT Test_3dd671be-f8c3-4f3d-ac2e-25d2f7e1bea6
INFO  [2023-01-26 18:09:22,881] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow ABS_EXPORT Test
INFO  [2023-01-26 18:09:22,882] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_ABS_EXPORT Test_124c5d66-9c7c-41f5-b6de-dad7b3e03526
INFO  [2023-01-26 18:09:22,882] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_ABS_EXPORT Test_3dd671be-f8c3-4f3d-ac2e-25d2f7e1bea6
INFO  [2023-01-26 18:09:22,966] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of ABS_EXPORT$20Test
INFO  [2023-01-26 18:09:22,966] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:23,004] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test ABS_EXPORT Test
INFO  [2023-01-26 18:09:23,005] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test ARRAY_CONCEPT_QUERY Test
INFO  [2023-01-26 18:09:23,005] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:23,005] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:23,009] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=ARRAY_CONCEPT_QUERY Test, name=ARRAY_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:09:23,009] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:23,009] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=ARRAY_CONCEPT_QUERY Test, name=ARRAY_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:09:23,009] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:23,012] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker ARRAY_CONCEPT_QUERY$20Test.worker_ARRAY_CONCEPT_QUERY$20Test_9f1a1bd6-eeca-4aae-9ccc-61a516bb5b6b are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:23,012] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker ARRAY_CONCEPT_QUERY$20Test.worker_ARRAY_CONCEPT_QUERY$20Test_9f1a1bd6-eeca-4aae-9ccc-61a516bb5b6b are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:23,012] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:23,021] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker ARRAY_CONCEPT_QUERY$20Test.worker_ARRAY_CONCEPT_QUERY$20Test_e5c9f206-4c6a-43a3-acd6-14a3097eb91f are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:23,021] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker ARRAY_CONCEPT_QUERY$20Test.worker_ARRAY_CONCEPT_QUERY$20Test_e5c9f206-4c6a-43a3-acd6-14a3097eb91f are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:23,021] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:23,025] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:23,130] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:23,137] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:23,137] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ARRAY_CONCEPT_QUERY$20Test.table1
INFO  [2023-01-26 18:09:23,137] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table ARRAY_CONCEPT_QUERY$20Test.table1
INFO  [2023-01-26 18:09:23,253] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:23,364] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:23,364] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:23,364] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 137 B in total
INFO  [2023-01-26 18:09:23,364] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ARRAY_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000330593sINFO  [2023-01-26 18:09:23,398] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=7, min=1, average=1.750000, max=4}
INFO  [2023-01-26 18:09:23,398] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=7, nullLines=1), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:23,398] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=7, nullLines=0), subType=IntegerParser(super=Parser(lines=7, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@59b1b590)
INFO  [2023-01-26 18:09:23,401] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ARRAY_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:23,401] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:23,401] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_ARRAY_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:23,415] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into ARRAY_CONCEPT_QUERY$20Test.table1
127.0.0.1 - - [26/Jan/2023:18:09:23 +0000] "POST /admin/datasets/ARRAY_CONCEPT_QUERY%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_ARRAY_CONCEPT_QUERY+Test%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:09:23,415] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:23,416] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:23,417] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:23,417] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:23,418] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:09:23,418] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ARRAY_CONCEPT_QUERY$20Test.table1.table1], containing 7 entries.
INFO  [2023-01-26 18:09:23,419] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[ARRAY_CONCEPT_QUERY$20Test.table1.table1], containing 7 entries.
WARN  [2023-01-26 18:09:23,419] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:23,419] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ARRAY_CONCEPT_QUERY$20Test.table1.table1.0
INFO  [2023-01-26 18:09:23,420] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received ARRAY_CONCEPT_QUERY$20Test.table1.table1.1
INFO  [2023-01-26 18:09:23,526] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:23,532] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:23,548] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:23,548] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:23,548] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:23,654] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: ARRAY_CONCEPT_QUERY Test QUERY INIT
INFO  [2023-01-26 18:09:23,666] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[ARRAY_CONCEPT_QUERY$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:23,666] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[52b4d761-5f14-4992-ae24-371ea0f8f9f1] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_ARRAY_CONCEPT_QUERY Test))]]
INFO  [2023-01-26 18:09:23,669] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ArrayConceptQuery ARRAY_CONCEPT_QUERY$20Test.52b4d761-5f14-4992-ae24-371ea0f8f9f1
INFO  [2023-01-26 18:09:23,670] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ArrayConceptQuery ARRAY_CONCEPT_QUERY$20Test.52b4d761-5f14-4992-ae24-371ea0f8f9f1
127.0.0.1 - - [26/Jan/2023:18:09:23 +0000] "POST /api/datasets/ARRAY_CONCEPT_QUERY$20Test/queries HTTP/1.1" 201 2173 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:09:23,673] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[ARRAY_CONCEPT_QUERY$20Test.52b4d761-5f14-4992-ae24-371ea0f8f9f1] with 1 results within PT0.003208S
INFO  [2023-01-26 18:09:23,674] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=ARRAY_CONCEPT_QUERY$20Test.52b4d761-5f14-4992-ae24-371ea0f8f9f1, workerId=ARRAY_CONCEPT_QUERY$20Test.worker_ARRAY_CONCEPT_QUERY$20Test_9f1a1bd6-eeca-4aae-9ccc-61a516bb5b6b, startTime=2023-01-26T18:09:23.669928, finishTime=2023-01-26T18:09:23.673136) of size 1
INFO  [2023-01-26 18:09:23,679] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[ARRAY_CONCEPT_QUERY$20Test.52b4d761-5f14-4992-ae24-371ea0f8f9f1] with 3 results within PT0.009333S
INFO  [2023-01-26 18:09:23,680] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=ARRAY_CONCEPT_QUERY$20Test.52b4d761-5f14-4992-ae24-371ea0f8f9f1, workerId=ARRAY_CONCEPT_QUERY$20Test.worker_ARRAY_CONCEPT_QUERY$20Test_e5c9f206-4c6a-43a3-acd6-14a3097eb91f, startTime=2023-01-26T18:09:23.670054, finishTime=2023-01-26T18:09:23.679387) of size 3
INFO  [2023-01-26 18:09:23,680] com.bakdata.conquery.models.execution.ManagedExecution: DONE 52b4d761-5f14-4992-ae24-371ea0f8f9f1 ManagedQuery within PT0.013279S
127.0.0.1 - - [26/Jan/2023:18:09:23 +0000] "GET /api/datasets/ARRAY_CONCEPT_QUERY$20Test/queries/ARRAY_CONCEPT_QUERY$20Test.52b4d761-5f14-4992-ae24-371ea0f8f9f1 HTTP/1.1" 200 2469 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:09:23,696] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=ARRAY_CONCEPT_QUERY Test], queryId=52b4d761-5f14-4992-ae24-371ea0f8f9f1, label=select	@§$, creationTime=2023-01-26T18:09:23.666725, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@e5a5fed[Count = 0], startTime=2023-01-26T18:09:23.666956, finishTime=2023-01-26T18:09:23.680235, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@a1789e7), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_ARRAY_CONCEPT_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ArrayConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@3ca59d5, com.bakdata.conquery.models.query.ColumnDescriptor@7778101e, com.bakdata.conquery.models.query.ColumnDescriptor@2b819c2b, com.bakdata.conquery.models.query.ColumnDescriptor@1def600d]) download on dataset Dataset[label=null, name=ARRAY_CONCEPT_QUERY Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:23,696] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=ARRAY_CONCEPT_QUERY Test], queryId=52b4d761-5f14-4992-ae24-371ea0f8f9f1, label=select	@§$, creationTime=2023-01-26T18:09:23.666725, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@e5a5fed[Count = 0], startTime=2023-01-26T18:09:23.666956, finishTime=2023-01-26T18:09:23.680235, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@a1789e7), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_ARRAY_CONCEPT_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ArrayConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@3ca59d5, com.bakdata.conquery.models.query.ColumnDescriptor@7778101e, com.bakdata.conquery.models.query.ColumnDescriptor@2b819c2b, com.bakdata.conquery.models.query.ColumnDescriptor@1def600d]) on dataset Dataset[label=null, name=ARRAY_CONCEPT_QUERY Test]
127.0.0.1 - - [26/Jan/2023:18:09:23 +0000] "GET /api/datasets/ARRAY_CONCEPT_QUERY%20Test/result/ARRAY_CONCEPT_QUERY$20Test.52b4d761-5f14-4992-ae24-371ea0f8f9f1.csv?pretty=false HTTP/1.1" 200 201 "-" "Conquery (test client)" 15
INFO  [2023-01-26 18:09:23,709] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest ARRAY_CONCEPT_QUERY Test on 5 rows
INFO  [2023-01-26 18:09:23,709] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast ARRAY_CONCEPT_QUERY Test
INFO  [2023-01-26 18:09:23,710] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=ARRAY_CONCEPT_QUERY Test, name=ARRAY_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:09:23,710] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=ARRAY_CONCEPT_QUERY Test, name=ARRAY_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:09:23,710] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_ARRAY_CONCEPT_QUERY Test_9f1a1bd6-eeca-4aae-9ccc-61a516bb5b6b
INFO  [2023-01-26 18:09:23,710] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_ARRAY_CONCEPT_QUERY Test_e5c9f206-4c6a-43a3-acd6-14a3097eb91f
INFO  [2023-01-26 18:09:23,712] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_ARRAY_CONCEPT_QUERY Test_9f1a1bd6-eeca-4aae-9ccc-61a516bb5b6b
INFO  [2023-01-26 18:09:23,720] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_ARRAY_CONCEPT_QUERY Test_e5c9f206-4c6a-43a3-acd6-14a3097eb91f
INFO  [2023-01-26 18:09:23,809] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow ARRAY_CONCEPT_QUERY Test
INFO  [2023-01-26 18:09:23,823] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of ARRAY_CONCEPT_QUERY$20Test
INFO  [2023-01-26 18:09:23,823] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:23,854] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test ARRAY_CONCEPT_QUERY Test
INFO  [2023-01-26 18:09:23,854] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test
INFO  [2023-01-26 18:09:23,854] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:23,854] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:23,855] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test, name=BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:09:23,855] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test, name=BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:09:23,855] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:23,855] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:23,863] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_b7aec764-d4fa-4da3-8927-1077c0ea45e9 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:23,863] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_b7aec764-d4fa-4da3-8927-1077c0ea45e9 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:23,863] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:23,863] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_6359dc90-4e58-4adb-bca3-09002e0e69d2 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:23,863] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_6359dc90-4e58-4adb-bca3-09002e0e69d2 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:23,863] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:23,867] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:23,967] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:23,974] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:23,974] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1
INFO  [2023-01-26 18:09:23,974] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1
INFO  [2023-01-26 18:09:24,087] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:24,197] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:24,198] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:24,198] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 158 B in total
INFO  [2023-01-26 18:09:24,198] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000335184sINFO  [2023-01-26 18:09:24,232] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=8, sum=8, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:24,232] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=8, nullLines=2), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:24,232] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=8, nullLines=0), subType=IntegerParser(super=Parser(lines=8, nullLines=0), minValue=13828, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@716ecb7f)
INFO  [2023-01-26 18:09:24,235] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:24,235] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:24,235] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:24,258] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1
127.0.0.1 - - [26/Jan/2023:18:09:24 +0000] "POST /admin/datasets/BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY+Test%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:09:24,259] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:24,259] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:24,260] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:24,260] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:24,262] com.bakdata.conquery.models.jobs.ImportJob: Start sending 3 Buckets
INFO  [2023-01-26 18:09:24,262] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1.table1], containing 8 entries.
WARN  [2023-01-26 18:09:24,263] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:24,263] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1.table1.1
INFO  [2023-01-26 18:09:24,263] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1.table1], containing 8 entries.
INFO  [2023-01-26 18:09:24,264] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1.table1.0
INFO  [2023-01-26 18:09:24,264] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1.table1.2
INFO  [2023-01-26 18:09:24,368] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:24,374] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:24,418] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:24,419] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:24,419] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:24,524] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test QUERY INIT
INFO  [2023-01-26 18:09:24,538] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:24,538] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[0bd7be59-609b-4c41-a05c-d67db8178e3f] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test))]]
127.0.0.1 - - [26/Jan/2023:18:09:24 +0000] "POST /api/datasets/BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test/queries HTTP/1.1" 201 1579 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:09:24,542] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.0bd7be59-609b-4c41-a05c-d67db8178e3f
INFO  [2023-01-26 18:09:24,542] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.0bd7be59-609b-4c41-a05c-d67db8178e3f
INFO  [2023-01-26 18:09:24,554] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.0bd7be59-609b-4c41-a05c-d67db8178e3f] with 0 results within PT0.011866S
INFO  [2023-01-26 18:09:24,554] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.0bd7be59-609b-4c41-a05c-d67db8178e3f] with 1 results within PT0.011955S
INFO  [2023-01-26 18:09:24,555] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.0bd7be59-609b-4c41-a05c-d67db8178e3f, workerId=BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_6359dc90-4e58-4adb-bca3-09002e0e69d2, startTime=2023-01-26T18:09:24.542624, finishTime=2023-01-26T18:09:24.554490) of size 0
INFO  [2023-01-26 18:09:24,555] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.0bd7be59-609b-4c41-a05c-d67db8178e3f, workerId=BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_b7aec764-d4fa-4da3-8927-1077c0ea45e9, startTime=2023-01-26T18:09:24.542862, finishTime=2023-01-26T18:09:24.554817) of size 1
INFO  [2023-01-26 18:09:24,555] com.bakdata.conquery.models.execution.ManagedExecution: DONE 0bd7be59-609b-4c41-a05c-d67db8178e3f ManagedQuery within PT0.01649S
127.0.0.1 - - [26/Jan/2023:18:09:24 +0000] "GET /api/datasets/BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test/queries/BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.0bd7be59-609b-4c41-a05c-d67db8178e3f HTTP/1.1" 200 1999 "-" "Conquery (test client)" 4
INFO  [2023-01-26 18:09:24,567] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test], queryId=0bd7be59-609b-4c41-a05c-d67db8178e3f, label=Geschlecht-SELECT	@§$, creationTime=2023-01-26T18:09:24.538779, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@5c45a46e[Count = 0], startTime=2023-01-26T18:09:24.538975, finishTime=2023-01-26T18:09:24.555465, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@33683560), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@2cdd4133, com.bakdata.conquery.models.query.ColumnDescriptor@49a38a80]) download on dataset Dataset[label=null, name=BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:24,567] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test], queryId=0bd7be59-609b-4c41-a05c-d67db8178e3f, label=Geschlecht-SELECT	@§$, creationTime=2023-01-26T18:09:24.538779, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@5c45a46e[Count = 0], startTime=2023-01-26T18:09:24.538975, finishTime=2023-01-26T18:09:24.555465, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@33683560), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@2cdd4133, com.bakdata.conquery.models.query.ColumnDescriptor@49a38a80]) on dataset Dataset[label=null, name=BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test]
127.0.0.1 - - [26/Jan/2023:18:09:24 +0000] "GET /api/datasets/BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY%20Test/result/BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.0bd7be59-609b-4c41-a05c-d67db8178e3f.csv?pretty=false HTTP/1.1" 200 39 "-" "Conquery (test client)" 19
INFO  [2023-01-26 18:09:24,585] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test on 2 rows
INFO  [2023-01-26 18:09:24,585] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test
INFO  [2023-01-26 18:09:24,585] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test, name=BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:09:24,585] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test, name=BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:09:24,585] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test_6359dc90-4e58-4adb-bca3-09002e0e69d2
INFO  [2023-01-26 18:09:24,585] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test_b7aec764-d4fa-4da3-8927-1077c0ea45e9
INFO  [2023-01-26 18:09:24,655] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test
INFO  [2023-01-26 18:09:24,662] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test_b7aec764-d4fa-4da3-8927-1077c0ea45e9
INFO  [2023-01-26 18:09:24,663] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test_6359dc90-4e58-4adb-bca3-09002e0e69d2
INFO  [2023-01-26 18:09:24,663] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test
INFO  [2023-01-26 18:09:24,663] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:24,824] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test BIG_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test
INFO  [2023-01-26 18:09:24,824] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test
INFO  [2023-01-26 18:09:24,824] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:24,824] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:24,825] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test, name=BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:09:24,825] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:24,825] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test, name=BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:09:24,825] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:24,829] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_1d7c4871-9156-4d51-80f0-ead32e47124c are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:24,829] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_1d7c4871-9156-4d51-80f0-ead32e47124c are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:24,829] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:24,831] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:24,832] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_a66df22e-f2a1-4c2d-b25a-676fe68824f7 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:24,832] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_a66df22e-f2a1-4c2d-b25a-676fe68824f7 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:24,832] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:24,936] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:24,942] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:24,943] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1
INFO  [2023-01-26 18:09:24,943] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1
INFO  [2023-01-26 18:09:25,059] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:25,178] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:25,178] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:25,178] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 158 B in total
INFO  [2023-01-26 18:09:25,178] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.00017309sINFO  [2023-01-26 18:09:25,196] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=8, sum=8, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:25,196] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=8, nullLines=2), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:25,196] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=8, nullLines=0), subType=IntegerParser(super=Parser(lines=8, nullLines=0), minValue=13828, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@4a91608a)
INFO  [2023-01-26 18:09:25,199] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:25,199] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:25,199] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:25,216] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1
127.0.0.1 - - [26/Jan/2023:18:09:25 +0000] "POST /admin/datasets/BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY+Test%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:09:25,217] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:25,217] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:25,218] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:25,218] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:25,220] com.bakdata.conquery.models.jobs.ImportJob: Start sending 3 Buckets
INFO  [2023-01-26 18:09:25,220] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1.table1], containing 8 entries.
INFO  [2023-01-26 18:09:25,220] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1.table1], containing 8 entries.
WARN  [2023-01-26 18:09:25,221] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:25,221] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1.table1.0
INFO  [2023-01-26 18:09:25,221] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1.table1.1
INFO  [2023-01-26 18:09:25,221] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1.table1.2
INFO  [2023-01-26 18:09:25,332] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:25,337] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:25,353] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:25,353] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:25,353] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:25,459] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test QUERY INIT
INFO  [2023-01-26 18:09:25,473] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:25,473] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[fd8e037b-f8d5-4e26-a792-020b28ef279b] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test))]]
INFO  [2023-01-26 18:09:25,476] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.fd8e037b-f8d5-4e26-a792-020b28ef279b
INFO  [2023-01-26 18:09:25,477] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.fd8e037b-f8d5-4e26-a792-020b28ef279b
127.0.0.1 - - [26/Jan/2023:18:09:25 +0000] "POST /api/datasets/BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test/queries HTTP/1.1" 201 1656 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:09:25,478] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.fd8e037b-f8d5-4e26-a792-020b28ef279b] with 3 results within PT0.001262S
INFO  [2023-01-26 18:09:25,478] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.fd8e037b-f8d5-4e26-a792-020b28ef279b] with 4 results within PT0.001631S
INFO  [2023-01-26 18:09:25,478] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.fd8e037b-f8d5-4e26-a792-020b28ef279b, workerId=BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_a66df22e-f2a1-4c2d-b25a-676fe68824f7, startTime=2023-01-26T18:09:25.477143, finishTime=2023-01-26T18:09:25.478405) of size 3
INFO  [2023-01-26 18:09:25,479] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.fd8e037b-f8d5-4e26-a792-020b28ef279b, workerId=BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_1d7c4871-9156-4d51-80f0-ead32e47124c, startTime=2023-01-26T18:09:25.477010, finishTime=2023-01-26T18:09:25.478641) of size 4
INFO  [2023-01-26 18:09:25,479] com.bakdata.conquery.models.execution.ManagedExecution: DONE fd8e037b-f8d5-4e26-a792-020b28ef279b ManagedQuery within PT0.005469S
127.0.0.1 - - [26/Jan/2023:18:09:25 +0000] "GET /api/datasets/BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test/queries/BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.fd8e037b-f8d5-4e26-a792-020b28ef279b HTTP/1.1" 200 2111 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:09:25,496] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test], queryId=fd8e037b-f8d5-4e26-a792-020b28ef279b, label=Geschlecht-SELECT	@§$, creationTime=2023-01-26T18:09:25.473292, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@7c2846fc[Count = 0], startTime=2023-01-26T18:09:25.473728, finishTime=2023-01-26T18:09:25.479197, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@54fb664e), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=7, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@1208170f, com.bakdata.conquery.models.query.ColumnDescriptor@2c737734]) download on dataset Dataset[label=null, name=BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:25,496] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test], queryId=fd8e037b-f8d5-4e26-a792-020b28ef279b, label=Geschlecht-SELECT	@§$, creationTime=2023-01-26T18:09:25.473292, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@7c2846fc[Count = 0], startTime=2023-01-26T18:09:25.473728, finishTime=2023-01-26T18:09:25.479197, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@54fb664e), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=7, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@1208170f, com.bakdata.conquery.models.query.ColumnDescriptor@2c737734]) on dataset Dataset[label=null, name=BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test]
127.0.0.1 - - [26/Jan/2023:18:09:25 +0000] "GET /api/datasets/BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY%20Test/result/BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.fd8e037b-f8d5-4e26-a792-020b28ef279b.csv?pretty=false HTTP/1.1" 200 48 "-" "Conquery (test client)" 22
INFO  [2023-01-26 18:09:25,517] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test on 8 rows
INFO  [2023-01-26 18:09:25,518] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test
INFO  [2023-01-26 18:09:25,518] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test, name=BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:09:25,518] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test, name=BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:09:25,518] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test_a66df22e-f2a1-4c2d-b25a-676fe68824f7
INFO  [2023-01-26 18:09:25,518] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test_1d7c4871-9156-4d51-80f0-ead32e47124c
INFO  [2023-01-26 18:09:25,528] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test
INFO  [2023-01-26 18:09:25,528] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test
INFO  [2023-01-26 18:09:25,528] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:25,528] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test_1d7c4871-9156-4d51-80f0-ead32e47124c
INFO  [2023-01-26 18:09:25,531] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test_a66df22e-f2a1-4c2d-b25a-676fe68824f7
INFO  [2023-01-26 18:09:25,658] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test BIG_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test
INFO  [2023-01-26 18:09:25,660] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test COMMON_CONCEPT_ICD_QUERY Test
INFO  [2023-01-26 18:09:25,660] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:25,660] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:25,661] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=COMMON_CONCEPT_ICD_QUERY Test, name=COMMON_CONCEPT_ICD_QUERY Test]
INFO  [2023-01-26 18:09:25,661] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=COMMON_CONCEPT_ICD_QUERY Test, name=COMMON_CONCEPT_ICD_QUERY Test]
INFO  [2023-01-26 18:09:25,661] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:25,661] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:25,662] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker COMMON_CONCEPT_ICD_QUERY$20Test.worker_COMMON_CONCEPT_ICD_QUERY$20Test_b4d3429d-c03b-4970-9eab-4b12dd63bd77 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:25,662] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker COMMON_CONCEPT_ICD_QUERY$20Test.worker_COMMON_CONCEPT_ICD_QUERY$20Test_b4d3429d-c03b-4970-9eab-4b12dd63bd77 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:25,662] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:25,662] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker COMMON_CONCEPT_ICD_QUERY$20Test.worker_COMMON_CONCEPT_ICD_QUERY$20Test_536d1094-2c3d-4139-935c-5144f6160a55 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:25,662] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker COMMON_CONCEPT_ICD_QUERY$20Test.worker_COMMON_CONCEPT_ICD_QUERY$20Test_536d1094-2c3d-4139-935c-5144f6160a55 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:25,662] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:25,667] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:25,767] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:25,773] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:25,773] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table COMMON_CONCEPT_ICD_QUERY$20Test.kh_diagnose
INFO  [2023-01-26 18:09:25,774] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table COMMON_CONCEPT_ICD_QUERY$20Test.kh_diagnose
INFO  [2023-01-26 18:09:25,890] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:26,004] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:26,004] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:26,005] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 136 B in total
INFO  [2023-01-26 18:09:26,005] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COMMON_CONCEPT_ICD_QUERY Test/kh_diagnose.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.00021065sINFO  [2023-01-26 18:09:26,026] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=3, sum=3, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:26,026] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[entlassungsdatum] with DateParser(super=Parser(lines=3, nullLines=0), subType=IntegerParser(super=Parser(lines=3, nullLines=0), minValue=17256, maxValue=17347), dateReader=com.bakdata.conquery.util.DateReader@1f0847c7)
INFO  [2023-01-26 18:09:26,026] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[icd_code] with StringParser(super=Parser(lines=3, nullLines=0), encoding=null, prefix=F2, suffix=)
INFO  [2023-01-26 18:09:26,026] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[aufnahmedatum] with DateParser(super=Parser(lines=3, nullLines=0), subType=IntegerParser(super=Parser(lines=3, nullLines=0), minValue=17167, maxValue=17257), dateReader=com.bakdata.conquery.util.DateReader@6f9a7b45)
INFO  [2023-01-26 18:09:26,030] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COMMON_CONCEPT_ICD_QUERY Test/kh_diagnose.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:26,030] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:26,030] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COMMON_CONCEPT_ICD_QUERY Test/kh_diagnose.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:26,051] com.bakdata.conquery.models.jobs.ImportJob: Importing kh_diagnose into COMMON_CONCEPT_ICD_QUERY$20Test.kh_diagnose
127.0.0.1 - - [26/Jan/2023:18:09:26 +0000] "POST /admin/datasets/COMMON_CONCEPT_ICD_QUERY%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_COMMON_CONCEPT_ICD_QUERY+Test%2Fkh_diagnose.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 11
INFO  [2023-01-26 18:09:26,051] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:26,052] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:26,053] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:26,053] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:26,055] com.bakdata.conquery.models.jobs.ImportJob: Start sending 1 Buckets
INFO  [2023-01-26 18:09:26,055] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[COMMON_CONCEPT_ICD_QUERY$20Test.kh_diagnose.kh_diagnose], containing 3 entries.
INFO  [2023-01-26 18:09:26,055] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[COMMON_CONCEPT_ICD_QUERY$20Test.kh_diagnose.kh_diagnose], containing 3 entries.
WARN  [2023-01-26 18:09:26,056] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:26,056] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received COMMON_CONCEPT_ICD_QUERY$20Test.kh_diagnose.kh_diagnose.0
INFO  [2023-01-26 18:09:26,161] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:26,167] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:26,178] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:26,178] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:26,284] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: COMMON_CONCEPT_ICD_QUERY Test QUERY INIT
INFO  [2023-01-26 18:09:26,295] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[COMMON_CONCEPT_ICD_QUERY$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:26,295] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[27231b27-547f-4cba-82e0-647df87e80c6] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_COMMON_CONCEPT_ICD_QUERY Test))]]
INFO  [2023-01-26 18:09:26,298] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery COMMON_CONCEPT_ICD_QUERY$20Test.27231b27-547f-4cba-82e0-647df87e80c6
INFO  [2023-01-26 18:09:26,298] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery COMMON_CONCEPT_ICD_QUERY$20Test.27231b27-547f-4cba-82e0-647df87e80c6
WARN  [2023-01-26 18:09:26,298] com.bakdata.conquery.models.query.QueryExecutor: Entities for query are empty
INFO  [2023-01-26 18:09:26,298] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[COMMON_CONCEPT_ICD_QUERY$20Test.27231b27-547f-4cba-82e0-647df87e80c6] with 0 results within PT0.000139S
INFO  [2023-01-26 18:09:26,298] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=COMMON_CONCEPT_ICD_QUERY$20Test.27231b27-547f-4cba-82e0-647df87e80c6, workerId=COMMON_CONCEPT_ICD_QUERY$20Test.worker_COMMON_CONCEPT_ICD_QUERY$20Test_b4d3429d-c03b-4970-9eab-4b12dd63bd77, startTime=2023-01-26T18:09:26.298040, finishTime=2023-01-26T18:09:26.298179) of size 0
127.0.0.1 - - [26/Jan/2023:18:09:26 +0000] "POST /api/datasets/COMMON_CONCEPT_ICD_QUERY$20Test/queries HTTP/1.1" 201 1306 "-" "Conquery (test client)" 5
INFO  [2023-01-26 18:09:26,298] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[COMMON_CONCEPT_ICD_QUERY$20Test.27231b27-547f-4cba-82e0-647df87e80c6] with 2 results within PT0.000718S
INFO  [2023-01-26 18:09:26,299] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=COMMON_CONCEPT_ICD_QUERY$20Test.27231b27-547f-4cba-82e0-647df87e80c6, workerId=COMMON_CONCEPT_ICD_QUERY$20Test.worker_COMMON_CONCEPT_ICD_QUERY$20Test_536d1094-2c3d-4139-935c-5144f6160a55, startTime=2023-01-26T18:09:26.298037, finishTime=2023-01-26T18:09:26.298755) of size 2
INFO  [2023-01-26 18:09:26,299] com.bakdata.conquery.models.execution.ManagedExecution: DONE 27231b27-547f-4cba-82e0-647df87e80c6 ManagedQuery within PT0.003465S
127.0.0.1 - - [26/Jan/2023:18:09:26 +0000] "GET /api/datasets/COMMON_CONCEPT_ICD_QUERY$20Test/queries/COMMON_CONCEPT_ICD_QUERY$20Test.27231b27-547f-4cba-82e0-647df87e80c6 HTTP/1.1" 200 1621 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:09:26,325] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=COMMON_CONCEPT_ICD_QUERY Test], queryId=27231b27-547f-4cba-82e0-647df87e80c6, label=F20	@§$, creationTime=2023-01-26T18:09:26.295638, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@4167d1b5[Count = 0], startTime=2023-01-26T18:09:26.295811, finishTime=2023-01-26T18:09:26.299276, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@6b2eb89), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_COMMON_CONCEPT_ICD_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@220a2490, com.bakdata.conquery.models.query.ColumnDescriptor@1d4fb858]) download on dataset Dataset[label=null, name=COMMON_CONCEPT_ICD_QUERY Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:26,325] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=COMMON_CONCEPT_ICD_QUERY Test], queryId=27231b27-547f-4cba-82e0-647df87e80c6, label=F20	@§$, creationTime=2023-01-26T18:09:26.295638, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@4167d1b5[Count = 0], startTime=2023-01-26T18:09:26.295811, finishTime=2023-01-26T18:09:26.299276, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@6b2eb89), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_COMMON_CONCEPT_ICD_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@220a2490, com.bakdata.conquery.models.query.ColumnDescriptor@1d4fb858]) on dataset Dataset[label=null, name=COMMON_CONCEPT_ICD_QUERY Test]
127.0.0.1 - - [26/Jan/2023:18:09:26 +0000] "GET /api/datasets/COMMON_CONCEPT_ICD_QUERY%20Test/result/COMMON_CONCEPT_ICD_QUERY$20Test.27231b27-547f-4cba-82e0-647df87e80c6.csv?pretty=false HTTP/1.1" 200 66 "-" "Conquery (test client)" 17
INFO  [2023-01-26 18:09:26,341] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest COMMON_CONCEPT_ICD_QUERY Test on 3 rows
INFO  [2023-01-26 18:09:26,341] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast COMMON_CONCEPT_ICD_QUERY Test
INFO  [2023-01-26 18:09:26,341] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=COMMON_CONCEPT_ICD_QUERY Test, name=COMMON_CONCEPT_ICD_QUERY Test]
INFO  [2023-01-26 18:09:26,341] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=COMMON_CONCEPT_ICD_QUERY Test, name=COMMON_CONCEPT_ICD_QUERY Test]
INFO  [2023-01-26 18:09:26,341] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_COMMON_CONCEPT_ICD_QUERY Test_b4d3429d-c03b-4970-9eab-4b12dd63bd77
INFO  [2023-01-26 18:09:26,341] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_COMMON_CONCEPT_ICD_QUERY Test_536d1094-2c3d-4139-935c-5144f6160a55
INFO  [2023-01-26 18:09:26,361] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow COMMON_CONCEPT_ICD_QUERY Test
INFO  [2023-01-26 18:09:26,362] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_COMMON_CONCEPT_ICD_QUERY Test_b4d3429d-c03b-4970-9eab-4b12dd63bd77
INFO  [2023-01-26 18:09:26,362] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_COMMON_CONCEPT_ICD_QUERY Test_536d1094-2c3d-4139-935c-5144f6160a55
INFO  [2023-01-26 18:09:26,458] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of COMMON_CONCEPT_ICD_QUERY$20Test
INFO  [2023-01-26 18:09:26,459] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:26,485] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test COMMON_CONCEPT_ICD_QUERY Test
INFO  [2023-01-26 18:09:26,486] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test COMPOUND_DATERANGE Test
INFO  [2023-01-26 18:09:26,486] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:26,486] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:26,487] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=COMPOUND_DATERANGE Test, name=COMPOUND_DATERANGE Test]
INFO  [2023-01-26 18:09:26,487] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=COMPOUND_DATERANGE Test, name=COMPOUND_DATERANGE Test]
INFO  [2023-01-26 18:09:26,487] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:26,487] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:26,491] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker COMPOUND_DATERANGE$20Test.worker_COMPOUND_DATERANGE$20Test_068fc788-3eb8-4e89-b4d1-17acbd4c771a are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:26,491] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker COMPOUND_DATERANGE$20Test.worker_COMPOUND_DATERANGE$20Test_068fc788-3eb8-4e89-b4d1-17acbd4c771a are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:26,491] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:26,491] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker COMPOUND_DATERANGE$20Test.worker_COMPOUND_DATERANGE$20Test_bea42723-515c-480c-960c-694062346f10 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:26,491] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker COMPOUND_DATERANGE$20Test.worker_COMPOUND_DATERANGE$20Test_bea42723-515c-480c-960c-694062346f10 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:26,491] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:26,494] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:26,593] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:26,604] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:26,604] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table COMPOUND_DATERANGE$20Test.test_table
INFO  [2023-01-26 18:09:26,605] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table COMPOUND_DATERANGE$20Test.test_table
INFO  [2023-01-26 18:09:26,718] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:26,830] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:26,830] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:26,830] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 213 B in total
INFO  [2023-01-26 18:09:26,830] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COMPOUND_DATERANGE Test/test_table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000470699sINFO  [2023-01-26 18:09:26,878] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=9, sum=9, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:26,878] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[behandlung_ende] with DateParser(super=Parser(lines=9, nullLines=2), subType=IntegerParser(super=Parser(lines=9, nullLines=2), minValue=14958, maxValue=16139), dateReader=com.bakdata.conquery.util.DateReader@56e08ddb)
INFO  [2023-01-26 18:09:26,878] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[behandlung_start] with DateParser(super=Parser(lines=9, nullLines=2), subType=IntegerParser(super=Parser(lines=9, nullLines=2), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@142d824f)
INFO  [2023-01-26 18:09:26,878] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[behandlung] with CompoundDateRangeParser(super=Parser(lines=9, nullLines=0), startColumn=behandlung_start, endColumn=behandlung_ende)
INFO  [2023-01-26 18:09:26,883] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COMPOUND_DATERANGE Test/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:26,883] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:26,883] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COMPOUND_DATERANGE Test/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:26,905] com.bakdata.conquery.models.jobs.ImportJob: Importing test_table into COMPOUND_DATERANGE$20Test.test_table
INFO  [2023-01-26 18:09:26,906] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:09:26 +0000] "POST /admin/datasets/COMPOUND_DATERANGE%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_COMPOUND_DATERANGE+Test%2Ftest_table.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 13
INFO  [2023-01-26 18:09:26,906] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:26,906] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:26,906] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:26,908] com.bakdata.conquery.models.jobs.ImportJob: Start sending 3 Buckets
INFO  [2023-01-26 18:09:26,909] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[COMPOUND_DATERANGE$20Test.test_table.test_table], containing 9 entries.
INFO  [2023-01-26 18:09:26,909] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[COMPOUND_DATERANGE$20Test.test_table.test_table], containing 9 entries.
WARN  [2023-01-26 18:09:26,909] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:26,909] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received COMPOUND_DATERANGE$20Test.test_table.test_table.0
INFO  [2023-01-26 18:09:26,910] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received COMPOUND_DATERANGE$20Test.test_table.test_table.1
INFO  [2023-01-26 18:09:26,910] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received COMPOUND_DATERANGE$20Test.test_table.test_table.2
INFO  [2023-01-26 18:09:27,015] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:27,020] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:27,030] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:27,031] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:27,031] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:27,136] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: COMPOUND_DATERANGE Test QUERY INIT
INFO  [2023-01-26 18:09:27,151] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[COMPOUND_DATERANGE$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:27,152] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[a3f3338a-5d95-429b-a178-fb7cf1db8eeb] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_COMPOUND_DATERANGE Test))]]
INFO  [2023-01-26 18:09:27,155] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery COMPOUND_DATERANGE$20Test.a3f3338a-5d95-429b-a178-fb7cf1db8eeb
INFO  [2023-01-26 18:09:27,155] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery COMPOUND_DATERANGE$20Test.a3f3338a-5d95-429b-a178-fb7cf1db8eeb
INFO  [2023-01-26 18:09:27,156] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[COMPOUND_DATERANGE$20Test.a3f3338a-5d95-429b-a178-fb7cf1db8eeb] with 3 results within PT0.001025S
INFO  [2023-01-26 18:09:27,156] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[COMPOUND_DATERANGE$20Test.a3f3338a-5d95-429b-a178-fb7cf1db8eeb] with 4 results within PT0.001081S
INFO  [2023-01-26 18:09:27,157] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=COMPOUND_DATERANGE$20Test.a3f3338a-5d95-429b-a178-fb7cf1db8eeb, workerId=COMPOUND_DATERANGE$20Test.worker_COMPOUND_DATERANGE$20Test_bea42723-515c-480c-960c-694062346f10, startTime=2023-01-26T18:09:27.155585, finishTime=2023-01-26T18:09:27.156666) of size 4
INFO  [2023-01-26 18:09:27,157] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=COMPOUND_DATERANGE$20Test.a3f3338a-5d95-429b-a178-fb7cf1db8eeb, workerId=COMPOUND_DATERANGE$20Test.worker_COMPOUND_DATERANGE$20Test_068fc788-3eb8-4e89-b4d1-17acbd4c771a, startTime=2023-01-26T18:09:27.155584, finishTime=2023-01-26T18:09:27.156609) of size 3
INFO  [2023-01-26 18:09:27,157] com.bakdata.conquery.models.execution.ManagedExecution: DONE a3f3338a-5d95-429b-a178-fb7cf1db8eeb ManagedQuery within PT0.005021S
127.0.0.1 - - [26/Jan/2023:18:09:27 +0000] "POST /api/datasets/COMPOUND_DATERANGE$20Test/queries HTTP/1.1" 201 1114 "-" "Conquery (test client)" 9
127.0.0.1 - - [26/Jan/2023:18:09:27 +0000] "GET /api/datasets/COMPOUND_DATERANGE$20Test/queries/COMPOUND_DATERANGE$20Test.a3f3338a-5d95-429b-a178-fb7cf1db8eeb HTTP/1.1" 200 1405 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:09:27,177] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=COMPOUND_DATERANGE Test], queryId=a3f3338a-5d95-429b-a178-fb7cf1db8eeb, label=test_tree	@§$, creationTime=2023-01-26T18:09:27.152093, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@1d9218cb[Count = 0], startTime=2023-01-26T18:09:27.152397, finishTime=2023-01-26T18:09:27.157418, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@651f91be), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_COMPOUND_DATERANGE Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=7, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@52b8f145, com.bakdata.conquery.models.query.ColumnDescriptor@7f43c5b]) download on dataset Dataset[label=null, name=COMPOUND_DATERANGE Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:27,178] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=COMPOUND_DATERANGE Test], queryId=a3f3338a-5d95-429b-a178-fb7cf1db8eeb, label=test_tree	@§$, creationTime=2023-01-26T18:09:27.152093, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@1d9218cb[Count = 0], startTime=2023-01-26T18:09:27.152397, finishTime=2023-01-26T18:09:27.157418, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@651f91be), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_COMPOUND_DATERANGE Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=7, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@52b8f145, com.bakdata.conquery.models.query.ColumnDescriptor@7f43c5b]) on dataset Dataset[label=null, name=COMPOUND_DATERANGE Test]
127.0.0.1 - - [26/Jan/2023:18:09:27 +0000] "GET /api/datasets/COMPOUND_DATERANGE%20Test/result/COMPOUND_DATERANGE$20Test.a3f3338a-5d95-429b-a178-fb7cf1db8eeb.csv?pretty=false HTTP/1.1" 200 183 "-" "Conquery (test client)" 20
INFO  [2023-01-26 18:09:27,197] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest COMPOUND_DATERANGE Test on 8 rows
INFO  [2023-01-26 18:09:27,197] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast COMPOUND_DATERANGE Test
INFO  [2023-01-26 18:09:27,197] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=COMPOUND_DATERANGE Test, name=COMPOUND_DATERANGE Test]
INFO  [2023-01-26 18:09:27,197] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=COMPOUND_DATERANGE Test, name=COMPOUND_DATERANGE Test]
INFO  [2023-01-26 18:09:27,197] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_COMPOUND_DATERANGE Test_068fc788-3eb8-4e89-b4d1-17acbd4c771a
INFO  [2023-01-26 18:09:27,197] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_COMPOUND_DATERANGE Test_bea42723-515c-480c-960c-694062346f10
INFO  [2023-01-26 18:09:27,205] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_COMPOUND_DATERANGE Test_068fc788-3eb8-4e89-b4d1-17acbd4c771a
INFO  [2023-01-26 18:09:27,205] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_COMPOUND_DATERANGE Test_bea42723-515c-480c-960c-694062346f10
INFO  [2023-01-26 18:09:27,205] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow COMPOUND_DATERANGE Test
INFO  [2023-01-26 18:09:27,210] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of COMPOUND_DATERANGE$20Test
INFO  [2023-01-26 18:09:27,210] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:27,336] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test COMPOUND_DATERANGE Test
INFO  [2023-01-26 18:09:27,337] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE Test
INFO  [2023-01-26 18:09:27,337] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:27,337] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:27,339] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE Test, name=CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE Test]
INFO  [2023-01-26 18:09:27,339] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE Test, name=CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE Test]
INFO  [2023-01-26 18:09:27,339] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:27,339] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:27,342] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE$20Test.worker_CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE$20Test_43aee736-7f2b-48ec-80b0-5c77eaa663cf are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:27,342] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE$20Test.worker_CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE$20Test_43aee736-7f2b-48ec-80b0-5c77eaa663cf are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:27,342] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:27,342] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:27,342] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE$20Test.worker_CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE$20Test_278adb8b-9121-4e91-944f-355b69013b1d are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:27,342] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE$20Test.worker_CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE$20Test_278adb8b-9121-4e91-944f-355b69013b1d are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:27,342] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:27,445] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:27,453] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:27,454] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE$20Test.test_table
INFO  [2023-01-26 18:09:27,454] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE$20Test.test_table
INFO  [2023-01-26 18:09:27,572] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:27,682] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:27,682] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:27,682] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 44 B in total
INFO  [2023-01-26 18:09:27,683] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE Test/test_table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000214197sINFO  [2023-01-26 18:09:27,704] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=4, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:27,704] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=4, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:27,707] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE Test/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:27,707] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:27,707] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE Test/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:27,725] com.bakdata.conquery.models.jobs.ImportJob: Importing test_table into CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE$20Test.test_table
127.0.0.1 - - [26/Jan/2023:18:09:27 +0000] "POST /admin/datasets/CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE+Test%2Ftest_table.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 10
INFO  [2023-01-26 18:09:27,726] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:27,726] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:27,727] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:27,727] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:27,729] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:09:27,729] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE$20Test.test_table.test_table], containing 4 entries.
INFO  [2023-01-26 18:09:27,729] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE$20Test.test_table.test_table], containing 4 entries.
WARN  [2023-01-26 18:09:27,730] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:27,730] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE$20Test.test_table.test_table.0
INFO  [2023-01-26 18:09:27,730] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE$20Test.test_table.test_table.1
INFO  [2023-01-26 18:09:27,837] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:27,842] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:27,853] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:27,854] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:27,854] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:27,960] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE Test QUERY INIT
INFO  [2023-01-26 18:09:27,980] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:27,980] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[1b2b3098-89b5-4178-8b51-54c110d937bf] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE Test))]]
INFO  [2023-01-26 18:09:27,983] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE$20Test.1b2b3098-89b5-4178-8b51-54c110d937bf
INFO  [2023-01-26 18:09:27,983] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE$20Test.1b2b3098-89b5-4178-8b51-54c110d937bf
INFO  [2023-01-26 18:09:27,984] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE$20Test.1b2b3098-89b5-4178-8b51-54c110d937bf] with 0 results within PT0.000642S
INFO  [2023-01-26 18:09:27,984] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE$20Test.1b2b3098-89b5-4178-8b51-54c110d937bf] with 2 results within PT0.000813S
127.0.0.1 - - [26/Jan/2023:18:09:27 +0000] "POST /api/datasets/CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE$20Test/queries HTTP/1.1" 201 1657 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:09:27,984] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE$20Test.1b2b3098-89b5-4178-8b51-54c110d937bf, workerId=CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE$20Test.worker_CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE$20Test_43aee736-7f2b-48ec-80b0-5c77eaa663cf, startTime=2023-01-26T18:09:27.983439, finishTime=2023-01-26T18:09:27.984081) of size 0
INFO  [2023-01-26 18:09:27,984] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE$20Test.1b2b3098-89b5-4178-8b51-54c110d937bf, workerId=CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE$20Test.worker_CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE$20Test_278adb8b-9121-4e91-944f-355b69013b1d, startTime=2023-01-26T18:09:27.983419, finishTime=2023-01-26T18:09:27.984232) of size 2
INFO  [2023-01-26 18:09:27,984] com.bakdata.conquery.models.execution.ManagedExecution: DONE 1b2b3098-89b5-4178-8b51-54c110d937bf ManagedQuery within PT0.003942S
127.0.0.1 - - [26/Jan/2023:18:09:27 +0000] "GET /api/datasets/CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE$20Test/queries/CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE$20Test.1b2b3098-89b5-4178-8b51-54c110d937bf HTTP/1.1" 200 2056 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:09:28,004] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE Test], queryId=1b2b3098-89b5-4178-8b51-54c110d937bf, label=test_tree---test_child1	@§$, creationTime=2023-01-26T18:09:27.980663, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@612e2df7[Count = 0], startTime=2023-01-26T18:09:27.980851, finishTime=2023-01-26T18:09:27.984793, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@246bc16f), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@2a2f9956, com.bakdata.conquery.models.query.ColumnDescriptor@5239e0d8, com.bakdata.conquery.models.query.ColumnDescriptor@42682efd]) download on dataset Dataset[label=null, name=CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:28,005] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE Test], queryId=1b2b3098-89b5-4178-8b51-54c110d937bf, label=test_tree---test_child1	@§$, creationTime=2023-01-26T18:09:27.980663, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@612e2df7[Count = 0], startTime=2023-01-26T18:09:27.980851, finishTime=2023-01-26T18:09:27.984793, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@246bc16f), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@2a2f9956, com.bakdata.conquery.models.query.ColumnDescriptor@5239e0d8, com.bakdata.conquery.models.query.ColumnDescriptor@42682efd]) on dataset Dataset[label=null, name=CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE Test]
127.0.0.1 - - [26/Jan/2023:18:09:28 +0000] "GET /api/datasets/CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE%20Test/result/CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE$20Test.1b2b3098-89b5-4178-8b51-54c110d937bf.csv?pretty=false HTTP/1.1" 200 110 "-" "Conquery (test client)" 16
INFO  [2023-01-26 18:09:28,019] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE Test on 3 rows
INFO  [2023-01-26 18:09:28,020] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE Test
INFO  [2023-01-26 18:09:28,020] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE Test, name=CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE Test]
INFO  [2023-01-26 18:09:28,020] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE Test, name=CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE Test]
INFO  [2023-01-26 18:09:28,020] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE Test_43aee736-7f2b-48ec-80b0-5c77eaa663cf
INFO  [2023-01-26 18:09:28,020] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE Test_278adb8b-9121-4e91-944f-355b69013b1d
INFO  [2023-01-26 18:09:28,039] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE Test
INFO  [2023-01-26 18:09:28,040] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE Test_278adb8b-9121-4e91-944f-355b69013b1d
INFO  [2023-01-26 18:09:28,040] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE Test_43aee736-7f2b-48ec-80b0-5c77eaa663cf
INFO  [2023-01-26 18:09:28,130] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE$20Test
INFO  [2023-01-26 18:09:28,130] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:28,159] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test CONCEPT_DATE_RESTRICTION_WITHOUT_VALIDITYDATE Test
INFO  [2023-01-26 18:09:28,160] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test CONCEPT_RESTRICTION Test
INFO  [2023-01-26 18:09:28,160] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:28,160] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:28,161] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=CONCEPT_RESTRICTION Test, name=CONCEPT_RESTRICTION Test]
INFO  [2023-01-26 18:09:28,161] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=CONCEPT_RESTRICTION Test, name=CONCEPT_RESTRICTION Test]
INFO  [2023-01-26 18:09:28,161] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:28,161] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:28,162] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker CONCEPT_RESTRICTION$20Test.worker_CONCEPT_RESTRICTION$20Test_c4e47527-ad6d-42e9-bfeb-c5deb1de91cd are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:28,162] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker CONCEPT_RESTRICTION$20Test.worker_CONCEPT_RESTRICTION$20Test_c4e47527-ad6d-42e9-bfeb-c5deb1de91cd are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:28,162] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:28,163] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker CONCEPT_RESTRICTION$20Test.worker_CONCEPT_RESTRICTION$20Test_0bd0d184-b337-4bbb-ad5e-e31bd7841c2f are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:28,163] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker CONCEPT_RESTRICTION$20Test.worker_CONCEPT_RESTRICTION$20Test_0bd0d184-b337-4bbb-ad5e-e31bd7841c2f are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:28,163] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:28,167] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:28,267] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:28,274] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:28,275] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table CONCEPT_RESTRICTION$20Test.kh_diagnose
INFO  [2023-01-26 18:09:28,275] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table CONCEPT_RESTRICTION$20Test.kh_diagnose
INFO  [2023-01-26 18:09:28,385] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:28,497] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:28,497] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:28,497] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 137 B in total
INFO  [2023-01-26 18:09:28,498] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_CONCEPT_RESTRICTION Test/kh_diagnose.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000329849sINFO  [2023-01-26 18:09:28,531] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=3, sum=3, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:28,531] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[entlassungsdatum] with DateParser(super=Parser(lines=3, nullLines=0), subType=IntegerParser(super=Parser(lines=3, nullLines=0), minValue=17256, maxValue=17347), dateReader=com.bakdata.conquery.util.DateReader@47eec15f)
INFO  [2023-01-26 18:09:28,531] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[icd_code] with StringParser(super=Parser(lines=3, nullLines=0), encoding=null, prefix=F2, suffix=)
INFO  [2023-01-26 18:09:28,531] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[aufnahmedatum] with DateParser(super=Parser(lines=3, nullLines=0), subType=IntegerParser(super=Parser(lines=3, nullLines=0), minValue=17167, maxValue=17257), dateReader=com.bakdata.conquery.util.DateReader@7aa4d0d8)
INFO  [2023-01-26 18:09:28,535] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_CONCEPT_RESTRICTION Test/kh_diagnose.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:28,535] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:28,535] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_CONCEPT_RESTRICTION Test/kh_diagnose.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:28,554] com.bakdata.conquery.models.jobs.ImportJob: Importing kh_diagnose into CONCEPT_RESTRICTION$20Test.kh_diagnose
127.0.0.1 - - [26/Jan/2023:18:09:28 +0000] "POST /admin/datasets/CONCEPT_RESTRICTION%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_CONCEPT_RESTRICTION+Test%2Fkh_diagnose.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:09:28,554] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:28,555] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:28,555] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:28,556] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:28,557] com.bakdata.conquery.models.jobs.ImportJob: Start sending 1 Buckets
INFO  [2023-01-26 18:09:28,567] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[CONCEPT_RESTRICTION$20Test.kh_diagnose.kh_diagnose], containing 3 entries.
INFO  [2023-01-26 18:09:28,567] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[CONCEPT_RESTRICTION$20Test.kh_diagnose.kh_diagnose], containing 3 entries.
WARN  [2023-01-26 18:09:28,568] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:28,568] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received CONCEPT_RESTRICTION$20Test.kh_diagnose.kh_diagnose.0
INFO  [2023-01-26 18:09:28,673] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:28,678] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:28,697] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:28,697] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:28,803] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: CONCEPT_RESTRICTION Test QUERY INIT
INFO  [2023-01-26 18:09:28,820] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[CONCEPT_RESTRICTION$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:28,820] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[3a1722fb-eeab-4af6-a8e9-2f9e63d51add] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_CONCEPT_RESTRICTION Test))]]
INFO  [2023-01-26 18:09:28,823] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery CONCEPT_RESTRICTION$20Test.3a1722fb-eeab-4af6-a8e9-2f9e63d51add
INFO  [2023-01-26 18:09:28,823] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery CONCEPT_RESTRICTION$20Test.3a1722fb-eeab-4af6-a8e9-2f9e63d51add
WARN  [2023-01-26 18:09:28,823] com.bakdata.conquery.models.query.QueryExecutor: Entities for query are empty
INFO  [2023-01-26 18:09:28,823] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[CONCEPT_RESTRICTION$20Test.3a1722fb-eeab-4af6-a8e9-2f9e63d51add] with 0 results within PT0.00022S
127.0.0.1 - - [26/Jan/2023:18:09:28 +0000] "POST /api/datasets/CONCEPT_RESTRICTION$20Test/queries HTTP/1.1" 201 1291 "-" "Conquery (test client)" 5
INFO  [2023-01-26 18:09:28,824] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=CONCEPT_RESTRICTION$20Test.3a1722fb-eeab-4af6-a8e9-2f9e63d51add, workerId=CONCEPT_RESTRICTION$20Test.worker_CONCEPT_RESTRICTION$20Test_0bd0d184-b337-4bbb-ad5e-e31bd7841c2f, startTime=2023-01-26T18:09:28.823334, finishTime=2023-01-26T18:09:28.823554) of size 0
INFO  [2023-01-26 18:09:28,824] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[CONCEPT_RESTRICTION$20Test.3a1722fb-eeab-4af6-a8e9-2f9e63d51add] with 1 results within PT0.001063S
INFO  [2023-01-26 18:09:28,824] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=CONCEPT_RESTRICTION$20Test.3a1722fb-eeab-4af6-a8e9-2f9e63d51add, workerId=CONCEPT_RESTRICTION$20Test.worker_CONCEPT_RESTRICTION$20Test_c4e47527-ad6d-42e9-bfeb-c5deb1de91cd, startTime=2023-01-26T18:09:28.823334, finishTime=2023-01-26T18:09:28.824397) of size 1
INFO  [2023-01-26 18:09:28,825] com.bakdata.conquery.models.execution.ManagedExecution: DONE 3a1722fb-eeab-4af6-a8e9-2f9e63d51add ManagedQuery within PT0.004619S
127.0.0.1 - - [26/Jan/2023:18:09:28 +0000] "GET /api/datasets/CONCEPT_RESTRICTION$20Test/queries/CONCEPT_RESTRICTION$20Test.3a1722fb-eeab-4af6-a8e9-2f9e63d51add HTTP/1.1" 200 1586 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:09:28,853] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=CONCEPT_RESTRICTION Test], queryId=3a1722fb-eeab-4af6-a8e9-2f9e63d51add, label=F20	@§$, creationTime=2023-01-26T18:09:28.820218, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@180c2267[Count = 0], startTime=2023-01-26T18:09:28.820396, finishTime=2023-01-26T18:09:28.825015, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@636e17e0), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_CONCEPT_RESTRICTION Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@10b27965, com.bakdata.conquery.models.query.ColumnDescriptor@1cfa123e]) download on dataset Dataset[label=null, name=CONCEPT_RESTRICTION Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:28,853] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=CONCEPT_RESTRICTION Test], queryId=3a1722fb-eeab-4af6-a8e9-2f9e63d51add, label=F20	@§$, creationTime=2023-01-26T18:09:28.820218, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@180c2267[Count = 0], startTime=2023-01-26T18:09:28.820396, finishTime=2023-01-26T18:09:28.825015, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@636e17e0), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_CONCEPT_RESTRICTION Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@10b27965, com.bakdata.conquery.models.query.ColumnDescriptor@1cfa123e]) on dataset Dataset[label=null, name=CONCEPT_RESTRICTION Test]
127.0.0.1 - - [26/Jan/2023:18:09:28 +0000] "GET /api/datasets/CONCEPT_RESTRICTION%20Test/result/CONCEPT_RESTRICTION$20Test.3a1722fb-eeab-4af6-a8e9-2f9e63d51add.csv?pretty=false HTTP/1.1" 200 39 "-" "Conquery (test client)" 27
INFO  [2023-01-26 18:09:28,878] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest CONCEPT_RESTRICTION Test on 2 rows
INFO  [2023-01-26 18:09:28,878] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast CONCEPT_RESTRICTION Test
INFO  [2023-01-26 18:09:28,878] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=CONCEPT_RESTRICTION Test, name=CONCEPT_RESTRICTION Test]
INFO  [2023-01-26 18:09:28,878] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=CONCEPT_RESTRICTION Test, name=CONCEPT_RESTRICTION Test]
INFO  [2023-01-26 18:09:28,878] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_CONCEPT_RESTRICTION Test_0bd0d184-b337-4bbb-ad5e-e31bd7841c2f
INFO  [2023-01-26 18:09:28,879] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_CONCEPT_RESTRICTION Test_c4e47527-ad6d-42e9-bfeb-c5deb1de91cd
INFO  [2023-01-26 18:09:28,976] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow CONCEPT_RESTRICTION Test
INFO  [2023-01-26 18:09:28,976] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_CONCEPT_RESTRICTION Test_c4e47527-ad6d-42e9-bfeb-c5deb1de91cd
INFO  [2023-01-26 18:09:28,976] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_CONCEPT_RESTRICTION Test_0bd0d184-b337-4bbb-ad5e-e31bd7841c2f
INFO  [2023-01-26 18:09:29,076] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of CONCEPT_RESTRICTION$20Test
INFO  [2023-01-26 18:09:29,076] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:29,103] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test CONCEPT_RESTRICTION Test
INFO  [2023-01-26 18:09:29,104] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test CONCEPT_WITHOUT_VALIDITYDATE Test
INFO  [2023-01-26 18:09:29,104] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:29,104] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:29,105] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=CONCEPT_WITHOUT_VALIDITYDATE Test, name=CONCEPT_WITHOUT_VALIDITYDATE Test]
INFO  [2023-01-26 18:09:29,105] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=CONCEPT_WITHOUT_VALIDITYDATE Test, name=CONCEPT_WITHOUT_VALIDITYDATE Test]
INFO  [2023-01-26 18:09:29,105] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:29,105] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:29,106] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker CONCEPT_WITHOUT_VALIDITYDATE$20Test.worker_CONCEPT_WITHOUT_VALIDITYDATE$20Test_ca75d5de-bc79-4628-b110-47e7a8fd5468 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:29,106] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker CONCEPT_WITHOUT_VALIDITYDATE$20Test.worker_CONCEPT_WITHOUT_VALIDITYDATE$20Test_ca75d5de-bc79-4628-b110-47e7a8fd5468 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:29,106] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:29,106] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker CONCEPT_WITHOUT_VALIDITYDATE$20Test.worker_CONCEPT_WITHOUT_VALIDITYDATE$20Test_2fc6811f-3d0c-4b4b-90d9-a3313bc4a4d2 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:29,106] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker CONCEPT_WITHOUT_VALIDITYDATE$20Test.worker_CONCEPT_WITHOUT_VALIDITYDATE$20Test_2fc6811f-3d0c-4b4b-90d9-a3313bc4a4d2 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:29,106] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:29,110] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:29,211] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:29,217] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:29,217] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table CONCEPT_WITHOUT_VALIDITYDATE$20Test.test_table
INFO  [2023-01-26 18:09:29,217] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table CONCEPT_WITHOUT_VALIDITYDATE$20Test.test_table
INFO  [2023-01-26 18:09:29,336] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:29,446] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:29,447] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:29,447] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 44 B in total
INFO  [2023-01-26 18:09:29,447] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_CONCEPT_WITHOUT_VALIDITYDATE Test/test_table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000168758sINFO  [2023-01-26 18:09:29,464] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=4, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:29,464] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=4, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:29,467] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_CONCEPT_WITHOUT_VALIDITYDATE Test/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:29,467] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:29,467] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_CONCEPT_WITHOUT_VALIDITYDATE Test/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:29,482] com.bakdata.conquery.models.jobs.ImportJob: Importing test_table into CONCEPT_WITHOUT_VALIDITYDATE$20Test.test_table
127.0.0.1 - - [26/Jan/2023:18:09:29 +0000] "POST /admin/datasets/CONCEPT_WITHOUT_VALIDITYDATE%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_CONCEPT_WITHOUT_VALIDITYDATE+Test%2Ftest_table.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:09:29,482] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:29,483] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:29,483] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:29,483] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:29,484] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:09:29,484] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[CONCEPT_WITHOUT_VALIDITYDATE$20Test.test_table.test_table], containing 4 entries.
INFO  [2023-01-26 18:09:29,485] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[CONCEPT_WITHOUT_VALIDITYDATE$20Test.test_table.test_table], containing 4 entries.
WARN  [2023-01-26 18:09:29,485] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:29,485] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received CONCEPT_WITHOUT_VALIDITYDATE$20Test.test_table.test_table.0
INFO  [2023-01-26 18:09:29,485] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received CONCEPT_WITHOUT_VALIDITYDATE$20Test.test_table.test_table.1
INFO  [2023-01-26 18:09:29,590] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:29,608] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:29,620] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:29,621] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:29,621] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:29,726] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: CONCEPT_WITHOUT_VALIDITYDATE Test QUERY INIT
INFO  [2023-01-26 18:09:29,736] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[CONCEPT_WITHOUT_VALIDITYDATE$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:29,737] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[40b2ec72-909a-4521-a213-26b41fe53bf2] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_CONCEPT_WITHOUT_VALIDITYDATE Test))]]
INFO  [2023-01-26 18:09:29,739] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery CONCEPT_WITHOUT_VALIDITYDATE$20Test.40b2ec72-909a-4521-a213-26b41fe53bf2
INFO  [2023-01-26 18:09:29,739] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery CONCEPT_WITHOUT_VALIDITYDATE$20Test.40b2ec72-909a-4521-a213-26b41fe53bf2
127.0.0.1 - - [26/Jan/2023:18:09:29 +0000] "POST /api/datasets/CONCEPT_WITHOUT_VALIDITYDATE$20Test/queries HTTP/1.1" 201 1471 "-" "Conquery (test client)" 4
INFO  [2023-01-26 18:09:29,740] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[CONCEPT_WITHOUT_VALIDITYDATE$20Test.40b2ec72-909a-4521-a213-26b41fe53bf2] with 0 results within PT0.001384S
INFO  [2023-01-26 18:09:29,741] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=CONCEPT_WITHOUT_VALIDITYDATE$20Test.40b2ec72-909a-4521-a213-26b41fe53bf2, workerId=CONCEPT_WITHOUT_VALIDITYDATE$20Test.worker_CONCEPT_WITHOUT_VALIDITYDATE$20Test_2fc6811f-3d0c-4b4b-90d9-a3313bc4a4d2, startTime=2023-01-26T18:09:29.739101, finishTime=2023-01-26T18:09:29.740485) of size 0
INFO  [2023-01-26 18:09:29,746] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[CONCEPT_WITHOUT_VALIDITYDATE$20Test.40b2ec72-909a-4521-a213-26b41fe53bf2] with 2 results within PT0.007094S
INFO  [2023-01-26 18:09:29,746] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=CONCEPT_WITHOUT_VALIDITYDATE$20Test.40b2ec72-909a-4521-a213-26b41fe53bf2, workerId=CONCEPT_WITHOUT_VALIDITYDATE$20Test.worker_CONCEPT_WITHOUT_VALIDITYDATE$20Test_ca75d5de-bc79-4628-b110-47e7a8fd5468, startTime=2023-01-26T18:09:29.739101, finishTime=2023-01-26T18:09:29.746195) of size 2
INFO  [2023-01-26 18:09:29,746] com.bakdata.conquery.models.execution.ManagedExecution: DONE 40b2ec72-909a-4521-a213-26b41fe53bf2 ManagedQuery within PT0.009527S
127.0.0.1 - - [26/Jan/2023:18:09:29 +0000] "GET /api/datasets/CONCEPT_WITHOUT_VALIDITYDATE$20Test/queries/CONCEPT_WITHOUT_VALIDITYDATE$20Test.40b2ec72-909a-4521-a213-26b41fe53bf2 HTTP/1.1" 200 1802 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:09:29,762] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=CONCEPT_WITHOUT_VALIDITYDATE Test], queryId=40b2ec72-909a-4521-a213-26b41fe53bf2, label=test_tree---test_child1	@§$, creationTime=2023-01-26T18:09:29.737137, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@4860d44[Count = 0], startTime=2023-01-26T18:09:29.737312, finishTime=2023-01-26T18:09:29.746839, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@5f18055e), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_CONCEPT_WITHOUT_VALIDITYDATE Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@39255aba, com.bakdata.conquery.models.query.ColumnDescriptor@1b9db52f, com.bakdata.conquery.models.query.ColumnDescriptor@2f456735]) download on dataset Dataset[label=null, name=CONCEPT_WITHOUT_VALIDITYDATE Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:29,762] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=CONCEPT_WITHOUT_VALIDITYDATE Test], queryId=40b2ec72-909a-4521-a213-26b41fe53bf2, label=test_tree---test_child1	@§$, creationTime=2023-01-26T18:09:29.737137, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@4860d44[Count = 0], startTime=2023-01-26T18:09:29.737312, finishTime=2023-01-26T18:09:29.746839, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@5f18055e), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_CONCEPT_WITHOUT_VALIDITYDATE Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@39255aba, com.bakdata.conquery.models.query.ColumnDescriptor@1b9db52f, com.bakdata.conquery.models.query.ColumnDescriptor@2f456735]) on dataset Dataset[label=null, name=CONCEPT_WITHOUT_VALIDITYDATE Test]
127.0.0.1 - - [26/Jan/2023:18:09:29 +0000] "GET /api/datasets/CONCEPT_WITHOUT_VALIDITYDATE%20Test/result/CONCEPT_WITHOUT_VALIDITYDATE$20Test.40b2ec72-909a-4521-a213-26b41fe53bf2.csv?pretty=false HTTP/1.1" 200 86 "-" "Conquery (test client)" 22
INFO  [2023-01-26 18:09:29,783] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest CONCEPT_WITHOUT_VALIDITYDATE Test on 3 rows
INFO  [2023-01-26 18:09:29,783] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast CONCEPT_WITHOUT_VALIDITYDATE Test
INFO  [2023-01-26 18:09:29,783] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=CONCEPT_WITHOUT_VALIDITYDATE Test, name=CONCEPT_WITHOUT_VALIDITYDATE Test]
INFO  [2023-01-26 18:09:29,783] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=CONCEPT_WITHOUT_VALIDITYDATE Test, name=CONCEPT_WITHOUT_VALIDITYDATE Test]
INFO  [2023-01-26 18:09:29,783] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_CONCEPT_WITHOUT_VALIDITYDATE Test_2fc6811f-3d0c-4b4b-90d9-a3313bc4a4d2
INFO  [2023-01-26 18:09:29,783] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_CONCEPT_WITHOUT_VALIDITYDATE Test_ca75d5de-bc79-4628-b110-47e7a8fd5468
INFO  [2023-01-26 18:09:29,805] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow CONCEPT_WITHOUT_VALIDITYDATE Test
INFO  [2023-01-26 18:09:29,806] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_CONCEPT_WITHOUT_VALIDITYDATE Test_ca75d5de-bc79-4628-b110-47e7a8fd5468
INFO  [2023-01-26 18:09:29,806] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_CONCEPT_WITHOUT_VALIDITYDATE Test_2fc6811f-3d0c-4b4b-90d9-a3313bc4a4d2
INFO  [2023-01-26 18:09:29,896] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of CONCEPT_WITHOUT_VALIDITYDATE$20Test
INFO  [2023-01-26 18:09:29,896] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:29,926] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test CONCEPT_WITHOUT_VALIDITYDATE Test
INFO  [2023-01-26 18:09:29,926] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test SIMPLE_TREECONCEPT_QUERY Test
INFO  [2023-01-26 18:09:29,926] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:29,926] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:29,928] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SIMPLE_TREECONCEPT_QUERY Test, name=SIMPLE_TREECONCEPT_QUERY Test]
INFO  [2023-01-26 18:09:29,928] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SIMPLE_TREECONCEPT_QUERY Test, name=SIMPLE_TREECONCEPT_QUERY Test]
INFO  [2023-01-26 18:09:29,928] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:29,928] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:29,932] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SIMPLE_TREECONCEPT_QUERY$20Test.worker_SIMPLE_TREECONCEPT_QUERY$20Test_ef406a54-6008-4756-a0e1-69fbd48cf209 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:29,932] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SIMPLE_TREECONCEPT_QUERY$20Test.worker_SIMPLE_TREECONCEPT_QUERY$20Test_ef406a54-6008-4756-a0e1-69fbd48cf209 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:29,932] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:29,932] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SIMPLE_TREECONCEPT_QUERY$20Test.worker_SIMPLE_TREECONCEPT_QUERY$20Test_8ebb915a-75d4-4fde-8c43-e9f6b1bba9ea are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:29,932] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SIMPLE_TREECONCEPT_QUERY$20Test.worker_SIMPLE_TREECONCEPT_QUERY$20Test_8ebb915a-75d4-4fde-8c43-e9f6b1bba9ea are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:29,932] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:29,935] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:30,040] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:30,049] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:30,049] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SIMPLE_TREECONCEPT_QUERY$20Test.table
INFO  [2023-01-26 18:09:30,049] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SIMPLE_TREECONCEPT_QUERY$20Test.table
INFO  [2023-01-26 18:09:30,162] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:30,272] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:30,272] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:30,272] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 175 B in total
INFO  [2023-01-26 18:09:30,272] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SIMPLE_TREECONCEPT_QUERY Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000207848sINFO  [2023-01-26 18:09:30,294] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=6, sum=7, min=1, average=1.166667, max=2}
INFO  [2023-01-26 18:09:30,294] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=7, nullLines=0), subType=IntegerParser(super=Parser(lines=7, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@40e4a86f)
INFO  [2023-01-26 18:09:30,294] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[include] with StringParser(super=Parser(lines=7, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:30,294] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[column] with StringParser(super=Parser(lines=7, nullLines=1), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:30,299] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SIMPLE_TREECONCEPT_QUERY Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:30,299] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:30,299] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SIMPLE_TREECONCEPT_QUERY Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:30,320] com.bakdata.conquery.models.jobs.ImportJob: Importing table into SIMPLE_TREECONCEPT_QUERY$20Test.table
127.0.0.1 - - [26/Jan/2023:18:09:30 +0000] "POST /admin/datasets/SIMPLE_TREECONCEPT_QUERY%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_SIMPLE_TREECONCEPT_QUERY+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 11
INFO  [2023-01-26 18:09:30,321] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:30,322] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:30,322] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:30,324] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:09:30,324] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SIMPLE_TREECONCEPT_QUERY$20Test.table.table], containing 7 entries.
WARN  [2023-01-26 18:09:30,325] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:30,325] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SIMPLE_TREECONCEPT_QUERY$20Test.table.table], containing 7 entries.
INFO  [2023-01-26 18:09:30,326] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SIMPLE_TREECONCEPT_QUERY$20Test.table.table.0
INFO  [2023-01-26 18:09:30,329] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SIMPLE_TREECONCEPT_QUERY$20Test.table.table.1
INFO  [2023-01-26 18:09:30,331] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:30,434] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:30,439] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:30,453] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:30,453] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:30,453] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:30,559] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: SIMPLE_TREECONCEPT_QUERY Test QUERY INIT
INFO  [2023-01-26 18:09:30,576] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[SIMPLE_TREECONCEPT_QUERY$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:30,577] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[de4b43c2-6266-4404-b33c-4db1c4a31b80] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_SIMPLE_TREECONCEPT_QUERY Test))]]
INFO  [2023-01-26 18:09:30,579] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SIMPLE_TREECONCEPT_QUERY$20Test.de4b43c2-6266-4404-b33c-4db1c4a31b80
INFO  [2023-01-26 18:09:30,579] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SIMPLE_TREECONCEPT_QUERY$20Test.de4b43c2-6266-4404-b33c-4db1c4a31b80
127.0.0.1 - - [26/Jan/2023:18:09:30 +0000] "POST /api/datasets/SIMPLE_TREECONCEPT_QUERY$20Test/queries HTTP/1.1" 201 1123 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:09:30,583] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SIMPLE_TREECONCEPT_QUERY$20Test.de4b43c2-6266-4404-b33c-4db1c4a31b80] with 2 results within PT0.004263S
INFO  [2023-01-26 18:09:30,583] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SIMPLE_TREECONCEPT_QUERY$20Test.de4b43c2-6266-4404-b33c-4db1c4a31b80] with 0 results within PT0.00428S
INFO  [2023-01-26 18:09:30,584] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SIMPLE_TREECONCEPT_QUERY$20Test.de4b43c2-6266-4404-b33c-4db1c4a31b80, workerId=SIMPLE_TREECONCEPT_QUERY$20Test.worker_SIMPLE_TREECONCEPT_QUERY$20Test_ef406a54-6008-4756-a0e1-69fbd48cf209, startTime=2023-01-26T18:09:30.579580, finishTime=2023-01-26T18:09:30.583843) of size 2
INFO  [2023-01-26 18:09:30,584] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SIMPLE_TREECONCEPT_QUERY$20Test.de4b43c2-6266-4404-b33c-4db1c4a31b80, workerId=SIMPLE_TREECONCEPT_QUERY$20Test.worker_SIMPLE_TREECONCEPT_QUERY$20Test_8ebb915a-75d4-4fde-8c43-e9f6b1bba9ea, startTime=2023-01-26T18:09:30.579608, finishTime=2023-01-26T18:09:30.583888) of size 0
INFO  [2023-01-26 18:09:30,584] com.bakdata.conquery.models.execution.ManagedExecution: DONE de4b43c2-6266-4404-b33c-4db1c4a31b80 ManagedQuery within PT0.007128S
127.0.0.1 - - [26/Jan/2023:18:09:30 +0000] "GET /api/datasets/SIMPLE_TREECONCEPT_QUERY$20Test/queries/SIMPLE_TREECONCEPT_QUERY$20Test.de4b43c2-6266-4404-b33c-4db1c4a31b80 HTTP/1.1" 200 1437 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:09:30,601] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SIMPLE_TREECONCEPT_QUERY Test], queryId=de4b43c2-6266-4404-b33c-4db1c4a31b80, label=tree---a1	@§$, creationTime=2023-01-26T18:09:30.577192, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@59b5b87f[Count = 0], startTime=2023-01-26T18:09:30.577422, finishTime=2023-01-26T18:09:30.584550, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@40105e16), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SIMPLE_TREECONCEPT_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@24f3f9f1, com.bakdata.conquery.models.query.ColumnDescriptor@16f13164]) download on dataset Dataset[label=null, name=SIMPLE_TREECONCEPT_QUERY Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:30,601] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SIMPLE_TREECONCEPT_QUERY Test], queryId=de4b43c2-6266-4404-b33c-4db1c4a31b80, label=tree---a1	@§$, creationTime=2023-01-26T18:09:30.577192, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@59b5b87f[Count = 0], startTime=2023-01-26T18:09:30.577422, finishTime=2023-01-26T18:09:30.584550, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@40105e16), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SIMPLE_TREECONCEPT_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@24f3f9f1, com.bakdata.conquery.models.query.ColumnDescriptor@16f13164]) on dataset Dataset[label=null, name=SIMPLE_TREECONCEPT_QUERY Test]
127.0.0.1 - - [26/Jan/2023:18:09:30 +0000] "GET /api/datasets/SIMPLE_TREECONCEPT_QUERY%20Test/result/SIMPLE_TREECONCEPT_QUERY$20Test.de4b43c2-6266-4404-b33c-4db1c4a31b80.csv?pretty=false HTTP/1.1" 200 65 "-" "Conquery (test client)" 14
INFO  [2023-01-26 18:09:30,614] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest SIMPLE_TREECONCEPT_QUERY Test on 3 rows
INFO  [2023-01-26 18:09:30,614] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast SIMPLE_TREECONCEPT_QUERY Test
INFO  [2023-01-26 18:09:30,614] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SIMPLE_TREECONCEPT_QUERY Test, name=SIMPLE_TREECONCEPT_QUERY Test]
INFO  [2023-01-26 18:09:30,614] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SIMPLE_TREECONCEPT_QUERY Test, name=SIMPLE_TREECONCEPT_QUERY Test]
INFO  [2023-01-26 18:09:30,614] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SIMPLE_TREECONCEPT_QUERY Test_ef406a54-6008-4756-a0e1-69fbd48cf209
INFO  [2023-01-26 18:09:30,614] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SIMPLE_TREECONCEPT_QUERY Test_8ebb915a-75d4-4fde-8c43-e9f6b1bba9ea
INFO  [2023-01-26 18:09:30,633] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SIMPLE_TREECONCEPT_QUERY Test_ef406a54-6008-4756-a0e1-69fbd48cf209
INFO  [2023-01-26 18:09:30,634] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow SIMPLE_TREECONCEPT_QUERY Test
INFO  [2023-01-26 18:09:30,650] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SIMPLE_TREECONCEPT_QUERY Test_8ebb915a-75d4-4fde-8c43-e9f6b1bba9ea
INFO  [2023-01-26 18:09:30,725] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of SIMPLE_TREECONCEPT_QUERY$20Test
INFO  [2023-01-26 18:09:30,725] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:30,758] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test SIMPLE_TREECONCEPT_QUERY Test
INFO  [2023-01-26 18:09:30,759] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test CQExternal Extra Data Test
INFO  [2023-01-26 18:09:30,759] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:30,759] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:30,760] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=CQExternal Extra Data Test, name=CQExternal Extra Data Test]
INFO  [2023-01-26 18:09:30,760] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=CQExternal Extra Data Test, name=CQExternal Extra Data Test]
INFO  [2023-01-26 18:09:30,761] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:30,761] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:30,765] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:30,765] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker CQExternal$20Extra$20Data$20Test.worker_CQExternal$20Extra$20Data$20Test_4002c837-7e30-4b2c-94d5-9cc5cfcc8a80 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:30,765] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker CQExternal$20Extra$20Data$20Test.worker_CQExternal$20Extra$20Data$20Test_4002c837-7e30-4b2c-94d5-9cc5cfcc8a80 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:30,765] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:30,807] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker CQExternal$20Extra$20Data$20Test.worker_CQExternal$20Extra$20Data$20Test_ce9cbca9-9d96-43dc-9f93-f14c2a5df1a9 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:30,807] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker CQExternal$20Extra$20Data$20Test.worker_CQExternal$20Extra$20Data$20Test_ce9cbca9-9d96-43dc-9f93-f14c2a5df1a9 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:30,807] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:30,866] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:30,874] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:30,874] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table CQExternal$20Extra$20Data$20Test.test_table
INFO  [2023-01-26 18:09:30,874] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table CQExternal$20Extra$20Data$20Test.test_table
INFO  [2023-01-26 18:09:30,988] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:31,096] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:31,097] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:31,097] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 88 B in total
INFO  [2023-01-26 18:09:31,097] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_CQExternal Extra Data Test/test_table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000216395sINFO  [2023-01-26 18:09:31,119] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=6, sum=6, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:31,119] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=15340, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@6d1d7ff8)
INFO  [2023-01-26 18:09:31,122] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_CQExternal Extra Data Test/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:31,122] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:31,122] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_CQExternal Extra Data Test/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:31,142] com.bakdata.conquery.models.jobs.ImportJob: Importing test_table into CQExternal$20Extra$20Data$20Test.test_table
INFO  [2023-01-26 18:09:31,143] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:09:31 +0000] "POST /admin/datasets/CQExternal%20Extra%20Data%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_CQExternal+Extra+Data+Test%2Ftest_table.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:09:31,143] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:31,143] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:31,143] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:31,144] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:09:31,145] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[CQExternal$20Extra$20Data$20Test.test_table.test_table], containing 6 entries.
INFO  [2023-01-26 18:09:31,145] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[CQExternal$20Extra$20Data$20Test.test_table.test_table], containing 6 entries.
WARN  [2023-01-26 18:09:31,146] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:31,146] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received CQExternal$20Extra$20Data$20Test.test_table.test_table.0
INFO  [2023-01-26 18:09:31,146] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received CQExternal$20Extra$20Data$20Test.test_table.test_table.1
INFO  [2023-01-26 18:09:31,251] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:31,257] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:31,267] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:31,268] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:31,268] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:31,374] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: CQExternal Extra Data Test QUERY INIT
INFO  [2023-01-26 18:09:31,392] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[CQExternal$20Extra$20Data$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:31,394] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[b7908fbb-3f95-48a7-989c-10265b0be5e9] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_CQExternal Extra Data Test))]]
INFO  [2023-01-26 18:09:31,397] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery CQExternal$20Extra$20Data$20Test.b7908fbb-3f95-48a7-989c-10265b0be5e9
INFO  [2023-01-26 18:09:31,397] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery CQExternal$20Extra$20Data$20Test.b7908fbb-3f95-48a7-989c-10265b0be5e9
INFO  [2023-01-26 18:09:31,399] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[CQExternal$20Extra$20Data$20Test.b7908fbb-3f95-48a7-989c-10265b0be5e9] with 2 results within PT0.001305S
127.0.0.1 - - [26/Jan/2023:18:09:31 +0000] "POST /api/datasets/CQExternal$20Extra$20Data$20Test/queries HTTP/1.1" 201 1185 "-" "Conquery (test client)" 10
INFO  [2023-01-26 18:09:31,400] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=CQExternal$20Extra$20Data$20Test.b7908fbb-3f95-48a7-989c-10265b0be5e9, workerId=CQExternal$20Extra$20Data$20Test.worker_CQExternal$20Extra$20Data$20Test_4002c837-7e30-4b2c-94d5-9cc5cfcc8a80, startTime=2023-01-26T18:09:31.397928, finishTime=2023-01-26T18:09:31.399233) of size 2
INFO  [2023-01-26 18:09:31,406] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[CQExternal$20Extra$20Data$20Test.b7908fbb-3f95-48a7-989c-10265b0be5e9] with 1 results within PT0.008308S
INFO  [2023-01-26 18:09:31,406] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=CQExternal$20Extra$20Data$20Test.b7908fbb-3f95-48a7-989c-10265b0be5e9, workerId=CQExternal$20Extra$20Data$20Test.worker_CQExternal$20Extra$20Data$20Test_ce9cbca9-9d96-43dc-9f93-f14c2a5df1a9, startTime=2023-01-26T18:09:31.397929, finishTime=2023-01-26T18:09:31.406237) of size 1
INFO  [2023-01-26 18:09:31,407] com.bakdata.conquery.models.execution.ManagedExecution: DONE b7908fbb-3f95-48a7-989c-10265b0be5e9 ManagedQuery within PT0.012637S
127.0.0.1 - - [26/Jan/2023:18:09:31 +0000] "GET /api/datasets/CQExternal$20Extra$20Data$20Test/queries/CQExternal$20Extra$20Data$20Test.b7908fbb-3f95-48a7-989c-10265b0be5e9 HTTP/1.1" 200 1505 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:09:31,420] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=CQExternal Extra Data Test], queryId=b7908fbb-3f95-48a7-989c-10265b0be5e9, label=Uploaded-List	@§$, creationTime=2023-01-26T18:09:31.392957, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@780bce3d[Count = 0], startTime=2023-01-26T18:09:31.394420, finishTime=2023-01-26T18:09:31.407057, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@7c829717), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_CQExternal Extra Data Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=3, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@419c3d73, com.bakdata.conquery.models.query.ColumnDescriptor@38c2c82a, com.bakdata.conquery.models.query.ColumnDescriptor@1e1e8329]) download on dataset Dataset[label=null, name=CQExternal Extra Data Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:31,421] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=CQExternal Extra Data Test], queryId=b7908fbb-3f95-48a7-989c-10265b0be5e9, label=Uploaded-List	@§$, creationTime=2023-01-26T18:09:31.392957, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@780bce3d[Count = 0], startTime=2023-01-26T18:09:31.394420, finishTime=2023-01-26T18:09:31.407057, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@7c829717), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_CQExternal Extra Data Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=3, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@419c3d73, com.bakdata.conquery.models.query.ColumnDescriptor@38c2c82a, com.bakdata.conquery.models.query.ColumnDescriptor@1e1e8329]) on dataset Dataset[label=null, name=CQExternal Extra Data Test]
127.0.0.1 - - [26/Jan/2023:18:09:31 +0000] "GET /api/datasets/CQExternal%20Extra%20Data%20Test/result/CQExternal$20Extra$20Data$20Test.b7908fbb-3f95-48a7-989c-10265b0be5e9.csv?pretty=false HTTP/1.1" 200 132 "-" "Conquery (test client)" 15
INFO  [2023-01-26 18:09:31,434] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest CQExternal Extra Data Test on 4 rows
INFO  [2023-01-26 18:09:31,434] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast CQExternal Extra Data Test
INFO  [2023-01-26 18:09:31,434] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=CQExternal Extra Data Test, name=CQExternal Extra Data Test]
INFO  [2023-01-26 18:09:31,434] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_CQExternal Extra Data Test_4002c837-7e30-4b2c-94d5-9cc5cfcc8a80
INFO  [2023-01-26 18:09:31,434] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=CQExternal Extra Data Test, name=CQExternal Extra Data Test]
INFO  [2023-01-26 18:09:31,435] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_CQExternal Extra Data Test_ce9cbca9-9d96-43dc-9f93-f14c2a5df1a9
INFO  [2023-01-26 18:09:31,460] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow CQExternal Extra Data Test
INFO  [2023-01-26 18:09:31,461] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_CQExternal Extra Data Test_ce9cbca9-9d96-43dc-9f93-f14c2a5df1a9
INFO  [2023-01-26 18:09:31,461] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_CQExternal Extra Data Test_4002c837-7e30-4b2c-94d5-9cc5cfcc8a80
INFO  [2023-01-26 18:09:31,546] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of CQExternal$20Extra$20Data$20Test
INFO  [2023-01-26 18:09:31,546] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:31,573] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test CQExternal Extra Data Test
INFO  [2023-01-26 18:09:31,573] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test DATE_DISTANCE_ERSTER Test
INFO  [2023-01-26 18:09:31,573] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:31,573] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:31,586] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DATE_DISTANCE_ERSTER Test, name=DATE_DISTANCE_ERSTER Test]
INFO  [2023-01-26 18:09:31,586] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DATE_DISTANCE_ERSTER Test, name=DATE_DISTANCE_ERSTER Test]
INFO  [2023-01-26 18:09:31,586] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:31,586] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:31,588] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DATE_DISTANCE_ERSTER$20Test.worker_DATE_DISTANCE_ERSTER$20Test_f1797fc3-9b16-4554-8d30-ca0ed1e614ff are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:31,588] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DATE_DISTANCE_ERSTER$20Test.worker_DATE_DISTANCE_ERSTER$20Test_f1797fc3-9b16-4554-8d30-ca0ed1e614ff are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:31,588] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:31,590] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DATE_DISTANCE_ERSTER$20Test.worker_DATE_DISTANCE_ERSTER$20Test_da04eed0-de0e-4029-b182-ea699e8a730a are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:31,590] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DATE_DISTANCE_ERSTER$20Test.worker_DATE_DISTANCE_ERSTER$20Test_da04eed0-de0e-4029-b182-ea699e8a730a are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:31,590] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:31,592] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:31,694] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:31,701] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:31,701] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DATE_DISTANCE_ERSTER$20Test.table1
INFO  [2023-01-26 18:09:31,701] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DATE_DISTANCE_ERSTER$20Test.table1
INFO  [2023-01-26 18:09:31,814] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:31,930] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:31,930] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:31,930] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 1.5 KiB in total
INFO  [2023-01-26 18:09:31,930] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_ERSTER Test/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.00019262sINFO  [2023-01-26 18:09:31,950] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=22, sum=26, min=1, average=1.181818, max=2}
INFO  [2023-01-26 18:09:31,950] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[letzter] with DateParser(super=Parser(lines=26, nullLines=2), subType=IntegerParser(super=Parser(lines=26, nullLines=2), minValue=14974, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@48c0069a)
INFO  [2023-01-26 18:09:31,950] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geburtsdatum] with DateParser(super=Parser(lines=26, nullLines=7), subType=IntegerParser(super=Parser(lines=26, nullLines=7), minValue=10592, maxValue=11323), dateReader=com.bakdata.conquery.util.DateReader@c53a9c1)
INFO  [2023-01-26 18:09:31,950] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[erster] with DateParser(super=Parser(lines=26, nullLines=2), subType=IntegerParser(super=Parser(lines=26, nullLines=2), minValue=14610, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@4756b63f)
INFO  [2023-01-26 18:09:31,950] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[versichertenzeit] with DateRangeParser(super=Parser(lines=26, nullLines=2), minParser=DateParser(super=Parser(lines=24, nullLines=0), subType=IntegerParser(super=Parser(lines=24, nullLines=0), minValue=14610, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@67f55787), maxParser=DateParser(super=Parser(lines=24, nullLines=0), subType=IntegerParser(super=Parser(lines=24, nullLines=0), minValue=14974, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@542a11f6), dateReader=com.bakdata.conquery.util.DateReader@68d60865, onlyQuarters=false, maxValue=16070, minValue=14610, anyOpen=false)
INFO  [2023-01-26 18:09:31,953] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_ERSTER Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:31,953] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:31,953] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_ERSTER Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:31,967] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into DATE_DISTANCE_ERSTER$20Test.table1
INFO  [2023-01-26 18:09:31,967] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:09:31 +0000] "POST /admin/datasets/DATE_DISTANCE_ERSTER%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_DATE_DISTANCE_ERSTER+Test%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:09:31,968] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:31,968] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:31,968] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:31,969] com.bakdata.conquery.models.jobs.ImportJob: Start sending 8 Buckets
INFO  [2023-01-26 18:09:31,969] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DATE_DISTANCE_ERSTER$20Test.table1.table1], containing 26 entries.
INFO  [2023-01-26 18:09:31,969] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DATE_DISTANCE_ERSTER$20Test.table1.table1], containing 26 entries.
INFO  [2023-01-26 18:09:31,970] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_ERSTER$20Test.table1.table1.0
INFO  [2023-01-26 18:09:31,970] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_ERSTER$20Test.table1.table1.2
INFO  [2023-01-26 18:09:31,970] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_ERSTER$20Test.table1.table1.1
INFO  [2023-01-26 18:09:31,970] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_ERSTER$20Test.table1.table1.4
WARN  [2023-01-26 18:09:31,970] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:31,970] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_ERSTER$20Test.table1.table1.3
INFO  [2023-01-26 18:09:31,970] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_ERSTER$20Test.table1.table1.5
INFO  [2023-01-26 18:09:31,970] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_ERSTER$20Test.table1.table1.7
INFO  [2023-01-26 18:09:32,012] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_ERSTER$20Test.table1.table1.6
INFO  [2023-01-26 18:09:32,117] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:32,122] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:32,134] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:32,134] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:32,134] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:32,241] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: DATE_DISTANCE_ERSTER Test QUERY INIT
INFO  [2023-01-26 18:09:32,252] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[DATE_DISTANCE_ERSTER$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:32,252] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[70d4a291-2219-4b26-99dc-aa531ba92979] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_ERSTER Test))]]
INFO  [2023-01-26 18:09:32,255] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DATE_DISTANCE_ERSTER$20Test.70d4a291-2219-4b26-99dc-aa531ba92979
INFO  [2023-01-26 18:09:32,255] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DATE_DISTANCE_ERSTER$20Test.70d4a291-2219-4b26-99dc-aa531ba92979
127.0.0.1 - - [26/Jan/2023:18:09:32 +0000] "POST /api/datasets/DATE_DISTANCE_ERSTER$20Test/queries HTTP/1.1" 201 1393 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:09:32,259] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DATE_DISTANCE_ERSTER$20Test.70d4a291-2219-4b26-99dc-aa531ba92979] with 2 results within PT0.004364S
INFO  [2023-01-26 18:09:32,259] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DATE_DISTANCE_ERSTER$20Test.70d4a291-2219-4b26-99dc-aa531ba92979] with 0 results within PT0.003863S
INFO  [2023-01-26 18:09:32,260] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DATE_DISTANCE_ERSTER$20Test.70d4a291-2219-4b26-99dc-aa531ba92979, workerId=DATE_DISTANCE_ERSTER$20Test.worker_DATE_DISTANCE_ERSTER$20Test_da04eed0-de0e-4029-b182-ea699e8a730a, startTime=2023-01-26T18:09:32.255162, finishTime=2023-01-26T18:09:32.259526) of size 2
INFO  [2023-01-26 18:09:32,260] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DATE_DISTANCE_ERSTER$20Test.70d4a291-2219-4b26-99dc-aa531ba92979, workerId=DATE_DISTANCE_ERSTER$20Test.worker_DATE_DISTANCE_ERSTER$20Test_f1797fc3-9b16-4554-8d30-ca0ed1e614ff, startTime=2023-01-26T18:09:32.255922, finishTime=2023-01-26T18:09:32.259785) of size 0
INFO  [2023-01-26 18:09:32,260] com.bakdata.conquery.models.execution.ManagedExecution: DONE 70d4a291-2219-4b26-99dc-aa531ba92979 ManagedQuery within PT0.007886S
127.0.0.1 - - [26/Jan/2023:18:09:32 +0000] "GET /api/datasets/DATE_DISTANCE_ERSTER$20Test/queries/DATE_DISTANCE_ERSTER$20Test.70d4a291-2219-4b26-99dc-aa531ba92979 HTTP/1.1" 200 1692 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:09:32,291] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DATE_DISTANCE_ERSTER Test], queryId=70d4a291-2219-4b26-99dc-aa531ba92979, label=Alter	@§$, creationTime=2023-01-26T18:09:32.252417, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@60150823[Count = 0], startTime=2023-01-26T18:09:32.252561, finishTime=2023-01-26T18:09:32.260447, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@533d4fcc), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_ERSTER Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@b0a236e, com.bakdata.conquery.models.query.ColumnDescriptor@4c5dbf8e]) download on dataset Dataset[label=null, name=DATE_DISTANCE_ERSTER Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:32,292] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DATE_DISTANCE_ERSTER Test], queryId=70d4a291-2219-4b26-99dc-aa531ba92979, label=Alter	@§$, creationTime=2023-01-26T18:09:32.252417, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@60150823[Count = 0], startTime=2023-01-26T18:09:32.252561, finishTime=2023-01-26T18:09:32.260447, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@533d4fcc), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_ERSTER Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@b0a236e, com.bakdata.conquery.models.query.ColumnDescriptor@4c5dbf8e]) on dataset Dataset[label=null, name=DATE_DISTANCE_ERSTER Test]
127.0.0.1 - - [26/Jan/2023:18:09:32 +0000] "GET /api/datasets/DATE_DISTANCE_ERSTER%20Test/result/DATE_DISTANCE_ERSTER$20Test.70d4a291-2219-4b26-99dc-aa531ba92979.csv?pretty=false HTTP/1.1" 200 65 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:09:32,294] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest DATE_DISTANCE_ERSTER Test on 3 rows
INFO  [2023-01-26 18:09:32,294] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast DATE_DISTANCE_ERSTER Test
INFO  [2023-01-26 18:09:32,294] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DATE_DISTANCE_ERSTER Test, name=DATE_DISTANCE_ERSTER Test]
INFO  [2023-01-26 18:09:32,294] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DATE_DISTANCE_ERSTER Test, name=DATE_DISTANCE_ERSTER Test]
INFO  [2023-01-26 18:09:32,294] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DATE_DISTANCE_ERSTER Test_f1797fc3-9b16-4554-8d30-ca0ed1e614ff
INFO  [2023-01-26 18:09:32,294] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DATE_DISTANCE_ERSTER Test_da04eed0-de0e-4029-b182-ea699e8a730a
INFO  [2023-01-26 18:09:32,388] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DATE_DISTANCE_ERSTER Test_f1797fc3-9b16-4554-8d30-ca0ed1e614ff
INFO  [2023-01-26 18:09:32,388] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow DATE_DISTANCE_ERSTER Test
INFO  [2023-01-26 18:09:32,390] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DATE_DISTANCE_ERSTER Test_da04eed0-de0e-4029-b182-ea699e8a730a
INFO  [2023-01-26 18:09:32,391] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of DATE_DISTANCE_ERSTER$20Test
INFO  [2023-01-26 18:09:32,391] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:32,539] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test DATE_DISTANCE_ERSTER Test
INFO  [2023-01-26 18:09:32,540] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test DATE_DISTANCE_LETZTER Test
INFO  [2023-01-26 18:09:32,540] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:32,540] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:32,541] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DATE_DISTANCE_LETZTER Test, name=DATE_DISTANCE_LETZTER Test]
INFO  [2023-01-26 18:09:32,541] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DATE_DISTANCE_LETZTER Test, name=DATE_DISTANCE_LETZTER Test]
INFO  [2023-01-26 18:09:32,541] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:32,541] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:32,542] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DATE_DISTANCE_LETZTER$20Test.worker_DATE_DISTANCE_LETZTER$20Test_53b52812-84a1-4a13-8231-ce9a9ad48da4 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:32,542] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DATE_DISTANCE_LETZTER$20Test.worker_DATE_DISTANCE_LETZTER$20Test_53b52812-84a1-4a13-8231-ce9a9ad48da4 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:32,542] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:32,542] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DATE_DISTANCE_LETZTER$20Test.worker_DATE_DISTANCE_LETZTER$20Test_5788a241-2365-42c7-91ad-5db1f10b622b are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:32,542] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DATE_DISTANCE_LETZTER$20Test.worker_DATE_DISTANCE_LETZTER$20Test_5788a241-2365-42c7-91ad-5db1f10b622b are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:32,542] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:32,543] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:32,647] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:32,654] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:32,654] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DATE_DISTANCE_LETZTER$20Test.table1
INFO  [2023-01-26 18:09:32,654] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DATE_DISTANCE_LETZTER$20Test.table1
INFO  [2023-01-26 18:09:32,768] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:32,876] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:32,876] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:32,876] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 1.5 KiB in total
INFO  [2023-01-26 18:09:32,876] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_LETZTER Test/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000237317sINFO  [2023-01-26 18:09:32,900] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=22, sum=26, min=1, average=1.181818, max=2}
INFO  [2023-01-26 18:09:32,900] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[letzter] with DateParser(super=Parser(lines=26, nullLines=2), subType=IntegerParser(super=Parser(lines=26, nullLines=2), minValue=14974, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@1772e838)
INFO  [2023-01-26 18:09:32,900] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[erster] with DateParser(super=Parser(lines=26, nullLines=2), subType=IntegerParser(super=Parser(lines=26, nullLines=2), minValue=14610, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@342827b7)
INFO  [2023-01-26 18:09:32,900] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geburtsdatum] with DateParser(super=Parser(lines=26, nullLines=7), subType=IntegerParser(super=Parser(lines=26, nullLines=7), minValue=10592, maxValue=11323), dateReader=com.bakdata.conquery.util.DateReader@2ceeb9)
INFO  [2023-01-26 18:09:32,900] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[versichertenzeit] with DateRangeParser(super=Parser(lines=26, nullLines=2), minParser=DateParser(super=Parser(lines=24, nullLines=0), subType=IntegerParser(super=Parser(lines=24, nullLines=0), minValue=14610, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@6821b6f), maxParser=DateParser(super=Parser(lines=24, nullLines=0), subType=IntegerParser(super=Parser(lines=24, nullLines=0), minValue=14974, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@7ec5de0a), dateReader=com.bakdata.conquery.util.DateReader@1b87a66d, onlyQuarters=false, maxValue=16070, minValue=14610, anyOpen=false)
INFO  [2023-01-26 18:09:32,903] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_LETZTER Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:32,903] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:32,903] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_LETZTER Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:32,918] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into DATE_DISTANCE_LETZTER$20Test.table1
INFO  [2023-01-26 18:09:32,919] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:09:32 +0000] "POST /admin/datasets/DATE_DISTANCE_LETZTER%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_DATE_DISTANCE_LETZTER+Test%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:09:32,919] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:32,919] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:32,919] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:32,920] com.bakdata.conquery.models.jobs.ImportJob: Start sending 8 Buckets
INFO  [2023-01-26 18:09:32,921] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DATE_DISTANCE_LETZTER$20Test.table1.table1], containing 26 entries.
INFO  [2023-01-26 18:09:32,921] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DATE_DISTANCE_LETZTER$20Test.table1.table1], containing 26 entries.
INFO  [2023-01-26 18:09:32,921] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_LETZTER$20Test.table1.table1.0
INFO  [2023-01-26 18:09:32,921] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_LETZTER$20Test.table1.table1.1
INFO  [2023-01-26 18:09:32,921] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_LETZTER$20Test.table1.table1.2
INFO  [2023-01-26 18:09:32,922] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_LETZTER$20Test.table1.table1.4
WARN  [2023-01-26 18:09:32,922] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:32,922] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_LETZTER$20Test.table1.table1.3
INFO  [2023-01-26 18:09:32,922] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_LETZTER$20Test.table1.table1.6
INFO  [2023-01-26 18:09:32,922] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_LETZTER$20Test.table1.table1.5
INFO  [2023-01-26 18:09:32,922] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_LETZTER$20Test.table1.table1.7
INFO  [2023-01-26 18:09:33,029] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:33,035] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:33,046] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:33,047] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:33,047] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:33,152] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: DATE_DISTANCE_LETZTER Test QUERY INIT
INFO  [2023-01-26 18:09:33,165] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[DATE_DISTANCE_LETZTER$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:33,165] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[de6f7bd1-292e-4cce-851a-2729f7188132] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_LETZTER Test))]]
INFO  [2023-01-26 18:09:33,169] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DATE_DISTANCE_LETZTER$20Test.de6f7bd1-292e-4cce-851a-2729f7188132
INFO  [2023-01-26 18:09:33,169] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DATE_DISTANCE_LETZTER$20Test.de6f7bd1-292e-4cce-851a-2729f7188132
127.0.0.1 - - [26/Jan/2023:18:09:33 +0000] "POST /api/datasets/DATE_DISTANCE_LETZTER$20Test/queries HTTP/1.1" 201 1397 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:09:33,175] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DATE_DISTANCE_LETZTER$20Test.de6f7bd1-292e-4cce-851a-2729f7188132] with 0 results within PT0.005695S
INFO  [2023-01-26 18:09:33,175] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DATE_DISTANCE_LETZTER$20Test.de6f7bd1-292e-4cce-851a-2729f7188132, workerId=DATE_DISTANCE_LETZTER$20Test.worker_DATE_DISTANCE_LETZTER$20Test_5788a241-2365-42c7-91ad-5db1f10b622b, startTime=2023-01-26T18:09:33.169305, finishTime=2023-01-26T18:09:33.175) of size 0
INFO  [2023-01-26 18:09:33,175] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DATE_DISTANCE_LETZTER$20Test.de6f7bd1-292e-4cce-851a-2729f7188132] with 2 results within PT0.006229S
INFO  [2023-01-26 18:09:33,176] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DATE_DISTANCE_LETZTER$20Test.de6f7bd1-292e-4cce-851a-2729f7188132, workerId=DATE_DISTANCE_LETZTER$20Test.worker_DATE_DISTANCE_LETZTER$20Test_53b52812-84a1-4a13-8231-ce9a9ad48da4, startTime=2023-01-26T18:09:33.169281, finishTime=2023-01-26T18:09:33.175510) of size 2
INFO  [2023-01-26 18:09:33,176] com.bakdata.conquery.models.execution.ManagedExecution: DONE de6f7bd1-292e-4cce-851a-2729f7188132 ManagedQuery within PT0.010251S
127.0.0.1 - - [26/Jan/2023:18:09:33 +0000] "GET /api/datasets/DATE_DISTANCE_LETZTER$20Test/queries/DATE_DISTANCE_LETZTER$20Test.de6f7bd1-292e-4cce-851a-2729f7188132 HTTP/1.1" 200 1701 "-" "Conquery (test client)" 4
INFO  [2023-01-26 18:09:33,190] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DATE_DISTANCE_LETZTER Test], queryId=de6f7bd1-292e-4cce-851a-2729f7188132, label=Alter	@§$, creationTime=2023-01-26T18:09:33.165712, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@2031c123[Count = 0], startTime=2023-01-26T18:09:33.165897, finishTime=2023-01-26T18:09:33.176148, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@43be7143), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_LETZTER Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@6668f0ea, com.bakdata.conquery.models.query.ColumnDescriptor@69fc34b8]) download on dataset Dataset[label=null, name=DATE_DISTANCE_LETZTER Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:33,190] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DATE_DISTANCE_LETZTER Test], queryId=de6f7bd1-292e-4cce-851a-2729f7188132, label=Alter	@§$, creationTime=2023-01-26T18:09:33.165712, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@2031c123[Count = 0], startTime=2023-01-26T18:09:33.165897, finishTime=2023-01-26T18:09:33.176148, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@43be7143), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_LETZTER Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@6668f0ea, com.bakdata.conquery.models.query.ColumnDescriptor@69fc34b8]) on dataset Dataset[label=null, name=DATE_DISTANCE_LETZTER Test]
127.0.0.1 - - [26/Jan/2023:18:09:33 +0000] "GET /api/datasets/DATE_DISTANCE_LETZTER%20Test/result/DATE_DISTANCE_LETZTER$20Test.de6f7bd1-292e-4cce-851a-2729f7188132.csv?pretty=false HTTP/1.1" 200 65 "-" "Conquery (test client)" 39
INFO  [2023-01-26 18:09:33,227] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest DATE_DISTANCE_LETZTER Test on 3 rows
INFO  [2023-01-26 18:09:33,227] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast DATE_DISTANCE_LETZTER Test
INFO  [2023-01-26 18:09:33,227] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DATE_DISTANCE_LETZTER Test, name=DATE_DISTANCE_LETZTER Test]
INFO  [2023-01-26 18:09:33,227] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DATE_DISTANCE_LETZTER Test, name=DATE_DISTANCE_LETZTER Test]
INFO  [2023-01-26 18:09:33,228] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DATE_DISTANCE_LETZTER Test_53b52812-84a1-4a13-8231-ce9a9ad48da4
INFO  [2023-01-26 18:09:33,228] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DATE_DISTANCE_LETZTER Test_5788a241-2365-42c7-91ad-5db1f10b622b
INFO  [2023-01-26 18:09:33,241] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow DATE_DISTANCE_LETZTER Test
INFO  [2023-01-26 18:09:33,242] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DATE_DISTANCE_LETZTER Test_53b52812-84a1-4a13-8231-ce9a9ad48da4
INFO  [2023-01-26 18:09:33,242] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DATE_DISTANCE_LETZTER Test_5788a241-2365-42c7-91ad-5db1f10b622b
INFO  [2023-01-26 18:09:33,335] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of DATE_DISTANCE_LETZTER$20Test
INFO  [2023-01-26 18:09:33,335] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:33,352] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test DATE_DISTANCE_LETZTER Test
INFO  [2023-01-26 18:09:33,353] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test DATE_DISTANCE_VERSICHERTENZEIT Test
INFO  [2023-01-26 18:09:33,353] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:33,353] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:33,354] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DATE_DISTANCE_VERSICHERTENZEIT Test, name=DATE_DISTANCE_VERSICHERTENZEIT Test]
INFO  [2023-01-26 18:09:33,354] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DATE_DISTANCE_VERSICHERTENZEIT Test, name=DATE_DISTANCE_VERSICHERTENZEIT Test]
INFO  [2023-01-26 18:09:33,354] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:33,354] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:33,356] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DATE_DISTANCE_VERSICHERTENZEIT$20Test.worker_DATE_DISTANCE_VERSICHERTENZEIT$20Test_0b70f134-ea74-4047-99ed-87a58a30e408 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:33,356] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DATE_DISTANCE_VERSICHERTENZEIT$20Test.worker_DATE_DISTANCE_VERSICHERTENZEIT$20Test_0b70f134-ea74-4047-99ed-87a58a30e408 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:33,356] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:33,356] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DATE_DISTANCE_VERSICHERTENZEIT$20Test.worker_DATE_DISTANCE_VERSICHERTENZEIT$20Test_9ad46b2f-3c35-4ac8-9354-f022a604e9dc are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:33,356] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DATE_DISTANCE_VERSICHERTENZEIT$20Test.worker_DATE_DISTANCE_VERSICHERTENZEIT$20Test_9ad46b2f-3c35-4ac8-9354-f022a604e9dc are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:33,356] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:33,360] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:33,461] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:33,468] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:33,468] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DATE_DISTANCE_VERSICHERTENZEIT$20Test.table1
INFO  [2023-01-26 18:09:33,468] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DATE_DISTANCE_VERSICHERTENZEIT$20Test.table1
INFO  [2023-01-26 18:09:33,583] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:33,690] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:33,691] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:33,691] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 1.5 KiB in total
INFO  [2023-01-26 18:09:33,691] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_VERSICHERTENZEIT Test/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000343414sINFO  [2023-01-26 18:09:33,726] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=22, sum=26, min=1, average=1.181818, max=2}
INFO  [2023-01-26 18:09:33,726] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[letzter] with DateParser(super=Parser(lines=26, nullLines=2), subType=IntegerParser(super=Parser(lines=26, nullLines=2), minValue=14974, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@48b012d8)
INFO  [2023-01-26 18:09:33,726] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[erster] with DateParser(super=Parser(lines=26, nullLines=2), subType=IntegerParser(super=Parser(lines=26, nullLines=2), minValue=14610, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@69921c6c)
INFO  [2023-01-26 18:09:33,726] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geburtsdatum] with DateParser(super=Parser(lines=26, nullLines=7), subType=IntegerParser(super=Parser(lines=26, nullLines=7), minValue=10592, maxValue=11323), dateReader=com.bakdata.conquery.util.DateReader@792c07da)
INFO  [2023-01-26 18:09:33,726] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[versichertenzeit] with DateRangeParser(super=Parser(lines=26, nullLines=2), minParser=DateParser(super=Parser(lines=24, nullLines=0), subType=IntegerParser(super=Parser(lines=24, nullLines=0), minValue=14610, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@63d4e3d9), maxParser=DateParser(super=Parser(lines=24, nullLines=0), subType=IntegerParser(super=Parser(lines=24, nullLines=0), minValue=14974, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@733dd192), dateReader=com.bakdata.conquery.util.DateReader@62b16395, onlyQuarters=false, maxValue=16070, minValue=14610, anyOpen=false)
INFO  [2023-01-26 18:09:33,728] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_VERSICHERTENZEIT Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:33,728] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:33,728] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_VERSICHERTENZEIT Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:33,743] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into DATE_DISTANCE_VERSICHERTENZEIT$20Test.table1
127.0.0.1 - - [26/Jan/2023:18:09:33 +0000] "POST /admin/datasets/DATE_DISTANCE_VERSICHERTENZEIT%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_DATE_DISTANCE_VERSICHERTENZEIT+Test%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:09:33,744] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:33,744] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:33,744] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:33,744] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:33,745] com.bakdata.conquery.models.jobs.ImportJob: Start sending 8 Buckets
INFO  [2023-01-26 18:09:33,746] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DATE_DISTANCE_VERSICHERTENZEIT$20Test.table1.table1], containing 26 entries.
INFO  [2023-01-26 18:09:33,746] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DATE_DISTANCE_VERSICHERTENZEIT$20Test.table1.table1], containing 26 entries.
INFO  [2023-01-26 18:09:33,746] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_VERSICHERTENZEIT$20Test.table1.table1.0
INFO  [2023-01-26 18:09:33,747] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_VERSICHERTENZEIT$20Test.table1.table1.2
INFO  [2023-01-26 18:09:33,747] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_VERSICHERTENZEIT$20Test.table1.table1.1
INFO  [2023-01-26 18:09:33,747] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_VERSICHERTENZEIT$20Test.table1.table1.3
WARN  [2023-01-26 18:09:33,747] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:33,747] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_VERSICHERTENZEIT$20Test.table1.table1.4
INFO  [2023-01-26 18:09:33,747] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_VERSICHERTENZEIT$20Test.table1.table1.5
INFO  [2023-01-26 18:09:33,747] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_VERSICHERTENZEIT$20Test.table1.table1.7
INFO  [2023-01-26 18:09:33,761] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_VERSICHERTENZEIT$20Test.table1.table1.6
INFO  [2023-01-26 18:09:33,866] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:33,871] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:33,885] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:33,885] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:33,885] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:33,991] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: DATE_DISTANCE_VERSICHERTENZEIT Test QUERY INIT
INFO  [2023-01-26 18:09:34,007] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[DATE_DISTANCE_VERSICHERTENZEIT$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:34,008] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[f8b7f9ae-b288-43fb-9d9d-d5558d5a2027] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_VERSICHERTENZEIT Test))]]
INFO  [2023-01-26 18:09:34,011] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DATE_DISTANCE_VERSICHERTENZEIT$20Test.f8b7f9ae-b288-43fb-9d9d-d5558d5a2027
INFO  [2023-01-26 18:09:34,012] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DATE_DISTANCE_VERSICHERTENZEIT$20Test.f8b7f9ae-b288-43fb-9d9d-d5558d5a2027
127.0.0.1 - - [26/Jan/2023:18:09:34 +0000] "POST /api/datasets/DATE_DISTANCE_VERSICHERTENZEIT$20Test/queries HTTP/1.1" 201 1433 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:09:34,019] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DATE_DISTANCE_VERSICHERTENZEIT$20Test.f8b7f9ae-b288-43fb-9d9d-d5558d5a2027] with 0 results within PT0.007486S
INFO  [2023-01-26 18:09:34,020] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DATE_DISTANCE_VERSICHERTENZEIT$20Test.f8b7f9ae-b288-43fb-9d9d-d5558d5a2027, workerId=DATE_DISTANCE_VERSICHERTENZEIT$20Test.worker_DATE_DISTANCE_VERSICHERTENZEIT$20Test_9ad46b2f-3c35-4ac8-9354-f022a604e9dc, startTime=2023-01-26T18:09:34.012421, finishTime=2023-01-26T18:09:34.019907) of size 0
INFO  [2023-01-26 18:09:34,020] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DATE_DISTANCE_VERSICHERTENZEIT$20Test.f8b7f9ae-b288-43fb-9d9d-d5558d5a2027] with 4 results within PT0.008809S
INFO  [2023-01-26 18:09:34,021] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DATE_DISTANCE_VERSICHERTENZEIT$20Test.f8b7f9ae-b288-43fb-9d9d-d5558d5a2027, workerId=DATE_DISTANCE_VERSICHERTENZEIT$20Test.worker_DATE_DISTANCE_VERSICHERTENZEIT$20Test_0b70f134-ea74-4047-99ed-87a58a30e408, startTime=2023-01-26T18:09:34.012044, finishTime=2023-01-26T18:09:34.020853) of size 4
INFO  [2023-01-26 18:09:34,021] com.bakdata.conquery.models.execution.ManagedExecution: DONE f8b7f9ae-b288-43fb-9d9d-d5558d5a2027 ManagedQuery within PT0.013164S
127.0.0.1 - - [26/Jan/2023:18:09:34 +0000] "GET /api/datasets/DATE_DISTANCE_VERSICHERTENZEIT$20Test/queries/DATE_DISTANCE_VERSICHERTENZEIT$20Test.f8b7f9ae-b288-43fb-9d9d-d5558d5a2027 HTTP/1.1" 200 1773 "-" "Conquery (test client)" 4
INFO  [2023-01-26 18:09:34,041] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DATE_DISTANCE_VERSICHERTENZEIT Test], queryId=f8b7f9ae-b288-43fb-9d9d-d5558d5a2027, label=Alter	@§$, creationTime=2023-01-26T18:09:34.008091, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@707fe160[Count = 0], startTime=2023-01-26T18:09:34.008289, finishTime=2023-01-26T18:09:34.021453, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@5f59b9d6), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_VERSICHERTENZEIT Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@385f5f26, com.bakdata.conquery.models.query.ColumnDescriptor@52679414]) download on dataset Dataset[label=null, name=DATE_DISTANCE_VERSICHERTENZEIT Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:34,042] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DATE_DISTANCE_VERSICHERTENZEIT Test], queryId=f8b7f9ae-b288-43fb-9d9d-d5558d5a2027, label=Alter	@§$, creationTime=2023-01-26T18:09:34.008091, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@707fe160[Count = 0], startTime=2023-01-26T18:09:34.008289, finishTime=2023-01-26T18:09:34.021453, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@5f59b9d6), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_VERSICHERTENZEIT Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@385f5f26, com.bakdata.conquery.models.query.ColumnDescriptor@52679414]) on dataset Dataset[label=null, name=DATE_DISTANCE_VERSICHERTENZEIT Test]
127.0.0.1 - - [26/Jan/2023:18:09:34 +0000] "GET /api/datasets/DATE_DISTANCE_VERSICHERTENZEIT%20Test/result/DATE_DISTANCE_VERSICHERTENZEIT$20Test.f8b7f9ae-b288-43fb-9d9d-d5558d5a2027.csv?pretty=false HTTP/1.1" 200 117 "-" "Conquery (test client)" 30
INFO  [2023-01-26 18:09:34,070] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest DATE_DISTANCE_VERSICHERTENZEIT Test on 5 rows
INFO  [2023-01-26 18:09:34,070] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast DATE_DISTANCE_VERSICHERTENZEIT Test
INFO  [2023-01-26 18:09:34,071] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DATE_DISTANCE_VERSICHERTENZEIT Test, name=DATE_DISTANCE_VERSICHERTENZEIT Test]
INFO  [2023-01-26 18:09:34,071] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DATE_DISTANCE_VERSICHERTENZEIT Test, name=DATE_DISTANCE_VERSICHERTENZEIT Test]
INFO  [2023-01-26 18:09:34,071] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DATE_DISTANCE_VERSICHERTENZEIT Test_9ad46b2f-3c35-4ac8-9354-f022a604e9dc
INFO  [2023-01-26 18:09:34,071] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DATE_DISTANCE_VERSICHERTENZEIT Test_0b70f134-ea74-4047-99ed-87a58a30e408
INFO  [2023-01-26 18:09:34,168] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow DATE_DISTANCE_VERSICHERTENZEIT Test
INFO  [2023-01-26 18:09:34,168] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DATE_DISTANCE_VERSICHERTENZEIT Test_9ad46b2f-3c35-4ac8-9354-f022a604e9dc
INFO  [2023-01-26 18:09:34,168] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DATE_DISTANCE_VERSICHERTENZEIT Test_0b70f134-ea74-4047-99ed-87a58a30e408
INFO  [2023-01-26 18:09:34,268] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of DATE_DISTANCE_VERSICHERTENZEIT$20Test
INFO  [2023-01-26 18:09:34,268] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:34,294] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test DATE_DISTANCE_VERSICHERTENZEIT Test
INFO  [2023-01-26 18:09:34,295] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test DATE_DISTANCE_AGE_SPAN_ERSTER Test
INFO  [2023-01-26 18:09:34,295] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:34,295] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:34,296] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DATE_DISTANCE_AGE_SPAN_ERSTER Test, name=DATE_DISTANCE_AGE_SPAN_ERSTER Test]
INFO  [2023-01-26 18:09:34,296] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DATE_DISTANCE_AGE_SPAN_ERSTER Test, name=DATE_DISTANCE_AGE_SPAN_ERSTER Test]
INFO  [2023-01-26 18:09:34,296] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:34,296] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:34,298] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DATE_DISTANCE_AGE_SPAN_ERSTER$20Test.worker_DATE_DISTANCE_AGE_SPAN_ERSTER$20Test_ba3e445a-beb4-4c17-89c5-370e73a47627 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:34,298] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DATE_DISTANCE_AGE_SPAN_ERSTER$20Test.worker_DATE_DISTANCE_AGE_SPAN_ERSTER$20Test_ba3e445a-beb4-4c17-89c5-370e73a47627 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:34,298] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:34,298] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DATE_DISTANCE_AGE_SPAN_ERSTER$20Test.worker_DATE_DISTANCE_AGE_SPAN_ERSTER$20Test_e256f447-cac7-4100-84f7-05567e8555d7 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:34,298] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DATE_DISTANCE_AGE_SPAN_ERSTER$20Test.worker_DATE_DISTANCE_AGE_SPAN_ERSTER$20Test_e256f447-cac7-4100-84f7-05567e8555d7 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:34,299] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:34,301] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:34,403] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:34,409] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:34,409] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DATE_DISTANCE_AGE_SPAN_ERSTER$20Test.table1
INFO  [2023-01-26 18:09:34,409] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DATE_DISTANCE_AGE_SPAN_ERSTER$20Test.table1
INFO  [2023-01-26 18:09:34,524] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:34,633] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:34,633] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:34,633] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 1.5 KiB in total
INFO  [2023-01-26 18:09:34,633] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_AGE_SPAN_ERSTER Test/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000173711sINFO  [2023-01-26 18:09:34,651] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=22, sum=26, min=1, average=1.181818, max=2}
INFO  [2023-01-26 18:09:34,651] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[letzter] with DateParser(super=Parser(lines=26, nullLines=2), subType=IntegerParser(super=Parser(lines=26, nullLines=2), minValue=14974, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@123b23d4)
INFO  [2023-01-26 18:09:34,651] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[erster] with DateParser(super=Parser(lines=26, nullLines=2), subType=IntegerParser(super=Parser(lines=26, nullLines=2), minValue=14610, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@7fdd2b52)
INFO  [2023-01-26 18:09:34,651] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[versichertenzeit] with DateRangeParser(super=Parser(lines=26, nullLines=2), minParser=DateParser(super=Parser(lines=24, nullLines=0), subType=IntegerParser(super=Parser(lines=24, nullLines=0), minValue=14610, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@50f005c), maxParser=DateParser(super=Parser(lines=24, nullLines=0), subType=IntegerParser(super=Parser(lines=24, nullLines=0), minValue=14974, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@4181e10f), dateReader=com.bakdata.conquery.util.DateReader@5cad19ec, onlyQuarters=false, maxValue=16070, minValue=14610, anyOpen=false)
INFO  [2023-01-26 18:09:34,651] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geburtsdatum] with DateParser(super=Parser(lines=26, nullLines=7), subType=IntegerParser(super=Parser(lines=26, nullLines=7), minValue=10592, maxValue=11323), dateReader=com.bakdata.conquery.util.DateReader@7d8d0ca8)
INFO  [2023-01-26 18:09:34,654] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_AGE_SPAN_ERSTER Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:34,654] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:34,654] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_AGE_SPAN_ERSTER Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:34,669] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into DATE_DISTANCE_AGE_SPAN_ERSTER$20Test.table1
127.0.0.1 - - [26/Jan/2023:18:09:34 +0000] "POST /admin/datasets/DATE_DISTANCE_AGE_SPAN_ERSTER%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_DATE_DISTANCE_AGE_SPAN_ERSTER+Test%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:09:34,670] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:34,672] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:34,672] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:34,672] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:34,675] com.bakdata.conquery.models.jobs.ImportJob: Start sending 8 Buckets
INFO  [2023-01-26 18:09:34,675] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DATE_DISTANCE_AGE_SPAN_ERSTER$20Test.table1.table1], containing 26 entries.
INFO  [2023-01-26 18:09:34,675] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DATE_DISTANCE_AGE_SPAN_ERSTER$20Test.table1.table1], containing 26 entries.
INFO  [2023-01-26 18:09:34,676] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGE_SPAN_ERSTER$20Test.table1.table1.0
INFO  [2023-01-26 18:09:34,676] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGE_SPAN_ERSTER$20Test.table1.table1.1
INFO  [2023-01-26 18:09:34,676] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGE_SPAN_ERSTER$20Test.table1.table1.2
INFO  [2023-01-26 18:09:34,676] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGE_SPAN_ERSTER$20Test.table1.table1.4
INFO  [2023-01-26 18:09:34,676] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGE_SPAN_ERSTER$20Test.table1.table1.3
WARN  [2023-01-26 18:09:34,676] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:34,676] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGE_SPAN_ERSTER$20Test.table1.table1.6
INFO  [2023-01-26 18:09:34,677] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGE_SPAN_ERSTER$20Test.table1.table1.5
INFO  [2023-01-26 18:09:34,677] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGE_SPAN_ERSTER$20Test.table1.table1.7
INFO  [2023-01-26 18:09:34,782] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:34,787] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:34,804] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:34,804] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:34,804] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:34,909] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: DATE_DISTANCE_AGE_SPAN_ERSTER Test QUERY INIT
INFO  [2023-01-26 18:09:34,922] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[DATE_DISTANCE_AGE_SPAN_ERSTER$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:34,922] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[1df5291a-4a0f-4a25-9f97-33f792d4939f] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_AGE_SPAN_ERSTER Test))]]
INFO  [2023-01-26 18:09:34,925] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DATE_DISTANCE_AGE_SPAN_ERSTER$20Test.1df5291a-4a0f-4a25-9f97-33f792d4939f
INFO  [2023-01-26 18:09:34,925] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DATE_DISTANCE_AGE_SPAN_ERSTER$20Test.1df5291a-4a0f-4a25-9f97-33f792d4939f
127.0.0.1 - - [26/Jan/2023:18:09:34 +0000] "POST /api/datasets/DATE_DISTANCE_AGE_SPAN_ERSTER$20Test/queries HTTP/1.1" 201 1429 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:09:34,929] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DATE_DISTANCE_AGE_SPAN_ERSTER$20Test.1df5291a-4a0f-4a25-9f97-33f792d4939f] with 1 results within PT0.003493S
INFO  [2023-01-26 18:09:34,929] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DATE_DISTANCE_AGE_SPAN_ERSTER$20Test.1df5291a-4a0f-4a25-9f97-33f792d4939f] with 3 results within PT0.003948S
INFO  [2023-01-26 18:09:34,929] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DATE_DISTANCE_AGE_SPAN_ERSTER$20Test.1df5291a-4a0f-4a25-9f97-33f792d4939f, workerId=DATE_DISTANCE_AGE_SPAN_ERSTER$20Test.worker_DATE_DISTANCE_AGE_SPAN_ERSTER$20Test_e256f447-cac7-4100-84f7-05567e8555d7, startTime=2023-01-26T18:09:34.925610, finishTime=2023-01-26T18:09:34.929103) of size 1
INFO  [2023-01-26 18:09:34,929] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DATE_DISTANCE_AGE_SPAN_ERSTER$20Test.1df5291a-4a0f-4a25-9f97-33f792d4939f, workerId=DATE_DISTANCE_AGE_SPAN_ERSTER$20Test.worker_DATE_DISTANCE_AGE_SPAN_ERSTER$20Test_ba3e445a-beb4-4c17-89c5-370e73a47627, startTime=2023-01-26T18:09:34.925464, finishTime=2023-01-26T18:09:34.929412) of size 3
INFO  [2023-01-26 18:09:34,929] com.bakdata.conquery.models.execution.ManagedExecution: DONE 1df5291a-4a0f-4a25-9f97-33f792d4939f ManagedQuery within PT0.007388S
127.0.0.1 - - [26/Jan/2023:18:09:34 +0000] "GET /api/datasets/DATE_DISTANCE_AGE_SPAN_ERSTER$20Test/queries/DATE_DISTANCE_AGE_SPAN_ERSTER$20Test.1df5291a-4a0f-4a25-9f97-33f792d4939f HTTP/1.1" 200 1764 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:09:34,945] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DATE_DISTANCE_AGE_SPAN_ERSTER Test], queryId=1df5291a-4a0f-4a25-9f97-33f792d4939f, label=Alter	@§$, creationTime=2023-01-26T18:09:34.922347, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@39836f0f[Count = 0], startTime=2023-01-26T18:09:34.922518, finishTime=2023-01-26T18:09:34.929906, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@3c3cb617), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_AGE_SPAN_ERSTER Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@3c168516, com.bakdata.conquery.models.query.ColumnDescriptor@6e23b5b3]) download on dataset Dataset[label=null, name=DATE_DISTANCE_AGE_SPAN_ERSTER Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:34,945] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DATE_DISTANCE_AGE_SPAN_ERSTER Test], queryId=1df5291a-4a0f-4a25-9f97-33f792d4939f, label=Alter	@§$, creationTime=2023-01-26T18:09:34.922347, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@39836f0f[Count = 0], startTime=2023-01-26T18:09:34.922518, finishTime=2023-01-26T18:09:34.929906, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@3c3cb617), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_AGE_SPAN_ERSTER Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@3c168516, com.bakdata.conquery.models.query.ColumnDescriptor@6e23b5b3]) on dataset Dataset[label=null, name=DATE_DISTANCE_AGE_SPAN_ERSTER Test]
127.0.0.1 - - [26/Jan/2023:18:09:34 +0000] "GET /api/datasets/DATE_DISTANCE_AGE_SPAN_ERSTER%20Test/result/DATE_DISTANCE_AGE_SPAN_ERSTER$20Test.1df5291a-4a0f-4a25-9f97-33f792d4939f.csv?pretty=false HTTP/1.1" 200 119 "-" "Conquery (test client)" 25
INFO  [2023-01-26 18:09:34,969] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest DATE_DISTANCE_AGE_SPAN_ERSTER Test on 5 rows
INFO  [2023-01-26 18:09:34,970] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast DATE_DISTANCE_AGE_SPAN_ERSTER Test
INFO  [2023-01-26 18:09:34,970] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DATE_DISTANCE_AGE_SPAN_ERSTER Test, name=DATE_DISTANCE_AGE_SPAN_ERSTER Test]
INFO  [2023-01-26 18:09:34,970] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DATE_DISTANCE_AGE_SPAN_ERSTER Test, name=DATE_DISTANCE_AGE_SPAN_ERSTER Test]
INFO  [2023-01-26 18:09:34,970] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DATE_DISTANCE_AGE_SPAN_ERSTER Test_e256f447-cac7-4100-84f7-05567e8555d7
INFO  [2023-01-26 18:09:34,970] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DATE_DISTANCE_AGE_SPAN_ERSTER Test_ba3e445a-beb4-4c17-89c5-370e73a47627
INFO  [2023-01-26 18:09:34,996] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow DATE_DISTANCE_AGE_SPAN_ERSTER Test
INFO  [2023-01-26 18:09:35,004] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DATE_DISTANCE_AGE_SPAN_ERSTER Test_e256f447-cac7-4100-84f7-05567e8555d7
INFO  [2023-01-26 18:09:35,004] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DATE_DISTANCE_AGE_SPAN_ERSTER Test_ba3e445a-beb4-4c17-89c5-370e73a47627
INFO  [2023-01-26 18:09:35,077] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of DATE_DISTANCE_AGE_SPAN_ERSTER$20Test
INFO  [2023-01-26 18:09:35,077] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:35,109] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test DATE_DISTANCE_AGE_SPAN_ERSTER Test
INFO  [2023-01-26 18:09:35,109] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test DATE_DISTANCE_AGE_SPAN_LETZTER Test
INFO  [2023-01-26 18:09:35,109] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:35,109] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:35,110] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DATE_DISTANCE_AGE_SPAN_LETZTER Test, name=DATE_DISTANCE_AGE_SPAN_LETZTER Test]
INFO  [2023-01-26 18:09:35,110] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DATE_DISTANCE_AGE_SPAN_LETZTER Test, name=DATE_DISTANCE_AGE_SPAN_LETZTER Test]
INFO  [2023-01-26 18:09:35,110] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:35,110] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:35,112] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DATE_DISTANCE_AGE_SPAN_LETZTER$20Test.worker_DATE_DISTANCE_AGE_SPAN_LETZTER$20Test_382180bd-a566-40b4-af31-491d67be3733 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:35,112] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DATE_DISTANCE_AGE_SPAN_LETZTER$20Test.worker_DATE_DISTANCE_AGE_SPAN_LETZTER$20Test_382180bd-a566-40b4-af31-491d67be3733 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:35,112] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:35,112] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DATE_DISTANCE_AGE_SPAN_LETZTER$20Test.worker_DATE_DISTANCE_AGE_SPAN_LETZTER$20Test_252fe670-3ff9-4033-99c3-0fff75e4141f are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:35,112] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DATE_DISTANCE_AGE_SPAN_LETZTER$20Test.worker_DATE_DISTANCE_AGE_SPAN_LETZTER$20Test_252fe670-3ff9-4033-99c3-0fff75e4141f are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:35,112] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:35,112] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:35,216] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:35,222] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:35,222] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DATE_DISTANCE_AGE_SPAN_LETZTER$20Test.table1
INFO  [2023-01-26 18:09:35,222] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DATE_DISTANCE_AGE_SPAN_LETZTER$20Test.table1
INFO  [2023-01-26 18:09:35,342] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:35,452] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:35,453] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:35,453] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 1.5 KiB in total
INFO  [2023-01-26 18:09:35,453] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_AGE_SPAN_LETZTER Test/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000255199sINFO  [2023-01-26 18:09:35,479] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=22, sum=26, min=1, average=1.181818, max=2}
INFO  [2023-01-26 18:09:35,479] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[letzter] with DateParser(super=Parser(lines=26, nullLines=2), subType=IntegerParser(super=Parser(lines=26, nullLines=2), minValue=14974, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@1b69ab95)
INFO  [2023-01-26 18:09:35,479] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[versichertenzeit] with DateRangeParser(super=Parser(lines=26, nullLines=2), minParser=DateParser(super=Parser(lines=24, nullLines=0), subType=IntegerParser(super=Parser(lines=24, nullLines=0), minValue=14610, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@35696427), maxParser=DateParser(super=Parser(lines=24, nullLines=0), subType=IntegerParser(super=Parser(lines=24, nullLines=0), minValue=14974, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@48199f36), dateReader=com.bakdata.conquery.util.DateReader@6de96a3, onlyQuarters=false, maxValue=16070, minValue=14610, anyOpen=false)
INFO  [2023-01-26 18:09:35,479] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geburtsdatum] with DateParser(super=Parser(lines=26, nullLines=7), subType=IntegerParser(super=Parser(lines=26, nullLines=7), minValue=10592, maxValue=11323), dateReader=com.bakdata.conquery.util.DateReader@2fb89f2d)
INFO  [2023-01-26 18:09:35,479] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[erster] with DateParser(super=Parser(lines=26, nullLines=2), subType=IntegerParser(super=Parser(lines=26, nullLines=2), minValue=14610, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@2540b65c)
INFO  [2023-01-26 18:09:35,481] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_AGE_SPAN_LETZTER Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:35,481] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:35,481] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_AGE_SPAN_LETZTER Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:35,498] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into DATE_DISTANCE_AGE_SPAN_LETZTER$20Test.table1
127.0.0.1 - - [26/Jan/2023:18:09:35 +0000] "POST /admin/datasets/DATE_DISTANCE_AGE_SPAN_LETZTER%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_DATE_DISTANCE_AGE_SPAN_LETZTER+Test%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:09:35,499] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:35,499] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:35,499] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:35,499] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:35,501] com.bakdata.conquery.models.jobs.ImportJob: Start sending 8 Buckets
INFO  [2023-01-26 18:09:35,501] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DATE_DISTANCE_AGE_SPAN_LETZTER$20Test.table1.table1], containing 26 entries.
INFO  [2023-01-26 18:09:35,501] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DATE_DISTANCE_AGE_SPAN_LETZTER$20Test.table1.table1], containing 26 entries.
INFO  [2023-01-26 18:09:35,511] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGE_SPAN_LETZTER$20Test.table1.table1.0
INFO  [2023-01-26 18:09:35,511] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGE_SPAN_LETZTER$20Test.table1.table1.1
INFO  [2023-01-26 18:09:35,511] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGE_SPAN_LETZTER$20Test.table1.table1.2
WARN  [2023-01-26 18:09:35,511] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:35,511] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGE_SPAN_LETZTER$20Test.table1.table1.4
INFO  [2023-01-26 18:09:35,512] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGE_SPAN_LETZTER$20Test.table1.table1.3
INFO  [2023-01-26 18:09:35,512] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGE_SPAN_LETZTER$20Test.table1.table1.5
INFO  [2023-01-26 18:09:35,512] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGE_SPAN_LETZTER$20Test.table1.table1.7
INFO  [2023-01-26 18:09:35,556] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGE_SPAN_LETZTER$20Test.table1.table1.6
INFO  [2023-01-26 18:09:35,665] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:35,671] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:35,682] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:35,682] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:35,682] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:35,788] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: DATE_DISTANCE_AGE_SPAN_LETZTER Test QUERY INIT
INFO  [2023-01-26 18:09:35,799] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[DATE_DISTANCE_AGE_SPAN_LETZTER$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:35,799] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[521291ca-c9af-463b-ab2e-f9d211859d55] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_AGE_SPAN_LETZTER Test))]]
INFO  [2023-01-26 18:09:35,802] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DATE_DISTANCE_AGE_SPAN_LETZTER$20Test.521291ca-c9af-463b-ab2e-f9d211859d55
INFO  [2023-01-26 18:09:35,802] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DATE_DISTANCE_AGE_SPAN_LETZTER$20Test.521291ca-c9af-463b-ab2e-f9d211859d55
127.0.0.1 - - [26/Jan/2023:18:09:35 +0000] "POST /api/datasets/DATE_DISTANCE_AGE_SPAN_LETZTER$20Test/queries HTTP/1.1" 201 1433 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:09:35,809] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DATE_DISTANCE_AGE_SPAN_LETZTER$20Test.521291ca-c9af-463b-ab2e-f9d211859d55] with 0 results within PT0.00671S
INFO  [2023-01-26 18:09:35,809] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DATE_DISTANCE_AGE_SPAN_LETZTER$20Test.521291ca-c9af-463b-ab2e-f9d211859d55, workerId=DATE_DISTANCE_AGE_SPAN_LETZTER$20Test.worker_DATE_DISTANCE_AGE_SPAN_LETZTER$20Test_252fe670-3ff9-4033-99c3-0fff75e4141f, startTime=2023-01-26T18:09:35.802555, finishTime=2023-01-26T18:09:35.809265) of size 0
INFO  [2023-01-26 18:09:35,810] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DATE_DISTANCE_AGE_SPAN_LETZTER$20Test.521291ca-c9af-463b-ab2e-f9d211859d55] with 4 results within PT0.007563S
INFO  [2023-01-26 18:09:35,810] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DATE_DISTANCE_AGE_SPAN_LETZTER$20Test.521291ca-c9af-463b-ab2e-f9d211859d55, workerId=DATE_DISTANCE_AGE_SPAN_LETZTER$20Test.worker_DATE_DISTANCE_AGE_SPAN_LETZTER$20Test_382180bd-a566-40b4-af31-491d67be3733, startTime=2023-01-26T18:09:35.802559, finishTime=2023-01-26T18:09:35.810122) of size 4
INFO  [2023-01-26 18:09:35,810] com.bakdata.conquery.models.execution.ManagedExecution: DONE 521291ca-c9af-463b-ab2e-f9d211859d55 ManagedQuery within PT0.011274S
127.0.0.1 - - [26/Jan/2023:18:09:35 +0000] "GET /api/datasets/DATE_DISTANCE_AGE_SPAN_LETZTER$20Test/queries/DATE_DISTANCE_AGE_SPAN_LETZTER$20Test.521291ca-c9af-463b-ab2e-f9d211859d55 HTTP/1.1" 200 1773 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:09:35,829] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DATE_DISTANCE_AGE_SPAN_LETZTER Test], queryId=521291ca-c9af-463b-ab2e-f9d211859d55, label=Alter	@§$, creationTime=2023-01-26T18:09:35.799276, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@51318d8b[Count = 0], startTime=2023-01-26T18:09:35.799468, finishTime=2023-01-26T18:09:35.810742, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2407c1de), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_AGE_SPAN_LETZTER Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@593b1514, com.bakdata.conquery.models.query.ColumnDescriptor@4548859f]) download on dataset Dataset[label=null, name=DATE_DISTANCE_AGE_SPAN_LETZTER Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:35,830] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DATE_DISTANCE_AGE_SPAN_LETZTER Test], queryId=521291ca-c9af-463b-ab2e-f9d211859d55, label=Alter	@§$, creationTime=2023-01-26T18:09:35.799276, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@51318d8b[Count = 0], startTime=2023-01-26T18:09:35.799468, finishTime=2023-01-26T18:09:35.810742, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2407c1de), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_AGE_SPAN_LETZTER Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@593b1514, com.bakdata.conquery.models.query.ColumnDescriptor@4548859f]) on dataset Dataset[label=null, name=DATE_DISTANCE_AGE_SPAN_LETZTER Test]
127.0.0.1 - - [26/Jan/2023:18:09:35 +0000] "GET /api/datasets/DATE_DISTANCE_AGE_SPAN_LETZTER%20Test/result/DATE_DISTANCE_AGE_SPAN_LETZTER$20Test.521291ca-c9af-463b-ab2e-f9d211859d55.csv?pretty=false HTTP/1.1" 200 119 "-" "Conquery (test client)" 21
INFO  [2023-01-26 18:09:35,849] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest DATE_DISTANCE_AGE_SPAN_LETZTER Test on 5 rows
INFO  [2023-01-26 18:09:35,849] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast DATE_DISTANCE_AGE_SPAN_LETZTER Test
INFO  [2023-01-26 18:09:35,850] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DATE_DISTANCE_AGE_SPAN_LETZTER Test, name=DATE_DISTANCE_AGE_SPAN_LETZTER Test]
INFO  [2023-01-26 18:09:35,850] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DATE_DISTANCE_AGE_SPAN_LETZTER Test, name=DATE_DISTANCE_AGE_SPAN_LETZTER Test]
INFO  [2023-01-26 18:09:35,850] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DATE_DISTANCE_AGE_SPAN_LETZTER Test_252fe670-3ff9-4033-99c3-0fff75e4141f
INFO  [2023-01-26 18:09:35,851] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DATE_DISTANCE_AGE_SPAN_LETZTER Test_382180bd-a566-40b4-af31-491d67be3733
INFO  [2023-01-26 18:09:35,911] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow DATE_DISTANCE_AGE_SPAN_LETZTER Test
INFO  [2023-01-26 18:09:35,911] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DATE_DISTANCE_AGE_SPAN_LETZTER Test_382180bd-a566-40b4-af31-491d67be3733
INFO  [2023-01-26 18:09:35,911] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DATE_DISTANCE_AGE_SPAN_LETZTER Test_252fe670-3ff9-4033-99c3-0fff75e4141f
INFO  [2023-01-26 18:09:35,912] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of DATE_DISTANCE_AGE_SPAN_LETZTER$20Test
INFO  [2023-01-26 18:09:35,912] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:36,088] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test DATE_DISTANCE_AGE_SPAN_LETZTER Test
INFO  [2023-01-26 18:09:36,088] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT Test
INFO  [2023-01-26 18:09:36,088] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:36,088] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:36,091] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT Test, name=DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT Test]
INFO  [2023-01-26 18:09:36,091] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT Test, name=DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT Test]
INFO  [2023-01-26 18:09:36,091] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:36,091] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:36,093] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test.worker_DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test_41d8eb77-8512-47eb-9ed4-c5483e16f740 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:36,093] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test.worker_DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test_41d8eb77-8512-47eb-9ed4-c5483e16f740 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:36,093] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:36,093] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test.worker_DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test_c992832f-35d8-43a2-8224-dfbcfd5873b8 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:36,093] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test.worker_DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test_c992832f-35d8-43a2-8224-dfbcfd5873b8 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:36,093] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:36,097] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:36,197] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:36,204] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:36,204] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test.table1
INFO  [2023-01-26 18:09:36,204] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test.table1
INFO  [2023-01-26 18:09:36,316] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:36,424] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:36,424] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:36,424] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 1.5 KiB in total
INFO  [2023-01-26 18:09:36,424] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT Test/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000455063sINFO  [2023-01-26 18:09:36,471] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=22, sum=26, min=1, average=1.181818, max=2}
INFO  [2023-01-26 18:09:36,471] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[letzter] with DateParser(super=Parser(lines=26, nullLines=2), subType=IntegerParser(super=Parser(lines=26, nullLines=2), minValue=14974, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@378d8fec)
INFO  [2023-01-26 18:09:36,471] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[erster] with DateParser(super=Parser(lines=26, nullLines=2), subType=IntegerParser(super=Parser(lines=26, nullLines=2), minValue=14610, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@502038dc)
INFO  [2023-01-26 18:09:36,471] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geburtsdatum] with DateParser(super=Parser(lines=26, nullLines=7), subType=IntegerParser(super=Parser(lines=26, nullLines=7), minValue=10592, maxValue=11323), dateReader=com.bakdata.conquery.util.DateReader@9aae079)
INFO  [2023-01-26 18:09:36,471] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[versichertenzeit] with DateRangeParser(super=Parser(lines=26, nullLines=2), minParser=DateParser(super=Parser(lines=24, nullLines=0), subType=IntegerParser(super=Parser(lines=24, nullLines=0), minValue=14610, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@32089ded), maxParser=DateParser(super=Parser(lines=24, nullLines=0), subType=IntegerParser(super=Parser(lines=24, nullLines=0), minValue=14974, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@4cbe8fd7), dateReader=com.bakdata.conquery.util.DateReader@485a5959, onlyQuarters=false, maxValue=16070, minValue=14610, anyOpen=false)
INFO  [2023-01-26 18:09:36,473] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:36,473] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:36,473] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:36,489] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test.table1
127.0.0.1 - - [26/Jan/2023:18:09:36 +0000] "POST /admin/datasets/DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT+Test%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:09:36,490] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:36,490] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:36,490] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:36,490] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:36,492] com.bakdata.conquery.models.jobs.ImportJob: Start sending 8 Buckets
INFO  [2023-01-26 18:09:36,492] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test.table1.table1], containing 26 entries.
INFO  [2023-01-26 18:09:36,492] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test.table1.table1], containing 26 entries.
INFO  [2023-01-26 18:09:36,493] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test.table1.table1.0
INFO  [2023-01-26 18:09:36,493] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test.table1.table1.2
INFO  [2023-01-26 18:09:36,493] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test.table1.table1.1
WARN  [2023-01-26 18:09:36,493] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:36,494] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test.table1.table1.4
INFO  [2023-01-26 18:09:36,494] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test.table1.table1.3
INFO  [2023-01-26 18:09:36,494] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test.table1.table1.6
INFO  [2023-01-26 18:09:36,494] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test.table1.table1.5
INFO  [2023-01-26 18:09:36,494] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test.table1.table1.7
INFO  [2023-01-26 18:09:36,599] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:36,604] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:36,667] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:36,668] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:36,668] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:36,773] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT Test QUERY INIT
INFO  [2023-01-26 18:09:36,792] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:36,792] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[346e554c-4cc0-407f-a9b1-29c6663a8662] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT Test))]]
INFO  [2023-01-26 18:09:36,796] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test.346e554c-4cc0-407f-a9b1-29c6663a8662
INFO  [2023-01-26 18:09:36,796] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test.346e554c-4cc0-407f-a9b1-29c6663a8662
127.0.0.1 - - [26/Jan/2023:18:09:36 +0000] "POST /api/datasets/DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test/queries HTTP/1.1" 201 1469 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:09:36,858] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test.346e554c-4cc0-407f-a9b1-29c6663a8662] with 2 results within PT0.062109S
INFO  [2023-01-26 18:09:36,858] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test.346e554c-4cc0-407f-a9b1-29c6663a8662] with 6 results within PT0.062584S
INFO  [2023-01-26 18:09:36,858] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test.346e554c-4cc0-407f-a9b1-29c6663a8662, workerId=DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test.worker_DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test_41d8eb77-8512-47eb-9ed4-c5483e16f740, startTime=2023-01-26T18:09:36.796138, finishTime=2023-01-26T18:09:36.858247) of size 2
INFO  [2023-01-26 18:09:36,859] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test.346e554c-4cc0-407f-a9b1-29c6663a8662, workerId=DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test.worker_DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test_c992832f-35d8-43a2-8224-dfbcfd5873b8, startTime=2023-01-26T18:09:36.796172, finishTime=2023-01-26T18:09:36.858756) of size 6
INFO  [2023-01-26 18:09:36,859] com.bakdata.conquery.models.execution.ManagedExecution: DONE 346e554c-4cc0-407f-a9b1-29c6663a8662 ManagedQuery within PT0.067051S
127.0.0.1 - - [26/Jan/2023:18:09:36 +0000] "GET /api/datasets/DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test/queries/DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test.346e554c-4cc0-407f-a9b1-29c6663a8662 HTTP/1.1" 200 1845 "-" "Conquery (test client)" 57
INFO  [2023-01-26 18:09:36,915] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT Test], queryId=346e554c-4cc0-407f-a9b1-29c6663a8662, label=Alter	@§$, creationTime=2023-01-26T18:09:36.792412, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@43336a6[Count = 0], startTime=2023-01-26T18:09:36.792591, finishTime=2023-01-26T18:09:36.859642, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@7e16c498), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=8, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@56d6ace6, com.bakdata.conquery.models.query.ColumnDescriptor@7fdc0303]) download on dataset Dataset[label=null, name=DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:36,915] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT Test], queryId=346e554c-4cc0-407f-a9b1-29c6663a8662, label=Alter	@§$, creationTime=2023-01-26T18:09:36.792412, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@43336a6[Count = 0], startTime=2023-01-26T18:09:36.792591, finishTime=2023-01-26T18:09:36.859642, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@7e16c498), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=8, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@56d6ace6, com.bakdata.conquery.models.query.ColumnDescriptor@7fdc0303]) on dataset Dataset[label=null, name=DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT Test]
127.0.0.1 - - [26/Jan/2023:18:09:36 +0000] "GET /api/datasets/DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT%20Test/result/DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test.346e554c-4cc0-407f-a9b1-29c6663a8662.csv?pretty=false HTTP/1.1" 200 225 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:09:36,917] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT Test on 9 rows
INFO  [2023-01-26 18:09:36,917] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT Test
INFO  [2023-01-26 18:09:36,917] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT Test, name=DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT Test]
INFO  [2023-01-26 18:09:36,917] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT Test, name=DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT Test]
INFO  [2023-01-26 18:09:36,918] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT Test_41d8eb77-8512-47eb-9ed4-c5483e16f740
INFO  [2023-01-26 18:09:36,918] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT Test_c992832f-35d8-43a2-8224-dfbcfd5873b8
INFO  [2023-01-26 18:09:37,007] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT Test_c992832f-35d8-43a2-8224-dfbcfd5873b8
INFO  [2023-01-26 18:09:37,007] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT Test_41d8eb77-8512-47eb-9ed4-c5483e16f740
INFO  [2023-01-26 18:09:37,007] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT Test
INFO  [2023-01-26 18:09:37,107] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT$20Test
INFO  [2023-01-26 18:09:37,107] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:37,211] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test DATE_DISTANCE_AGE_SPAN_VERSICHERTENZEIT Test
INFO  [2023-01-26 18:09:37,212] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test DATE_DISTANCE_NEGATION_ERSTER Test
INFO  [2023-01-26 18:09:37,212] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:37,212] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:37,213] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DATE_DISTANCE_NEGATION_ERSTER Test, name=DATE_DISTANCE_NEGATION_ERSTER Test]
INFO  [2023-01-26 18:09:37,213] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DATE_DISTANCE_NEGATION_ERSTER Test, name=DATE_DISTANCE_NEGATION_ERSTER Test]
INFO  [2023-01-26 18:09:37,213] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:37,213] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:37,217] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DATE_DISTANCE_NEGATION_ERSTER$20Test.worker_DATE_DISTANCE_NEGATION_ERSTER$20Test_6adb2ab1-b132-4dfa-b724-1c6d4034f2b0 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:37,217] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DATE_DISTANCE_NEGATION_ERSTER$20Test.worker_DATE_DISTANCE_NEGATION_ERSTER$20Test_6adb2ab1-b132-4dfa-b724-1c6d4034f2b0 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:37,217] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:37,220] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DATE_DISTANCE_NEGATION_ERSTER$20Test.worker_DATE_DISTANCE_NEGATION_ERSTER$20Test_5e20e1f5-7160-4057-8a4d-67a11bd9d48b are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:37,220] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DATE_DISTANCE_NEGATION_ERSTER$20Test.worker_DATE_DISTANCE_NEGATION_ERSTER$20Test_5e20e1f5-7160-4057-8a4d-67a11bd9d48b are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:37,220] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:37,224] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:37,324] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:37,331] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:37,331] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DATE_DISTANCE_NEGATION_ERSTER$20Test.table1
INFO  [2023-01-26 18:09:37,331] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DATE_DISTANCE_NEGATION_ERSTER$20Test.table1
INFO  [2023-01-26 18:09:37,455] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:37,565] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:37,565] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:37,565] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 1.5 KiB in total
INFO  [2023-01-26 18:09:37,565] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_NEGATION_ERSTER Test/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000206715sINFO  [2023-01-26 18:09:37,586] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=22, sum=26, min=1, average=1.181818, max=2}
INFO  [2023-01-26 18:09:37,586] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[letzter] with DateParser(super=Parser(lines=26, nullLines=2), subType=IntegerParser(super=Parser(lines=26, nullLines=2), minValue=14974, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@4699b215)
INFO  [2023-01-26 18:09:37,586] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[erster] with DateParser(super=Parser(lines=26, nullLines=2), subType=IntegerParser(super=Parser(lines=26, nullLines=2), minValue=14610, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@3a43a57f)
INFO  [2023-01-26 18:09:37,586] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geburtsdatum] with DateParser(super=Parser(lines=26, nullLines=7), subType=IntegerParser(super=Parser(lines=26, nullLines=7), minValue=10592, maxValue=11323), dateReader=com.bakdata.conquery.util.DateReader@7022fc5c)
INFO  [2023-01-26 18:09:37,586] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[versichertenzeit] with DateRangeParser(super=Parser(lines=26, nullLines=2), minParser=DateParser(super=Parser(lines=24, nullLines=0), subType=IntegerParser(super=Parser(lines=24, nullLines=0), minValue=14610, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@492bf7d5), maxParser=DateParser(super=Parser(lines=24, nullLines=0), subType=IntegerParser(super=Parser(lines=24, nullLines=0), minValue=14974, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@5cd65a14), dateReader=com.bakdata.conquery.util.DateReader@7c04f584, onlyQuarters=false, maxValue=16070, minValue=14610, anyOpen=false)
INFO  [2023-01-26 18:09:37,588] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_NEGATION_ERSTER Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:37,588] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:37,588] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_NEGATION_ERSTER Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:37,601] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into DATE_DISTANCE_NEGATION_ERSTER$20Test.table1
INFO  [2023-01-26 18:09:37,602] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:09:37 +0000] "POST /admin/datasets/DATE_DISTANCE_NEGATION_ERSTER%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_DATE_DISTANCE_NEGATION_ERSTER+Test%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:09:37,602] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:37,602] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:37,602] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:37,604] com.bakdata.conquery.models.jobs.ImportJob: Start sending 8 Buckets
INFO  [2023-01-26 18:09:37,604] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DATE_DISTANCE_NEGATION_ERSTER$20Test.table1.table1], containing 26 entries.
INFO  [2023-01-26 18:09:37,604] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DATE_DISTANCE_NEGATION_ERSTER$20Test.table1.table1], containing 26 entries.
INFO  [2023-01-26 18:09:37,605] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_NEGATION_ERSTER$20Test.table1.table1.0
INFO  [2023-01-26 18:09:37,605] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_NEGATION_ERSTER$20Test.table1.table1.1
WARN  [2023-01-26 18:09:37,605] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:37,605] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_NEGATION_ERSTER$20Test.table1.table1.4
INFO  [2023-01-26 18:09:37,605] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_NEGATION_ERSTER$20Test.table1.table1.2
INFO  [2023-01-26 18:09:37,605] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_NEGATION_ERSTER$20Test.table1.table1.6
INFO  [2023-01-26 18:09:37,605] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_NEGATION_ERSTER$20Test.table1.table1.3
INFO  [2023-01-26 18:09:37,605] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_NEGATION_ERSTER$20Test.table1.table1.5
INFO  [2023-01-26 18:09:37,605] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_NEGATION_ERSTER$20Test.table1.table1.7
INFO  [2023-01-26 18:09:37,710] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:37,716] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:37,726] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:37,727] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:37,727] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:37,832] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: DATE_DISTANCE_NEGATION_ERSTER Test QUERY INIT
INFO  [2023-01-26 18:09:37,844] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[DATE_DISTANCE_NEGATION_ERSTER$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:37,845] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[616fd928-6e6c-44b0-a82c-8d77d60e577b] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_NEGATION_ERSTER Test))]]
INFO  [2023-01-26 18:09:37,848] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DATE_DISTANCE_NEGATION_ERSTER$20Test.616fd928-6e6c-44b0-a82c-8d77d60e577b
INFO  [2023-01-26 18:09:37,848] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DATE_DISTANCE_NEGATION_ERSTER$20Test.616fd928-6e6c-44b0-a82c-8d77d60e577b
127.0.0.1 - - [26/Jan/2023:18:09:37 +0000] "POST /api/datasets/DATE_DISTANCE_NEGATION_ERSTER$20Test/queries HTTP/1.1" 201 1470 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:09:37,855] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DATE_DISTANCE_NEGATION_ERSTER$20Test.616fd928-6e6c-44b0-a82c-8d77d60e577b] with 10 results within PT0.006683S
INFO  [2023-01-26 18:09:37,855] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DATE_DISTANCE_NEGATION_ERSTER$20Test.616fd928-6e6c-44b0-a82c-8d77d60e577b] with 10 results within PT0.006785S
INFO  [2023-01-26 18:09:37,856] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DATE_DISTANCE_NEGATION_ERSTER$20Test.616fd928-6e6c-44b0-a82c-8d77d60e577b, workerId=DATE_DISTANCE_NEGATION_ERSTER$20Test.worker_DATE_DISTANCE_NEGATION_ERSTER$20Test_6adb2ab1-b132-4dfa-b724-1c6d4034f2b0, startTime=2023-01-26T18:09:37.848949, finishTime=2023-01-26T18:09:37.855734) of size 10
INFO  [2023-01-26 18:09:37,856] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DATE_DISTANCE_NEGATION_ERSTER$20Test.616fd928-6e6c-44b0-a82c-8d77d60e577b, workerId=DATE_DISTANCE_NEGATION_ERSTER$20Test.worker_DATE_DISTANCE_NEGATION_ERSTER$20Test_5e20e1f5-7160-4057-8a4d-67a11bd9d48b, startTime=2023-01-26T18:09:37.848981, finishTime=2023-01-26T18:09:37.855664) of size 10
INFO  [2023-01-26 18:09:37,856] com.bakdata.conquery.models.execution.ManagedExecution: DONE 616fd928-6e6c-44b0-a82c-8d77d60e577b ManagedQuery within PT0.011102S
127.0.0.1 - - [26/Jan/2023:18:09:37 +0000] "GET /api/datasets/DATE_DISTANCE_NEGATION_ERSTER$20Test/queries/DATE_DISTANCE_NEGATION_ERSTER$20Test.616fd928-6e6c-44b0-a82c-8d77d60e577b HTTP/1.1" 200 1807 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:09:37,873] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DATE_DISTANCE_NEGATION_ERSTER Test], queryId=616fd928-6e6c-44b0-a82c-8d77d60e577b, label=Alter	@§$, creationTime=2023-01-26T18:09:37.845094, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@12db9b48[Count = 0], startTime=2023-01-26T18:09:37.845286, finishTime=2023-01-26T18:09:37.856388, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2bfec4), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_NEGATION_ERSTER Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=20, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@c728aad, com.bakdata.conquery.models.query.ColumnDescriptor@464bd0a7]) download on dataset Dataset[label=null, name=DATE_DISTANCE_NEGATION_ERSTER Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:37,873] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DATE_DISTANCE_NEGATION_ERSTER Test], queryId=616fd928-6e6c-44b0-a82c-8d77d60e577b, label=Alter	@§$, creationTime=2023-01-26T18:09:37.845094, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@12db9b48[Count = 0], startTime=2023-01-26T18:09:37.845286, finishTime=2023-01-26T18:09:37.856388, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2bfec4), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_NEGATION_ERSTER Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=20, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@c728aad, com.bakdata.conquery.models.query.ColumnDescriptor@464bd0a7]) on dataset Dataset[label=null, name=DATE_DISTANCE_NEGATION_ERSTER Test]
127.0.0.1 - - [26/Jan/2023:18:09:37 +0000] "GET /api/datasets/DATE_DISTANCE_NEGATION_ERSTER%20Test/result/DATE_DISTANCE_NEGATION_ERSTER$20Test.616fd928-6e6c-44b0-a82c-8d77d60e577b.csv?pretty=false HTTP/1.1" 200 130 "-" "Conquery (test client)" 25
INFO  [2023-01-26 18:09:37,897] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest DATE_DISTANCE_NEGATION_ERSTER Test on 21 rows
INFO  [2023-01-26 18:09:37,898] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast DATE_DISTANCE_NEGATION_ERSTER Test
INFO  [2023-01-26 18:09:37,898] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DATE_DISTANCE_NEGATION_ERSTER Test, name=DATE_DISTANCE_NEGATION_ERSTER Test]
INFO  [2023-01-26 18:09:37,898] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DATE_DISTANCE_NEGATION_ERSTER Test, name=DATE_DISTANCE_NEGATION_ERSTER Test]
INFO  [2023-01-26 18:09:37,898] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DATE_DISTANCE_NEGATION_ERSTER Test_5e20e1f5-7160-4057-8a4d-67a11bd9d48b
INFO  [2023-01-26 18:09:37,898] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DATE_DISTANCE_NEGATION_ERSTER Test_6adb2ab1-b132-4dfa-b724-1c6d4034f2b0
INFO  [2023-01-26 18:09:37,913] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow DATE_DISTANCE_NEGATION_ERSTER Test
INFO  [2023-01-26 18:09:37,916] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DATE_DISTANCE_NEGATION_ERSTER Test_6adb2ab1-b132-4dfa-b724-1c6d4034f2b0
INFO  [2023-01-26 18:09:37,920] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DATE_DISTANCE_NEGATION_ERSTER Test_5e20e1f5-7160-4057-8a4d-67a11bd9d48b
INFO  [2023-01-26 18:09:38,005] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of DATE_DISTANCE_NEGATION_ERSTER$20Test
INFO  [2023-01-26 18:09:38,005] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:38,032] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test DATE_DISTANCE_NEGATION_ERSTER Test
INFO  [2023-01-26 18:09:38,032] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test DATE_DISTANCE_NEGATION_LETZTER Test
INFO  [2023-01-26 18:09:38,032] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:38,032] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:38,035] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DATE_DISTANCE_NEGATION_LETZTER Test, name=DATE_DISTANCE_NEGATION_LETZTER Test]
INFO  [2023-01-26 18:09:38,036] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DATE_DISTANCE_NEGATION_LETZTER Test, name=DATE_DISTANCE_NEGATION_LETZTER Test]
INFO  [2023-01-26 18:09:38,036] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:38,036] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:38,037] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DATE_DISTANCE_NEGATION_LETZTER$20Test.worker_DATE_DISTANCE_NEGATION_LETZTER$20Test_765c82e0-940a-4dd1-ab3d-9b51f5625c9d are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:38,037] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DATE_DISTANCE_NEGATION_LETZTER$20Test.worker_DATE_DISTANCE_NEGATION_LETZTER$20Test_765c82e0-940a-4dd1-ab3d-9b51f5625c9d are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:38,037] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:38,038] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DATE_DISTANCE_NEGATION_LETZTER$20Test.worker_DATE_DISTANCE_NEGATION_LETZTER$20Test_58d1ef89-c528-4489-b669-7e6b0efa8987 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:38,038] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DATE_DISTANCE_NEGATION_LETZTER$20Test.worker_DATE_DISTANCE_NEGATION_LETZTER$20Test_58d1ef89-c528-4489-b669-7e6b0efa8987 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:38,038] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:38,042] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:38,142] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:38,149] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:38,150] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DATE_DISTANCE_NEGATION_LETZTER$20Test.table1
INFO  [2023-01-26 18:09:38,150] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DATE_DISTANCE_NEGATION_LETZTER$20Test.table1
INFO  [2023-01-26 18:09:38,261] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:38,371] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:38,371] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:38,371] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 1.5 KiB in total
INFO  [2023-01-26 18:09:38,371] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_NEGATION_LETZTER Test/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000303117sINFO  [2023-01-26 18:09:38,402] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=22, sum=26, min=1, average=1.181818, max=2}
INFO  [2023-01-26 18:09:38,402] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[letzter] with DateParser(super=Parser(lines=26, nullLines=2), subType=IntegerParser(super=Parser(lines=26, nullLines=2), minValue=14974, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@3119ecd5)
INFO  [2023-01-26 18:09:38,402] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[erster] with DateParser(super=Parser(lines=26, nullLines=2), subType=IntegerParser(super=Parser(lines=26, nullLines=2), minValue=14610, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@2db3c400)
INFO  [2023-01-26 18:09:38,402] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geburtsdatum] with DateParser(super=Parser(lines=26, nullLines=7), subType=IntegerParser(super=Parser(lines=26, nullLines=7), minValue=10592, maxValue=11323), dateReader=com.bakdata.conquery.util.DateReader@4cd2a02f)
INFO  [2023-01-26 18:09:38,402] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[versichertenzeit] with DateRangeParser(super=Parser(lines=26, nullLines=2), minParser=DateParser(super=Parser(lines=24, nullLines=0), subType=IntegerParser(super=Parser(lines=24, nullLines=0), minValue=14610, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@6633ceb1), maxParser=DateParser(super=Parser(lines=24, nullLines=0), subType=IntegerParser(super=Parser(lines=24, nullLines=0), minValue=14974, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@d9964ad), dateReader=com.bakdata.conquery.util.DateReader@53eee44f, onlyQuarters=false, maxValue=16070, minValue=14610, anyOpen=false)
INFO  [2023-01-26 18:09:38,405] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_NEGATION_LETZTER Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:38,405] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:38,405] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_NEGATION_LETZTER Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:38,421] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into DATE_DISTANCE_NEGATION_LETZTER$20Test.table1
127.0.0.1 - - [26/Jan/2023:18:09:38 +0000] "POST /admin/datasets/DATE_DISTANCE_NEGATION_LETZTER%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_DATE_DISTANCE_NEGATION_LETZTER+Test%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:09:38,421] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:38,422] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:38,422] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:38,422] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:38,423] com.bakdata.conquery.models.jobs.ImportJob: Start sending 8 Buckets
INFO  [2023-01-26 18:09:38,423] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DATE_DISTANCE_NEGATION_LETZTER$20Test.table1.table1], containing 26 entries.
INFO  [2023-01-26 18:09:38,423] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DATE_DISTANCE_NEGATION_LETZTER$20Test.table1.table1], containing 26 entries.
INFO  [2023-01-26 18:09:38,424] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_NEGATION_LETZTER$20Test.table1.table1.0
INFO  [2023-01-26 18:09:38,425] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_NEGATION_LETZTER$20Test.table1.table1.1
INFO  [2023-01-26 18:09:38,425] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_NEGATION_LETZTER$20Test.table1.table1.2
INFO  [2023-01-26 18:09:38,425] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_NEGATION_LETZTER$20Test.table1.table1.4
WARN  [2023-01-26 18:09:38,425] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:38,425] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_NEGATION_LETZTER$20Test.table1.table1.3
INFO  [2023-01-26 18:09:38,425] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_NEGATION_LETZTER$20Test.table1.table1.5
INFO  [2023-01-26 18:09:38,425] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_NEGATION_LETZTER$20Test.table1.table1.7
INFO  [2023-01-26 18:09:38,468] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_NEGATION_LETZTER$20Test.table1.table1.6
INFO  [2023-01-26 18:09:38,573] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:38,578] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:38,589] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:38,590] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:38,590] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:38,709] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: DATE_DISTANCE_NEGATION_LETZTER Test QUERY INIT
INFO  [2023-01-26 18:09:38,719] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[DATE_DISTANCE_NEGATION_LETZTER$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:38,719] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[9803ca83-461e-46ca-af9a-bf7201b40a68] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_NEGATION_LETZTER Test))]]
INFO  [2023-01-26 18:09:38,722] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DATE_DISTANCE_NEGATION_LETZTER$20Test.9803ca83-461e-46ca-af9a-bf7201b40a68
INFO  [2023-01-26 18:09:38,722] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DATE_DISTANCE_NEGATION_LETZTER$20Test.9803ca83-461e-46ca-af9a-bf7201b40a68
127.0.0.1 - - [26/Jan/2023:18:09:38 +0000] "POST /api/datasets/DATE_DISTANCE_NEGATION_LETZTER$20Test/queries HTTP/1.1" 201 1474 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:09:38,733] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DATE_DISTANCE_NEGATION_LETZTER$20Test.9803ca83-461e-46ca-af9a-bf7201b40a68] with 10 results within PT0.010366S
INFO  [2023-01-26 18:09:38,734] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DATE_DISTANCE_NEGATION_LETZTER$20Test.9803ca83-461e-46ca-af9a-bf7201b40a68, workerId=DATE_DISTANCE_NEGATION_LETZTER$20Test.worker_DATE_DISTANCE_NEGATION_LETZTER$20Test_765c82e0-940a-4dd1-ab3d-9b51f5625c9d, startTime=2023-01-26T18:09:38.723010, finishTime=2023-01-26T18:09:38.733376) of size 10
INFO  [2023-01-26 18:09:38,743] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DATE_DISTANCE_NEGATION_LETZTER$20Test.9803ca83-461e-46ca-af9a-bf7201b40a68] with 10 results within PT0.020952S
INFO  [2023-01-26 18:09:38,744] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DATE_DISTANCE_NEGATION_LETZTER$20Test.9803ca83-461e-46ca-af9a-bf7201b40a68, workerId=DATE_DISTANCE_NEGATION_LETZTER$20Test.worker_DATE_DISTANCE_NEGATION_LETZTER$20Test_58d1ef89-c528-4489-b669-7e6b0efa8987, startTime=2023-01-26T18:09:38.723027, finishTime=2023-01-26T18:09:38.743979) of size 10
INFO  [2023-01-26 18:09:38,744] com.bakdata.conquery.models.execution.ManagedExecution: DONE 9803ca83-461e-46ca-af9a-bf7201b40a68 ManagedQuery within PT0.024705S
127.0.0.1 - - [26/Jan/2023:18:09:38 +0000] "GET /api/datasets/DATE_DISTANCE_NEGATION_LETZTER$20Test/queries/DATE_DISTANCE_NEGATION_LETZTER$20Test.9803ca83-461e-46ca-af9a-bf7201b40a68 HTTP/1.1" 200 1815 "-" "Conquery (test client)" 13
INFO  [2023-01-26 18:09:38,756] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DATE_DISTANCE_NEGATION_LETZTER Test], queryId=9803ca83-461e-46ca-af9a-bf7201b40a68, label=Alter	@§$, creationTime=2023-01-26T18:09:38.719789, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@46f0a978[Count = 0], startTime=2023-01-26T18:09:38.719972, finishTime=2023-01-26T18:09:38.744677, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@4d2bb3d2), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_NEGATION_LETZTER Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=20, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@2c8385dc, com.bakdata.conquery.models.query.ColumnDescriptor@4dcc5d68]) download on dataset Dataset[label=null, name=DATE_DISTANCE_NEGATION_LETZTER Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:38,757] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DATE_DISTANCE_NEGATION_LETZTER Test], queryId=9803ca83-461e-46ca-af9a-bf7201b40a68, label=Alter	@§$, creationTime=2023-01-26T18:09:38.719789, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@46f0a978[Count = 0], startTime=2023-01-26T18:09:38.719972, finishTime=2023-01-26T18:09:38.744677, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@4d2bb3d2), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_NEGATION_LETZTER Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=20, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@2c8385dc, com.bakdata.conquery.models.query.ColumnDescriptor@4dcc5d68]) on dataset Dataset[label=null, name=DATE_DISTANCE_NEGATION_LETZTER Test]
127.0.0.1 - - [26/Jan/2023:18:09:38 +0000] "GET /api/datasets/DATE_DISTANCE_NEGATION_LETZTER%20Test/result/DATE_DISTANCE_NEGATION_LETZTER$20Test.9803ca83-461e-46ca-af9a-bf7201b40a68.csv?pretty=false HTTP/1.1" 200 130 "-" "Conquery (test client)" 22
INFO  [2023-01-26 18:09:38,777] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest DATE_DISTANCE_NEGATION_LETZTER Test on 21 rows
INFO  [2023-01-26 18:09:38,777] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast DATE_DISTANCE_NEGATION_LETZTER Test
INFO  [2023-01-26 18:09:38,777] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DATE_DISTANCE_NEGATION_LETZTER Test, name=DATE_DISTANCE_NEGATION_LETZTER Test]
INFO  [2023-01-26 18:09:38,777] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DATE_DISTANCE_NEGATION_LETZTER Test, name=DATE_DISTANCE_NEGATION_LETZTER Test]
INFO  [2023-01-26 18:09:38,778] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DATE_DISTANCE_NEGATION_LETZTER Test_765c82e0-940a-4dd1-ab3d-9b51f5625c9d
INFO  [2023-01-26 18:09:38,778] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DATE_DISTANCE_NEGATION_LETZTER Test_58d1ef89-c528-4489-b669-7e6b0efa8987
INFO  [2023-01-26 18:09:38,836] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow DATE_DISTANCE_NEGATION_LETZTER Test
INFO  [2023-01-26 18:09:38,837] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DATE_DISTANCE_NEGATION_LETZTER Test_765c82e0-940a-4dd1-ab3d-9b51f5625c9d
INFO  [2023-01-26 18:09:38,837] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DATE_DISTANCE_NEGATION_LETZTER Test_58d1ef89-c528-4489-b669-7e6b0efa8987
INFO  [2023-01-26 18:09:38,925] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of DATE_DISTANCE_NEGATION_LETZTER$20Test
INFO  [2023-01-26 18:09:38,925] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:39,010] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test DATE_DISTANCE_NEGATION_LETZTER Test
INFO  [2023-01-26 18:09:39,010] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test DATE_DISTANCE_NEGATION_VERSICHERTENZEIT Test
INFO  [2023-01-26 18:09:39,010] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:39,011] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:39,011] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DATE_DISTANCE_NEGATION_VERSICHERTENZEIT Test, name=DATE_DISTANCE_NEGATION_VERSICHERTENZEIT Test]
INFO  [2023-01-26 18:09:39,011] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DATE_DISTANCE_NEGATION_VERSICHERTENZEIT Test, name=DATE_DISTANCE_NEGATION_VERSICHERTENZEIT Test]
INFO  [2023-01-26 18:09:39,011] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:39,011] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:39,013] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test.worker_DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test_77881c58-aa00-49b0-aad1-be8093679f2f are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:39,013] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test.worker_DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test_77881c58-aa00-49b0-aad1-be8093679f2f are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:39,013] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:39,013] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test.worker_DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test_ac857b62-0c76-421e-839c-6a6b39c163e9 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:39,013] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test.worker_DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test_ac857b62-0c76-421e-839c-6a6b39c163e9 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:39,013] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:39,017] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:39,117] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:39,124] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:39,124] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test.table1
INFO  [2023-01-26 18:09:39,124] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test.table1
INFO  [2023-01-26 18:09:39,241] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:39,349] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:39,349] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:39,349] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 1.5 KiB in total
INFO  [2023-01-26 18:09:39,349] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_NEGATION_VERSICHERTENZEIT Test/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.00021111sINFO  [2023-01-26 18:09:39,371] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=22, sum=26, min=1, average=1.181818, max=2}
INFO  [2023-01-26 18:09:39,371] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[letzter] with DateParser(super=Parser(lines=26, nullLines=2), subType=IntegerParser(super=Parser(lines=26, nullLines=2), minValue=14974, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@7a01a499)
INFO  [2023-01-26 18:09:39,371] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geburtsdatum] with DateParser(super=Parser(lines=26, nullLines=7), subType=IntegerParser(super=Parser(lines=26, nullLines=7), minValue=10592, maxValue=11323), dateReader=com.bakdata.conquery.util.DateReader@742a4e55)
INFO  [2023-01-26 18:09:39,371] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[erster] with DateParser(super=Parser(lines=26, nullLines=2), subType=IntegerParser(super=Parser(lines=26, nullLines=2), minValue=14610, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@34492272)
INFO  [2023-01-26 18:09:39,371] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[versichertenzeit] with DateRangeParser(super=Parser(lines=26, nullLines=2), minParser=DateParser(super=Parser(lines=24, nullLines=0), subType=IntegerParser(super=Parser(lines=24, nullLines=0), minValue=14610, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@3b300b3c), maxParser=DateParser(super=Parser(lines=24, nullLines=0), subType=IntegerParser(super=Parser(lines=24, nullLines=0), minValue=14974, maxValue=16070), dateReader=com.bakdata.conquery.util.DateReader@55d8f0b4), dateReader=com.bakdata.conquery.util.DateReader@e2b975e, onlyQuarters=false, maxValue=16070, minValue=14610, anyOpen=false)
INFO  [2023-01-26 18:09:39,373] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_NEGATION_VERSICHERTENZEIT Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:39,373] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:39,373] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_NEGATION_VERSICHERTENZEIT Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:39,389] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test.table1
127.0.0.1 - - [26/Jan/2023:18:09:39 +0000] "POST /admin/datasets/DATE_DISTANCE_NEGATION_VERSICHERTENZEIT%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_DATE_DISTANCE_NEGATION_VERSICHERTENZEIT+Test%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:09:39,389] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:39,389] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:39,390] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:39,390] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:39,391] com.bakdata.conquery.models.jobs.ImportJob: Start sending 8 Buckets
INFO  [2023-01-26 18:09:39,391] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test.table1.table1], containing 26 entries.
INFO  [2023-01-26 18:09:39,391] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test.table1.table1], containing 26 entries.
INFO  [2023-01-26 18:09:39,392] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test.table1.table1.0
INFO  [2023-01-26 18:09:39,392] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test.table1.table1.2
WARN  [2023-01-26 18:09:39,392] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:39,392] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test.table1.table1.1
INFO  [2023-01-26 18:09:39,392] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test.table1.table1.4
INFO  [2023-01-26 18:09:39,392] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test.table1.table1.3
INFO  [2023-01-26 18:09:39,392] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test.table1.table1.6
INFO  [2023-01-26 18:09:39,392] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test.table1.table1.5
INFO  [2023-01-26 18:09:39,392] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test.table1.table1.7
INFO  [2023-01-26 18:09:39,498] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:39,503] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:39,514] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:39,514] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:39,514] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:39,645] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: DATE_DISTANCE_NEGATION_VERSICHERTENZEIT Test QUERY INIT
INFO  [2023-01-26 18:09:39,656] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:39,656] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[b153460f-36b5-46cf-9f39-20b2f8815fb9] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_NEGATION_VERSICHERTENZEIT Test))]]
INFO  [2023-01-26 18:09:39,660] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test.b153460f-36b5-46cf-9f39-20b2f8815fb9
INFO  [2023-01-26 18:09:39,660] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test.b153460f-36b5-46cf-9f39-20b2f8815fb9
127.0.0.1 - - [26/Jan/2023:18:09:39 +0000] "POST /api/datasets/DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test/queries HTTP/1.1" 201 1510 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:09:39,664] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test.b153460f-36b5-46cf-9f39-20b2f8815fb9] with 10 results within PT0.00356S
INFO  [2023-01-26 18:09:39,664] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test.b153460f-36b5-46cf-9f39-20b2f8815fb9, workerId=DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test.worker_DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test_77881c58-aa00-49b0-aad1-be8093679f2f, startTime=2023-01-26T18:09:39.660702, finishTime=2023-01-26T18:09:39.664262) of size 10
INFO  [2023-01-26 18:09:39,666] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test.b153460f-36b5-46cf-9f39-20b2f8815fb9] with 8 results within PT0.005115S
INFO  [2023-01-26 18:09:39,666] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test.b153460f-36b5-46cf-9f39-20b2f8815fb9, workerId=DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test.worker_DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test_ac857b62-0c76-421e-839c-6a6b39c163e9, startTime=2023-01-26T18:09:39.660903, finishTime=2023-01-26T18:09:39.666018) of size 8
INFO  [2023-01-26 18:09:39,666] com.bakdata.conquery.models.execution.ManagedExecution: DONE b153460f-36b5-46cf-9f39-20b2f8815fb9 ManagedQuery within PT0.009559S
127.0.0.1 - - [26/Jan/2023:18:09:39 +0000] "GET /api/datasets/DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test/queries/DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test.b153460f-36b5-46cf-9f39-20b2f8815fb9 HTTP/1.1" 200 1886 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:09:39,683] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DATE_DISTANCE_NEGATION_VERSICHERTENZEIT Test], queryId=b153460f-36b5-46cf-9f39-20b2f8815fb9, label=Alter	@§$, creationTime=2023-01-26T18:09:39.656822, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@5e717b85[Count = 0], startTime=2023-01-26T18:09:39.656988, finishTime=2023-01-26T18:09:39.666547, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@4f496906), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_NEGATION_VERSICHERTENZEIT Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=18, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@4cc93e98, com.bakdata.conquery.models.query.ColumnDescriptor@1cd9d338]) download on dataset Dataset[label=null, name=DATE_DISTANCE_NEGATION_VERSICHERTENZEIT Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:39,683] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DATE_DISTANCE_NEGATION_VERSICHERTENZEIT Test], queryId=b153460f-36b5-46cf-9f39-20b2f8815fb9, label=Alter	@§$, creationTime=2023-01-26T18:09:39.656822, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@5e717b85[Count = 0], startTime=2023-01-26T18:09:39.656988, finishTime=2023-01-26T18:09:39.666547, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@4f496906), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_NEGATION_VERSICHERTENZEIT Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=18, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@4cc93e98, com.bakdata.conquery.models.query.ColumnDescriptor@1cd9d338]) on dataset Dataset[label=null, name=DATE_DISTANCE_NEGATION_VERSICHERTENZEIT Test]
127.0.0.1 - - [26/Jan/2023:18:09:39 +0000] "GET /api/datasets/DATE_DISTANCE_NEGATION_VERSICHERTENZEIT%20Test/result/DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test.b153460f-36b5-46cf-9f39-20b2f8815fb9.csv?pretty=false HTTP/1.1" 200 120 "-" "Conquery (test client)" 20
INFO  [2023-01-26 18:09:39,701] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest DATE_DISTANCE_NEGATION_VERSICHERTENZEIT Test on 19 rows
INFO  [2023-01-26 18:09:39,702] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast DATE_DISTANCE_NEGATION_VERSICHERTENZEIT Test
INFO  [2023-01-26 18:09:39,702] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DATE_DISTANCE_NEGATION_VERSICHERTENZEIT Test, name=DATE_DISTANCE_NEGATION_VERSICHERTENZEIT Test]
INFO  [2023-01-26 18:09:39,702] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DATE_DISTANCE_NEGATION_VERSICHERTENZEIT Test, name=DATE_DISTANCE_NEGATION_VERSICHERTENZEIT Test]
INFO  [2023-01-26 18:09:39,702] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DATE_DISTANCE_NEGATION_VERSICHERTENZEIT Test_77881c58-aa00-49b0-aad1-be8093679f2f
INFO  [2023-01-26 18:09:39,702] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DATE_DISTANCE_NEGATION_VERSICHERTENZEIT Test_ac857b62-0c76-421e-839c-6a6b39c163e9
INFO  [2023-01-26 18:09:39,711] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow DATE_DISTANCE_NEGATION_VERSICHERTENZEIT Test
INFO  [2023-01-26 18:09:39,712] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DATE_DISTANCE_NEGATION_VERSICHERTENZEIT Test_77881c58-aa00-49b0-aad1-be8093679f2f
INFO  [2023-01-26 18:09:39,712] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DATE_DISTANCE_NEGATION_VERSICHERTENZEIT Test_ac857b62-0c76-421e-839c-6a6b39c163e9
INFO  [2023-01-26 18:09:39,799] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of DATE_DISTANCE_NEGATION_VERSICHERTENZEIT$20Test
INFO  [2023-01-26 18:09:39,800] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:39,820] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test DATE_DISTANCE_NEGATION_VERSICHERTENZEIT Test
INFO  [2023-01-26 18:09:39,820] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test DELETE_IMPORT_TESTS Test
INFO  [2023-01-26 18:09:39,820] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:39,820] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:39,821] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DELETE_IMPORT_TESTS Test, name=DELETE_IMPORT_TESTS Test]
INFO  [2023-01-26 18:09:39,821] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DELETE_IMPORT_TESTS Test, name=DELETE_IMPORT_TESTS Test]
INFO  [2023-01-26 18:09:39,821] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:39,821] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:39,835] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DELETE_IMPORT_TESTS$20Test.worker_DELETE_IMPORT_TESTS$20Test_6de82c7e-9c51-44e3-9845-325f08f8b479 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:39,835] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DELETE_IMPORT_TESTS$20Test.worker_DELETE_IMPORT_TESTS$20Test_6de82c7e-9c51-44e3-9845-325f08f8b479 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:39,835] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:39,835] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DELETE_IMPORT_TESTS$20Test.worker_DELETE_IMPORT_TESTS$20Test_3eaaf774-6162-4e7e-8df0-14fa0a336773 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:39,835] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DELETE_IMPORT_TESTS$20Test.worker_DELETE_IMPORT_TESTS$20Test_3eaaf774-6162-4e7e-8df0-14fa0a336773 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:39,835] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:39,837] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:39,939] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:39,945] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:39,946] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DELETE_IMPORT_TESTS$20Test.test_table
INFO  [2023-01-26 18:09:39,946] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DELETE_IMPORT_TESTS$20Test.test_table
INFO  [2023-01-26 18:09:39,987] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DELETE_IMPORT_TESTS$20Test.test_table2
INFO  [2023-01-26 18:09:39,988] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DELETE_IMPORT_TESTS$20Test.test_table2
INFO  [2023-01-26 18:09:40,106] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:40,216] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:40,216] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:40,216] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:40,216] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 115 B in total
INFO  [2023-01-26 18:09:40,216] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DELETE_IMPORT_TESTS Test/test_table.import.json, tag=Optional.empty)
█████████████████████████                         ▌  50%	est. time remaining: 0.024016612sINFO  [2023-01-26 18:09:40,240] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=2, sum=2, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:40,240] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=2, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:40,240] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=2, nullLines=0), subType=IntegerParser(super=Parser(lines=2, nullLines=0), minValue=15655, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@3d0bd15f)
INFO  [2023-01-26 18:09:40,243] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DELETE_IMPORT_TESTS Test/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:40,243] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DELETE_IMPORT_TESTS Test/test_table2.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000471683sINFO  [2023-01-26 18:09:40,264] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=2, sum=2, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:40,264] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=2, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:40,264] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=2, nullLines=0), subType=IntegerParser(super=Parser(lines=2, nullLines=0), minValue=14805, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@6d95429)
INFO  [2023-01-26 18:09:40,266] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DELETE_IMPORT_TESTS Test/test_table2.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:40,267] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 2 Jobs:
INFO  [2023-01-26 18:09:40,267] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DELETE_IMPORT_TESTS Test/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:40,267] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DELETE_IMPORT_TESTS Test/test_table2.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:40,282] com.bakdata.conquery.models.jobs.ImportJob: Importing test_table into DELETE_IMPORT_TESTS$20Test.test_table
127.0.0.1 - - [26/Jan/2023:18:09:40 +0000] "POST /admin/datasets/DELETE_IMPORT_TESTS%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_DELETE_IMPORT_TESTS+Test%2Ftest_table.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:09:40,283] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:40,284] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:40,284] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:40,285] com.bakdata.conquery.models.jobs.ImportJob: Start sending 1 Buckets
INFO  [2023-01-26 18:09:40,285] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DELETE_IMPORT_TESTS$20Test.test_table.test_table], containing 2 entries.
INFO  [2023-01-26 18:09:40,285] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DELETE_IMPORT_TESTS$20Test.test_table.test_table], containing 2 entries.
WARN  [2023-01-26 18:09:40,286] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:40,286] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DELETE_IMPORT_TESTS$20Test.test_table.test_table.0
INFO  [2023-01-26 18:09:40,301] com.bakdata.conquery.models.jobs.ImportJob: Importing test_table2 into DELETE_IMPORT_TESTS$20Test.test_table2
INFO  [2023-01-26 18:09:40,301] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:40,302] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:40,302] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:40,302] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:09:40 +0000] "POST /admin/datasets/DELETE_IMPORT_TESTS%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_DELETE_IMPORT_TESTS+Test%2Ftest_table2.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 10
INFO  [2023-01-26 18:09:40,302] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:09:40,302] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DELETE_IMPORT_TESTS$20Test.test_table2.test_table2], containing 2 entries.
INFO  [2023-01-26 18:09:40,302] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DELETE_IMPORT_TESTS$20Test.test_table2.test_table2], containing 2 entries.
WARN  [2023-01-26 18:09:40,302] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:40,302] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DELETE_IMPORT_TESTS$20Test.test_table2.test_table2.0
INFO  [2023-01-26 18:09:40,302] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DELETE_IMPORT_TESTS$20Test.test_table2.test_table2.1
INFO  [2023-01-26 18:09:40,415] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:40,420] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:40,430] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:40,431] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:40,431] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:40,536] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: DELETE_IMPORT_TESTS Test QUERY INIT
INFO  [2023-01-26 18:09:40,546] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[DELETE_IMPORT_TESTS$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:40,547] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[8be5f6e5-ffa2-475e-b64f-2aaa95c860c7] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_DELETE_IMPORT_TESTS Test))]]
INFO  [2023-01-26 18:09:40,549] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DELETE_IMPORT_TESTS$20Test.8be5f6e5-ffa2-475e-b64f-2aaa95c860c7
INFO  [2023-01-26 18:09:40,549] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DELETE_IMPORT_TESTS$20Test.8be5f6e5-ffa2-475e-b64f-2aaa95c860c7
INFO  [2023-01-26 18:09:40,550] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DELETE_IMPORT_TESTS$20Test.8be5f6e5-ffa2-475e-b64f-2aaa95c860c7] with 0 results within PT0.000611S
INFO  [2023-01-26 18:09:40,550] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DELETE_IMPORT_TESTS$20Test.8be5f6e5-ffa2-475e-b64f-2aaa95c860c7] with 2 results within PT0.00088S
INFO  [2023-01-26 18:09:40,550] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DELETE_IMPORT_TESTS$20Test.8be5f6e5-ffa2-475e-b64f-2aaa95c860c7, workerId=DELETE_IMPORT_TESTS$20Test.worker_DELETE_IMPORT_TESTS$20Test_6de82c7e-9c51-44e3-9845-325f08f8b479, startTime=2023-01-26T18:09:40.549613, finishTime=2023-01-26T18:09:40.550224) of size 0
INFO  [2023-01-26 18:09:40,550] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DELETE_IMPORT_TESTS$20Test.8be5f6e5-ffa2-475e-b64f-2aaa95c860c7, workerId=DELETE_IMPORT_TESTS$20Test.worker_DELETE_IMPORT_TESTS$20Test_3eaaf774-6162-4e7e-8df0-14fa0a336773, startTime=2023-01-26T18:09:40.549600, finishTime=2023-01-26T18:09:40.550480) of size 2
127.0.0.1 - - [26/Jan/2023:18:09:40 +0000] "POST /api/datasets/DELETE_IMPORT_TESTS$20Test/queries HTTP/1.1" 201 1246 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:09:40,551] com.bakdata.conquery.models.execution.ManagedExecution: DONE 8be5f6e5-ffa2-475e-b64f-2aaa95c860c7 ManagedQuery within PT0.003996S
127.0.0.1 - - [26/Jan/2023:18:09:40 +0000] "GET /api/datasets/DELETE_IMPORT_TESTS$20Test/queries/DELETE_IMPORT_TESTS$20Test.8be5f6e5-ffa2-475e-b64f-2aaa95c860c7 HTTP/1.1" 200 1541 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:09:40,574] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DELETE_IMPORT_TESTS Test], queryId=8be5f6e5-ffa2-475e-b64f-2aaa95c860c7, label=test_tree---test_child1	@§$, creationTime=2023-01-26T18:09:40.546887, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@6354ac90[Count = 0], startTime=2023-01-26T18:09:40.547052, finishTime=2023-01-26T18:09:40.551048, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@5eab31f0), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DELETE_IMPORT_TESTS Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@5d4460b6, com.bakdata.conquery.models.query.ColumnDescriptor@3a2ed0b7]) download on dataset Dataset[label=null, name=DELETE_IMPORT_TESTS Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:40,574] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DELETE_IMPORT_TESTS Test], queryId=8be5f6e5-ffa2-475e-b64f-2aaa95c860c7, label=test_tree---test_child1	@§$, creationTime=2023-01-26T18:09:40.546887, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@6354ac90[Count = 0], startTime=2023-01-26T18:09:40.547052, finishTime=2023-01-26T18:09:40.551048, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@5eab31f0), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DELETE_IMPORT_TESTS Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@5d4460b6, com.bakdata.conquery.models.query.ColumnDescriptor@3a2ed0b7]) on dataset Dataset[label=null, name=DELETE_IMPORT_TESTS Test]
127.0.0.1 - - [26/Jan/2023:18:09:40 +0000] "GET /api/datasets/DELETE_IMPORT_TESTS%20Test/result/DELETE_IMPORT_TESTS$20Test.8be5f6e5-ffa2-475e-b64f-2aaa95c860c7.csv?pretty=false HTTP/1.1" 200 65 "-" "Conquery (test client)" 25
INFO  [2023-01-26 18:09:40,598] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest DELETE_IMPORT_TESTS Test on 3 rows
INFO  [2023-01-26 18:09:40,598] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast DELETE_IMPORT_TESTS Test
INFO  [2023-01-26 18:09:40,598] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DELETE_IMPORT_TESTS Test, name=DELETE_IMPORT_TESTS Test]
INFO  [2023-01-26 18:09:40,598] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DELETE_IMPORT_TESTS Test, name=DELETE_IMPORT_TESTS Test]
INFO  [2023-01-26 18:09:40,598] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DELETE_IMPORT_TESTS Test_6de82c7e-9c51-44e3-9845-325f08f8b479
INFO  [2023-01-26 18:09:40,598] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DELETE_IMPORT_TESTS Test_3eaaf774-6162-4e7e-8df0-14fa0a336773
INFO  [2023-01-26 18:09:40,621] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow DELETE_IMPORT_TESTS Test
INFO  [2023-01-26 18:09:40,637] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DELETE_IMPORT_TESTS Test_3eaaf774-6162-4e7e-8df0-14fa0a336773
INFO  [2023-01-26 18:09:40,637] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DELETE_IMPORT_TESTS Test_6de82c7e-9c51-44e3-9845-325f08f8b479
INFO  [2023-01-26 18:09:40,711] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of DELETE_IMPORT_TESTS$20Test
INFO  [2023-01-26 18:09:40,711] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:40,836] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test DELETE_IMPORT_TESTS Test
INFO  [2023-01-26 18:09:40,836] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY Test
INFO  [2023-01-26 18:09:40,836] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:40,836] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:40,837] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY Test, name=DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:09:40,837] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:40,838] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY Test, name=DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:09:40,838] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:40,839] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:40,839] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.worker_DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test_45e57da5-750e-4122-9f2e-3cd046035a4b are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:40,839] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.worker_DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test_45e57da5-750e-4122-9f2e-3cd046035a4b are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:40,839] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:40,839] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.worker_DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test_f6044544-4e9e-4005-a182-4ac3326395c5 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:40,839] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.worker_DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test_f6044544-4e9e-4005-a182-4ac3326395c5 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:40,839] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:40,943] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:40,950] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:40,950] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.table1
INFO  [2023-01-26 18:09:40,950] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.table1
INFO  [2023-01-26 18:09:41,062] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:41,170] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:41,170] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:41,171] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 221 B in total
INFO  [2023-01-26 18:09:41,171] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000189906sINFO  [2023-01-26 18:09:41,190] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=5, sum=5, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:41,190] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[ende] with DateParser(super=Parser(lines=5, nullLines=1), subType=IntegerParser(super=Parser(lines=5, nullLines=1), minValue=14608, maxValue=14644), dateReader=com.bakdata.conquery.util.DateReader@4b7dedf3)
INFO  [2023-01-26 18:09:41,190] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[anfang] with DateParser(super=Parser(lines=5, nullLines=1), subType=IntegerParser(super=Parser(lines=5, nullLines=1), minValue=14608, maxValue=14642), dateReader=com.bakdata.conquery.util.DateReader@14964916)
INFO  [2023-01-26 18:09:41,190] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=5, nullLines=1), minParser=DateParser(super=Parser(lines=4, nullLines=0), subType=IntegerParser(super=Parser(lines=4, nullLines=0), minValue=14608, maxValue=14642), dateReader=com.bakdata.conquery.util.DateReader@4c77340c), maxParser=DateParser(super=Parser(lines=4, nullLines=0), subType=IntegerParser(super=Parser(lines=4, nullLines=0), minValue=14608, maxValue=14644), dateReader=com.bakdata.conquery.util.DateReader@a0d9d23), dateReader=com.bakdata.conquery.util.DateReader@2e65ccb1, onlyQuarters=false, maxValue=14644, minValue=14608, anyOpen=false)
INFO  [2023-01-26 18:09:41,192] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:41,192] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:41,192] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:41,208] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.table1
127.0.0.1 - - [26/Jan/2023:18:09:41 +0000] "POST /admin/datasets/DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY+Test%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:09:41,208] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:41,209] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:41,209] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:41,209] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:41,212] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:09:41,212] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.table1.table1], containing 5 entries.
INFO  [2023-01-26 18:09:41,212] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.table1.table1], containing 5 entries.
WARN  [2023-01-26 18:09:41,213] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:41,213] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.table1.table1.0
INFO  [2023-01-26 18:09:41,214] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.table1.table1.1
INFO  [2023-01-26 18:09:41,319] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:41,324] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:41,336] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:41,336] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:41,336] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:41,448] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY Test QUERY INIT
INFO  [2023-01-26 18:09:41,458] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:41,458] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[4b69b334-ffb8-476d-9410-a49ff14a1390] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY Test))]]
INFO  [2023-01-26 18:09:41,461] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.4b69b334-ffb8-476d-9410-a49ff14a1390
INFO  [2023-01-26 18:09:41,461] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.4b69b334-ffb8-476d-9410-a49ff14a1390
INFO  [2023-01-26 18:09:41,462] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.4b69b334-ffb8-476d-9410-a49ff14a1390] with 0 results within PT0.000987S
INFO  [2023-01-26 18:09:41,462] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.4b69b334-ffb8-476d-9410-a49ff14a1390] with 2 results within PT0.001045S
INFO  [2023-01-26 18:09:41,462] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.4b69b334-ffb8-476d-9410-a49ff14a1390, workerId=DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.worker_DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test_45e57da5-750e-4122-9f2e-3cd046035a4b, startTime=2023-01-26T18:09:41.461435, finishTime=2023-01-26T18:09:41.462422) of size 0
INFO  [2023-01-26 18:09:41,462] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.4b69b334-ffb8-476d-9410-a49ff14a1390, workerId=DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.worker_DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test_f6044544-4e9e-4005-a182-4ac3326395c5, startTime=2023-01-26T18:09:41.461433, finishTime=2023-01-26T18:09:41.462478) of size 2
INFO  [2023-01-26 18:09:41,462] com.bakdata.conquery.models.execution.ManagedExecution: DONE 4b69b334-ffb8-476d-9410-a49ff14a1390 ManagedQuery within PT0.004157S
127.0.0.1 - - [26/Jan/2023:18:09:41 +0000] "POST /api/datasets/DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test/queries HTTP/1.1" 201 1482 "-" "Conquery (test client)" 6
127.0.0.1 - - [26/Jan/2023:18:09:41 +0000] "GET /api/datasets/DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test/queries/DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.4b69b334-ffb8-476d-9410-a49ff14a1390 HTTP/1.1" 200 1849 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:09:41,485] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY Test], queryId=4b69b334-ffb8-476d-9410-a49ff14a1390, label=KG-Tage-DURATION_SUM	@§$, creationTime=2023-01-26T18:09:41.458670, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@6e647652[Count = 0], startTime=2023-01-26T18:09:41.458807, finishTime=2023-01-26T18:09:41.462964, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@70a39edd), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@1b98d737, com.bakdata.conquery.models.query.ColumnDescriptor@48615005]) download on dataset Dataset[label=null, name=DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:41,485] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY Test], queryId=4b69b334-ffb8-476d-9410-a49ff14a1390, label=KG-Tage-DURATION_SUM	@§$, creationTime=2023-01-26T18:09:41.458670, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@6e647652[Count = 0], startTime=2023-01-26T18:09:41.458807, finishTime=2023-01-26T18:09:41.462964, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@70a39edd), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@1b98d737, com.bakdata.conquery.models.query.ColumnDescriptor@48615005]) on dataset Dataset[label=null, name=DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY Test]
127.0.0.1 - - [26/Jan/2023:18:09:41 +0000] "GET /api/datasets/DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY%20Test/result/DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.4b69b334-ffb8-476d-9410-a49ff14a1390.csv?pretty=false HTTP/1.1" 200 66 "-" "Conquery (test client)" 20
INFO  [2023-01-26 18:09:41,505] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY Test on 3 rows
INFO  [2023-01-26 18:09:41,505] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY Test
INFO  [2023-01-26 18:09:41,505] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY Test, name=DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:09:41,505] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY Test, name=DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:09:41,505] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY Test_45e57da5-750e-4122-9f2e-3cd046035a4b
INFO  [2023-01-26 18:09:41,505] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY Test_f6044544-4e9e-4005-a182-4ac3326395c5
INFO  [2023-01-26 18:09:41,544] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY Test_f6044544-4e9e-4005-a182-4ac3326395c5
INFO  [2023-01-26 18:09:41,544] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY Test
INFO  [2023-01-26 18:09:41,544] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY Test_45e57da5-750e-4122-9f2e-3cd046035a4b
INFO  [2023-01-26 18:09:41,615] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test
INFO  [2023-01-26 18:09:41,615] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:41,749] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test DURATION_SUM_EMPTY_DATE_CONCEPT_QUERY Test
INFO  [2023-01-26 18:09:41,750] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test AND Test
INFO  [2023-01-26 18:09:41,750] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:41,750] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:41,752] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=AND Test, name=AND Test]
INFO  [2023-01-26 18:09:41,752] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=AND Test, name=AND Test]
INFO  [2023-01-26 18:09:41,753] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:41,753] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:41,757] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker AND$20Test.worker_AND$20Test_14ce37f9-5cee-4a0f-82c4-aa8c31205344 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:41,757] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker AND$20Test.worker_AND$20Test_14ce37f9-5cee-4a0f-82c4-aa8c31205344 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:41,757] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:41,757] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker AND$20Test.worker_AND$20Test_121642c0-20be-4a30-b6b9-7fa9015f0427 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:41,757] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker AND$20Test.worker_AND$20Test_121642c0-20be-4a30-b6b9-7fa9015f0427 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:41,757] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:41,758] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:41,861] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:41,867] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:41,868] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table AND$20Test.table
INFO  [2023-01-26 18:09:41,868] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table AND$20Test.table
INFO  [2023-01-26 18:09:41,978] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:42,086] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:42,086] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:42,087] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 152 B in total
INFO  [2023-01-26 18:09:42,087] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000532255sINFO  [2023-01-26 18:09:42,141] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=8, min=1, average=2.000000, max=3}
INFO  [2023-01-26 18:09:42,141] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[column] with StringParser(super=Parser(lines=8, nullLines=1), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:42,141] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=8, nullLines=0), subType=IntegerParser(super=Parser(lines=8, nullLines=0), minValue=15340, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@53c231bd)
INFO  [2023-01-26 18:09:42,144] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:42,144] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:42,144] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:42,161] com.bakdata.conquery.models.jobs.ImportJob: Importing table into AND$20Test.table
127.0.0.1 - - [26/Jan/2023:18:09:42 +0000] "POST /admin/datasets/AND%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_AND+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:09:42,162] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:42,163] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:42,163] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:42,163] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:42,165] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:09:42,165] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[AND$20Test.table.table], containing 8 entries.
INFO  [2023-01-26 18:09:42,165] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[AND$20Test.table.table], containing 8 entries.
WARN  [2023-01-26 18:09:42,166] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:42,166] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received AND$20Test.table.table.0
INFO  [2023-01-26 18:09:42,166] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received AND$20Test.table.table.1
INFO  [2023-01-26 18:09:42,271] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:42,276] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:42,286] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:42,287] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:42,287] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:42,392] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: AND Test QUERY INIT
INFO  [2023-01-26 18:09:42,404] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[AND$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:42,404] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[5726afe5-4644-43ce-9f1f-3274d1953a79] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_AND Test))]]
INFO  [2023-01-26 18:09:42,408] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery AND$20Test.5726afe5-4644-43ce-9f1f-3274d1953a79
INFO  [2023-01-26 18:09:42,408] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery AND$20Test.5726afe5-4644-43ce-9f1f-3274d1953a79
INFO  [2023-01-26 18:09:42,409] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[AND$20Test.5726afe5-4644-43ce-9f1f-3274d1953a79] with 1 results within PT0.000784S
INFO  [2023-01-26 18:09:42,409] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[AND$20Test.5726afe5-4644-43ce-9f1f-3274d1953a79] with 1 results within PT0.001111S
INFO  [2023-01-26 18:09:42,409] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=AND$20Test.5726afe5-4644-43ce-9f1f-3274d1953a79, workerId=AND$20Test.worker_AND$20Test_14ce37f9-5cee-4a0f-82c4-aa8c31205344, startTime=2023-01-26T18:09:42.408408, finishTime=2023-01-26T18:09:42.409192) of size 1
INFO  [2023-01-26 18:09:42,410] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=AND$20Test.5726afe5-4644-43ce-9f1f-3274d1953a79, workerId=AND$20Test.worker_AND$20Test_121642c0-20be-4a30-b6b9-7fa9015f0427, startTime=2023-01-26T18:09:42.408443, finishTime=2023-01-26T18:09:42.409554) of size 1
INFO  [2023-01-26 18:09:42,410] com.bakdata.conquery.models.execution.ManagedExecution: DONE 5726afe5-4644-43ce-9f1f-3274d1953a79 ManagedQuery within PT0.005367S
127.0.0.1 - - [26/Jan/2023:18:09:42 +0000] "POST /api/datasets/AND$20Test/queries HTTP/1.1" 201 1722 "-" "Conquery (test client)" 11
127.0.0.1 - - [26/Jan/2023:18:09:42 +0000] "GET /api/datasets/AND$20Test/queries/AND$20Test.5726afe5-4644-43ce-9f1f-3274d1953a79 HTTP/1.1" 200 1737 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:09:42,443] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=AND Test], queryId=5726afe5-4644-43ce-9f1f-3274d1953a79, label=tree---a tree---b	@§$, creationTime=2023-01-26T18:09:42.404657, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@22c11ef[Count = 0], startTime=2023-01-26T18:09:42.404941, finishTime=2023-01-26T18:09:42.410308, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@5a17a787), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_AND Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@1e3dd85, com.bakdata.conquery.models.query.ColumnDescriptor@4aa26fe5, com.bakdata.conquery.models.query.ColumnDescriptor@28e3bc37]) download on dataset Dataset[label=null, name=AND Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:42,443] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=AND Test], queryId=5726afe5-4644-43ce-9f1f-3274d1953a79, label=tree---a tree---b	@§$, creationTime=2023-01-26T18:09:42.404657, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@22c11ef[Count = 0], startTime=2023-01-26T18:09:42.404941, finishTime=2023-01-26T18:09:42.410308, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@5a17a787), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_AND Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@1e3dd85, com.bakdata.conquery.models.query.ColumnDescriptor@4aa26fe5, com.bakdata.conquery.models.query.ColumnDescriptor@28e3bc37]) on dataset Dataset[label=null, name=AND Test]
127.0.0.1 - - [26/Jan/2023:18:09:42 +0000] "GET /api/datasets/AND%20Test/result/AND$20Test.5726afe5-4644-43ce-9f1f-3274d1953a79.csv?pretty=false HTTP/1.1" 200 91 "-" "Conquery (test client)" 24
INFO  [2023-01-26 18:09:42,465] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest AND Test on 3 rows
INFO  [2023-01-26 18:09:42,465] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast AND Test
INFO  [2023-01-26 18:09:42,465] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=AND Test, name=AND Test]
INFO  [2023-01-26 18:09:42,465] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=AND Test, name=AND Test]
INFO  [2023-01-26 18:09:42,465] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_AND Test_14ce37f9-5cee-4a0f-82c4-aa8c31205344
INFO  [2023-01-26 18:09:42,465] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_AND Test_121642c0-20be-4a30-b6b9-7fa9015f0427
INFO  [2023-01-26 18:09:42,563] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow AND Test
INFO  [2023-01-26 18:09:42,563] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_AND Test_14ce37f9-5cee-4a0f-82c4-aa8c31205344
INFO  [2023-01-26 18:09:42,563] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_AND Test_121642c0-20be-4a30-b6b9-7fa9015f0427
INFO  [2023-01-26 18:09:42,566] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of AND$20Test
INFO  [2023-01-26 18:09:42,566] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:42,692] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test AND Test
INFO  [2023-01-26 18:09:42,692] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test AND DATE LOGIC Test
INFO  [2023-01-26 18:09:42,692] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:42,692] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:42,696] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=AND DATE LOGIC Test, name=AND DATE LOGIC Test]
INFO  [2023-01-26 18:09:42,696] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=AND DATE LOGIC Test, name=AND DATE LOGIC Test]
INFO  [2023-01-26 18:09:42,696] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:42,696] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:42,701] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker AND$20DATE$20LOGIC$20Test.worker_AND$20DATE$20LOGIC$20Test_0b6b2d24-f4c6-4fd7-b229-e5c48bed07c2 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:42,701] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker AND$20DATE$20LOGIC$20Test.worker_AND$20DATE$20LOGIC$20Test_0b6b2d24-f4c6-4fd7-b229-e5c48bed07c2 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:42,701] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:42,701] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker AND$20DATE$20LOGIC$20Test.worker_AND$20DATE$20LOGIC$20Test_7f6ec627-824f-4085-99da-1afe0fddedf2 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:42,701] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker AND$20DATE$20LOGIC$20Test.worker_AND$20DATE$20LOGIC$20Test_7f6ec627-824f-4085-99da-1afe0fddedf2 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:42,701] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:42,701] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:42,805] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:42,812] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:42,813] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table AND$20DATE$20LOGIC$20Test.table
INFO  [2023-01-26 18:09:42,813] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table AND$20DATE$20LOGIC$20Test.table
INFO  [2023-01-26 18:09:42,923] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:43,031] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:43,031] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:43,031] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 240 B in total
INFO  [2023-01-26 18:09:43,031] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND DATE LOGIC Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000209393sINFO  [2023-01-26 18:09:43,052] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=5, sum=13, min=2, average=2.600000, max=4}
INFO  [2023-01-26 18:09:43,052] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[column] with StringParser(super=Parser(lines=13, nullLines=1), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:43,052] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=13, nullLines=0), subType=IntegerParser(super=Parser(lines=13, nullLines=0), minValue=15340, maxValue=15344), dateReader=com.bakdata.conquery.util.DateReader@2660b89d)
INFO  [2023-01-26 18:09:43,056] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND DATE LOGIC Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:43,056] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:43,056] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND DATE LOGIC Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:43,086] com.bakdata.conquery.models.jobs.ImportJob: Importing table into AND$20DATE$20LOGIC$20Test.table
127.0.0.1 - - [26/Jan/2023:18:09:43 +0000] "POST /admin/datasets/AND%20DATE%20LOGIC%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_AND+DATE+LOGIC+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:09:43,086] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:43,087] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:43,087] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:43,087] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:43,089] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:09:43,089] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[AND$20DATE$20LOGIC$20Test.table.table], containing 13 entries.
WARN  [2023-01-26 18:09:43,090] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:43,090] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received AND$20DATE$20LOGIC$20Test.table.table.0
INFO  [2023-01-26 18:09:43,090] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[AND$20DATE$20LOGIC$20Test.table.table], containing 13 entries.
INFO  [2023-01-26 18:09:43,090] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received AND$20DATE$20LOGIC$20Test.table.table.1
INFO  [2023-01-26 18:09:43,195] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:43,200] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:43,212] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:43,213] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:43,213] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:43,319] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: AND DATE LOGIC Test QUERY INIT
INFO  [2023-01-26 18:09:43,335] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[AND$20DATE$20LOGIC$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:43,336] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[1a69449c-c096-44ab-8d8b-4a83c4065d08] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_AND DATE LOGIC Test))]]
INFO  [2023-01-26 18:09:43,339] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery AND$20DATE$20LOGIC$20Test.1a69449c-c096-44ab-8d8b-4a83c4065d08
INFO  [2023-01-26 18:09:43,339] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery AND$20DATE$20LOGIC$20Test.1a69449c-c096-44ab-8d8b-4a83c4065d08
127.0.0.1 - - [26/Jan/2023:18:09:43 +0000] "POST /api/datasets/AND$20DATE$20LOGIC$20Test/queries HTTP/1.1" 201 1583 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:09:43,366] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[AND$20DATE$20LOGIC$20Test.1a69449c-c096-44ab-8d8b-4a83c4065d08] with 2 results within PT0.026812S
INFO  [2023-01-26 18:09:43,366] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=AND$20DATE$20LOGIC$20Test.1a69449c-c096-44ab-8d8b-4a83c4065d08, workerId=AND$20DATE$20LOGIC$20Test.worker_AND$20DATE$20LOGIC$20Test_7f6ec627-824f-4085-99da-1afe0fddedf2, startTime=2023-01-26T18:09:43.339417, finishTime=2023-01-26T18:09:43.366229) of size 2
INFO  [2023-01-26 18:09:43,367] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[AND$20DATE$20LOGIC$20Test.1a69449c-c096-44ab-8d8b-4a83c4065d08] with 2 results within PT0.0278S
INFO  [2023-01-26 18:09:43,367] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=AND$20DATE$20LOGIC$20Test.1a69449c-c096-44ab-8d8b-4a83c4065d08, workerId=AND$20DATE$20LOGIC$20Test.worker_AND$20DATE$20LOGIC$20Test_0b6b2d24-f4c6-4fd7-b229-e5c48bed07c2, startTime=2023-01-26T18:09:43.339416, finishTime=2023-01-26T18:09:43.367216) of size 2
INFO  [2023-01-26 18:09:43,367] com.bakdata.conquery.models.execution.ManagedExecution: DONE 1a69449c-c096-44ab-8d8b-4a83c4065d08 ManagedQuery within PT0.031463S
127.0.0.1 - - [26/Jan/2023:18:09:43 +0000] "GET /api/datasets/AND$20DATE$20LOGIC$20Test/queries/AND$20DATE$20LOGIC$20Test.1a69449c-c096-44ab-8d8b-4a83c4065d08 HTTP/1.1" 200 1875 "-" "Conquery (test client)" 21
INFO  [2023-01-26 18:09:43,384] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=AND DATE LOGIC Test], queryId=1a69449c-c096-44ab-8d8b-4a83c4065d08, label=tree---a tree---b	@§$, creationTime=2023-01-26T18:09:43.336174, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@56b45884[Count = 0], startTime=2023-01-26T18:09:43.336365, finishTime=2023-01-26T18:09:43.367828, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@8cf2b46), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_AND DATE LOGIC Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@4f81e505, com.bakdata.conquery.models.query.ColumnDescriptor@7a2ee0d2, com.bakdata.conquery.models.query.ColumnDescriptor@e2af76b]) download on dataset Dataset[label=null, name=AND DATE LOGIC Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:43,384] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=AND DATE LOGIC Test], queryId=1a69449c-c096-44ab-8d8b-4a83c4065d08, label=tree---a tree---b	@§$, creationTime=2023-01-26T18:09:43.336174, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@56b45884[Count = 0], startTime=2023-01-26T18:09:43.336365, finishTime=2023-01-26T18:09:43.367828, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@8cf2b46), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_AND DATE LOGIC Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@4f81e505, com.bakdata.conquery.models.query.ColumnDescriptor@7a2ee0d2, com.bakdata.conquery.models.query.ColumnDescriptor@e2af76b]) on dataset Dataset[label=null, name=AND DATE LOGIC Test]
127.0.0.1 - - [26/Jan/2023:18:09:43 +0000] "GET /api/datasets/AND%20DATE%20LOGIC%20Test/result/AND$20DATE$20LOGIC$20Test.1a69449c-c096-44ab-8d8b-4a83c4065d08.csv?pretty=false HTTP/1.1" 200 126 "-" "Conquery (test client)" 23
INFO  [2023-01-26 18:09:43,405] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest AND DATE LOGIC Test on 5 rows
INFO  [2023-01-26 18:09:43,405] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast AND DATE LOGIC Test
INFO  [2023-01-26 18:09:43,406] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=AND DATE LOGIC Test, name=AND DATE LOGIC Test]
INFO  [2023-01-26 18:09:43,406] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=AND DATE LOGIC Test, name=AND DATE LOGIC Test]
INFO  [2023-01-26 18:09:43,406] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_AND DATE LOGIC Test_7f6ec627-824f-4085-99da-1afe0fddedf2
INFO  [2023-01-26 18:09:43,406] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_AND DATE LOGIC Test_0b6b2d24-f4c6-4fd7-b229-e5c48bed07c2
INFO  [2023-01-26 18:09:43,505] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow AND DATE LOGIC Test
INFO  [2023-01-26 18:09:43,505] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_AND DATE LOGIC Test_0b6b2d24-f4c6-4fd7-b229-e5c48bed07c2
INFO  [2023-01-26 18:09:43,505] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_AND DATE LOGIC Test_7f6ec627-824f-4085-99da-1afe0fddedf2
INFO  [2023-01-26 18:09:43,605] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of AND$20DATE$20LOGIC$20Test
INFO  [2023-01-26 18:09:43,605] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:43,618] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test AND DATE LOGIC Test
INFO  [2023-01-26 18:09:43,618] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test AND DURATION SUM Test
INFO  [2023-01-26 18:09:43,618] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:43,618] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:43,621] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=AND DURATION SUM Test, name=AND DURATION SUM Test]
INFO  [2023-01-26 18:09:43,621] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=AND DURATION SUM Test, name=AND DURATION SUM Test]
INFO  [2023-01-26 18:09:43,621] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:43,621] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:43,623] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker AND$20DURATION$20SUM$20Test.worker_AND$20DURATION$20SUM$20Test_bb554bb1-175a-440d-b449-27534c3121ff are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:43,623] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker AND$20DURATION$20SUM$20Test.worker_AND$20DURATION$20SUM$20Test_bb554bb1-175a-440d-b449-27534c3121ff are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:43,623] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:43,623] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker AND$20DURATION$20SUM$20Test.worker_AND$20DURATION$20SUM$20Test_1021d125-c98e-4fa9-8ba4-0408801e596b are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:43,623] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker AND$20DURATION$20SUM$20Test.worker_AND$20DURATION$20SUM$20Test_1021d125-c98e-4fa9-8ba4-0408801e596b are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:43,623] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:43,627] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:43,727] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:43,734] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:43,734] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table AND$20DURATION$20SUM$20Test.table
INFO  [2023-01-26 18:09:43,734] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table AND$20DURATION$20SUM$20Test.table
INFO  [2023-01-26 18:09:43,849] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:43,959] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:43,960] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:43,960] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 307 B in total
INFO  [2023-01-26 18:09:43,960] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND DURATION SUM Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000248666sINFO  [2023-01-26 18:09:43,985] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=5, sum=17, min=2, average=3.400000, max=8}
INFO  [2023-01-26 18:09:43,985] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[column] with StringParser(super=Parser(lines=17, nullLines=1), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:43,985] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=17, nullLines=0), subType=IntegerParser(super=Parser(lines=17, nullLines=0), minValue=15340, maxValue=15344), dateReader=com.bakdata.conquery.util.DateReader@40e2ddf7)
INFO  [2023-01-26 18:09:43,988] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND DURATION SUM Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:43,988] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:43,988] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND DURATION SUM Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:44,004] com.bakdata.conquery.models.jobs.ImportJob: Importing table into AND$20DURATION$20SUM$20Test.table
INFO  [2023-01-26 18:09:44,005] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:09:44 +0000] "POST /admin/datasets/AND%20DURATION%20SUM%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_AND+DURATION+SUM+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 10
INFO  [2023-01-26 18:09:44,006] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:44,006] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:44,006] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:44,008] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:09:44,008] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[AND$20DURATION$20SUM$20Test.table.table], containing 17 entries.
INFO  [2023-01-26 18:09:44,008] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[AND$20DURATION$20SUM$20Test.table.table], containing 17 entries.
WARN  [2023-01-26 18:09:44,009] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:44,009] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received AND$20DURATION$20SUM$20Test.table.table.0
INFO  [2023-01-26 18:09:44,009] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received AND$20DURATION$20SUM$20Test.table.table.1
INFO  [2023-01-26 18:09:44,114] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:44,120] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:44,131] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:44,132] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:44,132] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:44,237] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: AND DURATION SUM Test QUERY INIT
INFO  [2023-01-26 18:09:44,252] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[AND$20DURATION$20SUM$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:44,253] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[f1635d0a-9c33-4dcd-8ba3-c84908bdcae7] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_AND DURATION SUM Test))]]
INFO  [2023-01-26 18:09:44,254] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery AND$20DURATION$20SUM$20Test.f1635d0a-9c33-4dcd-8ba3-c84908bdcae7
INFO  [2023-01-26 18:09:44,255] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery AND$20DURATION$20SUM$20Test.f1635d0a-9c33-4dcd-8ba3-c84908bdcae7
127.0.0.1 - - [26/Jan/2023:18:09:44 +0000] "POST /api/datasets/AND$20DURATION$20SUM$20Test/queries HTTP/1.1" 201 1853 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:09:44,256] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[AND$20DURATION$20SUM$20Test.f1635d0a-9c33-4dcd-8ba3-c84908bdcae7] with 2 results within PT0.001642S
INFO  [2023-01-26 18:09:44,256] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[AND$20DURATION$20SUM$20Test.f1635d0a-9c33-4dcd-8ba3-c84908bdcae7] with 2 results within PT0.001632S
INFO  [2023-01-26 18:09:44,257] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=AND$20DURATION$20SUM$20Test.f1635d0a-9c33-4dcd-8ba3-c84908bdcae7, workerId=AND$20DURATION$20SUM$20Test.worker_AND$20DURATION$20SUM$20Test_bb554bb1-175a-440d-b449-27534c3121ff, startTime=2023-01-26T18:09:44.255019, finishTime=2023-01-26T18:09:44.256661) of size 2
INFO  [2023-01-26 18:09:44,257] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=AND$20DURATION$20SUM$20Test.f1635d0a-9c33-4dcd-8ba3-c84908bdcae7, workerId=AND$20DURATION$20SUM$20Test.worker_AND$20DURATION$20SUM$20Test_1021d125-c98e-4fa9-8ba4-0408801e596b, startTime=2023-01-26T18:09:44.255037, finishTime=2023-01-26T18:09:44.256669) of size 2
INFO  [2023-01-26 18:09:44,257] com.bakdata.conquery.models.execution.ManagedExecution: DONE f1635d0a-9c33-4dcd-8ba3-c84908bdcae7 ManagedQuery within PT0.004223S
127.0.0.1 - - [26/Jan/2023:18:09:44 +0000] "GET /api/datasets/AND$20DURATION$20SUM$20Test/queries/AND$20DURATION$20SUM$20Test.f1635d0a-9c33-4dcd-8ba3-c84908bdcae7 HTTP/1.1" 200 2152 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:09:44,277] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=AND DURATION SUM Test], queryId=f1635d0a-9c33-4dcd-8ba3-c84908bdcae7, label=tree---a tree---b	@§$, creationTime=2023-01-26T18:09:44.252897, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@57efe0e0[Count = 0], startTime=2023-01-26T18:09:44.253093, finishTime=2023-01-26T18:09:44.257316, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@7fd4830a), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_AND DURATION SUM Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@18b225af, com.bakdata.conquery.models.query.ColumnDescriptor@19707a6e, com.bakdata.conquery.models.query.ColumnDescriptor@31307140, com.bakdata.conquery.models.query.ColumnDescriptor@6a2778bf]) download on dataset Dataset[label=null, name=AND DURATION SUM Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:44,277] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=AND DURATION SUM Test], queryId=f1635d0a-9c33-4dcd-8ba3-c84908bdcae7, label=tree---a tree---b	@§$, creationTime=2023-01-26T18:09:44.252897, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@57efe0e0[Count = 0], startTime=2023-01-26T18:09:44.253093, finishTime=2023-01-26T18:09:44.257316, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@7fd4830a), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_AND DURATION SUM Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@18b225af, com.bakdata.conquery.models.query.ColumnDescriptor@19707a6e, com.bakdata.conquery.models.query.ColumnDescriptor@31307140, com.bakdata.conquery.models.query.ColumnDescriptor@6a2778bf]) on dataset Dataset[label=null, name=AND DURATION SUM Test]
127.0.0.1 - - [26/Jan/2023:18:09:44 +0000] "GET /api/datasets/AND%20DURATION%20SUM%20Test/result/AND$20DURATION$20SUM$20Test.f1635d0a-9c33-4dcd-8ba3-c84908bdcae7.csv?pretty=false HTTP/1.1" 200 160 "-" "Conquery (test client)" 26
INFO  [2023-01-26 18:09:44,303] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest AND DURATION SUM Test on 5 rows
INFO  [2023-01-26 18:09:44,303] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast AND DURATION SUM Test
INFO  [2023-01-26 18:09:44,303] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=AND DURATION SUM Test, name=AND DURATION SUM Test]
INFO  [2023-01-26 18:09:44,303] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=AND DURATION SUM Test, name=AND DURATION SUM Test]
INFO  [2023-01-26 18:09:44,303] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_AND DURATION SUM Test_1021d125-c98e-4fa9-8ba4-0408801e596b
INFO  [2023-01-26 18:09:44,303] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_AND DURATION SUM Test_bb554bb1-175a-440d-b449-27534c3121ff
INFO  [2023-01-26 18:09:44,328] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_AND DURATION SUM Test_1021d125-c98e-4fa9-8ba4-0408801e596b
INFO  [2023-01-26 18:09:44,328] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow AND DURATION SUM Test
INFO  [2023-01-26 18:09:44,328] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_AND DURATION SUM Test_bb554bb1-175a-440d-b449-27534c3121ff
INFO  [2023-01-26 18:09:44,409] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of AND$20DURATION$20SUM$20Test
INFO  [2023-01-26 18:09:44,409] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:44,437] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test AND DURATION SUM Test
INFO  [2023-01-26 18:09:44,437] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test AND DURATION SUM Test
INFO  [2023-01-26 18:09:44,437] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:44,437] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:44,438] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=AND DURATION SUM Test[1], name=AND DURATION SUM Test[1]]
INFO  [2023-01-26 18:09:44,438] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=AND DURATION SUM Test[1], name=AND DURATION SUM Test[1]]
INFO  [2023-01-26 18:09:44,438] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:44,438] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:44,439] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:44,439] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker AND$20DURATION$20SUM$20Test[1].worker_AND$20DURATION$20SUM$20Test[1]_d8657828-fe95-4cba-aaf1-8fdb3d8a2c1c are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:44,439] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker AND$20DURATION$20SUM$20Test[1].worker_AND$20DURATION$20SUM$20Test[1]_d8657828-fe95-4cba-aaf1-8fdb3d8a2c1c are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:44,439] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:44,439] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker AND$20DURATION$20SUM$20Test[1].worker_AND$20DURATION$20SUM$20Test[1]_55430045-8505-460f-b176-43f81818eba0 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:44,439] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker AND$20DURATION$20SUM$20Test[1].worker_AND$20DURATION$20SUM$20Test[1]_55430045-8505-460f-b176-43f81818eba0 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:44,439] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:44,544] com.bakdata.conquery.resources.admin.rest.AdminDatasetProcessor: Received new SecondaryId[AND$20DURATION$20SUM$20Test[1].secondary]
INFO  [2023-01-26 18:09:44,545] com.bakdata.conquery.resources.admin.rest.AdminDatasetProcessor: Received new SecondaryId[AND$20DURATION$20SUM$20Test[1].ignored]
INFO  [2023-01-26 18:09:44,545] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:44,545] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId AND$20DURATION$20SUM$20Test[1].secondary
INFO  [2023-01-26 18:09:44,545] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId AND$20DURATION$20SUM$20Test[1].secondary
INFO  [2023-01-26 18:09:44,592] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId AND$20DURATION$20SUM$20Test[1].ignored
INFO  [2023-01-26 18:09:44,592] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId AND$20DURATION$20SUM$20Test[1].ignored
INFO  [2023-01-26 18:09:44,698] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:44,698] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table AND$20DURATION$20SUM$20Test[1].table1
INFO  [2023-01-26 18:09:44,698] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table AND$20DURATION$20SUM$20Test[1].table1
INFO  [2023-01-26 18:09:44,698] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table AND$20DURATION$20SUM$20Test[1].table2
INFO  [2023-01-26 18:09:44,699] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table AND$20DURATION$20SUM$20Test[1].table2
INFO  [2023-01-26 18:09:44,817] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:44,926] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:44,926] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:44,926] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:44,926] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 373 B in total
INFO  [2023-01-26 18:09:44,926] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND DURATION SUM Test[1]/table1.import.json, tag=Optional.empty)
██████████████████████████████████                ▌  68%	est. time remaining: 0.00845936sINFO  [2023-01-26 18:09:44,944] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=3, sum=12, min=1, average=4.000000, max=10}
INFO  [2023-01-26 18:09:44,944] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=12, nullLines=0), subType=IntegerParser(super=Parser(lines=12, nullLines=0), minValue=15340, maxValue=15343), dateReader=com.bakdata.conquery.util.DateReader@3dd6a3db)
INFO  [2023-01-26 18:09:44,944] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[column] with StringParser(super=Parser(lines=12, nullLines=2), encoding=null, prefix=A, suffix=A)
INFO  [2023-01-26 18:09:44,944] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[secondary] with StringParser(super=Parser(lines=12, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:44,948] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND DURATION SUM Test[1]/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:44,948] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND DURATION SUM Test[1]/table2.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000395968sINFO  [2023-01-26 18:09:44,966] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=3, sum=6, min=1, average=2.000000, max=4}
INFO  [2023-01-26 18:09:44,966] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[column] with StringParser(super=Parser(lines=6, nullLines=1), encoding=null, prefix=B, suffix=B)
INFO  [2023-01-26 18:09:44,966] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=15340, maxValue=15344), dateReader=com.bakdata.conquery.util.DateReader@4062911e)
INFO  [2023-01-26 18:09:44,968] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND DURATION SUM Test[1]/table2.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:44,969] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 2 Jobs:
INFO  [2023-01-26 18:09:44,969] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND DURATION SUM Test[1]/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:44,969] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND DURATION SUM Test[1]/table2.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:44,982] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into AND$20DURATION$20SUM$20Test[1].table1
127.0.0.1 - - [26/Jan/2023:18:09:44 +0000] "POST /admin/datasets/AND%20DURATION%20SUM%20Test%5B1%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_AND+DURATION+SUM+Test%5B1%5D%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:09:44,984] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:44,984] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:44,984] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:44,986] com.bakdata.conquery.models.jobs.ImportJob: Start sending 1 Buckets
INFO  [2023-01-26 18:09:44,987] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[AND$20DURATION$20SUM$20Test[1].table1.table1], containing 12 entries.
WARN  [2023-01-26 18:09:44,987] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:44,987] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[AND$20DURATION$20SUM$20Test[1].table1.table1], containing 12 entries.
INFO  [2023-01-26 18:09:44,988] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received AND$20DURATION$20SUM$20Test[1].table1.table1.0
INFO  [2023-01-26 18:09:44,997] com.bakdata.conquery.models.jobs.ImportJob: Importing table2 into AND$20DURATION$20SUM$20Test[1].table2
INFO  [2023-01-26 18:09:44,998] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:44,998] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:44,998] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
127.0.0.1 - - [26/Jan/2023:18:09:44 +0000] "POST /admin/datasets/AND%20DURATION%20SUM%20Test%5B1%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_AND+DURATION+SUM+Test%5B1%5D%2Ftable2.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:09:44,998] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:44,998] com.bakdata.conquery.models.jobs.ImportJob: Start sending 1 Buckets
WARN  [2023-01-26 18:09:44,998] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:44,998] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[AND$20DURATION$20SUM$20Test[1].table2.table2], containing 6 entries.
INFO  [2023-01-26 18:09:44,998] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[AND$20DURATION$20SUM$20Test[1].table2.table2], containing 6 entries.
INFO  [2023-01-26 18:09:44,999] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received AND$20DURATION$20SUM$20Test[1].table2.table2.0
INFO  [2023-01-26 18:09:45,104] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:45,109] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:45,121] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:45,121] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 2 Concepts
INFO  [2023-01-26 18:09:45,227] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: AND DURATION SUM Test QUERY INIT
INFO  [2023-01-26 18:09:45,248] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[AND$20DURATION$20SUM$20Test[1]] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:45,248] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[9309cc0a-88f5-40e2-b773-9813309a8829] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_AND DURATION SUM Test[1]))]]
INFO  [2023-01-26 18:09:45,252] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started SecondaryIdQuery AND$20DURATION$20SUM$20Test[1].9309cc0a-88f5-40e2-b773-9813309a8829
INFO  [2023-01-26 18:09:45,252] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started SecondaryIdQuery AND$20DURATION$20SUM$20Test[1].9309cc0a-88f5-40e2-b773-9813309a8829
WARN  [2023-01-26 18:09:45,253] com.bakdata.conquery.models.query.QueryExecutor: Entities for query are empty
INFO  [2023-01-26 18:09:45,253] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[AND$20DURATION$20SUM$20Test[1].9309cc0a-88f5-40e2-b773-9813309a8829] with 0 results within PT0.000187S
INFO  [2023-01-26 18:09:45,253] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=AND$20DURATION$20SUM$20Test[1].9309cc0a-88f5-40e2-b773-9813309a8829, workerId=AND$20DURATION$20SUM$20Test[1].worker_AND$20DURATION$20SUM$20Test[1]_55430045-8505-460f-b176-43f81818eba0, startTime=2023-01-26T18:09:45.253018, finishTime=2023-01-26T18:09:45.253205) of size 0
INFO  [2023-01-26 18:09:45,254] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[AND$20DURATION$20SUM$20Test[1].9309cc0a-88f5-40e2-b773-9813309a8829] with 2 results within PT0.001174S
INFO  [2023-01-26 18:09:45,254] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=AND$20DURATION$20SUM$20Test[1].9309cc0a-88f5-40e2-b773-9813309a8829, workerId=AND$20DURATION$20SUM$20Test[1].worker_AND$20DURATION$20SUM$20Test[1]_d8657828-fe95-4cba-aaf1-8fdb3d8a2c1c, startTime=2023-01-26T18:09:45.253012, finishTime=2023-01-26T18:09:45.254186) of size 2
INFO  [2023-01-26 18:09:45,254] com.bakdata.conquery.models.execution.ManagedExecution: DONE 9309cc0a-88f5-40e2-b773-9813309a8829 ManagedQuery within PT0.005977S
127.0.0.1 - - [26/Jan/2023:18:09:45 +0000] "POST /api/datasets/AND$20DURATION$20SUM$20Test%5B1%5D/queries HTTP/1.1" 201 2137 "-" "Conquery (test client)" 13
127.0.0.1 - - [26/Jan/2023:18:09:45 +0000] "GET /api/datasets/AND$20DURATION$20SUM$20Test%5B1%5D/queries/AND$20DURATION$20SUM$20Test%5B1%5D.9309cc0a-88f5-40e2-b773-9813309a8829 HTTP/1.1" 200 2720 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:09:45,309] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=AND DURATION SUM Test[1]], queryId=9309cc0a-88f5-40e2-b773-9813309a8829, label=tree1---a tree2---b	@§$, creationTime=2023-01-26T18:09:45.248620, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@104e528[Count = 0], startTime=2023-01-26T18:09:45.248882, finishTime=2023-01-26T18:09:45.254859, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2bac615e), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_AND DURATION SUM Test[1])), query=com.bakdata.conquery.apiv1.query.SecondaryIdQuery@1, lastResultCount=6, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@3d24c3f5, com.bakdata.conquery.models.query.ColumnDescriptor@75342667, com.bakdata.conquery.models.query.ColumnDescriptor@53bfa04c, com.bakdata.conquery.models.query.ColumnDescriptor@1b518df4, com.bakdata.conquery.models.query.ColumnDescriptor@71ce00]) download on dataset Dataset[label=null, name=AND DURATION SUM Test[1]] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:45,310] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=AND DURATION SUM Test[1]], queryId=9309cc0a-88f5-40e2-b773-9813309a8829, label=tree1---a tree2---b	@§$, creationTime=2023-01-26T18:09:45.248620, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@104e528[Count = 0], startTime=2023-01-26T18:09:45.248882, finishTime=2023-01-26T18:09:45.254859, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2bac615e), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_AND DURATION SUM Test[1])), query=com.bakdata.conquery.apiv1.query.SecondaryIdQuery@1, lastResultCount=6, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@3d24c3f5, com.bakdata.conquery.models.query.ColumnDescriptor@75342667, com.bakdata.conquery.models.query.ColumnDescriptor@53bfa04c, com.bakdata.conquery.models.query.ColumnDescriptor@1b518df4, com.bakdata.conquery.models.query.ColumnDescriptor@71ce00]) on dataset Dataset[label=null, name=AND DURATION SUM Test[1]]
127.0.0.1 - - [26/Jan/2023:18:09:45 +0000] "GET /api/datasets/AND%20DURATION%20SUM%20Test%5B1%5D/result/AND$20DURATION$20SUM$20Test%5B1%5D.9309cc0a-88f5-40e2-b773-9813309a8829.csv?pretty=false HTTP/1.1" 200 182 "-" "Conquery (test client)" 4
INFO  [2023-01-26 18:09:45,312] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest AND DURATION SUM Test on 7 rows
INFO  [2023-01-26 18:09:45,312] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast AND DURATION SUM Test[1]
INFO  [2023-01-26 18:09:45,312] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=AND DURATION SUM Test[1], name=AND DURATION SUM Test[1]]
INFO  [2023-01-26 18:09:45,312] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=AND DURATION SUM Test[1], name=AND DURATION SUM Test[1]]
INFO  [2023-01-26 18:09:45,312] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_AND DURATION SUM Test[1]_55430045-8505-460f-b176-43f81818eba0
INFO  [2023-01-26 18:09:45,317] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_AND DURATION SUM Test[1]_d8657828-fe95-4cba-aaf1-8fdb3d8a2c1c
INFO  [2023-01-26 18:09:45,344] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow AND DURATION SUM Test[1]
INFO  [2023-01-26 18:09:45,344] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_AND DURATION SUM Test[1]_55430045-8505-460f-b176-43f81818eba0
INFO  [2023-01-26 18:09:45,344] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_AND DURATION SUM Test[1]_d8657828-fe95-4cba-aaf1-8fdb3d8a2c1c
INFO  [2023-01-26 18:09:45,411] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of AND$20DURATION$20SUM$20Test[1]
INFO  [2023-01-26 18:09:45,411] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:45,526] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test AND DURATION SUM Test
INFO  [2023-01-26 18:09:45,527] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test AND NEGATION Test
INFO  [2023-01-26 18:09:45,527] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:45,527] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:45,528] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=AND NEGATION Test, name=AND NEGATION Test]
INFO  [2023-01-26 18:09:45,528] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=AND NEGATION Test, name=AND NEGATION Test]
INFO  [2023-01-26 18:09:45,528] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:45,528] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:45,532] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker AND$20NEGATION$20Test.worker_AND$20NEGATION$20Test_ae826f92-121e-4507-af2b-4501cbb6b8b7 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:45,532] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker AND$20NEGATION$20Test.worker_AND$20NEGATION$20Test_ae826f92-121e-4507-af2b-4501cbb6b8b7 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:45,532] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:45,532] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker AND$20NEGATION$20Test.worker_AND$20NEGATION$20Test_d44545f4-18a5-4504-be2f-1e06f1c9fb4f are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:45,532] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker AND$20NEGATION$20Test.worker_AND$20NEGATION$20Test_d44545f4-18a5-4504-be2f-1e06f1c9fb4f are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:45,532] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:45,534] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:45,635] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:45,642] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:45,642] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table AND$20NEGATION$20Test.table
INFO  [2023-01-26 18:09:45,642] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table AND$20NEGATION$20Test.table
INFO  [2023-01-26 18:09:45,751] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:45,860] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:45,860] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:45,860] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 202 B in total
INFO  [2023-01-26 18:09:45,860] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND NEGATION Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000198676sINFO  [2023-01-26 18:09:45,881] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=5, sum=11, min=1, average=2.200000, max=3}
INFO  [2023-01-26 18:09:45,881] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[column] with StringParser(super=Parser(lines=11, nullLines=2), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:45,881] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=11, nullLines=0), subType=IntegerParser(super=Parser(lines=11, nullLines=0), minValue=15340, maxValue=15342), dateReader=com.bakdata.conquery.util.DateReader@26f1f76)
INFO  [2023-01-26 18:09:45,885] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND NEGATION Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:45,885] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:45,885] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND NEGATION Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:45,900] com.bakdata.conquery.models.jobs.ImportJob: Importing table into AND$20NEGATION$20Test.table
127.0.0.1 - - [26/Jan/2023:18:09:45 +0000] "POST /admin/datasets/AND%20NEGATION%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_AND+NEGATION+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:09:45,901] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:45,901] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:45,902] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:45,902] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:45,903] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:09:45,904] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[AND$20NEGATION$20Test.table.table], containing 11 entries.
INFO  [2023-01-26 18:09:45,904] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[AND$20NEGATION$20Test.table.table], containing 11 entries.
WARN  [2023-01-26 18:09:45,904] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:45,904] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received AND$20NEGATION$20Test.table.table.0
INFO  [2023-01-26 18:09:45,905] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received AND$20NEGATION$20Test.table.table.1
INFO  [2023-01-26 18:09:46,011] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:46,016] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:46,027] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:46,027] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:46,027] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:46,149] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: AND NEGATION Test QUERY INIT
INFO  [2023-01-26 18:09:46,159] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[AND$20NEGATION$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:46,160] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[ad14d4dd-1167-45ea-a044-f277cf11f65f] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_AND NEGATION Test))]]
INFO  [2023-01-26 18:09:46,162] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery AND$20NEGATION$20Test.ad14d4dd-1167-45ea-a044-f277cf11f65f
INFO  [2023-01-26 18:09:46,162] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery AND$20NEGATION$20Test.ad14d4dd-1167-45ea-a044-f277cf11f65f
INFO  [2023-01-26 18:09:46,163] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[AND$20NEGATION$20Test.ad14d4dd-1167-45ea-a044-f277cf11f65f] with 1 results within PT0.000792S
INFO  [2023-01-26 18:09:46,163] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[AND$20NEGATION$20Test.ad14d4dd-1167-45ea-a044-f277cf11f65f] with 1 results within PT0.000846S
INFO  [2023-01-26 18:09:46,163] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=AND$20NEGATION$20Test.ad14d4dd-1167-45ea-a044-f277cf11f65f, workerId=AND$20NEGATION$20Test.worker_AND$20NEGATION$20Test_ae826f92-121e-4507-af2b-4501cbb6b8b7, startTime=2023-01-26T18:09:46.162657, finishTime=2023-01-26T18:09:46.163503) of size 1
INFO  [2023-01-26 18:09:46,164] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=AND$20NEGATION$20Test.ad14d4dd-1167-45ea-a044-f277cf11f65f, workerId=AND$20NEGATION$20Test.worker_AND$20NEGATION$20Test_d44545f4-18a5-4504-be2f-1e06f1c9fb4f, startTime=2023-01-26T18:09:46.162668, finishTime=2023-01-26T18:09:46.163460) of size 1
127.0.0.1 - - [26/Jan/2023:18:09:46 +0000] "POST /api/datasets/AND$20NEGATION$20Test/queries HTTP/1.1" 201 1618 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:09:46,164] com.bakdata.conquery.models.execution.ManagedExecution: DONE ad14d4dd-1167-45ea-a044-f277cf11f65f ManagedQuery within PT0.003832S
127.0.0.1 - - [26/Jan/2023:18:09:46 +0000] "GET /api/datasets/AND$20NEGATION$20Test/queries/AND$20NEGATION$20Test.ad14d4dd-1167-45ea-a044-f277cf11f65f HTTP/1.1" 200 1893 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:09:46,185] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=AND NEGATION Test], queryId=ad14d4dd-1167-45ea-a044-f277cf11f65f, label=tree---a tree---b	@§$, creationTime=2023-01-26T18:09:46.160154, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@1a8efff4[Count = 0], startTime=2023-01-26T18:09:46.160302, finishTime=2023-01-26T18:09:46.164134, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@5a9c3846), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_AND NEGATION Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@342e7094, com.bakdata.conquery.models.query.ColumnDescriptor@19310118, com.bakdata.conquery.models.query.ColumnDescriptor@742d3c95]) download on dataset Dataset[label=null, name=AND NEGATION Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:46,186] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=AND NEGATION Test], queryId=ad14d4dd-1167-45ea-a044-f277cf11f65f, label=tree---a tree---b	@§$, creationTime=2023-01-26T18:09:46.160154, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@1a8efff4[Count = 0], startTime=2023-01-26T18:09:46.160302, finishTime=2023-01-26T18:09:46.164134, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@5a9c3846), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_AND NEGATION Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@342e7094, com.bakdata.conquery.models.query.ColumnDescriptor@19310118, com.bakdata.conquery.models.query.ColumnDescriptor@742d3c95]) on dataset Dataset[label=null, name=AND NEGATION Test]
127.0.0.1 - - [26/Jan/2023:18:09:46 +0000] "GET /api/datasets/AND%20NEGATION%20Test/result/AND$20NEGATION$20Test.ad14d4dd-1167-45ea-a044-f277cf11f65f.csv?pretty=false HTTP/1.1" 200 90 "-" "Conquery (test client)" 37
INFO  [2023-01-26 18:09:46,221] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest AND NEGATION Test on 3 rows
INFO  [2023-01-26 18:09:46,221] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast AND NEGATION Test
INFO  [2023-01-26 18:09:46,222] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=AND NEGATION Test, name=AND NEGATION Test]
INFO  [2023-01-26 18:09:46,222] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=AND NEGATION Test, name=AND NEGATION Test]
INFO  [2023-01-26 18:09:46,222] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_AND NEGATION Test_d44545f4-18a5-4504-be2f-1e06f1c9fb4f
INFO  [2023-01-26 18:09:46,222] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_AND NEGATION Test_ae826f92-121e-4507-af2b-4501cbb6b8b7
INFO  [2023-01-26 18:09:46,244] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow AND NEGATION Test
INFO  [2023-01-26 18:09:46,244] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_AND NEGATION Test_ae826f92-121e-4507-af2b-4501cbb6b8b7
INFO  [2023-01-26 18:09:46,244] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_AND NEGATION Test_d44545f4-18a5-4504-be2f-1e06f1c9fb4f
INFO  [2023-01-26 18:09:46,322] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of AND$20NEGATION$20Test
INFO  [2023-01-26 18:09:46,322] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:46,450] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test AND NEGATION Test
INFO  [2023-01-26 18:09:46,450] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test AND NEGATION DATE LOGIC Test
INFO  [2023-01-26 18:09:46,450] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:46,450] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:46,451] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=AND NEGATION DATE LOGIC Test, name=AND NEGATION DATE LOGIC Test]
INFO  [2023-01-26 18:09:46,451] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=AND NEGATION DATE LOGIC Test, name=AND NEGATION DATE LOGIC Test]
INFO  [2023-01-26 18:09:46,451] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:46,451] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:46,453] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:46,453] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker AND$20NEGATION$20DATE$20LOGIC$20Test.worker_AND$20NEGATION$20DATE$20LOGIC$20Test_25d39566-1e15-40ed-8073-a2832fc5a6d2 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:46,453] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker AND$20NEGATION$20DATE$20LOGIC$20Test.worker_AND$20NEGATION$20DATE$20LOGIC$20Test_25d39566-1e15-40ed-8073-a2832fc5a6d2 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:46,453] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:46,453] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker AND$20NEGATION$20DATE$20LOGIC$20Test.worker_AND$20NEGATION$20DATE$20LOGIC$20Test_6bb92958-726c-4ca7-bb21-b9a87d29aac0 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:46,453] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker AND$20NEGATION$20DATE$20LOGIC$20Test.worker_AND$20NEGATION$20DATE$20LOGIC$20Test_6bb92958-726c-4ca7-bb21-b9a87d29aac0 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:46,453] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:46,557] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:46,563] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:46,564] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table AND$20NEGATION$20DATE$20LOGIC$20Test.table
INFO  [2023-01-26 18:09:46,564] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table AND$20NEGATION$20DATE$20LOGIC$20Test.table
INFO  [2023-01-26 18:09:46,675] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:46,794] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:46,794] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:46,794] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 172 B in total
INFO  [2023-01-26 18:09:46,794] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND NEGATION DATE LOGIC Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000769262sINFO  [2023-01-26 18:09:46,872] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=5, sum=9, min=1, average=1.800000, max=2}
INFO  [2023-01-26 18:09:46,872] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[column] with StringParser(super=Parser(lines=9, nullLines=1), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:46,872] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=9, nullLines=0), subType=IntegerParser(super=Parser(lines=9, nullLines=0), minValue=15340, maxValue=15344), dateReader=com.bakdata.conquery.util.DateReader@21e8fbf6)
INFO  [2023-01-26 18:09:46,875] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND NEGATION DATE LOGIC Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:46,875] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:46,875] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND NEGATION DATE LOGIC Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:46,894] com.bakdata.conquery.models.jobs.ImportJob: Importing table into AND$20NEGATION$20DATE$20LOGIC$20Test.table
127.0.0.1 - - [26/Jan/2023:18:09:46 +0000] "POST /admin/datasets/AND%20NEGATION%20DATE%20LOGIC%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_AND+NEGATION+DATE+LOGIC+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 12
INFO  [2023-01-26 18:09:46,895] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:46,895] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:46,896] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:46,896] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:46,897] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:09:46,897] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[AND$20NEGATION$20DATE$20LOGIC$20Test.table.table], containing 9 entries.
INFO  [2023-01-26 18:09:46,897] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[AND$20NEGATION$20DATE$20LOGIC$20Test.table.table], containing 9 entries.
WARN  [2023-01-26 18:09:46,898] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:46,898] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received AND$20NEGATION$20DATE$20LOGIC$20Test.table.table.0
INFO  [2023-01-26 18:09:46,898] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received AND$20NEGATION$20DATE$20LOGIC$20Test.table.table.1
INFO  [2023-01-26 18:09:47,003] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:47,008] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:47,029] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:47,030] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:47,030] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:47,135] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: AND NEGATION DATE LOGIC Test QUERY INIT
INFO  [2023-01-26 18:09:47,147] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[AND$20NEGATION$20DATE$20LOGIC$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:47,147] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[c05e795b-4578-45b4-bb9b-81e42ab4de39] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_AND NEGATION DATE LOGIC Test))]]
INFO  [2023-01-26 18:09:47,151] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery AND$20NEGATION$20DATE$20LOGIC$20Test.c05e795b-4578-45b4-bb9b-81e42ab4de39
INFO  [2023-01-26 18:09:47,151] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery AND$20NEGATION$20DATE$20LOGIC$20Test.c05e795b-4578-45b4-bb9b-81e42ab4de39
127.0.0.1 - - [26/Jan/2023:18:09:47 +0000] "POST /api/datasets/AND$20NEGATION$20DATE$20LOGIC$20Test/queries HTTP/1.1" 201 1678 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:09:47,152] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[AND$20NEGATION$20DATE$20LOGIC$20Test.c05e795b-4578-45b4-bb9b-81e42ab4de39] with 1 results within PT0.001769S
INFO  [2023-01-26 18:09:47,153] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[AND$20NEGATION$20DATE$20LOGIC$20Test.c05e795b-4578-45b4-bb9b-81e42ab4de39] with 1 results within PT0.002038S
INFO  [2023-01-26 18:09:47,153] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=AND$20NEGATION$20DATE$20LOGIC$20Test.c05e795b-4578-45b4-bb9b-81e42ab4de39, workerId=AND$20NEGATION$20DATE$20LOGIC$20Test.worker_AND$20NEGATION$20DATE$20LOGIC$20Test_6bb92958-726c-4ca7-bb21-b9a87d29aac0, startTime=2023-01-26T18:09:47.151066, finishTime=2023-01-26T18:09:47.152835) of size 1
INFO  [2023-01-26 18:09:47,154] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=AND$20NEGATION$20DATE$20LOGIC$20Test.c05e795b-4578-45b4-bb9b-81e42ab4de39, workerId=AND$20NEGATION$20DATE$20LOGIC$20Test.worker_AND$20NEGATION$20DATE$20LOGIC$20Test_25d39566-1e15-40ed-8073-a2832fc5a6d2, startTime=2023-01-26T18:09:47.151119, finishTime=2023-01-26T18:09:47.153157) of size 1
INFO  [2023-01-26 18:09:47,154] com.bakdata.conquery.models.execution.ManagedExecution: DONE c05e795b-4578-45b4-bb9b-81e42ab4de39 ManagedQuery within PT0.00625S
127.0.0.1 - - [26/Jan/2023:18:09:47 +0000] "GET /api/datasets/AND$20NEGATION$20DATE$20LOGIC$20Test/queries/AND$20NEGATION$20DATE$20LOGIC$20Test.c05e795b-4578-45b4-bb9b-81e42ab4de39 HTTP/1.1" 200 2012 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:09:47,175] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=AND NEGATION DATE LOGIC Test], queryId=c05e795b-4578-45b4-bb9b-81e42ab4de39, label=tree---a tree---b	@§$, creationTime=2023-01-26T18:09:47.147546, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@49a31cea[Count = 0], startTime=2023-01-26T18:09:47.147810, finishTime=2023-01-26T18:09:47.154060, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@731b2c2b), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_AND NEGATION DATE LOGIC Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@52cdb43d, com.bakdata.conquery.models.query.ColumnDescriptor@715621ce, com.bakdata.conquery.models.query.ColumnDescriptor@20433742]) download on dataset Dataset[label=null, name=AND NEGATION DATE LOGIC Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:47,175] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=AND NEGATION DATE LOGIC Test], queryId=c05e795b-4578-45b4-bb9b-81e42ab4de39, label=tree---a tree---b	@§$, creationTime=2023-01-26T18:09:47.147546, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@49a31cea[Count = 0], startTime=2023-01-26T18:09:47.147810, finishTime=2023-01-26T18:09:47.154060, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@731b2c2b), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_AND NEGATION DATE LOGIC Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@52cdb43d, com.bakdata.conquery.models.query.ColumnDescriptor@715621ce, com.bakdata.conquery.models.query.ColumnDescriptor@20433742]) on dataset Dataset[label=null, name=AND NEGATION DATE LOGIC Test]
127.0.0.1 - - [26/Jan/2023:18:09:47 +0000] "GET /api/datasets/AND%20NEGATION%20DATE%20LOGIC%20Test/result/AND$20NEGATION$20DATE$20LOGIC$20Test.c05e795b-4578-45b4-bb9b-81e42ab4de39.csv?pretty=false HTTP/1.1" 200 115 "-" "Conquery (test client)" 19
INFO  [2023-01-26 18:09:47,192] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest AND NEGATION DATE LOGIC Test on 3 rows
INFO  [2023-01-26 18:09:47,192] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast AND NEGATION DATE LOGIC Test
INFO  [2023-01-26 18:09:47,192] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=AND NEGATION DATE LOGIC Test, name=AND NEGATION DATE LOGIC Test]
INFO  [2023-01-26 18:09:47,192] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=AND NEGATION DATE LOGIC Test, name=AND NEGATION DATE LOGIC Test]
INFO  [2023-01-26 18:09:47,192] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_AND NEGATION DATE LOGIC Test_25d39566-1e15-40ed-8073-a2832fc5a6d2
INFO  [2023-01-26 18:09:47,192] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_AND NEGATION DATE LOGIC Test_6bb92958-726c-4ca7-bb21-b9a87d29aac0
INFO  [2023-01-26 18:09:47,252] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow AND NEGATION DATE LOGIC Test
INFO  [2023-01-26 18:09:47,252] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_AND NEGATION DATE LOGIC Test_25d39566-1e15-40ed-8073-a2832fc5a6d2
INFO  [2023-01-26 18:09:47,252] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_AND NEGATION DATE LOGIC Test_6bb92958-726c-4ca7-bb21-b9a87d29aac0
INFO  [2023-01-26 18:09:47,298] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of AND$20NEGATION$20DATE$20LOGIC$20Test
INFO  [2023-01-26 18:09:47,298] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:47,436] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test AND NEGATION DATE LOGIC Test
INFO  [2023-01-26 18:09:47,436] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test AND NEGATION DATE LOGIC Test
INFO  [2023-01-26 18:09:47,436] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:47,436] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:47,437] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=AND NEGATION DATE LOGIC Test[1], name=AND NEGATION DATE LOGIC Test[1]]
INFO  [2023-01-26 18:09:47,437] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=AND NEGATION DATE LOGIC Test[1], name=AND NEGATION DATE LOGIC Test[1]]
INFO  [2023-01-26 18:09:47,437] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:47,437] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:47,439] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker AND$20NEGATION$20DATE$20LOGIC$20Test[1].worker_AND$20NEGATION$20DATE$20LOGIC$20Test[1]_cd6912bb-be83-4dc2-b868-698115d292b4 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:47,439] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker AND$20NEGATION$20DATE$20LOGIC$20Test[1].worker_AND$20NEGATION$20DATE$20LOGIC$20Test[1]_cd6912bb-be83-4dc2-b868-698115d292b4 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:47,439] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:47,439] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker AND$20NEGATION$20DATE$20LOGIC$20Test[1].worker_AND$20NEGATION$20DATE$20LOGIC$20Test[1]_321d5b0d-428c-4a01-937e-a94805b454d4 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:47,439] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker AND$20NEGATION$20DATE$20LOGIC$20Test[1].worker_AND$20NEGATION$20DATE$20LOGIC$20Test[1]_321d5b0d-428c-4a01-937e-a94805b454d4 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:47,439] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:47,443] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:47,543] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:47,550] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:47,550] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table AND$20NEGATION$20DATE$20LOGIC$20Test[1].table
INFO  [2023-01-26 18:09:47,550] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table AND$20NEGATION$20DATE$20LOGIC$20Test[1].table
INFO  [2023-01-26 18:09:47,661] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:47,769] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:47,769] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:47,769] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 206 B in total
INFO  [2023-01-26 18:09:47,769] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND NEGATION DATE LOGIC Test[1]/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000191845sINFO  [2023-01-26 18:09:47,789] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=5, sum=11, min=1, average=2.200000, max=4}
INFO  [2023-01-26 18:09:47,789] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[column] with StringParser(super=Parser(lines=11, nullLines=1), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:47,789] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=11, nullLines=0), subType=IntegerParser(super=Parser(lines=11, nullLines=0), minValue=15340, maxValue=15344), dateReader=com.bakdata.conquery.util.DateReader@77b38759)
INFO  [2023-01-26 18:09:47,791] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND NEGATION DATE LOGIC Test[1]/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:47,791] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:47,791] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND NEGATION DATE LOGIC Test[1]/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:47,817] com.bakdata.conquery.models.jobs.ImportJob: Importing table into AND$20NEGATION$20DATE$20LOGIC$20Test[1].table
INFO  [2023-01-26 18:09:47,818] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:09:47 +0000] "POST /admin/datasets/AND%20NEGATION%20DATE%20LOGIC%20Test%5B1%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_AND+NEGATION+DATE+LOGIC+Test%5B1%5D%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:09:47,818] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:47,818] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:47,818] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:47,820] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:09:47,820] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[AND$20NEGATION$20DATE$20LOGIC$20Test[1].table.table], containing 11 entries.
INFO  [2023-01-26 18:09:47,820] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[AND$20NEGATION$20DATE$20LOGIC$20Test[1].table.table], containing 11 entries.
WARN  [2023-01-26 18:09:47,820] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:47,821] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received AND$20NEGATION$20DATE$20LOGIC$20Test[1].table.table.0
INFO  [2023-01-26 18:09:47,821] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received AND$20NEGATION$20DATE$20LOGIC$20Test[1].table.table.1
INFO  [2023-01-26 18:09:47,926] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:47,931] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:47,944] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:47,944] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:47,944] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:48,049] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: AND NEGATION DATE LOGIC Test QUERY INIT
INFO  [2023-01-26 18:09:48,061] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[AND$20NEGATION$20DATE$20LOGIC$20Test[1]] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:48,061] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[f3a95d63-cfaa-4845-aca3-c0d7d28c3100] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_AND NEGATION DATE LOGIC Test[1]))]]
INFO  [2023-01-26 18:09:48,064] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery AND$20NEGATION$20DATE$20LOGIC$20Test[1].f3a95d63-cfaa-4845-aca3-c0d7d28c3100
INFO  [2023-01-26 18:09:48,065] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[AND$20NEGATION$20DATE$20LOGIC$20Test[1].f3a95d63-cfaa-4845-aca3-c0d7d28c3100] with 1 results within PT0.000752S
INFO  [2023-01-26 18:09:48,065] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=AND$20NEGATION$20DATE$20LOGIC$20Test[1].f3a95d63-cfaa-4845-aca3-c0d7d28c3100, workerId=AND$20NEGATION$20DATE$20LOGIC$20Test[1].worker_AND$20NEGATION$20DATE$20LOGIC$20Test[1]_cd6912bb-be83-4dc2-b868-698115d292b4, startTime=2023-01-26T18:09:48.064352, finishTime=2023-01-26T18:09:48.065104) of size 1
INFO  [2023-01-26 18:09:48,068] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery AND$20NEGATION$20DATE$20LOGIC$20Test[1].f3a95d63-cfaa-4845-aca3-c0d7d28c3100
INFO  [2023-01-26 18:09:48,069] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[AND$20NEGATION$20DATE$20LOGIC$20Test[1].f3a95d63-cfaa-4845-aca3-c0d7d28c3100] with 1 results within PT0.000837S
127.0.0.1 - - [26/Jan/2023:18:09:48 +0000] "POST /api/datasets/AND$20NEGATION$20DATE$20LOGIC$20Test%5B1%5D/queries HTTP/1.1" 201 1794 "-" "Conquery (test client)" 10
INFO  [2023-01-26 18:09:48,069] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=AND$20NEGATION$20DATE$20LOGIC$20Test[1].f3a95d63-cfaa-4845-aca3-c0d7d28c3100, workerId=AND$20NEGATION$20DATE$20LOGIC$20Test[1].worker_AND$20NEGATION$20DATE$20LOGIC$20Test[1]_321d5b0d-428c-4a01-937e-a94805b454d4, startTime=2023-01-26T18:09:48.068472, finishTime=2023-01-26T18:09:48.069309) of size 1
INFO  [2023-01-26 18:09:48,069] com.bakdata.conquery.models.execution.ManagedExecution: DONE f3a95d63-cfaa-4845-aca3-c0d7d28c3100 ManagedQuery within PT0.008259S
127.0.0.1 - - [26/Jan/2023:18:09:48 +0000] "GET /api/datasets/AND$20NEGATION$20DATE$20LOGIC$20Test%5B1%5D/queries/AND$20NEGATION$20DATE$20LOGIC$20Test%5B1%5D.f3a95d63-cfaa-4845-aca3-c0d7d28c3100 HTTP/1.1" 200 2449 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:09:48,089] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=AND NEGATION DATE LOGIC Test[1]], queryId=f3a95d63-cfaa-4845-aca3-c0d7d28c3100, label=tree---a tree---b	@§$, creationTime=2023-01-26T18:09:48.061398, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@20fdaecc[Count = 0], startTime=2023-01-26T18:09:48.061560, finishTime=2023-01-26T18:09:48.069819, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@53183ef8), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_AND NEGATION DATE LOGIC Test[1])), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@1fa50483, com.bakdata.conquery.models.query.ColumnDescriptor@d9ab45a, com.bakdata.conquery.models.query.ColumnDescriptor@405ce0eb]) download on dataset Dataset[label=null, name=AND NEGATION DATE LOGIC Test[1]] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:48,089] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=AND NEGATION DATE LOGIC Test[1]], queryId=f3a95d63-cfaa-4845-aca3-c0d7d28c3100, label=tree---a tree---b	@§$, creationTime=2023-01-26T18:09:48.061398, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@20fdaecc[Count = 0], startTime=2023-01-26T18:09:48.061560, finishTime=2023-01-26T18:09:48.069819, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@53183ef8), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_AND NEGATION DATE LOGIC Test[1])), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@1fa50483, com.bakdata.conquery.models.query.ColumnDescriptor@d9ab45a, com.bakdata.conquery.models.query.ColumnDescriptor@405ce0eb]) on dataset Dataset[label=null, name=AND NEGATION DATE LOGIC Test[1]]
127.0.0.1 - - [26/Jan/2023:18:09:48 +0000] "GET /api/datasets/AND%20NEGATION%20DATE%20LOGIC%20Test%5B1%5D/result/AND$20NEGATION$20DATE$20LOGIC$20Test%5B1%5D.f3a95d63-cfaa-4845-aca3-c0d7d28c3100.csv?pretty=false HTTP/1.1" 200 91 "-" "Conquery (test client)" 33
INFO  [2023-01-26 18:09:48,122] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest AND NEGATION DATE LOGIC Test on 3 rows
INFO  [2023-01-26 18:09:48,122] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast AND NEGATION DATE LOGIC Test[1]
INFO  [2023-01-26 18:09:48,122] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=AND NEGATION DATE LOGIC Test[1], name=AND NEGATION DATE LOGIC Test[1]]
INFO  [2023-01-26 18:09:48,122] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=AND NEGATION DATE LOGIC Test[1], name=AND NEGATION DATE LOGIC Test[1]]
INFO  [2023-01-26 18:09:48,122] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_AND NEGATION DATE LOGIC Test[1]_321d5b0d-428c-4a01-937e-a94805b454d4
INFO  [2023-01-26 18:09:48,122] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_AND NEGATION DATE LOGIC Test[1]_cd6912bb-be83-4dc2-b868-698115d292b4
INFO  [2023-01-26 18:09:48,137] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow AND NEGATION DATE LOGIC Test[1]
INFO  [2023-01-26 18:09:48,138] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_AND NEGATION DATE LOGIC Test[1]_cd6912bb-be83-4dc2-b868-698115d292b4
INFO  [2023-01-26 18:09:48,138] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_AND NEGATION DATE LOGIC Test[1]_321d5b0d-428c-4a01-937e-a94805b454d4
INFO  [2023-01-26 18:09:48,236] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of AND$20NEGATION$20DATE$20LOGIC$20Test[1]
INFO  [2023-01-26 18:09:48,236] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:48,250] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test AND NEGATION DATE LOGIC Test
INFO  [2023-01-26 18:09:48,250] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test AND Test
INFO  [2023-01-26 18:09:48,250] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:48,250] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:48,252] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=AND Test[1], name=AND Test[1]]
INFO  [2023-01-26 18:09:48,252] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=AND Test[1], name=AND Test[1]]
INFO  [2023-01-26 18:09:48,252] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:48,252] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:48,255] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker AND$20Test[1].worker_AND$20Test[1]_f9aefc45-7ae4-48a9-b8f1-fad7da17697b are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:48,255] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker AND$20Test[1].worker_AND$20Test[1]_f9aefc45-7ae4-48a9-b8f1-fad7da17697b are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:48,255] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:48,255] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker AND$20Test[1].worker_AND$20Test[1]_4ba1b712-2900-427f-9a42-82b734264313 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:48,255] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker AND$20Test[1].worker_AND$20Test[1]_4ba1b712-2900-427f-9a42-82b734264313 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:48,255] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:48,259] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:48,358] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:48,365] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:48,365] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table AND$20Test[1].table
INFO  [2023-01-26 18:09:48,365] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table AND$20Test[1].table
INFO  [2023-01-26 18:09:48,478] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:48,589] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:48,590] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:48,590] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 152 B in total
INFO  [2023-01-26 18:09:48,590] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND Test[1]/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000421767sINFO  [2023-01-26 18:09:48,633] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=8, min=1, average=2.000000, max=3}
INFO  [2023-01-26 18:09:48,633] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[column] with StringParser(super=Parser(lines=8, nullLines=1), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:48,633] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=8, nullLines=0), subType=IntegerParser(super=Parser(lines=8, nullLines=0), minValue=15340, maxValue=15341), dateReader=com.bakdata.conquery.util.DateReader@238d12d0)
INFO  [2023-01-26 18:09:48,637] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND Test[1]/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:48,637] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:48,637] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND Test[1]/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:48,658] com.bakdata.conquery.models.jobs.ImportJob: Importing table into AND$20Test[1].table
INFO  [2023-01-26 18:09:48,659] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:09:48 +0000] "POST /admin/datasets/AND%20Test%5B1%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_AND+Test%5B1%5D%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 11
INFO  [2023-01-26 18:09:48,659] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:48,660] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:48,660] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:48,661] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:09:48,661] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[AND$20Test[1].table.table], containing 8 entries.
INFO  [2023-01-26 18:09:48,661] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[AND$20Test[1].table.table], containing 8 entries.
WARN  [2023-01-26 18:09:48,662] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:48,662] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received AND$20Test[1].table.table.0
INFO  [2023-01-26 18:09:48,662] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received AND$20Test[1].table.table.1
INFO  [2023-01-26 18:09:48,767] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:48,772] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:48,783] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:48,783] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:48,783] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:48,889] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: AND Test QUERY INIT
INFO  [2023-01-26 18:09:48,899] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[AND$20Test[1]] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:48,900] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[7700f7aa-5f1b-459f-8dce-ceeccfd08bb3] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_AND Test[1]))]]
INFO  [2023-01-26 18:09:48,902] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery AND$20Test[1].7700f7aa-5f1b-459f-8dce-ceeccfd08bb3
INFO  [2023-01-26 18:09:48,902] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery AND$20Test[1].7700f7aa-5f1b-459f-8dce-ceeccfd08bb3
INFO  [2023-01-26 18:09:48,903] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[AND$20Test[1].7700f7aa-5f1b-459f-8dce-ceeccfd08bb3] with 1 results within PT0.001006S
127.0.0.1 - - [26/Jan/2023:18:09:48 +0000] "POST /api/datasets/AND$20Test%5B1%5D/queries HTTP/1.1" 201 1668 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:09:48,904] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=AND$20Test[1].7700f7aa-5f1b-459f-8dce-ceeccfd08bb3, workerId=AND$20Test[1].worker_AND$20Test[1]_f9aefc45-7ae4-48a9-b8f1-fad7da17697b, startTime=2023-01-26T18:09:48.902916, finishTime=2023-01-26T18:09:48.903922) of size 1
INFO  [2023-01-26 18:09:48,904] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[AND$20Test[1].7700f7aa-5f1b-459f-8dce-ceeccfd08bb3] with 1 results within PT0.001751S
INFO  [2023-01-26 18:09:48,905] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=AND$20Test[1].7700f7aa-5f1b-459f-8dce-ceeccfd08bb3, workerId=AND$20Test[1].worker_AND$20Test[1]_4ba1b712-2900-427f-9a42-82b734264313, startTime=2023-01-26T18:09:48.902910, finishTime=2023-01-26T18:09:48.904661) of size 1
INFO  [2023-01-26 18:09:48,905] com.bakdata.conquery.models.execution.ManagedExecution: DONE 7700f7aa-5f1b-459f-8dce-ceeccfd08bb3 ManagedQuery within PT0.005225S
127.0.0.1 - - [26/Jan/2023:18:09:48 +0000] "GET /api/datasets/AND$20Test%5B1%5D/queries/AND$20Test%5B1%5D.7700f7aa-5f1b-459f-8dce-ceeccfd08bb3 HTTP/1.1" 200 2114 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:09:48,930] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=AND Test[1]], queryId=7700f7aa-5f1b-459f-8dce-ceeccfd08bb3, label=tree---a tree---b	@§$, creationTime=2023-01-26T18:09:48.899896, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@3c0c6917[Count = 0], startTime=2023-01-26T18:09:48.900105, finishTime=2023-01-26T18:09:48.905330, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@bfdbd30), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_AND Test[1])), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@24983837, com.bakdata.conquery.models.query.ColumnDescriptor@760111d1]) download on dataset Dataset[label=null, name=AND Test[1]] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:48,930] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=AND Test[1]], queryId=7700f7aa-5f1b-459f-8dce-ceeccfd08bb3, label=tree---a tree---b	@§$, creationTime=2023-01-26T18:09:48.899896, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@3c0c6917[Count = 0], startTime=2023-01-26T18:09:48.900105, finishTime=2023-01-26T18:09:48.905330, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@bfdbd30), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_AND Test[1])), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@24983837, com.bakdata.conquery.models.query.ColumnDescriptor@760111d1]) on dataset Dataset[label=null, name=AND Test[1]]
127.0.0.1 - - [26/Jan/2023:18:09:48 +0000] "GET /api/datasets/AND%20Test%5B1%5D/result/AND$20Test%5B1%5D.7700f7aa-5f1b-459f-8dce-ceeccfd08bb3.csv?pretty=false HTTP/1.1" 200 65 "-" "Conquery (test client)" 24
INFO  [2023-01-26 18:09:48,953] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest AND Test on 3 rows
INFO  [2023-01-26 18:09:48,953] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast AND Test[1]
INFO  [2023-01-26 18:09:48,954] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=AND Test[1], name=AND Test[1]]
INFO  [2023-01-26 18:09:48,954] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=AND Test[1], name=AND Test[1]]
INFO  [2023-01-26 18:09:48,954] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_AND Test[1]_f9aefc45-7ae4-48a9-b8f1-fad7da17697b
INFO  [2023-01-26 18:09:48,954] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_AND Test[1]_4ba1b712-2900-427f-9a42-82b734264313
INFO  [2023-01-26 18:09:48,958] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_AND Test[1]_f9aefc45-7ae4-48a9-b8f1-fad7da17697b
INFO  [2023-01-26 18:09:48,958] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow AND Test[1]
INFO  [2023-01-26 18:09:48,958] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_AND Test[1]_4ba1b712-2900-427f-9a42-82b734264313
INFO  [2023-01-26 18:09:48,962] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of AND$20Test[1]
INFO  [2023-01-26 18:09:48,962] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:49,088] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test AND Test
INFO  [2023-01-26 18:09:49,089] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test OR Test
INFO  [2023-01-26 18:09:49,089] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:49,089] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:49,096] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=OR Test, name=OR Test]
INFO  [2023-01-26 18:09:49,096] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:49,098] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=OR Test, name=OR Test]
INFO  [2023-01-26 18:09:49,098] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:49,104] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker OR$20Test.worker_OR$20Test_03d54b3d-8603-4329-8e70-399fd1f2a0fb are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:49,104] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker OR$20Test.worker_OR$20Test_03d54b3d-8603-4329-8e70-399fd1f2a0fb are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:49,104] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:49,108] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker OR$20Test.worker_OR$20Test_4df87969-6cba-427a-83ee-e0e221dc81dd are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:49,108] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker OR$20Test.worker_OR$20Test_4df87969-6cba-427a-83ee-e0e221dc81dd are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:49,108] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:49,112] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:49,215] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:49,222] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:49,222] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table OR$20Test.table
INFO  [2023-01-26 18:09:49,222] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table OR$20Test.table
INFO  [2023-01-26 18:09:49,333] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:49,440] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:49,440] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:49,440] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 167 B in total
INFO  [2023-01-26 18:09:49,441] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_OR Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000280902sINFO  [2023-01-26 18:09:49,469] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=5, sum=9, min=1, average=1.800000, max=3}
INFO  [2023-01-26 18:09:49,469] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[column] with StringParser(super=Parser(lines=9, nullLines=2), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:49,469] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=9, nullLines=0), subType=IntegerParser(super=Parser(lines=9, nullLines=0), minValue=15340, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@59e32d78)
INFO  [2023-01-26 18:09:49,473] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_OR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:49,473] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:49,473] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_OR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:49,490] com.bakdata.conquery.models.jobs.ImportJob: Importing table into OR$20Test.table
INFO  [2023-01-26 18:09:49,490] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:09:49 +0000] "POST /admin/datasets/OR%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_OR+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:09:49,491] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:49,492] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:49,492] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:49,493] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:09:49,493] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[OR$20Test.table.table], containing 9 entries.
INFO  [2023-01-26 18:09:49,493] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[OR$20Test.table.table], containing 9 entries.
WARN  [2023-01-26 18:09:49,494] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:49,494] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received OR$20Test.table.table.0
INFO  [2023-01-26 18:09:49,495] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received OR$20Test.table.table.1
INFO  [2023-01-26 18:09:49,599] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:49,604] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:49,619] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:49,619] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:49,619] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:49,743] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: OR Test QUERY INIT
INFO  [2023-01-26 18:09:49,754] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[OR$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:49,755] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[8b10fc7c-21e9-4926-bde9-80851f09f668] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_OR Test))]]
INFO  [2023-01-26 18:09:49,757] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery OR$20Test.8b10fc7c-21e9-4926-bde9-80851f09f668
INFO  [2023-01-26 18:09:49,757] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery OR$20Test.8b10fc7c-21e9-4926-bde9-80851f09f668
127.0.0.1 - - [26/Jan/2023:18:09:49 +0000] "POST /api/datasets/OR$20Test/queries HTTP/1.1" 201 1497 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:09:49,760] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[OR$20Test.8b10fc7c-21e9-4926-bde9-80851f09f668] with 1 results within PT0.002643S
INFO  [2023-01-26 18:09:49,760] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=OR$20Test.8b10fc7c-21e9-4926-bde9-80851f09f668, workerId=OR$20Test.worker_OR$20Test_4df87969-6cba-427a-83ee-e0e221dc81dd, startTime=2023-01-26T18:09:49.757742, finishTime=2023-01-26T18:09:49.760385) of size 1
INFO  [2023-01-26 18:09:49,762] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[OR$20Test.8b10fc7c-21e9-4926-bde9-80851f09f668] with 3 results within PT0.004253S
INFO  [2023-01-26 18:09:49,762] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=OR$20Test.8b10fc7c-21e9-4926-bde9-80851f09f668, workerId=OR$20Test.worker_OR$20Test_03d54b3d-8603-4329-8e70-399fd1f2a0fb, startTime=2023-01-26T18:09:49.757749, finishTime=2023-01-26T18:09:49.762002) of size 3
INFO  [2023-01-26 18:09:49,762] com.bakdata.conquery.models.execution.ManagedExecution: DONE 8b10fc7c-21e9-4926-bde9-80851f09f668 ManagedQuery within PT0.007393S
127.0.0.1 - - [26/Jan/2023:18:09:49 +0000] "GET /api/datasets/OR$20Test/queries/OR$20Test.8b10fc7c-21e9-4926-bde9-80851f09f668 HTTP/1.1" 200 1724 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:09:49,785] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=OR Test], queryId=8b10fc7c-21e9-4926-bde9-80851f09f668, label=tree---a tree---b	@§$, creationTime=2023-01-26T18:09:49.754881, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@6bca7400[Count = 0], startTime=2023-01-26T18:09:49.755084, finishTime=2023-01-26T18:09:49.762477, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@67cf907a), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_OR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@607126c2, com.bakdata.conquery.models.query.ColumnDescriptor@40b720b4, com.bakdata.conquery.models.query.ColumnDescriptor@786536d6]) download on dataset Dataset[label=null, name=OR Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:49,785] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=OR Test], queryId=8b10fc7c-21e9-4926-bde9-80851f09f668, label=tree---a tree---b	@§$, creationTime=2023-01-26T18:09:49.754881, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@6bca7400[Count = 0], startTime=2023-01-26T18:09:49.755084, finishTime=2023-01-26T18:09:49.762477, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@67cf907a), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_OR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@607126c2, com.bakdata.conquery.models.query.ColumnDescriptor@40b720b4, com.bakdata.conquery.models.query.ColumnDescriptor@786536d6]) on dataset Dataset[label=null, name=OR Test]
127.0.0.1 - - [26/Jan/2023:18:09:49 +0000] "GET /api/datasets/OR%20Test/result/OR$20Test.8b10fc7c-21e9-4926-bde9-80851f09f668.csv?pretty=false HTTP/1.1" 200 146 "-" "Conquery (test client)" 27
INFO  [2023-01-26 18:09:49,811] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest OR Test on 5 rows
INFO  [2023-01-26 18:09:49,811] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast OR Test
INFO  [2023-01-26 18:09:49,812] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=OR Test, name=OR Test]
INFO  [2023-01-26 18:09:49,812] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=OR Test, name=OR Test]
INFO  [2023-01-26 18:09:49,812] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_OR Test_4df87969-6cba-427a-83ee-e0e221dc81dd
INFO  [2023-01-26 18:09:49,815] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_OR Test_03d54b3d-8603-4329-8e70-399fd1f2a0fb
INFO  [2023-01-26 18:09:49,910] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow OR Test
INFO  [2023-01-26 18:09:49,910] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_OR Test_03d54b3d-8603-4329-8e70-399fd1f2a0fb
INFO  [2023-01-26 18:09:49,911] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_OR Test_4df87969-6cba-427a-83ee-e0e221dc81dd
INFO  [2023-01-26 18:09:50,010] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of OR$20Test
INFO  [2023-01-26 18:09:50,010] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:50,025] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test OR Test
INFO  [2023-01-26 18:09:50,025] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test OR_AND Select test
INFO  [2023-01-26 18:09:50,025] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:50,025] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:50,026] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=OR_AND Select test, name=OR_AND Select test]
INFO  [2023-01-26 18:09:50,026] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=OR_AND Select test, name=OR_AND Select test]
INFO  [2023-01-26 18:09:50,027] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:50,027] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:50,028] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:50,028] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker OR_AND$20Select$20test.worker_OR_AND$20Select$20test_d5077532-69e4-401e-82c3-5bd5b639e59c are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:50,028] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker OR_AND$20Select$20test.worker_OR_AND$20Select$20test_d5077532-69e4-401e-82c3-5bd5b639e59c are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:50,028] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:50,028] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker OR_AND$20Select$20test.worker_OR_AND$20Select$20test_8ca40513-6f48-4a86-91ae-cdaec361b1d7 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:50,028] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker OR_AND$20Select$20test.worker_OR_AND$20Select$20test_8ca40513-6f48-4a86-91ae-cdaec361b1d7 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:50,028] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:50,132] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:50,140] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:50,140] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table OR_AND$20Select$20test.table
INFO  [2023-01-26 18:09:50,140] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table OR_AND$20Select$20test.table
INFO  [2023-01-26 18:09:50,250] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:50,358] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:50,359] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:50,359] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 154 B in total
INFO  [2023-01-26 18:09:50,359] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_OR_AND Select test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000328903sINFO  [2023-01-26 18:09:50,392] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=8, min=1, average=2.000000, max=3}
INFO  [2023-01-26 18:09:50,392] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[column] with StringParser(super=Parser(lines=8, nullLines=1), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:50,392] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=8, nullLines=0), subType=IntegerParser(super=Parser(lines=8, nullLines=0), minValue=15340, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@3f324af9)
INFO  [2023-01-26 18:09:50,395] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_OR_AND Select test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:50,395] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:50,395] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_OR_AND Select test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:50,423] com.bakdata.conquery.models.jobs.ImportJob: Importing table into OR_AND$20Select$20test.table
127.0.0.1 - - [26/Jan/2023:18:09:50 +0000] "POST /admin/datasets/OR_AND%20Select%20test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_OR_AND+Select+test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:09:50,423] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:50,423] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:50,424] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:50,424] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:50,426] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:09:50,426] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[OR_AND$20Select$20test.table.table], containing 8 entries.
WARN  [2023-01-26 18:09:50,427] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:50,427] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received OR_AND$20Select$20test.table.table.0
INFO  [2023-01-26 18:09:50,427] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[OR_AND$20Select$20test.table.table], containing 8 entries.
INFO  [2023-01-26 18:09:50,427] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received OR_AND$20Select$20test.table.table.1
INFO  [2023-01-26 18:09:50,532] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:50,538] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:50,550] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:50,551] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:50,551] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:50,657] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: OR_AND Select test QUERY INIT
INFO  [2023-01-26 18:09:50,665] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[OR_AND$20Select$20test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:50,666] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[f49127b8-8227-4a54-ad0e-4f07f2307aa6] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_OR_AND Select test))]]
INFO  [2023-01-26 18:09:50,668] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery OR_AND$20Select$20test.f49127b8-8227-4a54-ad0e-4f07f2307aa6
INFO  [2023-01-26 18:09:50,668] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery OR_AND$20Select$20test.f49127b8-8227-4a54-ad0e-4f07f2307aa6
127.0.0.1 - - [26/Jan/2023:18:09:50 +0000] "POST /api/datasets/OR_AND$20Select$20test/queries HTTP/1.1" 201 2338 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:09:50,672] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[OR_AND$20Select$20test.f49127b8-8227-4a54-ad0e-4f07f2307aa6] with 1 results within PT0.003248S
INFO  [2023-01-26 18:09:50,672] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=OR_AND$20Select$20test.f49127b8-8227-4a54-ad0e-4f07f2307aa6, workerId=OR_AND$20Select$20test.worker_OR_AND$20Select$20test_d5077532-69e4-401e-82c3-5bd5b639e59c, startTime=2023-01-26T18:09:50.668820, finishTime=2023-01-26T18:09:50.672068) of size 1
INFO  [2023-01-26 18:09:50,676] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[OR_AND$20Select$20test.f49127b8-8227-4a54-ad0e-4f07f2307aa6] with 3 results within PT0.007289S
INFO  [2023-01-26 18:09:50,676] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=OR_AND$20Select$20test.f49127b8-8227-4a54-ad0e-4f07f2307aa6, workerId=OR_AND$20Select$20test.worker_OR_AND$20Select$20test_8ca40513-6f48-4a86-91ae-cdaec361b1d7, startTime=2023-01-26T18:09:50.668757, finishTime=2023-01-26T18:09:50.676046) of size 3
INFO  [2023-01-26 18:09:50,676] com.bakdata.conquery.models.execution.ManagedExecution: DONE f49127b8-8227-4a54-ad0e-4f07f2307aa6 ManagedQuery within PT0.010541S
127.0.0.1 - - [26/Jan/2023:18:09:50 +0000] "GET /api/datasets/OR_AND$20Select$20test/queries/OR_AND$20Select$20test.f49127b8-8227-4a54-ad0e-4f07f2307aa6 HTTP/1.1" 200 2618 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:09:50,690] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=OR_AND Select test], queryId=f49127b8-8227-4a54-ad0e-4f07f2307aa6, label=tree---a tree---b	@§$, creationTime=2023-01-26T18:09:50.665951, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@1a33ad54[Count = 0], startTime=2023-01-26T18:09:50.666154, finishTime=2023-01-26T18:09:50.676695, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@74d4d8e4), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_OR_AND Select test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@4df5942f, com.bakdata.conquery.models.query.ColumnDescriptor@83394, com.bakdata.conquery.models.query.ColumnDescriptor@7d667cc, com.bakdata.conquery.models.query.ColumnDescriptor@55179c2a]) download on dataset Dataset[label=null, name=OR_AND Select test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:50,691] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=OR_AND Select test], queryId=f49127b8-8227-4a54-ad0e-4f07f2307aa6, label=tree---a tree---b	@§$, creationTime=2023-01-26T18:09:50.665951, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@1a33ad54[Count = 0], startTime=2023-01-26T18:09:50.666154, finishTime=2023-01-26T18:09:50.676695, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@74d4d8e4), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_OR_AND Select test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@4df5942f, com.bakdata.conquery.models.query.ColumnDescriptor@83394, com.bakdata.conquery.models.query.ColumnDescriptor@7d667cc, com.bakdata.conquery.models.query.ColumnDescriptor@55179c2a]) on dataset Dataset[label=null, name=OR_AND Select test]
127.0.0.1 - - [26/Jan/2023:18:09:50 +0000] "GET /api/datasets/OR_AND%20Select%20test/result/OR_AND$20Select$20test.f49127b8-8227-4a54-ad0e-4f07f2307aa6.csv?pretty=false HTTP/1.1" 200 176 "-" "Conquery (test client)" 33
INFO  [2023-01-26 18:09:50,723] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest OR_AND Select test on 5 rows
INFO  [2023-01-26 18:09:50,723] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast OR_AND Select test
INFO  [2023-01-26 18:09:50,723] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=OR_AND Select test, name=OR_AND Select test]
INFO  [2023-01-26 18:09:50,723] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=OR_AND Select test, name=OR_AND Select test]
INFO  [2023-01-26 18:09:50,723] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_OR_AND Select test_d5077532-69e4-401e-82c3-5bd5b639e59c
INFO  [2023-01-26 18:09:50,723] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_OR_AND Select test_8ca40513-6f48-4a86-91ae-cdaec361b1d7
INFO  [2023-01-26 18:09:50,727] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow OR_AND Select test
INFO  [2023-01-26 18:09:50,727] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of OR_AND$20Select$20test
INFO  [2023-01-26 18:09:50,727] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:50,727] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_OR_AND Select test_d5077532-69e4-401e-82c3-5bd5b639e59c
INFO  [2023-01-26 18:09:50,727] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_OR_AND Select test_8ca40513-6f48-4a86-91ae-cdaec361b1d7
INFO  [2023-01-26 18:09:50,856] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test OR_AND Select test
INFO  [2023-01-26 18:09:50,856] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test OR DATE LOGIC Test
INFO  [2023-01-26 18:09:50,856] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:50,856] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:50,860] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=OR DATE LOGIC Test, name=OR DATE LOGIC Test]
INFO  [2023-01-26 18:09:50,860] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=OR DATE LOGIC Test, name=OR DATE LOGIC Test]
INFO  [2023-01-26 18:09:50,860] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:50,860] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:50,863] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker OR$20DATE$20LOGIC$20Test.worker_OR$20DATE$20LOGIC$20Test_517eb6b9-b551-495d-949f-e2143f0e6840 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:50,863] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker OR$20DATE$20LOGIC$20Test.worker_OR$20DATE$20LOGIC$20Test_517eb6b9-b551-495d-949f-e2143f0e6840 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:50,863] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:50,863] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker OR$20DATE$20LOGIC$20Test.worker_OR$20DATE$20LOGIC$20Test_1a306032-070a-477b-9cce-76cd8165f0b3 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:50,863] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker OR$20DATE$20LOGIC$20Test.worker_OR$20DATE$20LOGIC$20Test_1a306032-070a-477b-9cce-76cd8165f0b3 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:50,863] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:50,866] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:50,965] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:50,973] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:50,974] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table OR$20DATE$20LOGIC$20Test.table
INFO  [2023-01-26 18:09:50,974] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table OR$20DATE$20LOGIC$20Test.table
INFO  [2023-01-26 18:09:51,088] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:51,197] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:51,197] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:51,197] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 240 B in total
INFO  [2023-01-26 18:09:51,197] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_OR DATE LOGIC Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000264701sINFO  [2023-01-26 18:09:51,224] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=5, sum=13, min=2, average=2.600000, max=4}
INFO  [2023-01-26 18:09:51,224] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[column] with StringParser(super=Parser(lines=13, nullLines=1), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:51,224] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=13, nullLines=0), subType=IntegerParser(super=Parser(lines=13, nullLines=0), minValue=15340, maxValue=15344), dateReader=com.bakdata.conquery.util.DateReader@54d08b09)
INFO  [2023-01-26 18:09:51,228] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_OR DATE LOGIC Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:51,228] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:51,228] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_OR DATE LOGIC Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:51,247] com.bakdata.conquery.models.jobs.ImportJob: Importing table into OR$20DATE$20LOGIC$20Test.table
127.0.0.1 - - [26/Jan/2023:18:09:51 +0000] "POST /admin/datasets/OR%20DATE%20LOGIC%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_OR+DATE+LOGIC+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 11
INFO  [2023-01-26 18:09:51,248] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:51,248] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:51,249] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:51,249] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:51,250] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:09:51,250] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[OR$20DATE$20LOGIC$20Test.table.table], containing 13 entries.
INFO  [2023-01-26 18:09:51,250] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[OR$20DATE$20LOGIC$20Test.table.table], containing 13 entries.
WARN  [2023-01-26 18:09:51,251] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:51,251] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received OR$20DATE$20LOGIC$20Test.table.table.0
INFO  [2023-01-26 18:09:51,251] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received OR$20DATE$20LOGIC$20Test.table.table.1
INFO  [2023-01-26 18:09:51,356] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:51,361] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:51,378] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:51,378] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:51,378] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:51,484] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: OR DATE LOGIC Test QUERY INIT
INFO  [2023-01-26 18:09:51,497] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[OR$20DATE$20LOGIC$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:51,498] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[bb812df5-716e-4525-ae44-d336f3cfa030] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_OR DATE LOGIC Test))]]
INFO  [2023-01-26 18:09:51,501] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery OR$20DATE$20LOGIC$20Test.bb812df5-716e-4525-ae44-d336f3cfa030
INFO  [2023-01-26 18:09:51,501] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery OR$20DATE$20LOGIC$20Test.bb812df5-716e-4525-ae44-d336f3cfa030
127.0.0.1 - - [26/Jan/2023:18:09:51 +0000] "POST /api/datasets/OR$20DATE$20LOGIC$20Test/queries HTTP/1.1" 201 1574 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:09:51,502] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[OR$20DATE$20LOGIC$20Test.bb812df5-716e-4525-ae44-d336f3cfa030] with 2 results within PT0.001092S
INFO  [2023-01-26 18:09:51,502] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[OR$20DATE$20LOGIC$20Test.bb812df5-716e-4525-ae44-d336f3cfa030] with 3 results within PT0.001191S
INFO  [2023-01-26 18:09:51,502] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=OR$20DATE$20LOGIC$20Test.bb812df5-716e-4525-ae44-d336f3cfa030, workerId=OR$20DATE$20LOGIC$20Test.worker_OR$20DATE$20LOGIC$20Test_517eb6b9-b551-495d-949f-e2143f0e6840, startTime=2023-01-26T18:09:51.501273, finishTime=2023-01-26T18:09:51.502365) of size 2
INFO  [2023-01-26 18:09:51,502] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=OR$20DATE$20LOGIC$20Test.bb812df5-716e-4525-ae44-d336f3cfa030, workerId=OR$20DATE$20LOGIC$20Test.worker_OR$20DATE$20LOGIC$20Test_1a306032-070a-477b-9cce-76cd8165f0b3, startTime=2023-01-26T18:09:51.501178, finishTime=2023-01-26T18:09:51.502369) of size 3
INFO  [2023-01-26 18:09:51,503] com.bakdata.conquery.models.execution.ManagedExecution: DONE bb812df5-716e-4525-ae44-d336f3cfa030 ManagedQuery within PT0.004702S
127.0.0.1 - - [26/Jan/2023:18:09:51 +0000] "GET /api/datasets/OR$20DATE$20LOGIC$20Test/queries/OR$20DATE$20LOGIC$20Test.bb812df5-716e-4525-ae44-d336f3cfa030 HTTP/1.1" 200 1861 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:09:51,520] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=OR DATE LOGIC Test], queryId=bb812df5-716e-4525-ae44-d336f3cfa030, label=tree---a tree---b	@§$, creationTime=2023-01-26T18:09:51.498144, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@459a01e[Count = 0], startTime=2023-01-26T18:09:51.498337, finishTime=2023-01-26T18:09:51.503039, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@83f5e4f), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_OR DATE LOGIC Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=5, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@28054ab4, com.bakdata.conquery.models.query.ColumnDescriptor@5e8fad84, com.bakdata.conquery.models.query.ColumnDescriptor@179fbf1b]) download on dataset Dataset[label=null, name=OR DATE LOGIC Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:51,520] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=OR DATE LOGIC Test], queryId=bb812df5-716e-4525-ae44-d336f3cfa030, label=tree---a tree---b	@§$, creationTime=2023-01-26T18:09:51.498144, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@459a01e[Count = 0], startTime=2023-01-26T18:09:51.498337, finishTime=2023-01-26T18:09:51.503039, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@83f5e4f), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_OR DATE LOGIC Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=5, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@28054ab4, com.bakdata.conquery.models.query.ColumnDescriptor@5e8fad84, com.bakdata.conquery.models.query.ColumnDescriptor@179fbf1b]) on dataset Dataset[label=null, name=OR DATE LOGIC Test]
INFO  [2023-01-26 18:09:51,535] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest OR DATE LOGIC Test on 6 rows
127.0.0.1 - - [26/Jan/2023:18:09:51 +0000] "GET /api/datasets/OR%20DATE%20LOGIC%20Test/result/OR$20DATE$20LOGIC$20Test.bb812df5-716e-4525-ae44-d336f3cfa030.csv?pretty=false HTTP/1.1" 200 220 "-" "Conquery (test client)" 17
INFO  [2023-01-26 18:09:51,536] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast OR DATE LOGIC Test
INFO  [2023-01-26 18:09:51,536] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=OR DATE LOGIC Test, name=OR DATE LOGIC Test]
INFO  [2023-01-26 18:09:51,536] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=OR DATE LOGIC Test, name=OR DATE LOGIC Test]
INFO  [2023-01-26 18:09:51,536] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_OR DATE LOGIC Test_517eb6b9-b551-495d-949f-e2143f0e6840
INFO  [2023-01-26 18:09:51,536] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_OR DATE LOGIC Test_1a306032-070a-477b-9cce-76cd8165f0b3
INFO  [2023-01-26 18:09:51,558] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow OR DATE LOGIC Test
INFO  [2023-01-26 18:09:51,561] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_OR DATE LOGIC Test_517eb6b9-b551-495d-949f-e2143f0e6840
INFO  [2023-01-26 18:09:51,561] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_OR DATE LOGIC Test_1a306032-070a-477b-9cce-76cd8165f0b3
INFO  [2023-01-26 18:09:51,651] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of OR$20DATE$20LOGIC$20Test
INFO  [2023-01-26 18:09:51,651] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:51,683] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test OR DATE LOGIC Test
INFO  [2023-01-26 18:09:51,684] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test AND DURATION SUM Test
INFO  [2023-01-26 18:09:51,684] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:51,684] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:51,685] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=AND DURATION SUM Test[2], name=AND DURATION SUM Test[2]]
INFO  [2023-01-26 18:09:51,685] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=AND DURATION SUM Test[2], name=AND DURATION SUM Test[2]]
INFO  [2023-01-26 18:09:51,685] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:51,685] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:51,688] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker AND$20DURATION$20SUM$20Test[2].worker_AND$20DURATION$20SUM$20Test[2]_995d7e52-cda8-4097-9236-895cb38b9b8e are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:51,688] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker AND$20DURATION$20SUM$20Test[2].worker_AND$20DURATION$20SUM$20Test[2]_995d7e52-cda8-4097-9236-895cb38b9b8e are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:51,688] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:51,688] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker AND$20DURATION$20SUM$20Test[2].worker_AND$20DURATION$20SUM$20Test[2]_460eadb4-ebed-433d-94f3-8c994e967480 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:51,688] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker AND$20DURATION$20SUM$20Test[2].worker_AND$20DURATION$20SUM$20Test[2]_460eadb4-ebed-433d-94f3-8c994e967480 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:51,688] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:51,692] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:51,791] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:51,798] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:51,798] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table AND$20DURATION$20SUM$20Test[2].table
INFO  [2023-01-26 18:09:51,798] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table AND$20DURATION$20SUM$20Test[2].table
INFO  [2023-01-26 18:09:51,910] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:52,022] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:52,022] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:52,022] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 307 B in total
INFO  [2023-01-26 18:09:52,022] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND DURATION SUM Test[2]/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000206741sINFO  [2023-01-26 18:09:52,043] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=5, sum=17, min=2, average=3.400000, max=8}
INFO  [2023-01-26 18:09:52,043] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[column] with StringParser(super=Parser(lines=17, nullLines=1), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:52,043] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=17, nullLines=0), subType=IntegerParser(super=Parser(lines=17, nullLines=0), minValue=15340, maxValue=15344), dateReader=com.bakdata.conquery.util.DateReader@1f8008d1)
INFO  [2023-01-26 18:09:52,047] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND DURATION SUM Test[2]/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:52,047] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:52,047] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND DURATION SUM Test[2]/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:52,065] com.bakdata.conquery.models.jobs.ImportJob: Importing table into AND$20DURATION$20SUM$20Test[2].table
127.0.0.1 - - [26/Jan/2023:18:09:52 +0000] "POST /admin/datasets/AND%20DURATION%20SUM%20Test%5B2%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_AND+DURATION+SUM+Test%5B2%5D%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:09:52,066] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:52,066] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:52,066] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:52,066] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:52,068] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:09:52,068] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[AND$20DURATION$20SUM$20Test[2].table.table], containing 17 entries.
INFO  [2023-01-26 18:09:52,068] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[AND$20DURATION$20SUM$20Test[2].table.table], containing 17 entries.
WARN  [2023-01-26 18:09:52,069] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:52,069] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received AND$20DURATION$20SUM$20Test[2].table.table.0
INFO  [2023-01-26 18:09:52,069] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received AND$20DURATION$20SUM$20Test[2].table.table.1
INFO  [2023-01-26 18:09:52,174] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:52,179] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:52,193] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:52,194] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:52,194] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:52,300] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: AND DURATION SUM Test QUERY INIT
INFO  [2023-01-26 18:09:52,310] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[AND$20DURATION$20SUM$20Test[2]] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:52,311] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[6eed62e6-0632-48fe-9ad9-ee563f41db04] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_AND DURATION SUM Test[2]))]]
INFO  [2023-01-26 18:09:52,313] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery AND$20DURATION$20SUM$20Test[2].6eed62e6-0632-48fe-9ad9-ee563f41db04
INFO  [2023-01-26 18:09:52,313] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery AND$20DURATION$20SUM$20Test[2].6eed62e6-0632-48fe-9ad9-ee563f41db04
127.0.0.1 - - [26/Jan/2023:18:09:52 +0000] "POST /api/datasets/AND$20DURATION$20SUM$20Test%5B2%5D/queries HTTP/1.1" 201 1872 "-" "Conquery (test client)" 5
INFO  [2023-01-26 18:09:52,319] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[AND$20DURATION$20SUM$20Test[2].6eed62e6-0632-48fe-9ad9-ee563f41db04] with 2 results within PT0.005501S
INFO  [2023-01-26 18:09:52,319] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=AND$20DURATION$20SUM$20Test[2].6eed62e6-0632-48fe-9ad9-ee563f41db04, workerId=AND$20DURATION$20SUM$20Test[2].worker_AND$20DURATION$20SUM$20Test[2]_995d7e52-cda8-4097-9236-895cb38b9b8e, startTime=2023-01-26T18:09:52.313631, finishTime=2023-01-26T18:09:52.319132) of size 2
INFO  [2023-01-26 18:09:52,319] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[AND$20DURATION$20SUM$20Test[2].6eed62e6-0632-48fe-9ad9-ee563f41db04] with 2 results within PT0.00616S
INFO  [2023-01-26 18:09:52,320] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=AND$20DURATION$20SUM$20Test[2].6eed62e6-0632-48fe-9ad9-ee563f41db04, workerId=AND$20DURATION$20SUM$20Test[2].worker_AND$20DURATION$20SUM$20Test[2]_460eadb4-ebed-433d-94f3-8c994e967480, startTime=2023-01-26T18:09:52.313819, finishTime=2023-01-26T18:09:52.319979) of size 2
INFO  [2023-01-26 18:09:52,320] com.bakdata.conquery.models.execution.ManagedExecution: DONE 6eed62e6-0632-48fe-9ad9-ee563f41db04 ManagedQuery within PT0.009131S
127.0.0.1 - - [26/Jan/2023:18:09:52 +0000] "GET /api/datasets/AND$20DURATION$20SUM$20Test%5B2%5D/queries/AND$20DURATION$20SUM$20Test%5B2%5D.6eed62e6-0632-48fe-9ad9-ee563f41db04 HTTP/1.1" 200 2454 "-" "Conquery (test client)" 4
INFO  [2023-01-26 18:09:52,338] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=AND DURATION SUM Test[2]], queryId=6eed62e6-0632-48fe-9ad9-ee563f41db04, label=tree---a tree---b	@§$, creationTime=2023-01-26T18:09:52.311154, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@63176e9d[Count = 0], startTime=2023-01-26T18:09:52.311389, finishTime=2023-01-26T18:09:52.320520, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@21cc84f7), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_AND DURATION SUM Test[2])), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@5689fa69, com.bakdata.conquery.models.query.ColumnDescriptor@7e5eb364, com.bakdata.conquery.models.query.ColumnDescriptor@26e559b4, com.bakdata.conquery.models.query.ColumnDescriptor@634b9aa3]) download on dataset Dataset[label=null, name=AND DURATION SUM Test[2]] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:52,338] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=AND DURATION SUM Test[2]], queryId=6eed62e6-0632-48fe-9ad9-ee563f41db04, label=tree---a tree---b	@§$, creationTime=2023-01-26T18:09:52.311154, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@63176e9d[Count = 0], startTime=2023-01-26T18:09:52.311389, finishTime=2023-01-26T18:09:52.320520, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@21cc84f7), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_AND DURATION SUM Test[2])), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@5689fa69, com.bakdata.conquery.models.query.ColumnDescriptor@7e5eb364, com.bakdata.conquery.models.query.ColumnDescriptor@26e559b4, com.bakdata.conquery.models.query.ColumnDescriptor@634b9aa3]) on dataset Dataset[label=null, name=AND DURATION SUM Test[2]]
127.0.0.1 - - [26/Jan/2023:18:09:52 +0000] "GET /api/datasets/AND%20DURATION%20SUM%20Test%5B2%5D/result/AND$20DURATION$20SUM$20Test%5B2%5D.6eed62e6-0632-48fe-9ad9-ee563f41db04.csv?pretty=false HTTP/1.1" 200 181 "-" "Conquery (test client)" 23
INFO  [2023-01-26 18:09:52,359] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest AND DURATION SUM Test on 5 rows
INFO  [2023-01-26 18:09:52,359] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast AND DURATION SUM Test[2]
INFO  [2023-01-26 18:09:52,359] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=AND DURATION SUM Test[2], name=AND DURATION SUM Test[2]]
INFO  [2023-01-26 18:09:52,360] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=AND DURATION SUM Test[2], name=AND DURATION SUM Test[2]]
INFO  [2023-01-26 18:09:52,360] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_AND DURATION SUM Test[2]_995d7e52-cda8-4097-9236-895cb38b9b8e
INFO  [2023-01-26 18:09:52,360] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_AND DURATION SUM Test[2]_460eadb4-ebed-433d-94f3-8c994e967480
INFO  [2023-01-26 18:09:52,393] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow AND DURATION SUM Test[2]
INFO  [2023-01-26 18:09:52,393] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_AND DURATION SUM Test[2]_995d7e52-cda8-4097-9236-895cb38b9b8e
INFO  [2023-01-26 18:09:52,393] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_AND DURATION SUM Test[2]_460eadb4-ebed-433d-94f3-8c994e967480
INFO  [2023-01-26 18:09:52,469] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of AND$20DURATION$20SUM$20Test[2]
INFO  [2023-01-26 18:09:52,469] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:52,500] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test AND DURATION SUM Test
INFO  [2023-01-26 18:09:52,500] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test AND DURATION SUM Test
INFO  [2023-01-26 18:09:52,500] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:52,500] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:52,501] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=AND DURATION SUM Test[3], name=AND DURATION SUM Test[3]]
INFO  [2023-01-26 18:09:52,501] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=AND DURATION SUM Test[3], name=AND DURATION SUM Test[3]]
INFO  [2023-01-26 18:09:52,501] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:52,501] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:52,502] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker AND$20DURATION$20SUM$20Test[3].worker_AND$20DURATION$20SUM$20Test[3]_c25ffaba-5e37-4d67-827b-d16ff3e65e89 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:52,502] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker AND$20DURATION$20SUM$20Test[3].worker_AND$20DURATION$20SUM$20Test[3]_c25ffaba-5e37-4d67-827b-d16ff3e65e89 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:52,502] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:52,502] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker AND$20DURATION$20SUM$20Test[3].worker_AND$20DURATION$20SUM$20Test[3]_142b01da-3a43-4e46-ab4f-c2a09386d2f7 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:52,502] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker AND$20DURATION$20SUM$20Test[3].worker_AND$20DURATION$20SUM$20Test[3]_142b01da-3a43-4e46-ab4f-c2a09386d2f7 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:52,502] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:52,507] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:52,607] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:52,621] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:52,622] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table AND$20DURATION$20SUM$20Test[3].table
INFO  [2023-01-26 18:09:52,622] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table AND$20DURATION$20SUM$20Test[3].table
INFO  [2023-01-26 18:09:52,736] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:52,847] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:52,847] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:52,848] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 308 B in total
INFO  [2023-01-26 18:09:52,848] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND DURATION SUM Test[3]/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000372314sINFO  [2023-01-26 18:09:52,885] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=5, sum=17, min=2, average=3.400000, max=8}
INFO  [2023-01-26 18:09:52,886] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[column] with StringParser(super=Parser(lines=17, nullLines=1), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:52,886] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=17, nullLines=0), subType=IntegerParser(super=Parser(lines=17, nullLines=0), minValue=15340, maxValue=15344), dateReader=com.bakdata.conquery.util.DateReader@5fc86eb4)
INFO  [2023-01-26 18:09:52,889] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND DURATION SUM Test[3]/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:52,889] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:52,889] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND DURATION SUM Test[3]/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:52,905] com.bakdata.conquery.models.jobs.ImportJob: Importing table into AND$20DURATION$20SUM$20Test[3].table
INFO  [2023-01-26 18:09:52,905] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:09:52 +0000] "POST /admin/datasets/AND%20DURATION%20SUM%20Test%5B3%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_AND+DURATION+SUM+Test%5B3%5D%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:09:52,906] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:52,907] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:52,907] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:52,909] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:09:52,909] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[AND$20DURATION$20SUM$20Test[3].table.table], containing 17 entries.
INFO  [2023-01-26 18:09:52,909] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[AND$20DURATION$20SUM$20Test[3].table.table], containing 17 entries.
WARN  [2023-01-26 18:09:52,910] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:52,910] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received AND$20DURATION$20SUM$20Test[3].table.table.0
INFO  [2023-01-26 18:09:52,910] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received AND$20DURATION$20SUM$20Test[3].table.table.1
INFO  [2023-01-26 18:09:53,015] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:53,020] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:53,032] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:53,032] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:53,032] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:53,154] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: AND DURATION SUM Test QUERY INIT
INFO  [2023-01-26 18:09:53,164] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[AND$20DURATION$20SUM$20Test[3]] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:53,164] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[f0c2e0a0-089b-4e44-98b1-5055461f3662] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_AND DURATION SUM Test[3]))]]
INFO  [2023-01-26 18:09:53,166] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery AND$20DURATION$20SUM$20Test[3].f0c2e0a0-089b-4e44-98b1-5055461f3662
INFO  [2023-01-26 18:09:53,166] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery AND$20DURATION$20SUM$20Test[3].f0c2e0a0-089b-4e44-98b1-5055461f3662
127.0.0.1 - - [26/Jan/2023:18:09:53 +0000] "POST /api/datasets/AND$20DURATION$20SUM$20Test%5B3%5D/queries HTTP/1.1" 201 1697 "-" "Conquery (test client)" 5
INFO  [2023-01-26 18:09:53,167] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[AND$20DURATION$20SUM$20Test[3].f0c2e0a0-089b-4e44-98b1-5055461f3662] with 2 results within PT0.001546S
INFO  [2023-01-26 18:09:53,168] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[AND$20DURATION$20SUM$20Test[3].f0c2e0a0-089b-4e44-98b1-5055461f3662] with 2 results within PT0.001773S
INFO  [2023-01-26 18:09:53,168] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=AND$20DURATION$20SUM$20Test[3].f0c2e0a0-089b-4e44-98b1-5055461f3662, workerId=AND$20DURATION$20SUM$20Test[3].worker_AND$20DURATION$20SUM$20Test[3]_142b01da-3a43-4e46-ab4f-c2a09386d2f7, startTime=2023-01-26T18:09:53.166318, finishTime=2023-01-26T18:09:53.167864) of size 2
INFO  [2023-01-26 18:09:53,168] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=AND$20DURATION$20SUM$20Test[3].f0c2e0a0-089b-4e44-98b1-5055461f3662, workerId=AND$20DURATION$20SUM$20Test[3].worker_AND$20DURATION$20SUM$20Test[3]_c25ffaba-5e37-4d67-827b-d16ff3e65e89, startTime=2023-01-26T18:09:53.166334, finishTime=2023-01-26T18:09:53.168107) of size 2
INFO  [2023-01-26 18:09:53,168] com.bakdata.conquery.models.execution.ManagedExecution: DONE f0c2e0a0-089b-4e44-98b1-5055461f3662 ManagedQuery within PT0.004015S
127.0.0.1 - - [26/Jan/2023:18:09:53 +0000] "GET /api/datasets/AND$20DURATION$20SUM$20Test%5B3%5D/queries/AND$20DURATION$20SUM$20Test%5B3%5D.f0c2e0a0-089b-4e44-98b1-5055461f3662 HTTP/1.1" 200 2280 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:09:53,187] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=AND DURATION SUM Test[3]], queryId=f0c2e0a0-089b-4e44-98b1-5055461f3662, label=tree---a tree---b	@§$, creationTime=2023-01-26T18:09:53.164397, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@1a8bca5c[Count = 0], startTime=2023-01-26T18:09:53.164529, finishTime=2023-01-26T18:09:53.168544, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@47b87e32), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_AND DURATION SUM Test[3])), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@1900866e, com.bakdata.conquery.models.query.ColumnDescriptor@1d06b159, com.bakdata.conquery.models.query.ColumnDescriptor@599b418f]) download on dataset Dataset[label=null, name=AND DURATION SUM Test[3]] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:53,187] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=AND DURATION SUM Test[3]], queryId=f0c2e0a0-089b-4e44-98b1-5055461f3662, label=tree---a tree---b	@§$, creationTime=2023-01-26T18:09:53.164397, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@1a8bca5c[Count = 0], startTime=2023-01-26T18:09:53.164529, finishTime=2023-01-26T18:09:53.168544, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@47b87e32), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_AND DURATION SUM Test[3])), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@1900866e, com.bakdata.conquery.models.query.ColumnDescriptor@1d06b159, com.bakdata.conquery.models.query.ColumnDescriptor@599b418f]) on dataset Dataset[label=null, name=AND DURATION SUM Test[3]]
127.0.0.1 - - [26/Jan/2023:18:09:53 +0000] "GET /api/datasets/AND%20DURATION%20SUM%20Test%5B3%5D/result/AND$20DURATION$20SUM$20Test%5B3%5D.f0c2e0a0-089b-4e44-98b1-5055461f3662.csv?pretty=false HTTP/1.1" 200 230 "-" "Conquery (test client)" 35
INFO  [2023-01-26 18:09:53,221] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest AND DURATION SUM Test on 5 rows
INFO  [2023-01-26 18:09:53,221] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast AND DURATION SUM Test[3]
INFO  [2023-01-26 18:09:53,221] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=AND DURATION SUM Test[3], name=AND DURATION SUM Test[3]]
INFO  [2023-01-26 18:09:53,221] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=AND DURATION SUM Test[3], name=AND DURATION SUM Test[3]]
INFO  [2023-01-26 18:09:53,221] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_AND DURATION SUM Test[3]_142b01da-3a43-4e46-ab4f-c2a09386d2f7
INFO  [2023-01-26 18:09:53,221] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_AND DURATION SUM Test[3]_c25ffaba-5e37-4d67-827b-d16ff3e65e89
INFO  [2023-01-26 18:09:53,321] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow AND DURATION SUM Test[3]
INFO  [2023-01-26 18:09:53,321] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_AND DURATION SUM Test[3]_c25ffaba-5e37-4d67-827b-d16ff3e65e89
INFO  [2023-01-26 18:09:53,321] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_AND DURATION SUM Test[3]_142b01da-3a43-4e46-ab4f-c2a09386d2f7
INFO  [2023-01-26 18:09:53,421] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of AND$20DURATION$20SUM$20Test[3]
INFO  [2023-01-26 18:09:53,421] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:53,455] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test AND DURATION SUM Test
INFO  [2023-01-26 18:09:53,455] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test AND DURATION SUM Test
INFO  [2023-01-26 18:09:53,455] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:53,455] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:53,463] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=AND DURATION SUM Test[4], name=AND DURATION SUM Test[4]]
INFO  [2023-01-26 18:09:53,463] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=AND DURATION SUM Test[4], name=AND DURATION SUM Test[4]]
INFO  [2023-01-26 18:09:53,463] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:53,463] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:53,472] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker AND$20DURATION$20SUM$20Test[4].worker_AND$20DURATION$20SUM$20Test[4]_fd441551-a8db-448d-930c-32fac0439a3d are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:53,472] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker AND$20DURATION$20SUM$20Test[4].worker_AND$20DURATION$20SUM$20Test[4]_fd441551-a8db-448d-930c-32fac0439a3d are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:53,472] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:53,476] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker AND$20DURATION$20SUM$20Test[4].worker_AND$20DURATION$20SUM$20Test[4]_11e54b87-0867-4a33-8af0-2a6b0ec9fcf5 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:53,476] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker AND$20DURATION$20SUM$20Test[4].worker_AND$20DURATION$20SUM$20Test[4]_11e54b87-0867-4a33-8af0-2a6b0ec9fcf5 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:53,476] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:53,479] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:53,580] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:53,586] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:53,587] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table AND$20DURATION$20SUM$20Test[4].table
INFO  [2023-01-26 18:09:53,587] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table AND$20DURATION$20SUM$20Test[4].table
INFO  [2023-01-26 18:09:53,698] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:53,806] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:53,806] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:53,806] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 308 B in total
INFO  [2023-01-26 18:09:53,806] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND DURATION SUM Test[4]/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000614869sINFO  [2023-01-26 18:09:53,869] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=5, sum=17, min=2, average=3.400000, max=8}
INFO  [2023-01-26 18:09:53,869] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[column] with StringParser(super=Parser(lines=17, nullLines=1), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:53,869] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=17, nullLines=0), subType=IntegerParser(super=Parser(lines=17, nullLines=0), minValue=15340, maxValue=15344), dateReader=com.bakdata.conquery.util.DateReader@72009236)
INFO  [2023-01-26 18:09:53,871] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND DURATION SUM Test[4]/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:53,871] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:53,871] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_AND DURATION SUM Test[4]/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:53,885] com.bakdata.conquery.models.jobs.ImportJob: Importing table into AND$20DURATION$20SUM$20Test[4].table
127.0.0.1 - - [26/Jan/2023:18:09:53 +0000] "POST /admin/datasets/AND%20DURATION%20SUM%20Test%5B4%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_AND+DURATION+SUM+Test%5B4%5D%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:09:53,885] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:53,886] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:53,886] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:53,886] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:53,888] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:09:53,888] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[AND$20DURATION$20SUM$20Test[4].table.table], containing 17 entries.
WARN  [2023-01-26 18:09:53,889] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:53,889] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received AND$20DURATION$20SUM$20Test[4].table.table.1
INFO  [2023-01-26 18:09:53,889] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[AND$20DURATION$20SUM$20Test[4].table.table], containing 17 entries.
INFO  [2023-01-26 18:09:53,889] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received AND$20DURATION$20SUM$20Test[4].table.table.0
INFO  [2023-01-26 18:09:53,994] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:53,999] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:54,010] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:54,011] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:54,011] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:54,117] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: AND DURATION SUM Test QUERY INIT
INFO  [2023-01-26 18:09:54,125] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[AND$20DURATION$20SUM$20Test[4]] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:54,125] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[329a0092-49da-4d2f-8faa-3eb6b934a5a0] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_AND DURATION SUM Test[4]))]]
INFO  [2023-01-26 18:09:54,127] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery AND$20DURATION$20SUM$20Test[4].329a0092-49da-4d2f-8faa-3eb6b934a5a0
INFO  [2023-01-26 18:09:54,127] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery AND$20DURATION$20SUM$20Test[4].329a0092-49da-4d2f-8faa-3eb6b934a5a0
127.0.0.1 - - [26/Jan/2023:18:09:54 +0000] "POST /api/datasets/AND$20DURATION$20SUM$20Test%5B4%5D/queries HTTP/1.1" 201 1696 "-" "Conquery (test client)" 4
INFO  [2023-01-26 18:09:54,128] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[AND$20DURATION$20SUM$20Test[4].329a0092-49da-4d2f-8faa-3eb6b934a5a0] with 2 results within PT0.000862S
INFO  [2023-01-26 18:09:54,128] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[AND$20DURATION$20SUM$20Test[4].329a0092-49da-4d2f-8faa-3eb6b934a5a0] with 3 results within PT0.000917S
INFO  [2023-01-26 18:09:54,129] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=AND$20DURATION$20SUM$20Test[4].329a0092-49da-4d2f-8faa-3eb6b934a5a0, workerId=AND$20DURATION$20SUM$20Test[4].worker_AND$20DURATION$20SUM$20Test[4]_fd441551-a8db-448d-930c-32fac0439a3d, startTime=2023-01-26T18:09:54.127809, finishTime=2023-01-26T18:09:54.128726) of size 3
INFO  [2023-01-26 18:09:54,129] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=AND$20DURATION$20SUM$20Test[4].329a0092-49da-4d2f-8faa-3eb6b934a5a0, workerId=AND$20DURATION$20SUM$20Test[4].worker_AND$20DURATION$20SUM$20Test[4]_11e54b87-0867-4a33-8af0-2a6b0ec9fcf5, startTime=2023-01-26T18:09:54.127836, finishTime=2023-01-26T18:09:54.128698) of size 2
INFO  [2023-01-26 18:09:54,129] com.bakdata.conquery.models.execution.ManagedExecution: DONE 329a0092-49da-4d2f-8faa-3eb6b934a5a0 ManagedQuery within PT0.003514S
127.0.0.1 - - [26/Jan/2023:18:09:54 +0000] "GET /api/datasets/AND$20DURATION$20SUM$20Test%5B4%5D/queries/AND$20DURATION$20SUM$20Test%5B4%5D.329a0092-49da-4d2f-8faa-3eb6b934a5a0 HTTP/1.1" 200 2279 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:09:54,146] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=AND DURATION SUM Test[4]], queryId=329a0092-49da-4d2f-8faa-3eb6b934a5a0, label=tree---a tree---b	@§$, creationTime=2023-01-26T18:09:54.125781, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@4c18c3df[Count = 0], startTime=2023-01-26T18:09:54.125938, finishTime=2023-01-26T18:09:54.129452, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@5f70b4cc), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_AND DURATION SUM Test[4])), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=5, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@6a642228, com.bakdata.conquery.models.query.ColumnDescriptor@5f11e4fe, com.bakdata.conquery.models.query.ColumnDescriptor@559dd2f8]) download on dataset Dataset[label=null, name=AND DURATION SUM Test[4]] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:54,147] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=AND DURATION SUM Test[4]], queryId=329a0092-49da-4d2f-8faa-3eb6b934a5a0, label=tree---a tree---b	@§$, creationTime=2023-01-26T18:09:54.125781, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@4c18c3df[Count = 0], startTime=2023-01-26T18:09:54.125938, finishTime=2023-01-26T18:09:54.129452, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@5f70b4cc), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_AND DURATION SUM Test[4])), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=5, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@6a642228, com.bakdata.conquery.models.query.ColumnDescriptor@5f11e4fe, com.bakdata.conquery.models.query.ColumnDescriptor@559dd2f8]) on dataset Dataset[label=null, name=AND DURATION SUM Test[4]]
127.0.0.1 - - [26/Jan/2023:18:09:54 +0000] "GET /api/datasets/AND%20DURATION%20SUM%20Test%5B4%5D/result/AND$20DURATION$20SUM$20Test%5B4%5D.329a0092-49da-4d2f-8faa-3eb6b934a5a0.csv?pretty=false HTTP/1.1" 200 259 "-" "Conquery (test client)" 19
INFO  [2023-01-26 18:09:54,164] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest AND DURATION SUM Test on 6 rows
INFO  [2023-01-26 18:09:54,165] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast AND DURATION SUM Test[4]
INFO  [2023-01-26 18:09:54,165] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=AND DURATION SUM Test[4], name=AND DURATION SUM Test[4]]
INFO  [2023-01-26 18:09:54,165] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=AND DURATION SUM Test[4], name=AND DURATION SUM Test[4]]
INFO  [2023-01-26 18:09:54,165] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_AND DURATION SUM Test[4]_11e54b87-0867-4a33-8af0-2a6b0ec9fcf5
INFO  [2023-01-26 18:09:54,165] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_AND DURATION SUM Test[4]_fd441551-a8db-448d-930c-32fac0439a3d
INFO  [2023-01-26 18:09:54,172] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_AND DURATION SUM Test[4]_fd441551-a8db-448d-930c-32fac0439a3d
INFO  [2023-01-26 18:09:54,176] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_AND DURATION SUM Test[4]_11e54b87-0867-4a33-8af0-2a6b0ec9fcf5
INFO  [2023-01-26 18:09:54,264] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow AND DURATION SUM Test[4]
INFO  [2023-01-26 18:09:54,289] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of AND$20DURATION$20SUM$20Test[4]
INFO  [2023-01-26 18:09:54,289] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:54,316] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test AND DURATION SUM Test
INFO  [2023-01-26 18:09:54,316] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test MULTIPLE_CONNECTORS_QUERY Test
INFO  [2023-01-26 18:09:54,316] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:54,316] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:54,317] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=MULTIPLE_CONNECTORS_QUERY Test, name=MULTIPLE_CONNECTORS_QUERY Test]
INFO  [2023-01-26 18:09:54,317] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=MULTIPLE_CONNECTORS_QUERY Test, name=MULTIPLE_CONNECTORS_QUERY Test]
INFO  [2023-01-26 18:09:54,317] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:54,317] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:54,319] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker MULTIPLE_CONNECTORS_QUERY$20Test.worker_MULTIPLE_CONNECTORS_QUERY$20Test_fc13fb84-bb2f-4a24-aec6-1f5c3d19e4c6 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:54,319] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker MULTIPLE_CONNECTORS_QUERY$20Test.worker_MULTIPLE_CONNECTORS_QUERY$20Test_fc13fb84-bb2f-4a24-aec6-1f5c3d19e4c6 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:54,319] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:54,324] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker MULTIPLE_CONNECTORS_QUERY$20Test.worker_MULTIPLE_CONNECTORS_QUERY$20Test_3412db85-9839-412d-8f1e-57aff1978799 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:54,324] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker MULTIPLE_CONNECTORS_QUERY$20Test.worker_MULTIPLE_CONNECTORS_QUERY$20Test_3412db85-9839-412d-8f1e-57aff1978799 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:54,324] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:54,328] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:54,428] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:54,435] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:54,435] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table MULTIPLE_CONNECTORS_QUERY$20Test.kh_diagnose
INFO  [2023-01-26 18:09:54,435] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table MULTIPLE_CONNECTORS_QUERY$20Test.au_diagnose
INFO  [2023-01-26 18:09:54,435] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table MULTIPLE_CONNECTORS_QUERY$20Test.kh_diagnose
INFO  [2023-01-26 18:09:54,435] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table MULTIPLE_CONNECTORS_QUERY$20Test.au_diagnose
INFO  [2023-01-26 18:09:54,547] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:54,657] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:54,657] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:54,657] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:54,657] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 106 B in total
INFO  [2023-01-26 18:09:54,657] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTIPLE_CONNECTORS_QUERY Test/kh_diagnose.import.json, tag=Optional.empty)
██████████████████████████████████                ▌  68%	est. time remaining: 0.012434389sINFO  [2023-01-26 18:09:54,683] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=1, sum=1, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:54,683] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[entlassungsdatum] with DateParser(super=Parser(lines=1, nullLines=0), subType=IntegerParser(super=Parser(lines=1, nullLines=0), minValue=15340, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@3d34c8bc)
INFO  [2023-01-26 18:09:54,683] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[aufnahmedatum] with DateParser(super=Parser(lines=1, nullLines=0), subType=IntegerParser(super=Parser(lines=1, nullLines=0), minValue=15340, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@46d5adbd)
INFO  [2023-01-26 18:09:54,683] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[icd_code] with StringParser(super=Parser(lines=1, nullLines=0), encoding=null, prefix=F20, suffix=F20)
INFO  [2023-01-26 18:09:54,686] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTIPLE_CONNECTORS_QUERY Test/kh_diagnose.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:54,686] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTIPLE_CONNECTORS_QUERY Test/au_diagnose.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:54,705] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=0, sum=0, min=2147483647, average=0.000000, max=-2147483648}
INFO  [2023-01-26 18:09:54,705] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[au_ende] with DateParser(super=Parser(lines=0, nullLines=0), subType=IntegerParser(super=Parser(lines=0, nullLines=0), minValue=9223372036854775807, maxValue=-9223372036854775808), dateReader=com.bakdata.conquery.util.DateReader@607b8f5d)
INFO  [2023-01-26 18:09:54,705] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[au] with DateParser(super=Parser(lines=0, nullLines=0), subType=IntegerParser(super=Parser(lines=0, nullLines=0), minValue=9223372036854775807, maxValue=-9223372036854775808), dateReader=com.bakdata.conquery.util.DateReader@2258d7bc)
INFO  [2023-01-26 18:09:54,705] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[au_beginn] with DateParser(super=Parser(lines=0, nullLines=0), subType=IntegerParser(super=Parser(lines=0, nullLines=0), minValue=9223372036854775807, maxValue=-9223372036854775808), dateReader=com.bakdata.conquery.util.DateReader@25370d11)
INFO  [2023-01-26 18:09:54,705] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[icd_code] with StringParser(super=Parser(lines=0, nullLines=0), encoding=null, prefix=null, suffix=null)
INFO  [2023-01-26 18:09:54,707] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTIPLE_CONNECTORS_QUERY Test/au_diagnose.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:54,707] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 2 Jobs:
INFO  [2023-01-26 18:09:54,707] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTIPLE_CONNECTORS_QUERY Test/kh_diagnose.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:54,707] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTIPLE_CONNECTORS_QUERY Test/au_diagnose.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:54,723] com.bakdata.conquery.models.jobs.ImportJob: Importing kh_diagnose into MULTIPLE_CONNECTORS_QUERY$20Test.kh_diagnose
127.0.0.1 - - [26/Jan/2023:18:09:54 +0000] "POST /admin/datasets/MULTIPLE_CONNECTORS_QUERY%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_MULTIPLE_CONNECTORS_QUERY+Test%2Fkh_diagnose.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:09:54,724] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:54,724] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:54,724] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:54,726] com.bakdata.conquery.models.jobs.ImportJob: Start sending 1 Buckets
INFO  [2023-01-26 18:09:54,726] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[MULTIPLE_CONNECTORS_QUERY$20Test.kh_diagnose.kh_diagnose], containing 1 entries.
INFO  [2023-01-26 18:09:54,726] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[MULTIPLE_CONNECTORS_QUERY$20Test.kh_diagnose.kh_diagnose], containing 1 entries.
WARN  [2023-01-26 18:09:54,726] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:54,727] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTIPLE_CONNECTORS_QUERY$20Test.kh_diagnose.kh_diagnose.0
INFO  [2023-01-26 18:09:54,737] com.bakdata.conquery.models.jobs.ImportJob: Importing au_diagnose into MULTIPLE_CONNECTORS_QUERY$20Test.au_diagnose
INFO  [2023-01-26 18:09:54,737] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:54,737] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:54,737] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:54,738] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:09:54 +0000] "POST /admin/datasets/MULTIPLE_CONNECTORS_QUERY%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_MULTIPLE_CONNECTORS_QUERY+Test%2Fau_diagnose.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:09:54,738] com.bakdata.conquery.models.jobs.ImportJob: Start sending 0 Buckets
WARN  [2023-01-26 18:09:54,738] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
WARN  [2023-01-26 18:09:54,738] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:54,738] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[MULTIPLE_CONNECTORS_QUERY$20Test.au_diagnose.au_diagnose], containing 0 entries.
INFO  [2023-01-26 18:09:54,738] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[MULTIPLE_CONNECTORS_QUERY$20Test.au_diagnose.au_diagnose], containing 0 entries.
INFO  [2023-01-26 18:09:54,843] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:54,849] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:54,860] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:54,860] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:54,988] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: MULTIPLE_CONNECTORS_QUERY Test QUERY INIT
INFO  [2023-01-26 18:09:54,998] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[MULTIPLE_CONNECTORS_QUERY$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:54,998] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[3101689c-6e77-4a3d-8507-56fc17c25dc2] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_MULTIPLE_CONNECTORS_QUERY Test))]]
INFO  [2023-01-26 18:09:55,001] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery MULTIPLE_CONNECTORS_QUERY$20Test.3101689c-6e77-4a3d-8507-56fc17c25dc2
INFO  [2023-01-26 18:09:55,001] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery MULTIPLE_CONNECTORS_QUERY$20Test.3101689c-6e77-4a3d-8507-56fc17c25dc2
WARN  [2023-01-26 18:09:55,001] com.bakdata.conquery.models.query.QueryExecutor: Entities for query are empty
INFO  [2023-01-26 18:09:55,001] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[MULTIPLE_CONNECTORS_QUERY$20Test.3101689c-6e77-4a3d-8507-56fc17c25dc2] with 0 results within PT0.000135S
INFO  [2023-01-26 18:09:55,001] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[MULTIPLE_CONNECTORS_QUERY$20Test.3101689c-6e77-4a3d-8507-56fc17c25dc2] with 1 results within PT0.000619S
INFO  [2023-01-26 18:09:55,001] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=MULTIPLE_CONNECTORS_QUERY$20Test.3101689c-6e77-4a3d-8507-56fc17c25dc2, workerId=MULTIPLE_CONNECTORS_QUERY$20Test.worker_MULTIPLE_CONNECTORS_QUERY$20Test_fc13fb84-bb2f-4a24-aec6-1f5c3d19e4c6, startTime=2023-01-26T18:09:55.001272, finishTime=2023-01-26T18:09:55.001407) of size 0
127.0.0.1 - - [26/Jan/2023:18:09:55 +0000] "POST /api/datasets/MULTIPLE_CONNECTORS_QUERY$20Test/queries HTTP/1.1" 201 1611 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:09:55,002] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=MULTIPLE_CONNECTORS_QUERY$20Test.3101689c-6e77-4a3d-8507-56fc17c25dc2, workerId=MULTIPLE_CONNECTORS_QUERY$20Test.worker_MULTIPLE_CONNECTORS_QUERY$20Test_3412db85-9839-412d-8f1e-57aff1978799, startTime=2023-01-26T18:09:55.001191, finishTime=2023-01-26T18:09:55.001810) of size 1
INFO  [2023-01-26 18:09:55,002] com.bakdata.conquery.models.execution.ManagedExecution: DONE 3101689c-6e77-4a3d-8507-56fc17c25dc2 ManagedQuery within PT0.003738S
127.0.0.1 - - [26/Jan/2023:18:09:55 +0000] "GET /api/datasets/MULTIPLE_CONNECTORS_QUERY$20Test/queries/MULTIPLE_CONNECTORS_QUERY$20Test.3101689c-6e77-4a3d-8507-56fc17c25dc2 HTTP/1.1" 200 1930 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:09:55,022] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=MULTIPLE_CONNECTORS_QUERY Test], queryId=3101689c-6e77-4a3d-8507-56fc17c25dc2, label=F00-F99 F20-F29	@§$, creationTime=2023-01-26T18:09:54.998379, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@54a565a1[Count = 0], startTime=2023-01-26T18:09:54.998524, finishTime=2023-01-26T18:09:55.002262, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@291411d0), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_MULTIPLE_CONNECTORS_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@23413565, com.bakdata.conquery.models.query.ColumnDescriptor@2a29aec0]) download on dataset Dataset[label=null, name=MULTIPLE_CONNECTORS_QUERY Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:55,022] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=MULTIPLE_CONNECTORS_QUERY Test], queryId=3101689c-6e77-4a3d-8507-56fc17c25dc2, label=F00-F99 F20-F29	@§$, creationTime=2023-01-26T18:09:54.998379, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@54a565a1[Count = 0], startTime=2023-01-26T18:09:54.998524, finishTime=2023-01-26T18:09:55.002262, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@291411d0), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_MULTIPLE_CONNECTORS_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@23413565, com.bakdata.conquery.models.query.ColumnDescriptor@2a29aec0]) on dataset Dataset[label=null, name=MULTIPLE_CONNECTORS_QUERY Test]
127.0.0.1 - - [26/Jan/2023:18:09:55 +0000] "GET /api/datasets/MULTIPLE_CONNECTORS_QUERY%20Test/result/MULTIPLE_CONNECTORS_QUERY$20Test.3101689c-6e77-4a3d-8507-56fc17c25dc2.csv?pretty=false HTTP/1.1" 200 39 "-" "Conquery (test client)" 44
INFO  [2023-01-26 18:09:55,065] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest MULTIPLE_CONNECTORS_QUERY Test on 2 rows
INFO  [2023-01-26 18:09:55,066] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast MULTIPLE_CONNECTORS_QUERY Test
INFO  [2023-01-26 18:09:55,066] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=MULTIPLE_CONNECTORS_QUERY Test, name=MULTIPLE_CONNECTORS_QUERY Test]
INFO  [2023-01-26 18:09:55,066] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_MULTIPLE_CONNECTORS_QUERY Test_fc13fb84-bb2f-4a24-aec6-1f5c3d19e4c6
INFO  [2023-01-26 18:09:55,066] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=MULTIPLE_CONNECTORS_QUERY Test, name=MULTIPLE_CONNECTORS_QUERY Test]
INFO  [2023-01-26 18:09:55,071] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_MULTIPLE_CONNECTORS_QUERY Test_3412db85-9839-412d-8f1e-57aff1978799
INFO  [2023-01-26 18:09:55,117] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow MULTIPLE_CONNECTORS_QUERY Test
INFO  [2023-01-26 18:09:55,119] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_MULTIPLE_CONNECTORS_QUERY Test_fc13fb84-bb2f-4a24-aec6-1f5c3d19e4c6
INFO  [2023-01-26 18:09:55,164] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_MULTIPLE_CONNECTORS_QUERY Test_3412db85-9839-412d-8f1e-57aff1978799
INFO  [2023-01-26 18:09:55,164] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of MULTIPLE_CONNECTORS_QUERY$20Test
INFO  [2023-01-26 18:09:55,164] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:55,290] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test MULTIPLE_CONNECTORS_QUERY Test
INFO  [2023-01-26 18:09:55,290] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test MULTIPLE_TABLES_ICD_QUERY2 Test
INFO  [2023-01-26 18:09:55,290] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:55,290] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:55,291] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=MULTIPLE_TABLES_ICD_QUERY2 Test, name=MULTIPLE_TABLES_ICD_QUERY2 Test]
INFO  [2023-01-26 18:09:55,291] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=MULTIPLE_TABLES_ICD_QUERY2 Test, name=MULTIPLE_TABLES_ICD_QUERY2 Test]
INFO  [2023-01-26 18:09:55,291] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:55,291] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:55,292] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker MULTIPLE_TABLES_ICD_QUERY2$20Test.worker_MULTIPLE_TABLES_ICD_QUERY2$20Test_a037170f-08d2-445d-820f-75bb05c7ea0c are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:55,292] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker MULTIPLE_TABLES_ICD_QUERY2$20Test.worker_MULTIPLE_TABLES_ICD_QUERY2$20Test_a037170f-08d2-445d-820f-75bb05c7ea0c are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:55,292] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:55,298] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker MULTIPLE_TABLES_ICD_QUERY2$20Test.worker_MULTIPLE_TABLES_ICD_QUERY2$20Test_6474159a-6dbc-4f3d-a633-45933b48210d are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:55,298] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker MULTIPLE_TABLES_ICD_QUERY2$20Test.worker_MULTIPLE_TABLES_ICD_QUERY2$20Test_6474159a-6dbc-4f3d-a633-45933b48210d are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:55,298] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:55,302] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:55,408] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:55,414] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:55,415] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table MULTIPLE_TABLES_ICD_QUERY2$20Test.kh_diagnose
INFO  [2023-01-26 18:09:55,415] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table MULTIPLE_TABLES_ICD_QUERY2$20Test.kh_diagnose
INFO  [2023-01-26 18:09:55,415] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table MULTIPLE_TABLES_ICD_QUERY2$20Test.au_diagnose
INFO  [2023-01-26 18:09:55,415] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table MULTIPLE_TABLES_ICD_QUERY2$20Test.au_diagnose
INFO  [2023-01-26 18:09:55,527] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:55,635] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:55,635] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:55,635] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:55,636] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 1.3 KiB in total
INFO  [2023-01-26 18:09:55,636] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTIPLE_TABLES_ICD_QUERY2 Test/kh_diagnose.import.json, tag=Optional.empty)
████████████████████████                          ▌  48%	est. time remaining: 0.031590065sINFO  [2023-01-26 18:09:55,665] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=26, sum=37, min=1, average=1.423077, max=2}
INFO  [2023-01-26 18:09:55,665] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[entlassungsdatum] with DateParser(super=Parser(lines=37, nullLines=13), subType=IntegerParser(super=Parser(lines=37, nullLines=13), minValue=15430, maxValue=17317), dateReader=com.bakdata.conquery.util.DateReader@5236669)
INFO  [2023-01-26 18:09:55,665] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[icd_code] with StringParser(super=Parser(lines=37, nullLines=0), encoding=null, prefix=F, suffix=)
INFO  [2023-01-26 18:09:55,669] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTIPLE_TABLES_ICD_QUERY2 Test/kh_diagnose.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:55,669] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTIPLE_TABLES_ICD_QUERY2 Test/au_diagnose.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000546947sINFO  [2023-01-26 18:09:55,691] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=27, sum=40, min=1, average=1.481481, max=2}
INFO  [2023-01-26 18:09:55,692] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[au_beginn] with DateParser(super=Parser(lines=40, nullLines=14), subType=IntegerParser(super=Parser(lines=40, nullLines=14), minValue=15492, maxValue=17410), dateReader=com.bakdata.conquery.util.DateReader@5e61446d)
INFO  [2023-01-26 18:09:55,692] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[icd_code] with StringParser(super=Parser(lines=40, nullLines=0), encoding=null, prefix=F, suffix=)
INFO  [2023-01-26 18:09:55,695] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTIPLE_TABLES_ICD_QUERY2 Test/au_diagnose.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:55,695] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 2 Jobs:
INFO  [2023-01-26 18:09:55,695] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTIPLE_TABLES_ICD_QUERY2 Test/kh_diagnose.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:55,695] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTIPLE_TABLES_ICD_QUERY2 Test/au_diagnose.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:55,712] com.bakdata.conquery.models.jobs.ImportJob: Importing kh_diagnose into MULTIPLE_TABLES_ICD_QUERY2$20Test.kh_diagnose
127.0.0.1 - - [26/Jan/2023:18:09:55 +0000] "POST /admin/datasets/MULTIPLE_TABLES_ICD_QUERY2%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_MULTIPLE_TABLES_ICD_QUERY2+Test%2Fkh_diagnose.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:09:55,713] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:55,714] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries [DictionaryMapping(sourceDictionary=SuccinctTrie[size=12], targetDictionary=MapDictionary[size=12], numberOfNewIds=12)]
INFO  [2023-01-26 18:09:55,721] com.bakdata.conquery.models.jobs.ImportJob: Start sending 9 Buckets
INFO  [2023-01-26 18:09:55,721] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[MULTIPLE_TABLES_ICD_QUERY2$20Test.kh_diagnose.kh_diagnose], containing 37 entries.
INFO  [2023-01-26 18:09:55,721] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[MULTIPLE_TABLES_ICD_QUERY2$20Test.kh_diagnose.kh_diagnose], containing 37 entries.
INFO  [2023-01-26 18:09:55,723] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTIPLE_TABLES_ICD_QUERY2$20Test.kh_diagnose.kh_diagnose.0
INFO  [2023-01-26 18:09:55,723] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTIPLE_TABLES_ICD_QUERY2$20Test.kh_diagnose.kh_diagnose.1
INFO  [2023-01-26 18:09:55,723] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTIPLE_TABLES_ICD_QUERY2$20Test.kh_diagnose.kh_diagnose.2
INFO  [2023-01-26 18:09:55,723] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTIPLE_TABLES_ICD_QUERY2$20Test.kh_diagnose.kh_diagnose.3
INFO  [2023-01-26 18:09:55,723] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTIPLE_TABLES_ICD_QUERY2$20Test.kh_diagnose.kh_diagnose.4
WARN  [2023-01-26 18:09:55,723] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:55,723] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTIPLE_TABLES_ICD_QUERY2$20Test.kh_diagnose.kh_diagnose.5
INFO  [2023-01-26 18:09:55,723] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTIPLE_TABLES_ICD_QUERY2$20Test.kh_diagnose.kh_diagnose.8
INFO  [2023-01-26 18:09:55,741] com.bakdata.conquery.models.jobs.ImportJob: Importing au_diagnose into MULTIPLE_TABLES_ICD_QUERY2$20Test.au_diagnose
INFO  [2023-01-26 18:09:55,742] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
127.0.0.1 - - [26/Jan/2023:18:09:55 +0000] "POST /admin/datasets/MULTIPLE_TABLES_ICD_QUERY2%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_MULTIPLE_TABLES_ICD_QUERY2+Test%2Fau_diagnose.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 20
INFO  [2023-01-26 18:09:55,742] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:55,742] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries [DictionaryMapping(sourceDictionary=SuccinctTrie[size=12], targetDictionary=MapDictionary[size=12], numberOfNewIds=0)]
INFO  [2023-01-26 18:09:55,742] com.bakdata.conquery.models.jobs.ImportJob: Start sending 9 Buckets
INFO  [2023-01-26 18:09:55,742] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[MULTIPLE_TABLES_ICD_QUERY2$20Test.au_diagnose.au_diagnose], containing 40 entries.
INFO  [2023-01-26 18:09:55,743] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTIPLE_TABLES_ICD_QUERY2$20Test.au_diagnose.au_diagnose.3
INFO  [2023-01-26 18:09:55,743] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTIPLE_TABLES_ICD_QUERY2$20Test.au_diagnose.au_diagnose.4
INFO  [2023-01-26 18:09:55,743] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTIPLE_TABLES_ICD_QUERY2$20Test.au_diagnose.au_diagnose.5
WARN  [2023-01-26 18:09:55,743] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:55,743] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTIPLE_TABLES_ICD_QUERY2$20Test.au_diagnose.au_diagnose.8
INFO  [2023-01-26 18:09:55,761] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTIPLE_TABLES_ICD_QUERY2$20Test.kh_diagnose.kh_diagnose.6
INFO  [2023-01-26 18:09:55,761] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTIPLE_TABLES_ICD_QUERY2$20Test.kh_diagnose.kh_diagnose.7
INFO  [2023-01-26 18:09:55,762] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[MULTIPLE_TABLES_ICD_QUERY2$20Test.au_diagnose.au_diagnose], containing 40 entries.
INFO  [2023-01-26 18:09:55,762] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTIPLE_TABLES_ICD_QUERY2$20Test.au_diagnose.au_diagnose.0
INFO  [2023-01-26 18:09:55,762] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTIPLE_TABLES_ICD_QUERY2$20Test.au_diagnose.au_diagnose.1
INFO  [2023-01-26 18:09:55,762] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTIPLE_TABLES_ICD_QUERY2$20Test.au_diagnose.au_diagnose.2
INFO  [2023-01-26 18:09:55,762] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTIPLE_TABLES_ICD_QUERY2$20Test.au_diagnose.au_diagnose.6
INFO  [2023-01-26 18:09:55,763] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTIPLE_TABLES_ICD_QUERY2$20Test.au_diagnose.au_diagnose.7
INFO  [2023-01-26 18:09:55,868] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:55,874] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:55,885] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:55,885] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:55,885] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:55,990] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: MULTIPLE_TABLES_ICD_QUERY2 Test QUERY INIT
INFO  [2023-01-26 18:09:56,000] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[MULTIPLE_TABLES_ICD_QUERY2$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:56,001] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[604c088b-b844-41e4-9e71-1f3c90089a09] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_MULTIPLE_TABLES_ICD_QUERY2 Test))]]
INFO  [2023-01-26 18:09:56,004] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery MULTIPLE_TABLES_ICD_QUERY2$20Test.604c088b-b844-41e4-9e71-1f3c90089a09
INFO  [2023-01-26 18:09:56,004] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery MULTIPLE_TABLES_ICD_QUERY2$20Test.604c088b-b844-41e4-9e71-1f3c90089a09
127.0.0.1 - - [26/Jan/2023:18:09:56 +0000] "POST /api/datasets/MULTIPLE_TABLES_ICD_QUERY2$20Test/queries HTTP/1.1" 201 1355 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:09:56,011] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[MULTIPLE_TABLES_ICD_QUERY2$20Test.604c088b-b844-41e4-9e71-1f3c90089a09] with 1 results within PT0.007518S
INFO  [2023-01-26 18:09:56,012] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=MULTIPLE_TABLES_ICD_QUERY2$20Test.604c088b-b844-41e4-9e71-1f3c90089a09, workerId=MULTIPLE_TABLES_ICD_QUERY2$20Test.worker_MULTIPLE_TABLES_ICD_QUERY2$20Test_6474159a-6dbc-4f3d-a633-45933b48210d, startTime=2023-01-26T18:09:56.004379, finishTime=2023-01-26T18:09:56.011897) of size 1
INFO  [2023-01-26 18:09:56,013] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[MULTIPLE_TABLES_ICD_QUERY2$20Test.604c088b-b844-41e4-9e71-1f3c90089a09] with 6 results within PT0.008525S
INFO  [2023-01-26 18:09:56,013] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=MULTIPLE_TABLES_ICD_QUERY2$20Test.604c088b-b844-41e4-9e71-1f3c90089a09, workerId=MULTIPLE_TABLES_ICD_QUERY2$20Test.worker_MULTIPLE_TABLES_ICD_QUERY2$20Test_a037170f-08d2-445d-820f-75bb05c7ea0c, startTime=2023-01-26T18:09:56.004528, finishTime=2023-01-26T18:09:56.013053) of size 6
INFO  [2023-01-26 18:09:56,013] com.bakdata.conquery.models.execution.ManagedExecution: DONE 604c088b-b844-41e4-9e71-1f3c90089a09 ManagedQuery within PT0.012642S
127.0.0.1 - - [26/Jan/2023:18:09:56 +0000] "GET /api/datasets/MULTIPLE_TABLES_ICD_QUERY2$20Test/queries/MULTIPLE_TABLES_ICD_QUERY2$20Test.604c088b-b844-41e4-9e71-1f3c90089a09 HTTP/1.1" 200 1679 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:09:56,026] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=MULTIPLE_TABLES_ICD_QUERY2 Test], queryId=604c088b-b844-41e4-9e71-1f3c90089a09, label=icd---f20	@§$, creationTime=2023-01-26T18:09:56.000966, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@2255202f[Count = 0], startTime=2023-01-26T18:09:56.001136, finishTime=2023-01-26T18:09:56.013778, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@503a8ca0), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_MULTIPLE_TABLES_ICD_QUERY2 Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=7, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@388d118d, com.bakdata.conquery.models.query.ColumnDescriptor@70ca4a5a]) download on dataset Dataset[label=null, name=MULTIPLE_TABLES_ICD_QUERY2 Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:56,026] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=MULTIPLE_TABLES_ICD_QUERY2 Test], queryId=604c088b-b844-41e4-9e71-1f3c90089a09, label=icd---f20	@§$, creationTime=2023-01-26T18:09:56.000966, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@2255202f[Count = 0], startTime=2023-01-26T18:09:56.001136, finishTime=2023-01-26T18:09:56.013778, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@503a8ca0), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_MULTIPLE_TABLES_ICD_QUERY2 Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=7, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@388d118d, com.bakdata.conquery.models.query.ColumnDescriptor@70ca4a5a]) on dataset Dataset[label=null, name=MULTIPLE_TABLES_ICD_QUERY2 Test]
127.0.0.1 - - [26/Jan/2023:18:09:56 +0000] "GET /api/datasets/MULTIPLE_TABLES_ICD_QUERY2%20Test/result/MULTIPLE_TABLES_ICD_QUERY2$20Test.604c088b-b844-41e4-9e71-1f3c90089a09.csv?pretty=false HTTP/1.1" 200 312 "-" "Conquery (test client)" 21
INFO  [2023-01-26 18:09:56,046] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest MULTIPLE_TABLES_ICD_QUERY2 Test on 8 rows
INFO  [2023-01-26 18:09:56,047] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast MULTIPLE_TABLES_ICD_QUERY2 Test
INFO  [2023-01-26 18:09:56,047] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=MULTIPLE_TABLES_ICD_QUERY2 Test, name=MULTIPLE_TABLES_ICD_QUERY2 Test]
INFO  [2023-01-26 18:09:56,047] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=MULTIPLE_TABLES_ICD_QUERY2 Test, name=MULTIPLE_TABLES_ICD_QUERY2 Test]
INFO  [2023-01-26 18:09:56,047] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_MULTIPLE_TABLES_ICD_QUERY2 Test_a037170f-08d2-445d-820f-75bb05c7ea0c
INFO  [2023-01-26 18:09:56,047] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_MULTIPLE_TABLES_ICD_QUERY2 Test_6474159a-6dbc-4f3d-a633-45933b48210d
INFO  [2023-01-26 18:09:56,091] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow MULTIPLE_TABLES_ICD_QUERY2 Test
INFO  [2023-01-26 18:09:56,092] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_MULTIPLE_TABLES_ICD_QUERY2 Test_a037170f-08d2-445d-820f-75bb05c7ea0c
INFO  [2023-01-26 18:09:56,103] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_MULTIPLE_TABLES_ICD_QUERY2 Test_6474159a-6dbc-4f3d-a633-45933b48210d
INFO  [2023-01-26 18:09:56,165] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of MULTIPLE_TABLES_ICD_QUERY2$20Test
INFO  [2023-01-26 18:09:56,165] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:56,290] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test MULTIPLE_TABLES_ICD_QUERY2 Test
INFO  [2023-01-26 18:09:56,291] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test MULTI_CONCEPT_QUERY_SEPARATE_DATES Test
INFO  [2023-01-26 18:09:56,291] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:56,291] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:56,292] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=MULTI_CONCEPT_QUERY_SEPARATE_DATES Test, name=MULTI_CONCEPT_QUERY_SEPARATE_DATES Test]
INFO  [2023-01-26 18:09:56,292] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=MULTI_CONCEPT_QUERY_SEPARATE_DATES Test, name=MULTI_CONCEPT_QUERY_SEPARATE_DATES Test]
INFO  [2023-01-26 18:09:56,292] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:56,292] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:56,293] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test.worker_MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test_01a7afae-0576-4e74-88f1-b1d095b994de are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:56,293] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test.worker_MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test_01a7afae-0576-4e74-88f1-b1d095b994de are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:56,293] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:56,294] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test.worker_MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test_8ea9611e-4088-4f6a-8158-2894437a7344 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:56,294] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test.worker_MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test_8ea9611e-4088-4f6a-8158-2894437a7344 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:56,294] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:56,297] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:56,397] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:56,404] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:56,404] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test.test_table
INFO  [2023-01-26 18:09:56,404] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test.test_table
INFO  [2023-01-26 18:09:56,404] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test.test_table2
INFO  [2023-01-26 18:09:56,404] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test.test_table2
INFO  [2023-01-26 18:09:56,516] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:56,625] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:56,625] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:56,625] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:56,625] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 214 B in total
INFO  [2023-01-26 18:09:56,625] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTI_CONCEPT_QUERY_SEPARATE_DATES Test/test_table.import.json, tag=Optional.empty)
█████████████████████████                         ▌  50%	est. time remaining: 0.036157126sINFO  [2023-01-26 18:09:56,662] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=5, min=1, average=1.250000, max=2}
INFO  [2023-01-26 18:09:56,662] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=5, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:56,662] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=5, nullLines=0), subType=IntegerParser(super=Parser(lines=5, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@6ea05118)
INFO  [2023-01-26 18:09:56,664] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTI_CONCEPT_QUERY_SEPARATE_DATES Test/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:56,664] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTI_CONCEPT_QUERY_SEPARATE_DATES Test/test_table2.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000534581sINFO  [2023-01-26 18:09:56,679] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=5, min=1, average=1.250000, max=2}
INFO  [2023-01-26 18:09:56,680] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=5, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:56,680] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=5, nullLines=0), subType=IntegerParser(super=Parser(lines=5, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@496f79ee)
INFO  [2023-01-26 18:09:56,682] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTI_CONCEPT_QUERY_SEPARATE_DATES Test/test_table2.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:56,682] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 2 Jobs:
INFO  [2023-01-26 18:09:56,682] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTI_CONCEPT_QUERY_SEPARATE_DATES Test/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:56,682] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTI_CONCEPT_QUERY_SEPARATE_DATES Test/test_table2.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:56,700] com.bakdata.conquery.models.jobs.ImportJob: Importing test_table into MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test.test_table
127.0.0.1 - - [26/Jan/2023:18:09:56 +0000] "POST /admin/datasets/MULTI_CONCEPT_QUERY_SEPARATE_DATES%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_MULTI_CONCEPT_QUERY_SEPARATE_DATES+Test%2Ftest_table.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 13
INFO  [2023-01-26 18:09:56,702] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:56,703] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:56,703] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:56,706] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:09:56,706] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test.test_table.test_table], containing 5 entries.
INFO  [2023-01-26 18:09:56,706] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test.test_table.test_table], containing 5 entries.
WARN  [2023-01-26 18:09:56,708] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:56,708] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test.test_table.test_table.0
INFO  [2023-01-26 18:09:56,708] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test.test_table.test_table.1
INFO  [2023-01-26 18:09:56,715] com.bakdata.conquery.models.jobs.ImportJob: Importing test_table2 into MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test.test_table2
INFO  [2023-01-26 18:09:56,715] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
127.0.0.1 - - [26/Jan/2023:18:09:56 +0000] "POST /admin/datasets/MULTI_CONCEPT_QUERY_SEPARATE_DATES%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_MULTI_CONCEPT_QUERY_SEPARATE_DATES+Test%2Ftest_table2.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:09:56,715] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:56,716] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:56,716] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:56,716] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:09:56,716] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test.test_table2.test_table2], containing 5 entries.
INFO  [2023-01-26 18:09:56,716] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test.test_table2.test_table2], containing 5 entries.
WARN  [2023-01-26 18:09:56,716] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:56,716] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test.test_table2.test_table2.0
INFO  [2023-01-26 18:09:56,717] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test.test_table2.test_table2.1
INFO  [2023-01-26 18:09:56,822] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:56,827] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:56,841] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:56,842] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 2 Concepts
INFO  [2023-01-26 18:09:56,842] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 2 Concepts
INFO  [2023-01-26 18:09:56,947] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: MULTI_CONCEPT_QUERY_SEPARATE_DATES Test QUERY INIT
INFO  [2023-01-26 18:09:56,959] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:56,961] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[68c9b2f2-0ae4-40a2-b774-4849643d08bc] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_MULTI_CONCEPT_QUERY_SEPARATE_DATES Test))]]
INFO  [2023-01-26 18:09:56,964] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test.68c9b2f2-0ae4-40a2-b774-4849643d08bc
INFO  [2023-01-26 18:09:56,964] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test.68c9b2f2-0ae4-40a2-b774-4849643d08bc
INFO  [2023-01-26 18:09:56,965] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test.68c9b2f2-0ae4-40a2-b774-4849643d08bc] with 0 results within PT0.000725S
INFO  [2023-01-26 18:09:56,965] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test.68c9b2f2-0ae4-40a2-b774-4849643d08bc] with 2 results within PT0.001124S
INFO  [2023-01-26 18:09:56,966] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test.68c9b2f2-0ae4-40a2-b774-4849643d08bc, workerId=MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test.worker_MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test_8ea9611e-4088-4f6a-8158-2894437a7344, startTime=2023-01-26T18:09:56.964812, finishTime=2023-01-26T18:09:56.965537) of size 0
INFO  [2023-01-26 18:09:56,966] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test.68c9b2f2-0ae4-40a2-b774-4849643d08bc, workerId=MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test.worker_MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test_01a7afae-0576-4e74-88f1-b1d095b994de, startTime=2023-01-26T18:09:56.964584, finishTime=2023-01-26T18:09:56.965708) of size 2
INFO  [2023-01-26 18:09:56,966] com.bakdata.conquery.models.execution.ManagedExecution: DONE 68c9b2f2-0ae4-40a2-b774-4849643d08bc ManagedQuery within PT0.005176S
127.0.0.1 - - [26/Jan/2023:18:09:56 +0000] "POST /api/datasets/MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test/queries HTTP/1.1" 201 2160 "-" "Conquery (test client)" 9
127.0.0.1 - - [26/Jan/2023:18:09:56 +0000] "GET /api/datasets/MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test/queries/MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test.68c9b2f2-0ae4-40a2-b774-4849643d08bc HTTP/1.1" 200 2515 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:09:56,988] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=MULTI_CONCEPT_QUERY_SEPARATE_DATES Test], queryId=68c9b2f2-0ae4-40a2-b774-4849643d08bc, label=test_tree---test_child1 test_tree2---test_child1	@§$, creationTime=2023-01-26T18:09:56.960857, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@28b4ec6e[Count = 0], startTime=2023-01-26T18:09:56.961162, finishTime=2023-01-26T18:09:56.966338, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@dc14f45), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_MULTI_CONCEPT_QUERY_SEPARATE_DATES Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@410428da, com.bakdata.conquery.models.query.ColumnDescriptor@5e45c861, com.bakdata.conquery.models.query.ColumnDescriptor@511d885b, com.bakdata.conquery.models.query.ColumnDescriptor@56214e5a]) download on dataset Dataset[label=null, name=MULTI_CONCEPT_QUERY_SEPARATE_DATES Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:56,988] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=MULTI_CONCEPT_QUERY_SEPARATE_DATES Test], queryId=68c9b2f2-0ae4-40a2-b774-4849643d08bc, label=test_tree---test_child1 test_tree2---test_child1	@§$, creationTime=2023-01-26T18:09:56.960857, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@28b4ec6e[Count = 0], startTime=2023-01-26T18:09:56.961162, finishTime=2023-01-26T18:09:56.966338, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@dc14f45), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_MULTI_CONCEPT_QUERY_SEPARATE_DATES Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@410428da, com.bakdata.conquery.models.query.ColumnDescriptor@5e45c861, com.bakdata.conquery.models.query.ColumnDescriptor@511d885b, com.bakdata.conquery.models.query.ColumnDescriptor@56214e5a]) on dataset Dataset[label=null, name=MULTI_CONCEPT_QUERY_SEPARATE_DATES Test]
127.0.0.1 - - [26/Jan/2023:18:09:57 +0000] "GET /api/datasets/MULTI_CONCEPT_QUERY_SEPARATE_DATES%20Test/result/MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test.68c9b2f2-0ae4-40a2-b774-4849643d08bc.csv?pretty=false HTTP/1.1" 200 226 "-" "Conquery (test client)" 21
INFO  [2023-01-26 18:09:57,008] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest MULTI_CONCEPT_QUERY_SEPARATE_DATES Test on 3 rows
INFO  [2023-01-26 18:09:57,008] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast MULTI_CONCEPT_QUERY_SEPARATE_DATES Test
INFO  [2023-01-26 18:09:57,008] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=MULTI_CONCEPT_QUERY_SEPARATE_DATES Test, name=MULTI_CONCEPT_QUERY_SEPARATE_DATES Test]
INFO  [2023-01-26 18:09:57,009] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=MULTI_CONCEPT_QUERY_SEPARATE_DATES Test, name=MULTI_CONCEPT_QUERY_SEPARATE_DATES Test]
INFO  [2023-01-26 18:09:57,009] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_MULTI_CONCEPT_QUERY_SEPARATE_DATES Test_8ea9611e-4088-4f6a-8158-2894437a7344
INFO  [2023-01-26 18:09:57,009] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_MULTI_CONCEPT_QUERY_SEPARATE_DATES Test_01a7afae-0576-4e74-88f1-b1d095b994de
INFO  [2023-01-26 18:09:57,107] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow MULTI_CONCEPT_QUERY_SEPARATE_DATES Test
INFO  [2023-01-26 18:09:57,107] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_MULTI_CONCEPT_QUERY_SEPARATE_DATES Test_01a7afae-0576-4e74-88f1-b1d095b994de
INFO  [2023-01-26 18:09:57,107] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_MULTI_CONCEPT_QUERY_SEPARATE_DATES Test_8ea9611e-4088-4f6a-8158-2894437a7344
INFO  [2023-01-26 18:09:57,117] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of MULTI_CONCEPT_QUERY_SEPARATE_DATES$20Test
INFO  [2023-01-26 18:09:57,117] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:57,247] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test MULTI_CONCEPT_QUERY_SEPARATE_DATES Test
INFO  [2023-01-26 18:09:57,247] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test MULTI_CONNECTOR_QUERY_SEPARATE_DATES Test
INFO  [2023-01-26 18:09:57,247] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:57,248] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:57,249] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=MULTI_CONNECTOR_QUERY_SEPARATE_DATES Test, name=MULTI_CONNECTOR_QUERY_SEPARATE_DATES Test]
INFO  [2023-01-26 18:09:57,249] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=MULTI_CONNECTOR_QUERY_SEPARATE_DATES Test, name=MULTI_CONNECTOR_QUERY_SEPARATE_DATES Test]
INFO  [2023-01-26 18:09:57,249] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:57,249] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:57,252] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test.worker_MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test_5a017abd-704a-4757-b7c4-ec7f0631b032 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:57,252] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test.worker_MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test_5a017abd-704a-4757-b7c4-ec7f0631b032 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:57,252] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:57,252] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test.worker_MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test_114a8167-048a-44f1-abef-f721897ffc5e are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:57,252] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test.worker_MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test_114a8167-048a-44f1-abef-f721897ffc5e are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:57,252] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:57,255] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:57,354] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:57,362] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:57,362] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test.test_table
INFO  [2023-01-26 18:09:57,362] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test.test_table
INFO  [2023-01-26 18:09:57,362] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test.test_table2
INFO  [2023-01-26 18:09:57,362] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test.test_table2
INFO  [2023-01-26 18:09:57,478] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:57,597] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:57,597] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:57,597] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:57,597] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 224 B in total
INFO  [2023-01-26 18:09:57,597] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTI_CONNECTOR_QUERY_SEPARATE_DATES Test/test_table.import.json, tag=Optional.empty)
█████████████████████████                         ▌  50%	est. time remaining: 0.024722659sINFO  [2023-01-26 18:09:57,622] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=5, min=1, average=1.250000, max=2}
INFO  [2023-01-26 18:09:57,622] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=5, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:57,622] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=5, nullLines=0), subType=IntegerParser(super=Parser(lines=5, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@10e57b34)
INFO  [2023-01-26 18:09:57,626] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTI_CONNECTOR_QUERY_SEPARATE_DATES Test/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:57,627] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTI_CONNECTOR_QUERY_SEPARATE_DATES Test/test_table2.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000501133sINFO  [2023-01-26 18:09:57,648] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=5, min=1, average=1.250000, max=2}
INFO  [2023-01-26 18:09:57,648] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=5, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:57,648] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=5, nullLines=0), subType=IntegerParser(super=Parser(lines=5, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@361bc79b)
INFO  [2023-01-26 18:09:57,651] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTI_CONNECTOR_QUERY_SEPARATE_DATES Test/test_table2.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:57,651] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 2 Jobs:
INFO  [2023-01-26 18:09:57,651] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTI_CONNECTOR_QUERY_SEPARATE_DATES Test/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:57,651] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTI_CONNECTOR_QUERY_SEPARATE_DATES Test/test_table2.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:57,671] com.bakdata.conquery.models.jobs.ImportJob: Importing test_table into MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test.test_table
127.0.0.1 - - [26/Jan/2023:18:09:57 +0000] "POST /admin/datasets/MULTI_CONNECTOR_QUERY_SEPARATE_DATES%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_MULTI_CONNECTOR_QUERY_SEPARATE_DATES+Test%2Ftest_table.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 11
INFO  [2023-01-26 18:09:57,672] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:57,673] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:57,673] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:57,675] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:09:57,675] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test.test_table.test_table], containing 5 entries.
INFO  [2023-01-26 18:09:57,675] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test.test_table.test_table], containing 5 entries.
WARN  [2023-01-26 18:09:57,676] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:57,676] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test.test_table.test_table.0
INFO  [2023-01-26 18:09:57,676] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test.test_table.test_table.1
INFO  [2023-01-26 18:09:57,690] com.bakdata.conquery.models.jobs.ImportJob: Importing test_table2 into MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test.test_table2
INFO  [2023-01-26 18:09:57,690] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:57,690] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:57,690] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:57,690] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:09:57 +0000] "POST /admin/datasets/MULTI_CONNECTOR_QUERY_SEPARATE_DATES%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_MULTI_CONNECTOR_QUERY_SEPARATE_DATES+Test%2Ftest_table2.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:09:57,691] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
WARN  [2023-01-26 18:09:57,691] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:57,691] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test.test_table2.test_table2], containing 5 entries.
INFO  [2023-01-26 18:09:57,691] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test.test_table2.test_table2], containing 5 entries.
INFO  [2023-01-26 18:09:57,691] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test.test_table2.test_table2.0
INFO  [2023-01-26 18:09:57,691] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test.test_table2.test_table2.1
INFO  [2023-01-26 18:09:57,796] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:57,801] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:57,812] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:57,812] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:57,812] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:57,956] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: MULTI_CONNECTOR_QUERY_SEPARATE_DATES Test QUERY INIT
INFO  [2023-01-26 18:09:57,966] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:57,966] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[d3920827-1028-44ca-9b84-c27a01851bfb] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_MULTI_CONNECTOR_QUERY_SEPARATE_DATES Test))]]
INFO  [2023-01-26 18:09:57,968] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test.d3920827-1028-44ca-9b84-c27a01851bfb
INFO  [2023-01-26 18:09:57,968] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test.d3920827-1028-44ca-9b84-c27a01851bfb
127.0.0.1 - - [26/Jan/2023:18:09:57 +0000] "POST /api/datasets/MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test/queries HTTP/1.1" 201 1649 "-" "Conquery (test client)" 4
INFO  [2023-01-26 18:09:57,979] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test.d3920827-1028-44ca-9b84-c27a01851bfb] with 2 results within PT0.011356S
INFO  [2023-01-26 18:09:57,980] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test.d3920827-1028-44ca-9b84-c27a01851bfb, workerId=MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test.worker_MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test_114a8167-048a-44f1-abef-f721897ffc5e, startTime=2023-01-26T18:09:57.968231, finishTime=2023-01-26T18:09:57.979587) of size 2
INFO  [2023-01-26 18:09:57,985] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test.d3920827-1028-44ca-9b84-c27a01851bfb] with 0 results within PT0.016702S
INFO  [2023-01-26 18:09:57,985] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test.d3920827-1028-44ca-9b84-c27a01851bfb, workerId=MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test.worker_MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test_5a017abd-704a-4757-b7c4-ec7f0631b032, startTime=2023-01-26T18:09:57.968479, finishTime=2023-01-26T18:09:57.985181) of size 0
INFO  [2023-01-26 18:09:57,985] com.bakdata.conquery.models.execution.ManagedExecution: DONE d3920827-1028-44ca-9b84-c27a01851bfb ManagedQuery within PT0.019327S
127.0.0.1 - - [26/Jan/2023:18:09:57 +0000] "GET /api/datasets/MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test/queries/MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test.d3920827-1028-44ca-9b84-c27a01851bfb HTTP/1.1" 200 2013 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:09:57,996] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=MULTI_CONNECTOR_QUERY_SEPARATE_DATES Test], queryId=d3920827-1028-44ca-9b84-c27a01851bfb, label=test_tree---test_child1	@§$, creationTime=2023-01-26T18:09:57.966293, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@490d826d[Count = 0], startTime=2023-01-26T18:09:57.966442, finishTime=2023-01-26T18:09:57.985769, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@25b2e85a), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_MULTI_CONNECTOR_QUERY_SEPARATE_DATES Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@9a02c40, com.bakdata.conquery.models.query.ColumnDescriptor@4fade5df, com.bakdata.conquery.models.query.ColumnDescriptor@6a1608ad]) download on dataset Dataset[label=null, name=MULTI_CONNECTOR_QUERY_SEPARATE_DATES Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:57,996] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=MULTI_CONNECTOR_QUERY_SEPARATE_DATES Test], queryId=d3920827-1028-44ca-9b84-c27a01851bfb, label=test_tree---test_child1	@§$, creationTime=2023-01-26T18:09:57.966293, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@490d826d[Count = 0], startTime=2023-01-26T18:09:57.966442, finishTime=2023-01-26T18:09:57.985769, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@25b2e85a), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_MULTI_CONNECTOR_QUERY_SEPARATE_DATES Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@9a02c40, com.bakdata.conquery.models.query.ColumnDescriptor@4fade5df, com.bakdata.conquery.models.query.ColumnDescriptor@6a1608ad]) on dataset Dataset[label=null, name=MULTI_CONNECTOR_QUERY_SEPARATE_DATES Test]
127.0.0.1 - - [26/Jan/2023:18:09:58 +0000] "GET /api/datasets/MULTI_CONNECTOR_QUERY_SEPARATE_DATES%20Test/result/MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test.d3920827-1028-44ca-9b84-c27a01851bfb.csv?pretty=false HTTP/1.1" 200 156 "-" "Conquery (test client)" 20
INFO  [2023-01-26 18:09:58,015] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest MULTI_CONNECTOR_QUERY_SEPARATE_DATES Test on 3 rows
INFO  [2023-01-26 18:09:58,015] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast MULTI_CONNECTOR_QUERY_SEPARATE_DATES Test
INFO  [2023-01-26 18:09:58,015] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=MULTI_CONNECTOR_QUERY_SEPARATE_DATES Test, name=MULTI_CONNECTOR_QUERY_SEPARATE_DATES Test]
INFO  [2023-01-26 18:09:58,015] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=MULTI_CONNECTOR_QUERY_SEPARATE_DATES Test, name=MULTI_CONNECTOR_QUERY_SEPARATE_DATES Test]
INFO  [2023-01-26 18:09:58,015] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_MULTI_CONNECTOR_QUERY_SEPARATE_DATES Test_5a017abd-704a-4757-b7c4-ec7f0631b032
INFO  [2023-01-26 18:09:58,016] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_MULTI_CONNECTOR_QUERY_SEPARATE_DATES Test_114a8167-048a-44f1-abef-f721897ffc5e
INFO  [2023-01-26 18:09:58,051] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow MULTI_CONNECTOR_QUERY_SEPARATE_DATES Test
INFO  [2023-01-26 18:09:58,051] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_MULTI_CONNECTOR_QUERY_SEPARATE_DATES Test_114a8167-048a-44f1-abef-f721897ffc5e
INFO  [2023-01-26 18:09:58,051] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_MULTI_CONNECTOR_QUERY_SEPARATE_DATES Test_5a017abd-704a-4757-b7c4-ec7f0631b032
INFO  [2023-01-26 18:09:58,091] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of MULTI_CONNECTOR_QUERY_SEPARATE_DATES$20Test
INFO  [2023-01-26 18:09:58,091] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:58,256] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test MULTI_CONNECTOR_QUERY_SEPARATE_DATES Test
INFO  [2023-01-26 18:09:58,256] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test
INFO  [2023-01-26 18:09:58,256] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:58,256] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:58,257] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test, name=MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:09:58,258] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:58,258] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test, name=MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:09:58,258] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:58,264] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:58,265] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_67e4a1ff-74e5-499d-92a7-0b2a3fdc5438 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:58,265] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_67e4a1ff-74e5-499d-92a7-0b2a3fdc5438 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:58,265] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:58,265] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_a027b54e-ec41-44c6-a537-0c77b80ba1b8 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:58,265] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_a027b54e-ec41-44c6-a537-0c77b80ba1b8 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:58,265] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:58,368] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:58,374] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:58,375] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1
INFO  [2023-01-26 18:09:58,375] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1
INFO  [2023-01-26 18:09:58,498] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:58,609] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:58,609] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:58,609] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 158 B in total
INFO  [2023-01-26 18:09:58,609] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000217686sINFO  [2023-01-26 18:09:58,632] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=8, sum=8, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:58,632] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=8, nullLines=2), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:58,632] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=8, nullLines=0), subType=IntegerParser(super=Parser(lines=8, nullLines=0), minValue=13828, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@5adf68d1)
INFO  [2023-01-26 18:09:58,635] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:58,635] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:58,635] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:58,653] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1
INFO  [2023-01-26 18:09:58,654] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:09:58 +0000] "POST /admin/datasets/MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY+Test%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 10
INFO  [2023-01-26 18:09:58,655] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:58,655] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:58,655] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:58,657] com.bakdata.conquery.models.jobs.ImportJob: Start sending 3 Buckets
INFO  [2023-01-26 18:09:58,657] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1.table1], containing 8 entries.
INFO  [2023-01-26 18:09:58,657] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1.table1], containing 8 entries.
WARN  [2023-01-26 18:09:58,658] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:58,658] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1.table1.1
INFO  [2023-01-26 18:09:58,658] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1.table1.0
INFO  [2023-01-26 18:09:58,658] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1.table1.2
INFO  [2023-01-26 18:09:58,763] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:58,769] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:58,779] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:58,779] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:58,779] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:58,892] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test QUERY INIT
INFO  [2023-01-26 18:09:58,902] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:58,903] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[de79cf95-7f8d-4394-8b43-e012fd71d495] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test))]]
INFO  [2023-01-26 18:09:58,905] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.de79cf95-7f8d-4394-8b43-e012fd71d495
INFO  [2023-01-26 18:09:58,905] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.de79cf95-7f8d-4394-8b43-e012fd71d495
INFO  [2023-01-26 18:09:58,906] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.de79cf95-7f8d-4394-8b43-e012fd71d495] with 0 results within PT0.000729S
127.0.0.1 - - [26/Jan/2023:18:09:58 +0000] "POST /api/datasets/MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test/queries HTTP/1.1" 201 1559 "-" "Conquery (test client)" 5
INFO  [2023-01-26 18:09:58,906] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.de79cf95-7f8d-4394-8b43-e012fd71d495] with 1 results within PT0.000882S
INFO  [2023-01-26 18:09:58,907] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.de79cf95-7f8d-4394-8b43-e012fd71d495, workerId=MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_a027b54e-ec41-44c6-a537-0c77b80ba1b8, startTime=2023-01-26T18:09:58.905981, finishTime=2023-01-26T18:09:58.906710) of size 0
INFO  [2023-01-26 18:09:58,907] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.de79cf95-7f8d-4394-8b43-e012fd71d495, workerId=MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_67e4a1ff-74e5-499d-92a7-0b2a3fdc5438, startTime=2023-01-26T18:09:58.905908, finishTime=2023-01-26T18:09:58.906790) of size 1
INFO  [2023-01-26 18:09:58,907] com.bakdata.conquery.models.execution.ManagedExecution: DONE de79cf95-7f8d-4394-8b43-e012fd71d495 ManagedQuery within PT0.003877S
127.0.0.1 - - [26/Jan/2023:18:09:58 +0000] "GET /api/datasets/MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test/queries/MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.de79cf95-7f8d-4394-8b43-e012fd71d495 HTTP/1.1" 200 1962 "-" "Conquery (test client)" 4
INFO  [2023-01-26 18:09:58,929] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test], queryId=de79cf95-7f8d-4394-8b43-e012fd71d495, label=Geschlecht-SELECT	@§$, creationTime=2023-01-26T18:09:58.903216, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@4243eb4f[Count = 0], startTime=2023-01-26T18:09:58.903368, finishTime=2023-01-26T18:09:58.907245, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@7b82edf0), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@3b3906b8, com.bakdata.conquery.models.query.ColumnDescriptor@51f74df5]) download on dataset Dataset[label=null, name=MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:58,929] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test], queryId=de79cf95-7f8d-4394-8b43-e012fd71d495, label=Geschlecht-SELECT	@§$, creationTime=2023-01-26T18:09:58.903216, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@4243eb4f[Count = 0], startTime=2023-01-26T18:09:58.903368, finishTime=2023-01-26T18:09:58.907245, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@7b82edf0), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@3b3906b8, com.bakdata.conquery.models.query.ColumnDescriptor@51f74df5]) on dataset Dataset[label=null, name=MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test]
127.0.0.1 - - [26/Jan/2023:18:09:58 +0000] "GET /api/datasets/MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY%20Test/result/MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.de79cf95-7f8d-4394-8b43-e012fd71d495.csv?pretty=false HTTP/1.1" 200 39 "-" "Conquery (test client)" 29
INFO  [2023-01-26 18:09:58,956] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test on 2 rows
INFO  [2023-01-26 18:09:58,956] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test
INFO  [2023-01-26 18:09:58,956] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test, name=MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:09:58,956] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test, name=MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:09:58,957] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test_a027b54e-ec41-44c6-a537-0c77b80ba1b8
INFO  [2023-01-26 18:09:58,957] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test_67e4a1ff-74e5-499d-92a7-0b2a3fdc5438
INFO  [2023-01-26 18:09:58,958] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test
INFO  [2023-01-26 18:09:58,958] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test
INFO  [2023-01-26 18:09:58,958] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:58,964] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test_67e4a1ff-74e5-499d-92a7-0b2a3fdc5438
INFO  [2023-01-26 18:09:58,964] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test_a027b54e-ec41-44c6-a537-0c77b80ba1b8
INFO  [2023-01-26 18:09:59,085] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test MULTI_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test
INFO  [2023-01-26 18:09:59,085] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test
INFO  [2023-01-26 18:09:59,086] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:09:59,086] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:09:59,088] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test, name=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:09:59,088] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test, name=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:09:59,088] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:59,088] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:09:59,096] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_468731de-82c7-45b0-8639-1ffd8c2c94b0 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:59,096] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_468731de-82c7-45b0-8639-1ffd8c2c94b0 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:59,096] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:59,096] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_19f40a6d-3c53-4995-b05e-f8237a39b2bd are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:09:59,096] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_19f40a6d-3c53-4995-b05e-f8237a39b2bd are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:09:59,096] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:09:59,099] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:59,199] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:59,206] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:59,207] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1
INFO  [2023-01-26 18:09:59,207] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1
INFO  [2023-01-26 18:09:59,322] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:59,433] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:09:59,433] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:09:59,433] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 157 B in total
INFO  [2023-01-26 18:09:59,433] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000290857sINFO  [2023-01-26 18:09:59,463] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=8, sum=8, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:09:59,463] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=8, nullLines=2), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:09:59,463] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=8, nullLines=0), subType=IntegerParser(super=Parser(lines=8, nullLines=0), minValue=13828, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@684dca6d)
INFO  [2023-01-26 18:09:59,467] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:59,467] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:09:59,467] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:09:59,488] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1
127.0.0.1 - - [26/Jan/2023:18:09:59 +0000] "POST /admin/datasets/MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY+Test%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 12
INFO  [2023-01-26 18:09:59,489] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:59,489] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:09:59,490] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:09:59,490] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:09:59,492] com.bakdata.conquery.models.jobs.ImportJob: Start sending 3 Buckets
INFO  [2023-01-26 18:09:59,492] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1.table1], containing 8 entries.
INFO  [2023-01-26 18:09:59,493] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1.table1], containing 8 entries.
WARN  [2023-01-26 18:09:59,493] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:09:59,493] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1.table1.0
INFO  [2023-01-26 18:09:59,494] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1.table1.2
INFO  [2023-01-26 18:09:59,494] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1.table1.1
INFO  [2023-01-26 18:09:59,599] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:59,605] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:59,617] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:09:59,618] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:59,618] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:09:59,723] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test QUERY INIT
INFO  [2023-01-26 18:09:59,732] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:09:59,733] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[56684b7b-434d-4e2f-a20f-0c76e2067ba5] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test))]]
INFO  [2023-01-26 18:09:59,735] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.56684b7b-434d-4e2f-a20f-0c76e2067ba5
INFO  [2023-01-26 18:09:59,736] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.56684b7b-434d-4e2f-a20f-0c76e2067ba5
127.0.0.1 - - [26/Jan/2023:18:09:59 +0000] "POST /api/datasets/MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test/queries HTTP/1.1" 201 2179 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:09:59,736] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.56684b7b-434d-4e2f-a20f-0c76e2067ba5] with 2 results within PT0.000735S
INFO  [2023-01-26 18:09:59,737] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.56684b7b-434d-4e2f-a20f-0c76e2067ba5] with 4 results within PT0.001246S
INFO  [2023-01-26 18:09:59,737] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.56684b7b-434d-4e2f-a20f-0c76e2067ba5, workerId=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_19f40a6d-3c53-4995-b05e-f8237a39b2bd, startTime=2023-01-26T18:09:59.736226, finishTime=2023-01-26T18:09:59.736961) of size 2
INFO  [2023-01-26 18:09:59,737] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.56684b7b-434d-4e2f-a20f-0c76e2067ba5, workerId=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_468731de-82c7-45b0-8639-1ffd8c2c94b0, startTime=2023-01-26T18:09:59.736010, finishTime=2023-01-26T18:09:59.737256) of size 4
INFO  [2023-01-26 18:09:59,737] com.bakdata.conquery.models.execution.ManagedExecution: DONE 56684b7b-434d-4e2f-a20f-0c76e2067ba5 ManagedQuery within PT0.00464S
127.0.0.1 - - [26/Jan/2023:18:09:59 +0000] "GET /api/datasets/MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test/queries/MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.56684b7b-434d-4e2f-a20f-0c76e2067ba5 HTTP/1.1" 200 2617 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:09:59,766] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test], queryId=56684b7b-434d-4e2f-a20f-0c76e2067ba5, label=Geschlecht-SELECT	@§$, creationTime=2023-01-26T18:09:59.732877, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@2ff8ece7[Count = 0], startTime=2023-01-26T18:09:59.733040, finishTime=2023-01-26T18:09:59.737680, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2ebaf819), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=6, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@1448a121, com.bakdata.conquery.models.query.ColumnDescriptor@4f6e986a]) download on dataset Dataset[label=null, name=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:09:59,766] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test], queryId=56684b7b-434d-4e2f-a20f-0c76e2067ba5, label=Geschlecht-SELECT	@§$, creationTime=2023-01-26T18:09:59.732877, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@2ff8ece7[Count = 0], startTime=2023-01-26T18:09:59.733040, finishTime=2023-01-26T18:09:59.737680, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2ebaf819), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=6, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@1448a121, com.bakdata.conquery.models.query.ColumnDescriptor@4f6e986a]) on dataset Dataset[label=null, name=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test]
127.0.0.1 - - [26/Jan/2023:18:09:59 +0000] "GET /api/datasets/MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY%20Test/result/MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.56684b7b-434d-4e2f-a20f-0c76e2067ba5.csv?pretty=false HTTP/1.1" 200 43 "-" "Conquery (test client)" 25
INFO  [2023-01-26 18:09:59,791] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test on 7 rows
INFO  [2023-01-26 18:09:59,791] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test
INFO  [2023-01-26 18:09:59,791] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test, name=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:09:59,791] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test, name=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:09:59,791] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test_468731de-82c7-45b0-8639-1ffd8c2c94b0
INFO  [2023-01-26 18:09:59,794] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test_468731de-82c7-45b0-8639-1ffd8c2c94b0
INFO  [2023-01-26 18:09:59,795] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test_19f40a6d-3c53-4995-b05e-f8237a39b2bd
INFO  [2023-01-26 18:09:59,893] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test
INFO  [2023-01-26 18:09:59,894] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test_19f40a6d-3c53-4995-b05e-f8237a39b2bd
INFO  [2023-01-26 18:09:59,894] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test
INFO  [2023-01-26 18:09:59,894] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:00,023] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test
INFO  [2023-01-26 18:10:00,023] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2 Test
INFO  [2023-01-26 18:10:00,024] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:00,024] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:00,025] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2 Test, name=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2 Test]
INFO  [2023-01-26 18:10:00,025] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2 Test, name=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2 Test]
INFO  [2023-01-26 18:10:00,025] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:00,025] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:00,026] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:00,026] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test.worker_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test_81a0864a-3c43-4bd0-9b4f-c9415566befe are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:00,026] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test.worker_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test_81a0864a-3c43-4bd0-9b4f-c9415566befe are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:00,026] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:00,026] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test.worker_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test_155bf20d-455b-49a9-aeb0-d6d8f57dd45e are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:00,026] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test.worker_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test_155bf20d-455b-49a9-aeb0-d6d8f57dd45e are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:00,026] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:00,130] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:00,137] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:00,138] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test.table1
INFO  [2023-01-26 18:10:00,138] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test.table1
INFO  [2023-01-26 18:10:00,256] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:00,367] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:00,367] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:00,367] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 158 B in total
INFO  [2023-01-26 18:10:00,367] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2 Test/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000363765sINFO  [2023-01-26 18:10:00,404] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=8, sum=8, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:10:00,404] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=8, nullLines=2), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:00,404] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=8, nullLines=0), subType=IntegerParser(super=Parser(lines=8, nullLines=0), minValue=13828, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@534a208b)
INFO  [2023-01-26 18:10:00,407] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2 Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:00,407] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:00,407] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2 Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:00,422] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test.table1
127.0.0.1 - - [26/Jan/2023:18:10:00 +0000] "POST /admin/datasets/MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2+Test%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:10:00,423] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:00,423] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:00,424] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:00,424] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:00,425] com.bakdata.conquery.models.jobs.ImportJob: Start sending 3 Buckets
INFO  [2023-01-26 18:10:00,425] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test.table1.table1], containing 8 entries.
INFO  [2023-01-26 18:10:00,425] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test.table1.table1], containing 8 entries.
WARN  [2023-01-26 18:10:00,426] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:00,426] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test.table1.table1.0
INFO  [2023-01-26 18:10:00,427] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test.table1.table1.2
INFO  [2023-01-26 18:10:00,427] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test.table1.table1.1
INFO  [2023-01-26 18:10:00,531] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:00,537] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:00,550] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:00,550] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:00,550] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:00,664] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2 Test QUERY INIT
INFO  [2023-01-26 18:10:00,679] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:00,679] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[5fd049ac-c501-4967-8874-601bcf79d6a3] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2 Test))]]
INFO  [2023-01-26 18:10:00,684] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test.5fd049ac-c501-4967-8874-601bcf79d6a3
INFO  [2023-01-26 18:10:00,684] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test.5fd049ac-c501-4967-8874-601bcf79d6a3
127.0.0.1 - - [26/Jan/2023:18:10:00 +0000] "POST /api/datasets/MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test/queries HTTP/1.1" 201 1640 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:10:00,685] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test.5fd049ac-c501-4967-8874-601bcf79d6a3] with 3 results within PT0.00103S
INFO  [2023-01-26 18:10:00,685] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test.5fd049ac-c501-4967-8874-601bcf79d6a3] with 4 results within PT0.001347S
INFO  [2023-01-26 18:10:00,685] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test.5fd049ac-c501-4967-8874-601bcf79d6a3, workerId=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test.worker_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test_155bf20d-455b-49a9-aeb0-d6d8f57dd45e, startTime=2023-01-26T18:10:00.684247, finishTime=2023-01-26T18:10:00.685277) of size 3
INFO  [2023-01-26 18:10:00,686] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test.5fd049ac-c501-4967-8874-601bcf79d6a3, workerId=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test.worker_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test_81a0864a-3c43-4bd0-9b4f-c9415566befe, startTime=2023-01-26T18:10:00.684153, finishTime=2023-01-26T18:10:00.685500) of size 4
INFO  [2023-01-26 18:10:00,686] com.bakdata.conquery.models.execution.ManagedExecution: DONE 5fd049ac-c501-4967-8874-601bcf79d6a3 ManagedQuery within PT0.00634S
127.0.0.1 - - [26/Jan/2023:18:10:00 +0000] "GET /api/datasets/MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test/queries/MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test.5fd049ac-c501-4967-8874-601bcf79d6a3 HTTP/1.1" 200 2083 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:10:00,705] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2 Test], queryId=5fd049ac-c501-4967-8874-601bcf79d6a3, label=Geschlecht-SELECT	@§$, creationTime=2023-01-26T18:10:00.679579, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@6b486dd0[Count = 0], startTime=2023-01-26T18:10:00.679875, finishTime=2023-01-26T18:10:00.686215, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@11fa034), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2 Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=7, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@fc71e6, com.bakdata.conquery.models.query.ColumnDescriptor@e5df832]) download on dataset Dataset[label=null, name=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2 Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:00,705] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2 Test], queryId=5fd049ac-c501-4967-8874-601bcf79d6a3, label=Geschlecht-SELECT	@§$, creationTime=2023-01-26T18:10:00.679579, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@6b486dd0[Count = 0], startTime=2023-01-26T18:10:00.679875, finishTime=2023-01-26T18:10:00.686215, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@11fa034), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2 Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=7, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@fc71e6, com.bakdata.conquery.models.query.ColumnDescriptor@e5df832]) on dataset Dataset[label=null, name=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2 Test]
127.0.0.1 - - [26/Jan/2023:18:10:00 +0000] "GET /api/datasets/MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2%20Test/result/MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test.5fd049ac-c501-4967-8874-601bcf79d6a3.csv?pretty=false HTTP/1.1" 200 48 "-" "Conquery (test client)" 21
INFO  [2023-01-26 18:10:00,725] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2 Test on 8 rows
INFO  [2023-01-26 18:10:00,725] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2 Test
INFO  [2023-01-26 18:10:00,725] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2 Test
INFO  [2023-01-26 18:10:00,725] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2 Test, name=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2 Test]
INFO  [2023-01-26 18:10:00,725] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2 Test, name=MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2 Test]
INFO  [2023-01-26 18:10:00,725] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2 Test_81a0864a-3c43-4bd0-9b4f-c9415566befe
INFO  [2023-01-26 18:10:00,725] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2 Test_155bf20d-455b-49a9-aeb0-d6d8f57dd45e
INFO  [2023-01-26 18:10:00,726] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2 Test_81a0864a-3c43-4bd0-9b4f-c9415566befe
INFO  [2023-01-26 18:10:00,726] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2 Test_155bf20d-455b-49a9-aeb0-d6d8f57dd45e
INFO  [2023-01-26 18:10:00,727] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2$20Test
INFO  [2023-01-26 18:10:00,727] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:00,864] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test MULTI_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY2 Test
INFO  [2023-01-26 18:10:00,864] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test NUMBER_QUERY Test
INFO  [2023-01-26 18:10:00,864] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:00,864] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:00,865] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=NUMBER_QUERY Test, name=NUMBER_QUERY Test]
INFO  [2023-01-26 18:10:00,865] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=NUMBER_QUERY Test, name=NUMBER_QUERY Test]
INFO  [2023-01-26 18:10:00,865] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:00,865] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:00,870] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker NUMBER_QUERY$20Test.worker_NUMBER_QUERY$20Test_8fb4f790-bd80-4123-bd70-961b89d8ede2 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:00,870] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker NUMBER_QUERY$20Test.worker_NUMBER_QUERY$20Test_8fb4f790-bd80-4123-bd70-961b89d8ede2 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:00,870] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:00,870] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker NUMBER_QUERY$20Test.worker_NUMBER_QUERY$20Test_745dce51-15fb-4473-8152-be0be2c38e9d are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:00,870] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker NUMBER_QUERY$20Test.worker_NUMBER_QUERY$20Test_745dce51-15fb-4473-8152-be0be2c38e9d are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:00,870] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:00,871] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:00,973] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:00,980] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:00,981] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table NUMBER_QUERY$20Test.table1
INFO  [2023-01-26 18:10:00,981] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table NUMBER_QUERY$20Test.table1
INFO  [2023-01-26 18:10:01,095] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:01,204] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:01,204] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:01,204] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 372 B in total
INFO  [2023-01-26 18:10:01,204] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_QUERY Test/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.0003557sINFO  [2023-01-26 18:10:01,240] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=8, sum=12, min=1, average=1.500000, max=2}
INFO  [2023-01-26 18:10:01,240] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=12, nullLines=0), minParser=DateParser(super=Parser(lines=12, nullLines=0), subType=IntegerParser(super=Parser(lines=12, nullLines=0), minValue=16106, maxValue=16469), dateReader=com.bakdata.conquery.util.DateReader@38079312), maxParser=DateParser(super=Parser(lines=12, nullLines=0), subType=IntegerParser(super=Parser(lines=12, nullLines=0), minValue=16121, maxValue=16616), dateReader=com.bakdata.conquery.util.DateReader@742d5cab), dateReader=com.bakdata.conquery.util.DateReader@6c25a59a, onlyQuarters=false, maxValue=16616, minValue=16106, anyOpen=false)
INFO  [2023-01-26 18:10:01,240] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with RealParser(super=Parser(lines=12, nullLines=1), requiredPrecision=4.9E-324, floatULP=1.1920928955078125E-7)
INFO  [2023-01-26 18:10:01,243] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:01,243] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:01,243] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:01,257] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into NUMBER_QUERY$20Test.table1
127.0.0.1 - - [26/Jan/2023:18:10:01 +0000] "POST /admin/datasets/NUMBER_QUERY%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_NUMBER_QUERY+Test%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:10:01,258] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:01,259] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:01,259] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:01,259] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:01,260] com.bakdata.conquery.models.jobs.ImportJob: Start sending 3 Buckets
INFO  [2023-01-26 18:10:01,260] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[NUMBER_QUERY$20Test.table1.table1], containing 12 entries.
INFO  [2023-01-26 18:10:01,260] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[NUMBER_QUERY$20Test.table1.table1], containing 12 entries.
WARN  [2023-01-26 18:10:01,261] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:01,261] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_QUERY$20Test.table1.table1.0
INFO  [2023-01-26 18:10:01,261] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_QUERY$20Test.table1.table1.2
INFO  [2023-01-26 18:10:01,261] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_QUERY$20Test.table1.table1.1
INFO  [2023-01-26 18:10:01,367] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:01,373] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:01,386] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:01,386] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:01,386] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:01,491] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: NUMBER_QUERY Test QUERY INIT
INFO  [2023-01-26 18:10:01,504] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[NUMBER_QUERY$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:01,505] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[4104996d-d94c-4d28-aec8-b47b12a1c48f] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_QUERY Test))]]
INFO  [2023-01-26 18:10:01,509] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery NUMBER_QUERY$20Test.4104996d-d94c-4d28-aec8-b47b12a1c48f
INFO  [2023-01-26 18:10:01,509] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery NUMBER_QUERY$20Test.4104996d-d94c-4d28-aec8-b47b12a1c48f
127.0.0.1 - - [26/Jan/2023:18:10:01 +0000] "POST /api/datasets/NUMBER_QUERY$20Test/queries HTTP/1.1" 201 1358 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:10:01,512] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[NUMBER_QUERY$20Test.4104996d-d94c-4d28-aec8-b47b12a1c48f] with 2 results within PT0.002513S
INFO  [2023-01-26 18:10:01,513] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=NUMBER_QUERY$20Test.4104996d-d94c-4d28-aec8-b47b12a1c48f, workerId=NUMBER_QUERY$20Test.worker_NUMBER_QUERY$20Test_8fb4f790-bd80-4123-bd70-961b89d8ede2, startTime=2023-01-26T18:10:01.509974, finishTime=2023-01-26T18:10:01.512487) of size 2
INFO  [2023-01-26 18:10:01,520] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[NUMBER_QUERY$20Test.4104996d-d94c-4d28-aec8-b47b12a1c48f] with 2 results within PT0.01015S
INFO  [2023-01-26 18:10:01,520] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=NUMBER_QUERY$20Test.4104996d-d94c-4d28-aec8-b47b12a1c48f, workerId=NUMBER_QUERY$20Test.worker_NUMBER_QUERY$20Test_745dce51-15fb-4473-8152-be0be2c38e9d, startTime=2023-01-26T18:10:01.509986, finishTime=2023-01-26T18:10:01.520136) of size 2
INFO  [2023-01-26 18:10:01,520] com.bakdata.conquery.models.execution.ManagedExecution: DONE 4104996d-d94c-4d28-aec8-b47b12a1c48f ManagedQuery within PT0.015532S
127.0.0.1 - - [26/Jan/2023:18:10:01 +0000] "GET /api/datasets/NUMBER_QUERY$20Test/queries/NUMBER_QUERY$20Test.4104996d-d94c-4d28-aec8-b47b12a1c48f HTTP/1.1" 200 1626 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:10:01,531] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=NUMBER_QUERY Test], queryId=4104996d-d94c-4d28-aec8-b47b12a1c48f, label=vs	@§$, creationTime=2023-01-26T18:10:01.504972, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@11355ced[Count = 0], startTime=2023-01-26T18:10:01.505147, finishTime=2023-01-26T18:10:01.520679, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@363ee484), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@380527, com.bakdata.conquery.models.query.ColumnDescriptor@1b3431c1]) download on dataset Dataset[label=null, name=NUMBER_QUERY Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:01,532] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=NUMBER_QUERY Test], queryId=4104996d-d94c-4d28-aec8-b47b12a1c48f, label=vs	@§$, creationTime=2023-01-26T18:10:01.504972, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@11355ced[Count = 0], startTime=2023-01-26T18:10:01.505147, finishTime=2023-01-26T18:10:01.520679, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@363ee484), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@380527, com.bakdata.conquery.models.query.ColumnDescriptor@1b3431c1]) on dataset Dataset[label=null, name=NUMBER_QUERY Test]
127.0.0.1 - - [26/Jan/2023:18:10:01 +0000] "GET /api/datasets/NUMBER_QUERY%20Test/result/NUMBER_QUERY$20Test.4104996d-d94c-4d28-aec8-b47b12a1c48f.csv?pretty=false HTTP/1.1" 200 145 "-" "Conquery (test client)" 25
INFO  [2023-01-26 18:10:01,557] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest NUMBER_QUERY Test on 5 rows
INFO  [2023-01-26 18:10:01,557] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast NUMBER_QUERY Test
INFO  [2023-01-26 18:10:01,557] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=NUMBER_QUERY Test, name=NUMBER_QUERY Test]
INFO  [2023-01-26 18:10:01,557] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=NUMBER_QUERY Test, name=NUMBER_QUERY Test]
INFO  [2023-01-26 18:10:01,557] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_NUMBER_QUERY Test_8fb4f790-bd80-4123-bd70-961b89d8ede2
INFO  [2023-01-26 18:10:01,558] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_NUMBER_QUERY Test_745dce51-15fb-4473-8152-be0be2c38e9d
INFO  [2023-01-26 18:10:01,565] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow NUMBER_QUERY Test
INFO  [2023-01-26 18:10:01,569] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_NUMBER_QUERY Test_745dce51-15fb-4473-8152-be0be2c38e9d
INFO  [2023-01-26 18:10:01,569] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_NUMBER_QUERY Test_8fb4f790-bd80-4123-bd70-961b89d8ede2
INFO  [2023-01-26 18:10:01,661] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of NUMBER_QUERY$20Test
INFO  [2023-01-26 18:10:01,661] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:01,691] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test NUMBER_QUERY Test
INFO  [2023-01-26 18:10:01,692] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test NUMBER_MISSING_QUERY Test
INFO  [2023-01-26 18:10:01,692] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:01,692] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:01,693] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=NUMBER_MISSING_QUERY Test, name=NUMBER_MISSING_QUERY Test]
INFO  [2023-01-26 18:10:01,693] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=NUMBER_MISSING_QUERY Test, name=NUMBER_MISSING_QUERY Test]
INFO  [2023-01-26 18:10:01,693] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:01,693] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:01,694] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker NUMBER_MISSING_QUERY$20Test.worker_NUMBER_MISSING_QUERY$20Test_e289000c-f908-49bf-8f7f-2caf13b36d57 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:01,694] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker NUMBER_MISSING_QUERY$20Test.worker_NUMBER_MISSING_QUERY$20Test_e289000c-f908-49bf-8f7f-2caf13b36d57 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:01,694] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:01,696] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker NUMBER_MISSING_QUERY$20Test.worker_NUMBER_MISSING_QUERY$20Test_e664e7c4-4f62-4d2f-8296-94d0855df781 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:01,696] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker NUMBER_MISSING_QUERY$20Test.worker_NUMBER_MISSING_QUERY$20Test_e664e7c4-4f62-4d2f-8296-94d0855df781 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:01,696] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:01,699] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:01,801] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:01,808] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:01,808] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table NUMBER_MISSING_QUERY$20Test.table1
INFO  [2023-01-26 18:10:01,808] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table NUMBER_MISSING_QUERY$20Test.table1
INFO  [2023-01-26 18:10:01,920] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:02,031] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:02,032] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:02,032] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 129 B in total
INFO  [2023-01-26 18:10:02,032] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_MISSING_QUERY Test/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000314902sINFO  [2023-01-26 18:10:02,064] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=4, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:10:02,064] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=4, nullLines=0), minParser=DateParser(super=Parser(lines=4, nullLines=0), subType=IntegerParser(super=Parser(lines=4, nullLines=0), minValue=16251, maxValue=16555), dateReader=com.bakdata.conquery.util.DateReader@13f0895b), maxParser=DateParser(super=Parser(lines=4, nullLines=0), subType=IntegerParser(super=Parser(lines=4, nullLines=0), minValue=16616, maxValue=16616), dateReader=com.bakdata.conquery.util.DateReader@55821637), dateReader=com.bakdata.conquery.util.DateReader@201d4a42, onlyQuarters=false, maxValue=16616, minValue=16251, anyOpen=false)
INFO  [2023-01-26 18:10:02,064] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with RealParser(super=Parser(lines=4, nullLines=2), requiredPrecision=4.9E-324, floatULP=1.401298464324817E-45)
INFO  [2023-01-26 18:10:02,067] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_MISSING_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:02,067] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:02,067] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_MISSING_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:02,085] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into NUMBER_MISSING_QUERY$20Test.table1
127.0.0.1 - - [26/Jan/2023:18:10:02 +0000] "POST /admin/datasets/NUMBER_MISSING_QUERY%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_NUMBER_MISSING_QUERY+Test%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:10:02,086] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:02,086] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:02,086] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:02,086] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:02,088] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:02,088] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[NUMBER_MISSING_QUERY$20Test.table1.table1], containing 4 entries.
INFO  [2023-01-26 18:10:02,088] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[NUMBER_MISSING_QUERY$20Test.table1.table1], containing 4 entries.
WARN  [2023-01-26 18:10:02,089] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:02,089] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_MISSING_QUERY$20Test.table1.table1.0
INFO  [2023-01-26 18:10:02,089] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_MISSING_QUERY$20Test.table1.table1.1
INFO  [2023-01-26 18:10:02,194] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:02,200] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:02,210] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:02,210] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:02,210] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:02,316] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: NUMBER_MISSING_QUERY Test QUERY INIT
INFO  [2023-01-26 18:10:02,329] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[NUMBER_MISSING_QUERY$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:02,329] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[b08136b8-a07f-4db6-91af-f03e88e86627] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_MISSING_QUERY Test))]]
INFO  [2023-01-26 18:10:02,335] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery NUMBER_MISSING_QUERY$20Test.b08136b8-a07f-4db6-91af-f03e88e86627
INFO  [2023-01-26 18:10:02,335] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery NUMBER_MISSING_QUERY$20Test.b08136b8-a07f-4db6-91af-f03e88e86627
INFO  [2023-01-26 18:10:02,336] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[NUMBER_MISSING_QUERY$20Test.b08136b8-a07f-4db6-91af-f03e88e86627] with 0 results within PT0.00081S
127.0.0.1 - - [26/Jan/2023:18:10:02 +0000] "POST /api/datasets/NUMBER_MISSING_QUERY$20Test/queries HTTP/1.1" 201 1390 "-" "Conquery (test client)" 10
INFO  [2023-01-26 18:10:02,336] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[NUMBER_MISSING_QUERY$20Test.b08136b8-a07f-4db6-91af-f03e88e86627] with 1 results within PT0.001113S
INFO  [2023-01-26 18:10:02,336] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=NUMBER_MISSING_QUERY$20Test.b08136b8-a07f-4db6-91af-f03e88e86627, workerId=NUMBER_MISSING_QUERY$20Test.worker_NUMBER_MISSING_QUERY$20Test_e664e7c4-4f62-4d2f-8296-94d0855df781, startTime=2023-01-26T18:10:02.335269, finishTime=2023-01-26T18:10:02.336079) of size 0
INFO  [2023-01-26 18:10:02,336] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=NUMBER_MISSING_QUERY$20Test.b08136b8-a07f-4db6-91af-f03e88e86627, workerId=NUMBER_MISSING_QUERY$20Test.worker_NUMBER_MISSING_QUERY$20Test_e289000c-f908-49bf-8f7f-2caf13b36d57, startTime=2023-01-26T18:10:02.335250, finishTime=2023-01-26T18:10:02.336363) of size 1
INFO  [2023-01-26 18:10:02,336] com.bakdata.conquery.models.execution.ManagedExecution: DONE b08136b8-a07f-4db6-91af-f03e88e86627 ManagedQuery within PT0.007283S
127.0.0.1 - - [26/Jan/2023:18:10:02 +0000] "GET /api/datasets/NUMBER_MISSING_QUERY$20Test/queries/NUMBER_MISSING_QUERY$20Test.b08136b8-a07f-4db6-91af-f03e88e86627 HTTP/1.1" 200 1688 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:10:02,360] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=NUMBER_MISSING_QUERY Test], queryId=b08136b8-a07f-4db6-91af-f03e88e86627, label=vs	@§$, creationTime=2023-01-26T18:10:02.329424, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@d25e454[Count = 0], startTime=2023-01-26T18:10:02.329637, finishTime=2023-01-26T18:10:02.336920, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@5c20593c), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_MISSING_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@57c66b16, com.bakdata.conquery.models.query.ColumnDescriptor@7122ec2]) download on dataset Dataset[label=null, name=NUMBER_MISSING_QUERY Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:02,360] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=NUMBER_MISSING_QUERY Test], queryId=b08136b8-a07f-4db6-91af-f03e88e86627, label=vs	@§$, creationTime=2023-01-26T18:10:02.329424, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@d25e454[Count = 0], startTime=2023-01-26T18:10:02.329637, finishTime=2023-01-26T18:10:02.336920, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@5c20593c), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_MISSING_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@57c66b16, com.bakdata.conquery.models.query.ColumnDescriptor@7122ec2]) on dataset Dataset[label=null, name=NUMBER_MISSING_QUERY Test]
127.0.0.1 - - [26/Jan/2023:18:10:02 +0000] "GET /api/datasets/NUMBER_MISSING_QUERY%20Test/result/NUMBER_MISSING_QUERY$20Test.b08136b8-a07f-4db6-91af-f03e88e86627.csv?pretty=false HTTP/1.1" 200 40 "-" "Conquery (test client)" 20
INFO  [2023-01-26 18:10:02,378] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest NUMBER_MISSING_QUERY Test on 2 rows
INFO  [2023-01-26 18:10:02,378] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast NUMBER_MISSING_QUERY Test
INFO  [2023-01-26 18:10:02,379] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=NUMBER_MISSING_QUERY Test, name=NUMBER_MISSING_QUERY Test]
INFO  [2023-01-26 18:10:02,379] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=NUMBER_MISSING_QUERY Test, name=NUMBER_MISSING_QUERY Test]
INFO  [2023-01-26 18:10:02,379] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_NUMBER_MISSING_QUERY Test_e664e7c4-4f62-4d2f-8296-94d0855df781
INFO  [2023-01-26 18:10:02,379] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_NUMBER_MISSING_QUERY Test_e289000c-f908-49bf-8f7f-2caf13b36d57
INFO  [2023-01-26 18:10:02,393] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow NUMBER_MISSING_QUERY Test
INFO  [2023-01-26 18:10:02,394] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_NUMBER_MISSING_QUERY Test_e289000c-f908-49bf-8f7f-2caf13b36d57
INFO  [2023-01-26 18:10:02,396] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_NUMBER_MISSING_QUERY Test_e664e7c4-4f62-4d2f-8296-94d0855df781
INFO  [2023-01-26 18:10:02,489] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of NUMBER_MISSING_QUERY$20Test
INFO  [2023-01-26 18:10:02,489] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:02,516] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test NUMBER_MISSING_QUERY Test
INFO  [2023-01-26 18:10:02,516] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY Test
INFO  [2023-01-26 18:10:02,516] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:02,516] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:02,520] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY Test, name=NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY Test]
INFO  [2023-01-26 18:10:02,520] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY Test, name=NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY Test]
INFO  [2023-01-26 18:10:02,520] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:02,520] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:02,532] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY$20Test.worker_NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY$20Test_a31da6df-0f8c-4b79-bbdb-ee9d4b38410b are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:02,533] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY$20Test.worker_NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY$20Test_a31da6df-0f8c-4b79-bbdb-ee9d4b38410b are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:02,533] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:02,533] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY$20Test.worker_NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY$20Test_deb5d12e-834d-4190-b290-05be32dbcc2a are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:02,533] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY$20Test.worker_NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY$20Test_deb5d12e-834d-4190-b290-05be32dbcc2a are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:02,533] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:02,536] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:02,637] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:02,643] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:02,643] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY$20Test.table1
INFO  [2023-01-26 18:10:02,643] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY$20Test.table1
INFO  [2023-01-26 18:10:02,755] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:02,863] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:02,863] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:02,863] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 129 B in total
INFO  [2023-01-26 18:10:02,863] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY Test/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000264533sINFO  [2023-01-26 18:10:02,890] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=4, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:10:02,890] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=4, nullLines=0), minParser=DateParser(super=Parser(lines=4, nullLines=0), subType=IntegerParser(super=Parser(lines=4, nullLines=0), minValue=16251, maxValue=16555), dateReader=com.bakdata.conquery.util.DateReader@52664246), maxParser=DateParser(super=Parser(lines=4, nullLines=0), subType=IntegerParser(super=Parser(lines=4, nullLines=0), minValue=16616, maxValue=16616), dateReader=com.bakdata.conquery.util.DateReader@a3b0b56), dateReader=com.bakdata.conquery.util.DateReader@210ae083, onlyQuarters=false, maxValue=16616, minValue=16251, anyOpen=false)
INFO  [2023-01-26 18:10:02,890] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with RealParser(super=Parser(lines=4, nullLines=2), requiredPrecision=4.9E-324, floatULP=1.401298464324817E-45)
INFO  [2023-01-26 18:10:02,893] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:02,893] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:02,893] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:02,910] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY$20Test.table1
INFO  [2023-01-26 18:10:02,910] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:10:02 +0000] "POST /admin/datasets/NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY+Test%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:10:02,911] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:02,911] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:02,911] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:02,913] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:02,913] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY$20Test.table1.table1], containing 4 entries.
INFO  [2023-01-26 18:10:02,913] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY$20Test.table1.table1], containing 4 entries.
WARN  [2023-01-26 18:10:02,914] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:02,914] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY$20Test.table1.table1.1
INFO  [2023-01-26 18:10:02,914] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY$20Test.table1.table1.0
INFO  [2023-01-26 18:10:03,018] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:03,024] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:03,036] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:03,036] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:03,036] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:03,141] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY Test QUERY INIT
INFO  [2023-01-26 18:10:03,158] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:03,159] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[a908809a-3700-4d4f-b31e-977b86457499] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY Test))]]
INFO  [2023-01-26 18:10:03,172] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY$20Test.a908809a-3700-4d4f-b31e-977b86457499
INFO  [2023-01-26 18:10:03,172] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY$20Test.a908809a-3700-4d4f-b31e-977b86457499
INFO  [2023-01-26 18:10:03,173] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY$20Test.a908809a-3700-4d4f-b31e-977b86457499] with 0 results within PT0.000607S
127.0.0.1 - - [26/Jan/2023:18:10:03 +0000] "POST /api/datasets/NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY$20Test/queries HTTP/1.1" 201 1340 "-" "Conquery (test client)" 17
INFO  [2023-01-26 18:10:03,174] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY$20Test.a908809a-3700-4d4f-b31e-977b86457499, workerId=NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY$20Test.worker_NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY$20Test_a31da6df-0f8c-4b79-bbdb-ee9d4b38410b, startTime=2023-01-26T18:10:03.172568, finishTime=2023-01-26T18:10:03.173175) of size 0
INFO  [2023-01-26 18:10:03,179] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY$20Test.a908809a-3700-4d4f-b31e-977b86457499] with 2 results within PT0.006742S
INFO  [2023-01-26 18:10:03,179] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY$20Test.a908809a-3700-4d4f-b31e-977b86457499, workerId=NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY$20Test.worker_NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY$20Test_deb5d12e-834d-4190-b290-05be32dbcc2a, startTime=2023-01-26T18:10:03.172553, finishTime=2023-01-26T18:10:03.179295) of size 2
INFO  [2023-01-26 18:10:03,180] com.bakdata.conquery.models.execution.ManagedExecution: DONE a908809a-3700-4d4f-b31e-977b86457499 ManagedQuery within PT0.020896S
127.0.0.1 - - [26/Jan/2023:18:10:03 +0000] "GET /api/datasets/NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY$20Test/queries/NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY$20Test.a908809a-3700-4d4f-b31e-977b86457499 HTTP/1.1" 200 1728 "-" "Conquery (test client)" 4
INFO  [2023-01-26 18:10:03,196] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY Test], queryId=a908809a-3700-4d4f-b31e-977b86457499, label=vs	@§$, creationTime=2023-01-26T18:10:03.158942, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@2798ebae[Count = 0], startTime=2023-01-26T18:10:03.159116, finishTime=2023-01-26T18:10:03.180012, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@e4797ff), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@61ab53bc, com.bakdata.conquery.models.query.ColumnDescriptor@23b6f968]) download on dataset Dataset[label=null, name=NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:03,196] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY Test], queryId=a908809a-3700-4d4f-b31e-977b86457499, label=vs	@§$, creationTime=2023-01-26T18:10:03.158942, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@2798ebae[Count = 0], startTime=2023-01-26T18:10:03.159116, finishTime=2023-01-26T18:10:03.180012, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@e4797ff), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@61ab53bc, com.bakdata.conquery.models.query.ColumnDescriptor@23b6f968]) on dataset Dataset[label=null, name=NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY Test]
127.0.0.1 - - [26/Jan/2023:18:10:03 +0000] "GET /api/datasets/NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY%20Test/result/NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY$20Test.a908809a-3700-4d4f-b31e-977b86457499.csv?pretty=false HTTP/1.1" 200 67 "-" "Conquery (test client)" 20
INFO  [2023-01-26 18:10:03,215] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY Test on 3 rows
INFO  [2023-01-26 18:10:03,215] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY Test
INFO  [2023-01-26 18:10:03,215] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY Test, name=NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY Test]
INFO  [2023-01-26 18:10:03,215] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY Test, name=NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY Test]
INFO  [2023-01-26 18:10:03,215] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY Test_deb5d12e-834d-4190-b290-05be32dbcc2a
INFO  [2023-01-26 18:10:03,215] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY Test_a31da6df-0f8c-4b79-bbdb-ee9d4b38410b
INFO  [2023-01-26 18:10:03,223] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY Test
INFO  [2023-01-26 18:10:03,232] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY Test_a31da6df-0f8c-4b79-bbdb-ee9d4b38410b
INFO  [2023-01-26 18:10:03,232] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY Test_deb5d12e-834d-4190-b290-05be32dbcc2a
INFO  [2023-01-26 18:10:03,314] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY$20Test
INFO  [2023-01-26 18:10:03,314] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:03,342] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test NUMBER_MISSING_NO_FILTER_RESTRICTION_QUERY Test
INFO  [2023-01-26 18:10:03,342] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test NUMBER_MISSING_NO_RESTRICTION_QUERY Test
INFO  [2023-01-26 18:10:03,342] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:03,342] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:03,343] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=NUMBER_MISSING_NO_RESTRICTION_QUERY Test, name=NUMBER_MISSING_NO_RESTRICTION_QUERY Test]
INFO  [2023-01-26 18:10:03,343] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=NUMBER_MISSING_NO_RESTRICTION_QUERY Test, name=NUMBER_MISSING_NO_RESTRICTION_QUERY Test]
INFO  [2023-01-26 18:10:03,343] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:03,343] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:03,344] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:03,345] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker NUMBER_MISSING_NO_RESTRICTION_QUERY$20Test.worker_NUMBER_MISSING_NO_RESTRICTION_QUERY$20Test_ce0e88df-ea97-466d-91a3-36ec0ddbe249 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:03,345] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker NUMBER_MISSING_NO_RESTRICTION_QUERY$20Test.worker_NUMBER_MISSING_NO_RESTRICTION_QUERY$20Test_ce0e88df-ea97-466d-91a3-36ec0ddbe249 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:03,345] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:03,345] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker NUMBER_MISSING_NO_RESTRICTION_QUERY$20Test.worker_NUMBER_MISSING_NO_RESTRICTION_QUERY$20Test_aa2504a3-28ce-4079-91d3-36508593b30c are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:03,345] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker NUMBER_MISSING_NO_RESTRICTION_QUERY$20Test.worker_NUMBER_MISSING_NO_RESTRICTION_QUERY$20Test_aa2504a3-28ce-4079-91d3-36508593b30c are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:03,345] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:03,449] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:03,456] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:03,456] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table NUMBER_MISSING_NO_RESTRICTION_QUERY$20Test.table1
INFO  [2023-01-26 18:10:03,456] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table NUMBER_MISSING_NO_RESTRICTION_QUERY$20Test.table1
INFO  [2023-01-26 18:10:03,572] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:03,680] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:03,680] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:03,680] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 129 B in total
INFO  [2023-01-26 18:10:03,680] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_MISSING_NO_RESTRICTION_QUERY Test/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000434312sINFO  [2023-01-26 18:10:03,724] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=4, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:10:03,724] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=4, nullLines=0), minParser=DateParser(super=Parser(lines=4, nullLines=0), subType=IntegerParser(super=Parser(lines=4, nullLines=0), minValue=16251, maxValue=16555), dateReader=com.bakdata.conquery.util.DateReader@52dff47a), maxParser=DateParser(super=Parser(lines=4, nullLines=0), subType=IntegerParser(super=Parser(lines=4, nullLines=0), minValue=16616, maxValue=16616), dateReader=com.bakdata.conquery.util.DateReader@27e238a2), dateReader=com.bakdata.conquery.util.DateReader@9b1379b, onlyQuarters=false, maxValue=16616, minValue=16251, anyOpen=false)
INFO  [2023-01-26 18:10:03,724] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with RealParser(super=Parser(lines=4, nullLines=2), requiredPrecision=4.9E-324, floatULP=1.401298464324817E-45)
INFO  [2023-01-26 18:10:03,727] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_MISSING_NO_RESTRICTION_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:03,727] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:03,727] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_MISSING_NO_RESTRICTION_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:03,750] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into NUMBER_MISSING_NO_RESTRICTION_QUERY$20Test.table1
INFO  [2023-01-26 18:10:03,751] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:10:03 +0000] "POST /admin/datasets/NUMBER_MISSING_NO_RESTRICTION_QUERY%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_NUMBER_MISSING_NO_RESTRICTION_QUERY+Test%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 15
INFO  [2023-01-26 18:10:03,751] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:03,752] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:03,752] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:03,754] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:03,754] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[NUMBER_MISSING_NO_RESTRICTION_QUERY$20Test.table1.table1], containing 4 entries.
INFO  [2023-01-26 18:10:03,755] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[NUMBER_MISSING_NO_RESTRICTION_QUERY$20Test.table1.table1], containing 4 entries.
INFO  [2023-01-26 18:10:03,756] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_MISSING_NO_RESTRICTION_QUERY$20Test.table1.table1.0
WARN  [2023-01-26 18:10:03,756] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:03,756] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_MISSING_NO_RESTRICTION_QUERY$20Test.table1.table1.1
INFO  [2023-01-26 18:10:03,864] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:03,870] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:03,879] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:03,879] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:03,879] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:03,992] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: NUMBER_MISSING_NO_RESTRICTION_QUERY Test QUERY INIT
INFO  [2023-01-26 18:10:04,004] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[NUMBER_MISSING_NO_RESTRICTION_QUERY$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:04,004] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[c60caeb4-a69b-4b91-adfb-ebd56c239ffc] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_MISSING_NO_RESTRICTION_QUERY Test))]]
INFO  [2023-01-26 18:10:04,006] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery NUMBER_MISSING_NO_RESTRICTION_QUERY$20Test.c60caeb4-a69b-4b91-adfb-ebd56c239ffc
INFO  [2023-01-26 18:10:04,006] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery NUMBER_MISSING_NO_RESTRICTION_QUERY$20Test.c60caeb4-a69b-4b91-adfb-ebd56c239ffc
INFO  [2023-01-26 18:10:04,007] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[NUMBER_MISSING_NO_RESTRICTION_QUERY$20Test.c60caeb4-a69b-4b91-adfb-ebd56c239ffc] with 1 results within PT0.000537S
INFO  [2023-01-26 18:10:04,007] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[NUMBER_MISSING_NO_RESTRICTION_QUERY$20Test.c60caeb4-a69b-4b91-adfb-ebd56c239ffc] with 3 results within PT0.000747S
127.0.0.1 - - [26/Jan/2023:18:10:04 +0000] "POST /api/datasets/NUMBER_MISSING_NO_RESTRICTION_QUERY$20Test/queries HTTP/1.1" 201 1277 "-" "Conquery (test client)" 5
INFO  [2023-01-26 18:10:04,007] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=NUMBER_MISSING_NO_RESTRICTION_QUERY$20Test.c60caeb4-a69b-4b91-adfb-ebd56c239ffc, workerId=NUMBER_MISSING_NO_RESTRICTION_QUERY$20Test.worker_NUMBER_MISSING_NO_RESTRICTION_QUERY$20Test_aa2504a3-28ce-4079-91d3-36508593b30c, startTime=2023-01-26T18:10:04.006680, finishTime=2023-01-26T18:10:04.007217) of size 1
INFO  [2023-01-26 18:10:04,007] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=NUMBER_MISSING_NO_RESTRICTION_QUERY$20Test.c60caeb4-a69b-4b91-adfb-ebd56c239ffc, workerId=NUMBER_MISSING_NO_RESTRICTION_QUERY$20Test.worker_NUMBER_MISSING_NO_RESTRICTION_QUERY$20Test_ce0e88df-ea97-466d-91a3-36ec0ddbe249, startTime=2023-01-26T18:10:04.006668, finishTime=2023-01-26T18:10:04.007415) of size 3
INFO  [2023-01-26 18:10:04,007] com.bakdata.conquery.models.execution.ManagedExecution: DONE c60caeb4-a69b-4b91-adfb-ebd56c239ffc ManagedQuery within PT0.00331S
127.0.0.1 - - [26/Jan/2023:18:10:04 +0000] "GET /api/datasets/NUMBER_MISSING_NO_RESTRICTION_QUERY$20Test/queries/NUMBER_MISSING_NO_RESTRICTION_QUERY$20Test.c60caeb4-a69b-4b91-adfb-ebd56c239ffc HTTP/1.1" 200 1636 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:10:04,036] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=NUMBER_MISSING_NO_RESTRICTION_QUERY Test], queryId=c60caeb4-a69b-4b91-adfb-ebd56c239ffc, label=vs	@§$, creationTime=2023-01-26T18:10:04.004470, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@2ab491f0[Count = 0], startTime=2023-01-26T18:10:04.004607, finishTime=2023-01-26T18:10:04.007917, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@54f2898e), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_MISSING_NO_RESTRICTION_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@750a3a1b, com.bakdata.conquery.models.query.ColumnDescriptor@68cb84ec]) download on dataset Dataset[label=null, name=NUMBER_MISSING_NO_RESTRICTION_QUERY Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:04,036] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=NUMBER_MISSING_NO_RESTRICTION_QUERY Test], queryId=c60caeb4-a69b-4b91-adfb-ebd56c239ffc, label=vs	@§$, creationTime=2023-01-26T18:10:04.004470, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@2ab491f0[Count = 0], startTime=2023-01-26T18:10:04.004607, finishTime=2023-01-26T18:10:04.007917, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@54f2898e), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_MISSING_NO_RESTRICTION_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@750a3a1b, com.bakdata.conquery.models.query.ColumnDescriptor@68cb84ec]) on dataset Dataset[label=null, name=NUMBER_MISSING_NO_RESTRICTION_QUERY Test]
127.0.0.1 - - [26/Jan/2023:18:10:04 +0000] "GET /api/datasets/NUMBER_MISSING_NO_RESTRICTION_QUERY%20Test/result/NUMBER_MISSING_NO_RESTRICTION_QUERY$20Test.c60caeb4-a69b-4b91-adfb-ebd56c239ffc.csv?pretty=false HTTP/1.1" 200 121 "-" "Conquery (test client)" 24
INFO  [2023-01-26 18:10:04,059] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest NUMBER_MISSING_NO_RESTRICTION_QUERY Test on 5 rows
INFO  [2023-01-26 18:10:04,060] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast NUMBER_MISSING_NO_RESTRICTION_QUERY Test
INFO  [2023-01-26 18:10:04,060] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=NUMBER_MISSING_NO_RESTRICTION_QUERY Test, name=NUMBER_MISSING_NO_RESTRICTION_QUERY Test]
INFO  [2023-01-26 18:10:04,060] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=NUMBER_MISSING_NO_RESTRICTION_QUERY Test, name=NUMBER_MISSING_NO_RESTRICTION_QUERY Test]
INFO  [2023-01-26 18:10:04,060] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_NUMBER_MISSING_NO_RESTRICTION_QUERY Test_aa2504a3-28ce-4079-91d3-36508593b30c
INFO  [2023-01-26 18:10:04,060] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_NUMBER_MISSING_NO_RESTRICTION_QUERY Test_ce0e88df-ea97-466d-91a3-36ec0ddbe249
INFO  [2023-01-26 18:10:04,158] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow NUMBER_MISSING_NO_RESTRICTION_QUERY Test
INFO  [2023-01-26 18:10:04,158] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_NUMBER_MISSING_NO_RESTRICTION_QUERY Test_ce0e88df-ea97-466d-91a3-36ec0ddbe249
INFO  [2023-01-26 18:10:04,158] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_NUMBER_MISSING_NO_RESTRICTION_QUERY Test_aa2504a3-28ce-4079-91d3-36508593b30c
INFO  [2023-01-26 18:10:04,159] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of NUMBER_MISSING_NO_RESTRICTION_QUERY$20Test
INFO  [2023-01-26 18:10:04,159] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:04,293] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test NUMBER_MISSING_NO_RESTRICTION_QUERY Test
INFO  [2023-01-26 18:10:04,293] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test NUMBER_NEGATION_QUERY Test
INFO  [2023-01-26 18:10:04,293] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:04,293] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:04,294] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=NUMBER_NEGATION_QUERY Test, name=NUMBER_NEGATION_QUERY Test]
INFO  [2023-01-26 18:10:04,294] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=NUMBER_NEGATION_QUERY Test, name=NUMBER_NEGATION_QUERY Test]
INFO  [2023-01-26 18:10:04,294] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:04,294] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:04,295] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:04,295] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker NUMBER_NEGATION_QUERY$20Test.worker_NUMBER_NEGATION_QUERY$20Test_3eac2651-185c-42a2-8bdd-79fd94942d7b are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:04,295] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker NUMBER_NEGATION_QUERY$20Test.worker_NUMBER_NEGATION_QUERY$20Test_3eac2651-185c-42a2-8bdd-79fd94942d7b are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:04,296] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:04,296] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker NUMBER_NEGATION_QUERY$20Test.worker_NUMBER_NEGATION_QUERY$20Test_47d04047-956a-4b08-954a-e9c91d182680 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:04,296] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker NUMBER_NEGATION_QUERY$20Test.worker_NUMBER_NEGATION_QUERY$20Test_47d04047-956a-4b08-954a-e9c91d182680 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:04,296] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:04,400] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:04,406] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:04,406] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table NUMBER_NEGATION_QUERY$20Test.table1
INFO  [2023-01-26 18:10:04,406] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table NUMBER_NEGATION_QUERY$20Test.table1
INFO  [2023-01-26 18:10:04,519] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:04,628] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:04,628] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:04,628] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 372 B in total
INFO  [2023-01-26 18:10:04,628] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_NEGATION_QUERY Test/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000214976sINFO  [2023-01-26 18:10:04,650] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=8, sum=12, min=1, average=1.500000, max=2}
INFO  [2023-01-26 18:10:04,651] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=12, nullLines=0), minParser=DateParser(super=Parser(lines=12, nullLines=0), subType=IntegerParser(super=Parser(lines=12, nullLines=0), minValue=16106, maxValue=16469), dateReader=com.bakdata.conquery.util.DateReader@7eb3934c), maxParser=DateParser(super=Parser(lines=12, nullLines=0), subType=IntegerParser(super=Parser(lines=12, nullLines=0), minValue=16121, maxValue=16616), dateReader=com.bakdata.conquery.util.DateReader@38481bbb), dateReader=com.bakdata.conquery.util.DateReader@7707d2b8, onlyQuarters=false, maxValue=16616, minValue=16106, anyOpen=false)
INFO  [2023-01-26 18:10:04,651] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with RealParser(super=Parser(lines=12, nullLines=1), requiredPrecision=4.9E-324, floatULP=1.1920928955078125E-7)
INFO  [2023-01-26 18:10:04,653] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_NEGATION_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:04,653] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:04,653] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_NEGATION_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:04,674] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into NUMBER_NEGATION_QUERY$20Test.table1
127.0.0.1 - - [26/Jan/2023:18:10:04 +0000] "POST /admin/datasets/NUMBER_NEGATION_QUERY%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_NUMBER_NEGATION_QUERY+Test%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 12
INFO  [2023-01-26 18:10:04,676] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:04,676] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:04,676] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:04,676] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:04,678] com.bakdata.conquery.models.jobs.ImportJob: Start sending 3 Buckets
INFO  [2023-01-26 18:10:04,678] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[NUMBER_NEGATION_QUERY$20Test.table1.table1], containing 12 entries.
INFO  [2023-01-26 18:10:04,678] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[NUMBER_NEGATION_QUERY$20Test.table1.table1], containing 12 entries.
INFO  [2023-01-26 18:10:04,679] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_NEGATION_QUERY$20Test.table1.table1.0
WARN  [2023-01-26 18:10:04,680] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:04,680] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_NEGATION_QUERY$20Test.table1.table1.1
INFO  [2023-01-26 18:10:04,680] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_NEGATION_QUERY$20Test.table1.table1.2
INFO  [2023-01-26 18:10:04,784] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:04,789] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:04,802] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:04,803] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:04,803] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:04,908] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: NUMBER_NEGATION_QUERY Test QUERY INIT
INFO  [2023-01-26 18:10:04,932] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[NUMBER_NEGATION_QUERY$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:04,933] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[16b659b3-466c-4bc6-bc57-2d8b4e61056c] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_NEGATION_QUERY Test))]]
INFO  [2023-01-26 18:10:04,937] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery NUMBER_NEGATION_QUERY$20Test.16b659b3-466c-4bc6-bc57-2d8b4e61056c
INFO  [2023-01-26 18:10:04,937] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery NUMBER_NEGATION_QUERY$20Test.16b659b3-466c-4bc6-bc57-2d8b4e61056c
127.0.0.1 - - [26/Jan/2023:18:10:04 +0000] "POST /api/datasets/NUMBER_NEGATION_QUERY$20Test/queries HTTP/1.1" 201 1435 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:10:04,938] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[NUMBER_NEGATION_QUERY$20Test.16b659b3-466c-4bc6-bc57-2d8b4e61056c] with 1 results within PT0.001072S
INFO  [2023-01-26 18:10:04,939] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[NUMBER_NEGATION_QUERY$20Test.16b659b3-466c-4bc6-bc57-2d8b4e61056c] with 3 results within PT0.001419S
INFO  [2023-01-26 18:10:04,939] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=NUMBER_NEGATION_QUERY$20Test.16b659b3-466c-4bc6-bc57-2d8b4e61056c, workerId=NUMBER_NEGATION_QUERY$20Test.worker_NUMBER_NEGATION_QUERY$20Test_3eac2651-185c-42a2-8bdd-79fd94942d7b, startTime=2023-01-26T18:10:04.937688, finishTime=2023-01-26T18:10:04.938760) of size 1
INFO  [2023-01-26 18:10:04,939] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=NUMBER_NEGATION_QUERY$20Test.16b659b3-466c-4bc6-bc57-2d8b4e61056c, workerId=NUMBER_NEGATION_QUERY$20Test.worker_NUMBER_NEGATION_QUERY$20Test_47d04047-956a-4b08-954a-e9c91d182680, startTime=2023-01-26T18:10:04.937676, finishTime=2023-01-26T18:10:04.939095) of size 3
INFO  [2023-01-26 18:10:04,939] com.bakdata.conquery.models.execution.ManagedExecution: DONE 16b659b3-466c-4bc6-bc57-2d8b4e61056c ManagedQuery within PT0.006376S
127.0.0.1 - - [26/Jan/2023:18:10:04 +0000] "GET /api/datasets/NUMBER_NEGATION_QUERY$20Test/queries/NUMBER_NEGATION_QUERY$20Test.16b659b3-466c-4bc6-bc57-2d8b4e61056c HTTP/1.1" 200 1738 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:10:04,957] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=NUMBER_NEGATION_QUERY Test], queryId=16b659b3-466c-4bc6-bc57-2d8b4e61056c, label=vs	@§$, creationTime=2023-01-26T18:10:04.933136, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@78bef51d[Count = 0], startTime=2023-01-26T18:10:04.933309, finishTime=2023-01-26T18:10:04.939685, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@6af7d468), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_NEGATION_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@18d73706, com.bakdata.conquery.models.query.ColumnDescriptor@67360052]) download on dataset Dataset[label=null, name=NUMBER_NEGATION_QUERY Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:04,957] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=NUMBER_NEGATION_QUERY Test], queryId=16b659b3-466c-4bc6-bc57-2d8b4e61056c, label=vs	@§$, creationTime=2023-01-26T18:10:04.933136, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@78bef51d[Count = 0], startTime=2023-01-26T18:10:04.933309, finishTime=2023-01-26T18:10:04.939685, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@6af7d468), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_NEGATION_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@18d73706, com.bakdata.conquery.models.query.ColumnDescriptor@67360052]) on dataset Dataset[label=null, name=NUMBER_NEGATION_QUERY Test]
127.0.0.1 - - [26/Jan/2023:18:10:04 +0000] "GET /api/datasets/NUMBER_NEGATION_QUERY%20Test/result/NUMBER_NEGATION_QUERY$20Test.16b659b3-466c-4bc6-bc57-2d8b4e61056c.csv?pretty=false HTTP/1.1" 200 37 "-" "Conquery (test client)" 29
INFO  [2023-01-26 18:10:04,985] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest NUMBER_NEGATION_QUERY Test on 5 rows
INFO  [2023-01-26 18:10:04,985] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast NUMBER_NEGATION_QUERY Test
INFO  [2023-01-26 18:10:04,985] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=NUMBER_NEGATION_QUERY Test, name=NUMBER_NEGATION_QUERY Test]
INFO  [2023-01-26 18:10:04,985] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=NUMBER_NEGATION_QUERY Test, name=NUMBER_NEGATION_QUERY Test]
INFO  [2023-01-26 18:10:04,986] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_NUMBER_NEGATION_QUERY Test_47d04047-956a-4b08-954a-e9c91d182680
INFO  [2023-01-26 18:10:04,986] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_NUMBER_NEGATION_QUERY Test_3eac2651-185c-42a2-8bdd-79fd94942d7b
INFO  [2023-01-26 18:10:04,998] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow NUMBER_NEGATION_QUERY Test
INFO  [2023-01-26 18:10:04,998] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_NUMBER_NEGATION_QUERY Test_47d04047-956a-4b08-954a-e9c91d182680
INFO  [2023-01-26 18:10:04,998] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_NUMBER_NEGATION_QUERY Test_3eac2651-185c-42a2-8bdd-79fd94942d7b
INFO  [2023-01-26 18:10:05,112] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of NUMBER_NEGATION_QUERY$20Test
INFO  [2023-01-26 18:10:05,112] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:05,117] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test NUMBER_NEGATION_QUERY Test
INFO  [2023-01-26 18:10:05,118] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test NUMBER_QUERY Test
INFO  [2023-01-26 18:10:05,118] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:05,118] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:05,136] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=NUMBER_QUERY Test[1], name=NUMBER_QUERY Test[1]]
INFO  [2023-01-26 18:10:05,136] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:05,138] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=NUMBER_QUERY Test[1], name=NUMBER_QUERY Test[1]]
INFO  [2023-01-26 18:10:05,138] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:05,147] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker NUMBER_QUERY$20Test[1].worker_NUMBER_QUERY$20Test[1]_7c12ade7-3ece-43ac-9156-f8ac3fc53654 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:05,147] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker NUMBER_QUERY$20Test[1].worker_NUMBER_QUERY$20Test[1]_7c12ade7-3ece-43ac-9156-f8ac3fc53654 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:05,147] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:05,147] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker NUMBER_QUERY$20Test[1].worker_NUMBER_QUERY$20Test[1]_3c1253a1-43b0-494a-ae53-4aec280bdf90 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:05,147] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker NUMBER_QUERY$20Test[1].worker_NUMBER_QUERY$20Test[1]_3c1253a1-43b0-494a-ae53-4aec280bdf90 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:05,147] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:05,148] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:05,244] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:05,257] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:05,258] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table NUMBER_QUERY$20Test[1].table1
INFO  [2023-01-26 18:10:05,258] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table NUMBER_QUERY$20Test[1].table1
INFO  [2023-01-26 18:10:05,390] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:05,503] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:05,510] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:05,510] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 372 B in total
INFO  [2023-01-26 18:10:05,510] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_QUERY Test[1]/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.00038456sINFO  [2023-01-26 18:10:05,549] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=8, sum=12, min=1, average=1.500000, max=2}
INFO  [2023-01-26 18:10:05,549] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=12, nullLines=0), minParser=DateParser(super=Parser(lines=12, nullLines=0), subType=IntegerParser(super=Parser(lines=12, nullLines=0), minValue=16106, maxValue=16469), dateReader=com.bakdata.conquery.util.DateReader@2a11eaf4), maxParser=DateParser(super=Parser(lines=12, nullLines=0), subType=IntegerParser(super=Parser(lines=12, nullLines=0), minValue=16121, maxValue=16616), dateReader=com.bakdata.conquery.util.DateReader@59a00ab5), dateReader=com.bakdata.conquery.util.DateReader@3e5ef6c7, onlyQuarters=false, maxValue=16616, minValue=16106, anyOpen=false)
INFO  [2023-01-26 18:10:05,549] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with RealParser(super=Parser(lines=12, nullLines=1), requiredPrecision=4.9E-324, floatULP=1.1920928955078125E-7)
INFO  [2023-01-26 18:10:05,552] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_QUERY Test[1]/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:05,552] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:05,552] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_NUMBER_QUERY Test[1]/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:05,571] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into NUMBER_QUERY$20Test[1].table1
INFO  [2023-01-26 18:10:05,571] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:10:05 +0000] "POST /admin/datasets/NUMBER_QUERY%20Test%5B1%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_NUMBER_QUERY+Test%5B1%5D%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 10
INFO  [2023-01-26 18:10:05,572] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:05,572] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:05,572] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:05,573] com.bakdata.conquery.models.jobs.ImportJob: Start sending 1 Buckets
WARN  [2023-01-26 18:10:05,574] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:05,578] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[NUMBER_QUERY$20Test[1].table1.table1], containing 12 entries.
INFO  [2023-01-26 18:10:05,578] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[NUMBER_QUERY$20Test[1].table1.table1], containing 12 entries.
INFO  [2023-01-26 18:10:05,579] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received NUMBER_QUERY$20Test[1].table1.table1.0
INFO  [2023-01-26 18:10:05,684] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:05,690] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:05,710] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:05,710] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:05,826] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: NUMBER_QUERY Test QUERY INIT
INFO  [2023-01-26 18:10:05,850] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[NUMBER_QUERY$20Test[1]] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:05,850] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[0eb509e1-9bf9-44e8-8b07-b9ccb42017b2] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_QUERY Test[1]))]]
127.0.0.1 - - [26/Jan/2023:18:10:05 +0000] "POST /api/datasets/NUMBER_QUERY$20Test%5B1%5D/queries HTTP/1.1" 201 1370 "-" "Conquery (test client)" 14
INFO  [2023-01-26 18:10:05,863] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery NUMBER_QUERY$20Test[1].0eb509e1-9bf9-44e8-8b07-b9ccb42017b2
INFO  [2023-01-26 18:10:05,863] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery NUMBER_QUERY$20Test[1].0eb509e1-9bf9-44e8-8b07-b9ccb42017b2
WARN  [2023-01-26 18:10:05,863] com.bakdata.conquery.models.query.QueryExecutor: Entities for query are empty
INFO  [2023-01-26 18:10:05,863] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[NUMBER_QUERY$20Test[1].0eb509e1-9bf9-44e8-8b07-b9ccb42017b2] with 0 results within PT0.000128S
INFO  [2023-01-26 18:10:05,864] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[NUMBER_QUERY$20Test[1].0eb509e1-9bf9-44e8-8b07-b9ccb42017b2] with 4 results within PT0.001085S
INFO  [2023-01-26 18:10:05,866] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=NUMBER_QUERY$20Test[1].0eb509e1-9bf9-44e8-8b07-b9ccb42017b2, workerId=NUMBER_QUERY$20Test[1].worker_NUMBER_QUERY$20Test[1]_3c1253a1-43b0-494a-ae53-4aec280bdf90, startTime=2023-01-26T18:10:05.863421, finishTime=2023-01-26T18:10:05.863549) of size 0
INFO  [2023-01-26 18:10:05,866] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=NUMBER_QUERY$20Test[1].0eb509e1-9bf9-44e8-8b07-b9ccb42017b2, workerId=NUMBER_QUERY$20Test[1].worker_NUMBER_QUERY$20Test[1]_7c12ade7-3ece-43ac-9156-f8ac3fc53654, startTime=2023-01-26T18:10:05.863334, finishTime=2023-01-26T18:10:05.864419) of size 4
INFO  [2023-01-26 18:10:05,866] com.bakdata.conquery.models.execution.ManagedExecution: DONE 0eb509e1-9bf9-44e8-8b07-b9ccb42017b2 ManagedQuery within PT0.016192S
127.0.0.1 - - [26/Jan/2023:18:10:05 +0000] "GET /api/datasets/NUMBER_QUERY$20Test%5B1%5D/queries/NUMBER_QUERY$20Test%5B1%5D.0eb509e1-9bf9-44e8-8b07-b9ccb42017b2 HTTP/1.1" 200 1890 "-" "Conquery (test client)" 4
INFO  [2023-01-26 18:10:05,880] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=NUMBER_QUERY Test[1]], queryId=0eb509e1-9bf9-44e8-8b07-b9ccb42017b2, label=vs	@§$, creationTime=2023-01-26T18:10:05.850586, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@3612c7f1[Count = 0], startTime=2023-01-26T18:10:05.850756, finishTime=2023-01-26T18:10:05.866948, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@6f5523db), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_QUERY Test[1])), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@65d3ac47], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@5de23e15], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@4d556fbe]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@d9b7eb8, com.bakdata.conquery.models.query.ColumnDescriptor@2d160db5]) download on dataset Dataset[label=null, name=NUMBER_QUERY Test[1]] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:05,880] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=NUMBER_QUERY Test[1]], queryId=0eb509e1-9bf9-44e8-8b07-b9ccb42017b2, label=vs	@§$, creationTime=2023-01-26T18:10:05.850586, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@3612c7f1[Count = 0], startTime=2023-01-26T18:10:05.850756, finishTime=2023-01-26T18:10:05.866948, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@6f5523db), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_NUMBER_QUERY Test[1])), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@65d3ac47], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@5de23e15], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@4d556fbe]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@d9b7eb8, com.bakdata.conquery.models.query.ColumnDescriptor@2d160db5]) on dataset Dataset[label=null, name=NUMBER_QUERY Test[1]]
127.0.0.1 - - [26/Jan/2023:18:10:05 +0000] "GET /api/datasets/NUMBER_QUERY%20Test%5B1%5D/result/NUMBER_QUERY$20Test%5B1%5D.0eb509e1-9bf9-44e8-8b07-b9ccb42017b2.csv?pretty=false HTTP/1.1" 200 143 "-" "Conquery (test client)" 18
INFO  [2023-01-26 18:10:05,896] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest NUMBER_QUERY Test on 5 rows
INFO  [2023-01-26 18:10:05,898] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast NUMBER_QUERY Test[1]
INFO  [2023-01-26 18:10:05,898] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=NUMBER_QUERY Test[1], name=NUMBER_QUERY Test[1]]
INFO  [2023-01-26 18:10:05,898] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_NUMBER_QUERY Test[1]_3c1253a1-43b0-494a-ae53-4aec280bdf90
INFO  [2023-01-26 18:10:05,899] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=NUMBER_QUERY Test[1], name=NUMBER_QUERY Test[1]]
INFO  [2023-01-26 18:10:05,899] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_NUMBER_QUERY Test[1]_7c12ade7-3ece-43ac-9156-f8ac3fc53654
INFO  [2023-01-26 18:10:05,933] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow NUMBER_QUERY Test[1]
INFO  [2023-01-26 18:10:05,937] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_NUMBER_QUERY Test[1]_7c12ade7-3ece-43ac-9156-f8ac3fc53654
INFO  [2023-01-26 18:10:05,942] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_NUMBER_QUERY Test[1]_3c1253a1-43b0-494a-ae53-4aec280bdf90
INFO  [2023-01-26 18:10:05,975] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of NUMBER_QUERY$20Test[1]
INFO  [2023-01-26 18:10:05,975] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:06,116] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test NUMBER_QUERY Test
INFO  [2023-01-26 18:10:06,116] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test TEMPORAL_BEFORE_CONCEPT_QUERY Test
INFO  [2023-01-26 18:10:06,116] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:06,116] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:06,117] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=TEMPORAL_BEFORE_CONCEPT_QUERY Test, name=TEMPORAL_BEFORE_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:10:06,117] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=TEMPORAL_BEFORE_CONCEPT_QUERY Test, name=TEMPORAL_BEFORE_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:10:06,117] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:06,118] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:06,119] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker TEMPORAL_BEFORE_CONCEPT_QUERY$20Test.worker_TEMPORAL_BEFORE_CONCEPT_QUERY$20Test_442212d2-4eb7-4df5-8928-827b9ecc70ad are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:06,119] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker TEMPORAL_BEFORE_CONCEPT_QUERY$20Test.worker_TEMPORAL_BEFORE_CONCEPT_QUERY$20Test_442212d2-4eb7-4df5-8928-827b9ecc70ad are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:06,119] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:06,120] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker TEMPORAL_BEFORE_CONCEPT_QUERY$20Test.worker_TEMPORAL_BEFORE_CONCEPT_QUERY$20Test_0ab613b7-c585-4d8e-8166-4a4fe1efea42 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:06,120] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker TEMPORAL_BEFORE_CONCEPT_QUERY$20Test.worker_TEMPORAL_BEFORE_CONCEPT_QUERY$20Test_0ab613b7-c585-4d8e-8166-4a4fe1efea42 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:06,120] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:06,124] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:06,224] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:06,230] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:06,231] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table TEMPORAL_BEFORE_CONCEPT_QUERY$20Test.table1
INFO  [2023-01-26 18:10:06,231] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table TEMPORAL_BEFORE_CONCEPT_QUERY$20Test.table1
INFO  [2023-01-26 18:10:06,342] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:06,451] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:06,451] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:06,451] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 178 B in total
INFO  [2023-01-26 18:10:06,451] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_TEMPORAL_BEFORE_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.00020034sINFO  [2023-01-26 18:10:06,471] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=9, min=2, average=2.250000, max=3}
INFO  [2023-01-26 18:10:06,472] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=9, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:06,472] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=9, nullLines=0), subType=IntegerParser(super=Parser(lines=9, nullLines=0), minValue=14975, maxValue=15006), dateReader=com.bakdata.conquery.util.DateReader@3b051266)
INFO  [2023-01-26 18:10:06,475] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_TEMPORAL_BEFORE_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:06,475] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:06,475] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_TEMPORAL_BEFORE_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:06,503] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into TEMPORAL_BEFORE_CONCEPT_QUERY$20Test.table1
INFO  [2023-01-26 18:10:06,504] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:10:06 +0000] "POST /admin/datasets/TEMPORAL_BEFORE_CONCEPT_QUERY%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_TEMPORAL_BEFORE_CONCEPT_QUERY+Test%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 20
INFO  [2023-01-26 18:10:06,504] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:06,505] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:06,505] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:06,506] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:06,506] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[TEMPORAL_BEFORE_CONCEPT_QUERY$20Test.table1.table1], containing 9 entries.
INFO  [2023-01-26 18:10:06,506] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[TEMPORAL_BEFORE_CONCEPT_QUERY$20Test.table1.table1], containing 9 entries.
WARN  [2023-01-26 18:10:06,507] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:06,507] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received TEMPORAL_BEFORE_CONCEPT_QUERY$20Test.table1.table1.0
INFO  [2023-01-26 18:10:06,507] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received TEMPORAL_BEFORE_CONCEPT_QUERY$20Test.table1.table1.1
INFO  [2023-01-26 18:10:06,613] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:06,618] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:06,651] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:06,651] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:06,651] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:06,756] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: TEMPORAL_BEFORE_CONCEPT_QUERY Test QUERY INIT
INFO  [2023-01-26 18:10:06,775] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[TEMPORAL_BEFORE_CONCEPT_QUERY$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:06,776] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[4234d34c-0402-4468-a949-e98fde9c8e0d] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_TEMPORAL_BEFORE_CONCEPT_QUERY Test))]]
INFO  [2023-01-26 18:10:06,778] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery TEMPORAL_BEFORE_CONCEPT_QUERY$20Test.4234d34c-0402-4468-a949-e98fde9c8e0d
INFO  [2023-01-26 18:10:06,778] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery TEMPORAL_BEFORE_CONCEPT_QUERY$20Test.4234d34c-0402-4468-a949-e98fde9c8e0d
127.0.0.1 - - [26/Jan/2023:18:10:06 +0000] "POST /api/datasets/TEMPORAL_BEFORE_CONCEPT_QUERY$20Test/queries HTTP/1.1" 201 1932 "-" "Conquery (test client)" 5
INFO  [2023-01-26 18:10:06,780] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[TEMPORAL_BEFORE_CONCEPT_QUERY$20Test.4234d34c-0402-4468-a949-e98fde9c8e0d] with 1 results within PT0.001883S
INFO  [2023-01-26 18:10:06,780] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=TEMPORAL_BEFORE_CONCEPT_QUERY$20Test.4234d34c-0402-4468-a949-e98fde9c8e0d, workerId=TEMPORAL_BEFORE_CONCEPT_QUERY$20Test.worker_TEMPORAL_BEFORE_CONCEPT_QUERY$20Test_442212d2-4eb7-4df5-8928-827b9ecc70ad, startTime=2023-01-26T18:10:06.778495, finishTime=2023-01-26T18:10:06.780378) of size 1
INFO  [2023-01-26 18:10:06,785] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[TEMPORAL_BEFORE_CONCEPT_QUERY$20Test.4234d34c-0402-4468-a949-e98fde9c8e0d] with 1 results within PT0.006976S
INFO  [2023-01-26 18:10:06,787] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=TEMPORAL_BEFORE_CONCEPT_QUERY$20Test.4234d34c-0402-4468-a949-e98fde9c8e0d, workerId=TEMPORAL_BEFORE_CONCEPT_QUERY$20Test.worker_TEMPORAL_BEFORE_CONCEPT_QUERY$20Test_0ab613b7-c585-4d8e-8166-4a4fe1efea42, startTime=2023-01-26T18:10:06.778724, finishTime=2023-01-26T18:10:06.785700) of size 1
INFO  [2023-01-26 18:10:06,787] com.bakdata.conquery.models.execution.ManagedExecution: DONE 4234d34c-0402-4468-a949-e98fde9c8e0d ManagedQuery within PT0.011593S
127.0.0.1 - - [26/Jan/2023:18:10:06 +0000] "GET /api/datasets/TEMPORAL_BEFORE_CONCEPT_QUERY$20Test/queries/TEMPORAL_BEFORE_CONCEPT_QUERY$20Test.4234d34c-0402-4468-a949-e98fde9c8e0d HTTP/1.1" 200 2268 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:10:06,801] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=TEMPORAL_BEFORE_CONCEPT_QUERY Test], queryId=4234d34c-0402-4468-a949-e98fde9c8e0d, label=Geschlecht-SELECT	@§$, creationTime=2023-01-26T18:10:06.775878, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@58dce2a5[Count = 0], startTime=2023-01-26T18:10:06.776043, finishTime=2023-01-26T18:10:06.787636, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@67a63e78), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_TEMPORAL_BEFORE_CONCEPT_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@34052ace, com.bakdata.conquery.models.query.ColumnDescriptor@59bca4c]) download on dataset Dataset[label=null, name=TEMPORAL_BEFORE_CONCEPT_QUERY Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:06,801] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=TEMPORAL_BEFORE_CONCEPT_QUERY Test], queryId=4234d34c-0402-4468-a949-e98fde9c8e0d, label=Geschlecht-SELECT	@§$, creationTime=2023-01-26T18:10:06.775878, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@58dce2a5[Count = 0], startTime=2023-01-26T18:10:06.776043, finishTime=2023-01-26T18:10:06.787636, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@67a63e78), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_TEMPORAL_BEFORE_CONCEPT_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@34052ace, com.bakdata.conquery.models.query.ColumnDescriptor@59bca4c]) on dataset Dataset[label=null, name=TEMPORAL_BEFORE_CONCEPT_QUERY Test]
127.0.0.1 - - [26/Jan/2023:18:10:06 +0000] "GET /api/datasets/TEMPORAL_BEFORE_CONCEPT_QUERY%20Test/result/TEMPORAL_BEFORE_CONCEPT_QUERY$20Test.4234d34c-0402-4468-a949-e98fde9c8e0d.csv?pretty=false HTTP/1.1" 200 23 "-" "Conquery (test client)" 14
INFO  [2023-01-26 18:10:06,814] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest TEMPORAL_BEFORE_CONCEPT_QUERY Test on 3 rows
INFO  [2023-01-26 18:10:06,814] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast TEMPORAL_BEFORE_CONCEPT_QUERY Test
INFO  [2023-01-26 18:10:06,814] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=TEMPORAL_BEFORE_CONCEPT_QUERY Test, name=TEMPORAL_BEFORE_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:10:06,814] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=TEMPORAL_BEFORE_CONCEPT_QUERY Test, name=TEMPORAL_BEFORE_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:10:06,814] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_TEMPORAL_BEFORE_CONCEPT_QUERY Test_442212d2-4eb7-4df5-8928-827b9ecc70ad
INFO  [2023-01-26 18:10:06,814] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_TEMPORAL_BEFORE_CONCEPT_QUERY Test_0ab613b7-c585-4d8e-8166-4a4fe1efea42
INFO  [2023-01-26 18:10:06,818] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow TEMPORAL_BEFORE_CONCEPT_QUERY Test
INFO  [2023-01-26 18:10:06,818] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_TEMPORAL_BEFORE_CONCEPT_QUERY Test_442212d2-4eb7-4df5-8928-827b9ecc70ad
INFO  [2023-01-26 18:10:06,820] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_TEMPORAL_BEFORE_CONCEPT_QUERY Test_0ab613b7-c585-4d8e-8166-4a4fe1efea42
INFO  [2023-01-26 18:10:06,913] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of TEMPORAL_BEFORE_CONCEPT_QUERY$20Test
INFO  [2023-01-26 18:10:06,913] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:06,956] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test TEMPORAL_BEFORE_CONCEPT_QUERY Test
INFO  [2023-01-26 18:10:06,957] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test REL_EXPORT WITHOUT DATES Test
INFO  [2023-01-26 18:10:06,957] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:06,957] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:06,958] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=REL_EXPORT WITHOUT DATES Test, name=REL_EXPORT WITHOUT DATES Test]
INFO  [2023-01-26 18:10:06,958] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=REL_EXPORT WITHOUT DATES Test, name=REL_EXPORT WITHOUT DATES Test]
INFO  [2023-01-26 18:10:06,958] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:06,958] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:06,959] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker REL_EXPORT$20WITHOUT$20DATES$20Test.worker_REL_EXPORT$20WITHOUT$20DATES$20Test_a355f6d9-a2a7-4d65-8e48-0507db5b67f7 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:06,959] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker REL_EXPORT$20WITHOUT$20DATES$20Test.worker_REL_EXPORT$20WITHOUT$20DATES$20Test_a355f6d9-a2a7-4d65-8e48-0507db5b67f7 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:06,959] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:06,959] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker REL_EXPORT$20WITHOUT$20DATES$20Test.worker_REL_EXPORT$20WITHOUT$20DATES$20Test_7cfaa9c9-94ff-4792-a737-dad79a8fc10a are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:06,959] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker REL_EXPORT$20WITHOUT$20DATES$20Test.worker_REL_EXPORT$20WITHOUT$20DATES$20Test_7cfaa9c9-94ff-4792-a737-dad79a8fc10a are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:06,959] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:06,964] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:07,063] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:07,071] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:07,071] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table REL_EXPORT$20WITHOUT$20DATES$20Test.table
INFO  [2023-01-26 18:10:07,071] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table REL_EXPORT$20WITHOUT$20DATES$20Test.table
INFO  [2023-01-26 18:10:07,182] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:07,298] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:07,298] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:07,298] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 178 B in total
INFO  [2023-01-26 18:10:07,298] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL_EXPORT WITHOUT DATES Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000206166sINFO  [2023-01-26 18:10:07,319] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=2, sum=9, min=1, average=4.500000, max=8}
INFO  [2023-01-26 18:10:07,319] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[column] with StringParser(super=Parser(lines=9, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:07,319] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=9, nullLines=0), subType=IntegerParser(super=Parser(lines=9, nullLines=0), minValue=11109, maxValue=12935), dateReader=com.bakdata.conquery.util.DateReader@1a3d6c37)
INFO  [2023-01-26 18:10:07,323] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL_EXPORT WITHOUT DATES Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:07,323] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:07,323] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL_EXPORT WITHOUT DATES Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:07,342] com.bakdata.conquery.models.jobs.ImportJob: Importing table into REL_EXPORT$20WITHOUT$20DATES$20Test.table
INFO  [2023-01-26 18:10:07,342] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:10:07 +0000] "POST /admin/datasets/REL_EXPORT%20WITHOUT%20DATES%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_REL_EXPORT+WITHOUT+DATES+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 10
INFO  [2023-01-26 18:10:07,343] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:07,345] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:07,345] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:07,347] com.bakdata.conquery.models.jobs.ImportJob: Start sending 1 Buckets
INFO  [2023-01-26 18:10:07,347] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[REL_EXPORT$20WITHOUT$20DATES$20Test.table.table], containing 9 entries.
INFO  [2023-01-26 18:10:07,348] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[REL_EXPORT$20WITHOUT$20DATES$20Test.table.table], containing 9 entries.
WARN  [2023-01-26 18:10:07,348] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:07,348] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL_EXPORT$20WITHOUT$20DATES$20Test.table.table.0
INFO  [2023-01-26 18:10:07,455] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:07,460] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:07,478] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:07,479] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 2 Concepts
INFO  [2023-01-26 18:10:07,584] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: REL_EXPORT WITHOUT DATES Test QUERY INIT
INFO  [2023-01-26 18:10:07,596] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[REL_EXPORT$20WITHOUT$20DATES$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:07,597] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[5cf9ee2a-f3d0-4766-9fe7-934f7e3c44c6] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_REL_EXPORT WITHOUT DATES Test))]]
INFO  [2023-01-26 18:10:07,600] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started RelativeFormQuery REL_EXPORT$20WITHOUT$20DATES$20Test.5cf9ee2a-f3d0-4766-9fe7-934f7e3c44c6
WARN  [2023-01-26 18:10:07,600] com.bakdata.conquery.models.query.QueryExecutor: Entities for query are empty
INFO  [2023-01-26 18:10:07,600] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[REL_EXPORT$20WITHOUT$20DATES$20Test.5cf9ee2a-f3d0-4766-9fe7-934f7e3c44c6] with 0 results within PT0.000168S
INFO  [2023-01-26 18:10:07,600] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started RelativeFormQuery REL_EXPORT$20WITHOUT$20DATES$20Test.5cf9ee2a-f3d0-4766-9fe7-934f7e3c44c6
INFO  [2023-01-26 18:10:07,600] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=REL_EXPORT$20WITHOUT$20DATES$20Test.5cf9ee2a-f3d0-4766-9fe7-934f7e3c44c6, workerId=REL_EXPORT$20WITHOUT$20DATES$20Test.worker_REL_EXPORT$20WITHOUT$20DATES$20Test_7cfaa9c9-94ff-4792-a737-dad79a8fc10a, startTime=2023-01-26T18:10:07.600180, finishTime=2023-01-26T18:10:07.600348) of size 0
WARN  [2023-01-26 18:10:07,601] com.bakdata.conquery.models.forms.managed.RelativeFormQueryPlan: Sampled empty result for Entity[0]: `EARLIEST({-∞/+∞})`
INFO  [2023-01-26 18:10:07,601] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[REL_EXPORT$20WITHOUT$20DATES$20Test.5cf9ee2a-f3d0-4766-9fe7-934f7e3c44c6] with 1 results within PT0.000933S
127.0.0.1 - - [26/Jan/2023:18:10:07 +0000] "POST /api/datasets/REL_EXPORT$20WITHOUT$20DATES$20Test/queries HTTP/1.1" 201 3347 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:10:07,601] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=REL_EXPORT$20WITHOUT$20DATES$20Test.5cf9ee2a-f3d0-4766-9fe7-934f7e3c44c6, workerId=REL_EXPORT$20WITHOUT$20DATES$20Test.worker_REL_EXPORT$20WITHOUT$20DATES$20Test_a355f6d9-a2a7-4d65-8e48-0507db5b67f7, startTime=2023-01-26T18:10:07.600488, finishTime=2023-01-26T18:10:07.601421) of size 1
INFO  [2023-01-26 18:10:07,601] com.bakdata.conquery.models.execution.ManagedExecution: DONE 5cf9ee2a-f3d0-4766-9fe7-934f7e3c44c6 ManagedQuery within PT0.004746S
127.0.0.1 - - [26/Jan/2023:18:10:07 +0000] "GET /api/datasets/REL_EXPORT$20WITHOUT$20DATES$20Test/queries/REL_EXPORT$20WITHOUT$20DATES$20Test.5cf9ee2a-f3d0-4766-9fe7-934f7e3c44c6 HTTP/1.1" 200 3678 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:10:07,622] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=REL_EXPORT WITHOUT DATES Test], queryId=5cf9ee2a-f3d0-4766-9fe7-934f7e3c44c6, label=concept_dateless---child1 concept---child1	@§$, creationTime=2023-01-26T18:10:07.596946, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@341c1366[Count = 0], startTime=2023-01-26T18:10:07.597189, finishTime=2023-01-26T18:10:07.601935, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@5db9233b), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_REL_EXPORT WITHOUT DATES Test)), query=com.bakdata.conquery.models.forms.managed.RelativeFormQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@570ae586, com.bakdata.conquery.models.query.ColumnDescriptor@be5031d, com.bakdata.conquery.models.query.ColumnDescriptor@5f36a624, com.bakdata.conquery.models.query.ColumnDescriptor@4b02f602, com.bakdata.conquery.models.query.ColumnDescriptor@4b241c31, com.bakdata.conquery.models.query.ColumnDescriptor@68fa13a3, com.bakdata.conquery.models.query.ColumnDescriptor@2178f1e, com.bakdata.conquery.models.query.ColumnDescriptor@5e79dbb8]) download on dataset Dataset[label=null, name=REL_EXPORT WITHOUT DATES Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:07,622] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=REL_EXPORT WITHOUT DATES Test], queryId=5cf9ee2a-f3d0-4766-9fe7-934f7e3c44c6, label=concept_dateless---child1 concept---child1	@§$, creationTime=2023-01-26T18:10:07.596946, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@341c1366[Count = 0], startTime=2023-01-26T18:10:07.597189, finishTime=2023-01-26T18:10:07.601935, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@5db9233b), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_REL_EXPORT WITHOUT DATES Test)), query=com.bakdata.conquery.models.forms.managed.RelativeFormQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@570ae586, com.bakdata.conquery.models.query.ColumnDescriptor@be5031d, com.bakdata.conquery.models.query.ColumnDescriptor@5f36a624, com.bakdata.conquery.models.query.ColumnDescriptor@4b02f602, com.bakdata.conquery.models.query.ColumnDescriptor@4b241c31, com.bakdata.conquery.models.query.ColumnDescriptor@68fa13a3, com.bakdata.conquery.models.query.ColumnDescriptor@2178f1e, com.bakdata.conquery.models.query.ColumnDescriptor@5e79dbb8]) on dataset Dataset[label=null, name=REL_EXPORT WITHOUT DATES Test]
127.0.0.1 - - [26/Jan/2023:18:10:07 +0000] "GET /api/datasets/REL_EXPORT%20WITHOUT%20DATES%20Test/result/REL_EXPORT$20WITHOUT$20DATES$20Test.5cf9ee2a-f3d0-4766-9fe7-934f7e3c44c6.csv?pretty=false HTTP/1.1" 200 138 "-" "Conquery (test client)" 21
INFO  [2023-01-26 18:10:07,642] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest REL_EXPORT WITHOUT DATES Test on 2 rows
INFO  [2023-01-26 18:10:07,642] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast REL_EXPORT WITHOUT DATES Test
INFO  [2023-01-26 18:10:07,643] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=REL_EXPORT WITHOUT DATES Test, name=REL_EXPORT WITHOUT DATES Test]
INFO  [2023-01-26 18:10:07,643] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=REL_EXPORT WITHOUT DATES Test, name=REL_EXPORT WITHOUT DATES Test]
INFO  [2023-01-26 18:10:07,643] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_REL_EXPORT WITHOUT DATES Test_7cfaa9c9-94ff-4792-a737-dad79a8fc10a
INFO  [2023-01-26 18:10:07,643] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_REL_EXPORT WITHOUT DATES Test_a355f6d9-a2a7-4d65-8e48-0507db5b67f7
INFO  [2023-01-26 18:10:07,668] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow REL_EXPORT WITHOUT DATES Test
INFO  [2023-01-26 18:10:07,668] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_REL_EXPORT WITHOUT DATES Test_a355f6d9-a2a7-4d65-8e48-0507db5b67f7
INFO  [2023-01-26 18:10:07,668] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_REL_EXPORT WITHOUT DATES Test_7cfaa9c9-94ff-4792-a737-dad79a8fc10a
INFO  [2023-01-26 18:10:07,748] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of REL_EXPORT$20WITHOUT$20DATES$20Test
INFO  [2023-01-26 18:10:07,748] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:07,785] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test REL_EXPORT WITHOUT DATES Test
INFO  [2023-01-26 18:10:07,785] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test REL_EXPORT WITH DATES Test
INFO  [2023-01-26 18:10:07,785] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:07,785] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:07,788] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=REL_EXPORT WITH DATES Test, name=REL_EXPORT WITH DATES Test]
INFO  [2023-01-26 18:10:07,788] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=REL_EXPORT WITH DATES Test, name=REL_EXPORT WITH DATES Test]
INFO  [2023-01-26 18:10:07,788] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:07,788] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:07,802] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker REL_EXPORT$20WITH$20DATES$20Test.worker_REL_EXPORT$20WITH$20DATES$20Test_b91a863d-09fd-4966-b280-0e2569b7f2d2 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:07,802] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker REL_EXPORT$20WITH$20DATES$20Test.worker_REL_EXPORT$20WITH$20DATES$20Test_b91a863d-09fd-4966-b280-0e2569b7f2d2 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:07,802] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:07,803] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker REL_EXPORT$20WITH$20DATES$20Test.worker_REL_EXPORT$20WITH$20DATES$20Test_2bb2d6a8-de65-49d9-9d6b-51de8d26685b are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:07,804] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker REL_EXPORT$20WITH$20DATES$20Test.worker_REL_EXPORT$20WITH$20DATES$20Test_2bb2d6a8-de65-49d9-9d6b-51de8d26685b are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:07,804] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:07,804] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:07,908] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:07,914] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:07,915] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table REL_EXPORT$20WITH$20DATES$20Test.test_table
INFO  [2023-01-26 18:10:07,915] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table REL_EXPORT$20WITH$20DATES$20Test.test_table
INFO  [2023-01-26 18:10:08,028] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:08,137] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:08,138] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:08,138] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 183 B in total
INFO  [2023-01-26 18:10:08,138] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL_EXPORT WITH DATES Test/test_table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000301517sINFO  [2023-01-26 18:10:08,168] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=2, sum=9, min=1, average=4.500000, max=8}
INFO  [2023-01-26 18:10:08,168] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=9, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:08,168] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=9, nullLines=0), subType=IntegerParser(super=Parser(lines=9, nullLines=0), minValue=11109, maxValue=12935), dateReader=com.bakdata.conquery.util.DateReader@1c25c3bf)
INFO  [2023-01-26 18:10:08,172] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL_EXPORT WITH DATES Test/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:08,172] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:08,172] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REL_EXPORT WITH DATES Test/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:08,193] com.bakdata.conquery.models.jobs.ImportJob: Importing test_table into REL_EXPORT$20WITH$20DATES$20Test.test_table
INFO  [2023-01-26 18:10:08,194] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:10:08 +0000] "POST /admin/datasets/REL_EXPORT%20WITH%20DATES%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_REL_EXPORT+WITH+DATES+Test%2Ftest_table.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 13
INFO  [2023-01-26 18:10:08,194] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:08,195] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:08,195] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:08,198] com.bakdata.conquery.models.jobs.ImportJob: Start sending 1 Buckets
INFO  [2023-01-26 18:10:08,198] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[REL_EXPORT$20WITH$20DATES$20Test.test_table.test_table], containing 9 entries.
INFO  [2023-01-26 18:10:08,198] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[REL_EXPORT$20WITH$20DATES$20Test.test_table.test_table], containing 9 entries.
WARN  [2023-01-26 18:10:08,199] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:08,199] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REL_EXPORT$20WITH$20DATES$20Test.test_table.test_table.0
INFO  [2023-01-26 18:10:08,304] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:08,309] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:08,320] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:08,320] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:08,426] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: REL_EXPORT WITH DATES Test QUERY INIT
INFO  [2023-01-26 18:10:08,437] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[REL_EXPORT$20WITH$20DATES$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:08,437] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[711d95fb-b05d-44ce-9590-21ac1a7cb0f0] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_REL_EXPORT WITH DATES Test))]]
INFO  [2023-01-26 18:10:08,440] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started RelativeFormQuery REL_EXPORT$20WITH$20DATES$20Test.711d95fb-b05d-44ce-9590-21ac1a7cb0f0
INFO  [2023-01-26 18:10:08,440] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started RelativeFormQuery REL_EXPORT$20WITH$20DATES$20Test.711d95fb-b05d-44ce-9590-21ac1a7cb0f0
WARN  [2023-01-26 18:10:08,440] com.bakdata.conquery.models.query.QueryExecutor: Entities for query are empty
INFO  [2023-01-26 18:10:08,440] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[REL_EXPORT$20WITH$20DATES$20Test.711d95fb-b05d-44ce-9590-21ac1a7cb0f0] with 0 results within PT0.000146S
INFO  [2023-01-26 18:10:08,441] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=REL_EXPORT$20WITH$20DATES$20Test.711d95fb-b05d-44ce-9590-21ac1a7cb0f0, workerId=REL_EXPORT$20WITH$20DATES$20Test.worker_REL_EXPORT$20WITH$20DATES$20Test_2bb2d6a8-de65-49d9-9d6b-51de8d26685b, startTime=2023-01-26T18:10:08.440521, finishTime=2023-01-26T18:10:08.440667) of size 0
127.0.0.1 - - [26/Jan/2023:18:10:08 +0000] "POST /api/datasets/REL_EXPORT$20WITH$20DATES$20Test/queries HTTP/1.1" 201 3349 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:10:08,443] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[REL_EXPORT$20WITH$20DATES$20Test.711d95fb-b05d-44ce-9590-21ac1a7cb0f0] with 1 results within PT0.00293S
INFO  [2023-01-26 18:10:08,444] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=REL_EXPORT$20WITH$20DATES$20Test.711d95fb-b05d-44ce-9590-21ac1a7cb0f0, workerId=REL_EXPORT$20WITH$20DATES$20Test.worker_REL_EXPORT$20WITH$20DATES$20Test_b91a863d-09fd-4966-b280-0e2569b7f2d2, startTime=2023-01-26T18:10:08.440521, finishTime=2023-01-26T18:10:08.443451) of size 1
INFO  [2023-01-26 18:10:08,444] com.bakdata.conquery.models.execution.ManagedExecution: DONE 711d95fb-b05d-44ce-9590-21ac1a7cb0f0 ManagedQuery within PT0.006152S
127.0.0.1 - - [26/Jan/2023:18:10:08 +0000] "GET /api/datasets/REL_EXPORT$20WITH$20DATES$20Test/queries/REL_EXPORT$20WITH$20DATES$20Test.711d95fb-b05d-44ce-9590-21ac1a7cb0f0 HTTP/1.1" 200 3668 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:10:08,464] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=REL_EXPORT WITH DATES Test], queryId=711d95fb-b05d-44ce-9590-21ac1a7cb0f0, label=test_tree---test_child1	@§$, creationTime=2023-01-26T18:10:08.437731, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@d1ee0e0[Count = 0], startTime=2023-01-26T18:10:08.437947, finishTime=2023-01-26T18:10:08.444099, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@7d93fda1), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_REL_EXPORT WITH DATES Test)), query=com.bakdata.conquery.models.forms.managed.RelativeFormQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@56572549, com.bakdata.conquery.models.query.ColumnDescriptor@4e722c59, com.bakdata.conquery.models.query.ColumnDescriptor@3411dc97, com.bakdata.conquery.models.query.ColumnDescriptor@568d5141, com.bakdata.conquery.models.query.ColumnDescriptor@399f5bb4, com.bakdata.conquery.models.query.ColumnDescriptor@6650b83a, com.bakdata.conquery.models.query.ColumnDescriptor@5c1f2503, com.bakdata.conquery.models.query.ColumnDescriptor@60a46098]) download on dataset Dataset[label=null, name=REL_EXPORT WITH DATES Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:08,464] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=REL_EXPORT WITH DATES Test], queryId=711d95fb-b05d-44ce-9590-21ac1a7cb0f0, label=test_tree---test_child1	@§$, creationTime=2023-01-26T18:10:08.437731, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@d1ee0e0[Count = 0], startTime=2023-01-26T18:10:08.437947, finishTime=2023-01-26T18:10:08.444099, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@7d93fda1), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_REL_EXPORT WITH DATES Test)), query=com.bakdata.conquery.models.forms.managed.RelativeFormQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@56572549, com.bakdata.conquery.models.query.ColumnDescriptor@4e722c59, com.bakdata.conquery.models.query.ColumnDescriptor@3411dc97, com.bakdata.conquery.models.query.ColumnDescriptor@568d5141, com.bakdata.conquery.models.query.ColumnDescriptor@399f5bb4, com.bakdata.conquery.models.query.ColumnDescriptor@6650b83a, com.bakdata.conquery.models.query.ColumnDescriptor@5c1f2503, com.bakdata.conquery.models.query.ColumnDescriptor@60a46098]) on dataset Dataset[label=null, name=REL_EXPORT WITH DATES Test]
127.0.0.1 - - [26/Jan/2023:18:10:08 +0000] "GET /api/datasets/REL_EXPORT%20WITH%20DATES%20Test/result/REL_EXPORT$20WITH$20DATES$20Test.711d95fb-b05d-44ce-9590-21ac1a7cb0f0.csv?pretty=false HTTP/1.1" 200 607 "-" "Conquery (test client)" 17
INFO  [2023-01-26 18:10:08,480] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest REL_EXPORT WITH DATES Test on 10 rows
INFO  [2023-01-26 18:10:08,480] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast REL_EXPORT WITH DATES Test
INFO  [2023-01-26 18:10:08,480] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=REL_EXPORT WITH DATES Test, name=REL_EXPORT WITH DATES Test]
INFO  [2023-01-26 18:10:08,480] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=REL_EXPORT WITH DATES Test, name=REL_EXPORT WITH DATES Test]
INFO  [2023-01-26 18:10:08,480] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_REL_EXPORT WITH DATES Test_2bb2d6a8-de65-49d9-9d6b-51de8d26685b
INFO  [2023-01-26 18:10:08,480] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_REL_EXPORT WITH DATES Test_b91a863d-09fd-4966-b280-0e2569b7f2d2
INFO  [2023-01-26 18:10:08,488] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow REL_EXPORT WITH DATES Test
INFO  [2023-01-26 18:10:08,499] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of REL_EXPORT$20WITH$20DATES$20Test
INFO  [2023-01-26 18:10:08,499] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:08,503] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_REL_EXPORT WITH DATES Test_b91a863d-09fd-4966-b280-0e2569b7f2d2
INFO  [2023-01-26 18:10:08,521] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_REL_EXPORT WITH DATES Test_2bb2d6a8-de65-49d9-9d6b-51de8d26685b
INFO  [2023-01-26 18:10:08,725] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test REL_EXPORT WITH DATES Test
INFO  [2023-01-26 18:10:08,725] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test REUSED_QUERY Test
INFO  [2023-01-26 18:10:08,725] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:08,725] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:08,726] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=REUSED_QUERY Test, name=REUSED_QUERY Test]
INFO  [2023-01-26 18:10:08,726] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=REUSED_QUERY Test, name=REUSED_QUERY Test]
INFO  [2023-01-26 18:10:08,726] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:08,726] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:08,728] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker REUSED_QUERY$20Test.worker_REUSED_QUERY$20Test_21be9db6-ee22-4e71-98a8-a32db473cad1 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:08,728] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker REUSED_QUERY$20Test.worker_REUSED_QUERY$20Test_21be9db6-ee22-4e71-98a8-a32db473cad1 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:08,728] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:08,728] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker REUSED_QUERY$20Test.worker_REUSED_QUERY$20Test_5a2bb622-cc7a-4207-8325-61541e74acf8 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:08,728] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker REUSED_QUERY$20Test.worker_REUSED_QUERY$20Test_5a2bb622-cc7a-4207-8325-61541e74acf8 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:08,728] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:08,732] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:08,833] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:08,839] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:08,840] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table REUSED_QUERY$20Test.test_table
INFO  [2023-01-26 18:10:08,840] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table REUSED_QUERY$20Test.test_table
INFO  [2023-01-26 18:10:08,950] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:09,058] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:09,058] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:09,059] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 374 B in total
INFO  [2023-01-26 18:10:09,059] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REUSED_QUERY Test/test_table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000255647sINFO  [2023-01-26 18:10:09,085] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=21, sum=21, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:10:09,086] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=21, nullLines=0), subType=IntegerParser(super=Parser(lines=21, nullLines=0), minValue=11323, maxValue=11323), dateReader=com.bakdata.conquery.util.DateReader@1e69e6c8)
INFO  [2023-01-26 18:10:09,086] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=21, nullLines=0), encoding=null, prefix=a, suffix=a)
INFO  [2023-01-26 18:10:09,090] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REUSED_QUERY Test/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:09,090] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:09,090] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_REUSED_QUERY Test/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:09,114] com.bakdata.conquery.models.jobs.ImportJob: Importing test_table into REUSED_QUERY$20Test.test_table
INFO  [2023-01-26 18:10:09,115] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:10:09 +0000] "POST /admin/datasets/REUSED_QUERY%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_REUSED_QUERY+Test%2Ftest_table.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 17
INFO  [2023-01-26 18:10:09,115] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:09,115] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:09,115] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:09,117] com.bakdata.conquery.models.jobs.ImportJob: Start sending 7 Buckets
INFO  [2023-01-26 18:10:09,117] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[REUSED_QUERY$20Test.test_table.test_table], containing 21 entries.
INFO  [2023-01-26 18:10:09,117] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[REUSED_QUERY$20Test.test_table.test_table], containing 21 entries.
INFO  [2023-01-26 18:10:09,118] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REUSED_QUERY$20Test.test_table.test_table.0
INFO  [2023-01-26 18:10:09,118] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REUSED_QUERY$20Test.test_table.test_table.1
INFO  [2023-01-26 18:10:09,118] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REUSED_QUERY$20Test.test_table.test_table.2
WARN  [2023-01-26 18:10:09,118] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:09,118] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REUSED_QUERY$20Test.test_table.test_table.3
INFO  [2023-01-26 18:10:09,163] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REUSED_QUERY$20Test.test_table.test_table.4
INFO  [2023-01-26 18:10:09,164] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REUSED_QUERY$20Test.test_table.test_table.5
INFO  [2023-01-26 18:10:09,164] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received REUSED_QUERY$20Test.test_table.test_table.6
INFO  [2023-01-26 18:10:09,269] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:09,334] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:09,339] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:09,347] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:09,348] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:09,348] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:09,453] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: REUSED_QUERY Test QUERY INIT
INFO  [2023-01-26 18:10:09,469] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[REUSED_QUERY$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:09,470] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[00000000-0000-0000-0000-000000000001] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_REUSED_QUERY Test))]]
INFO  [2023-01-26 18:10:09,472] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery REUSED_QUERY$20Test.00000000-0000-0000-0000-000000000001
INFO  [2023-01-26 18:10:09,472] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery REUSED_QUERY$20Test.00000000-0000-0000-0000-000000000001
127.0.0.1 - - [26/Jan/2023:18:10:09 +0000] "POST /api/datasets/REUSED_QUERY$20Test/queries HTTP/1.1" 201 1315 "-" "Conquery (test client)" 5
INFO  [2023-01-26 18:10:09,473] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[REUSED_QUERY$20Test.00000000-0000-0000-0000-000000000001] with 5 results within PT0.001539S
INFO  [2023-01-26 18:10:09,473] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[REUSED_QUERY$20Test.00000000-0000-0000-0000-000000000001] with 6 results within PT0.001837S
INFO  [2023-01-26 18:10:09,474] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=REUSED_QUERY$20Test.00000000-0000-0000-0000-000000000001, workerId=REUSED_QUERY$20Test.worker_REUSED_QUERY$20Test_5a2bb622-cc7a-4207-8325-61541e74acf8, startTime=2023-01-26T18:10:09.472128, finishTime=2023-01-26T18:10:09.473667) of size 5
INFO  [2023-01-26 18:10:09,474] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=REUSED_QUERY$20Test.00000000-0000-0000-0000-000000000001, workerId=REUSED_QUERY$20Test.worker_REUSED_QUERY$20Test_21be9db6-ee22-4e71-98a8-a32db473cad1, startTime=2023-01-26T18:10:09.472112, finishTime=2023-01-26T18:10:09.473949) of size 6
INFO  [2023-01-26 18:10:09,474] com.bakdata.conquery.models.execution.ManagedExecution: DONE 00000000-0000-0000-0000-000000000001 ManagedQuery within PT0.004285S
127.0.0.1 - - [26/Jan/2023:18:10:09 +0000] "GET /api/datasets/REUSED_QUERY$20Test/queries/REUSED_QUERY$20Test.00000000-0000-0000-0000-000000000001 HTTP/1.1" 200 1583 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:10:09,491] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=REUSED_QUERY Test], queryId=00000000-0000-0000-0000-000000000001, label=Uploaded-List	@§$, creationTime=2023-01-26T18:10:09.316228, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@45790aab[Count = 0], startTime=2023-01-26T18:10:09.470164, finishTime=2023-01-26T18:10:09.474449, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@76c35589), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_REUSED_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=11, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@613cee24, com.bakdata.conquery.models.query.ColumnDescriptor@1fcbabd0]) download on dataset Dataset[label=null, name=REUSED_QUERY Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:09,491] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=REUSED_QUERY Test], queryId=00000000-0000-0000-0000-000000000001, label=Uploaded-List	@§$, creationTime=2023-01-26T18:10:09.316228, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@45790aab[Count = 0], startTime=2023-01-26T18:10:09.470164, finishTime=2023-01-26T18:10:09.474449, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@76c35589), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_REUSED_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=11, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@613cee24, com.bakdata.conquery.models.query.ColumnDescriptor@1fcbabd0]) on dataset Dataset[label=null, name=REUSED_QUERY Test]
127.0.0.1 - - [26/Jan/2023:18:10:09 +0000] "GET /api/datasets/REUSED_QUERY%20Test/result/REUSED_QUERY$20Test.00000000-0000-0000-0000-000000000001.csv?pretty=false HTTP/1.1" 200 331 "-" "Conquery (test client)" 19
INFO  [2023-01-26 18:10:09,509] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest REUSED_QUERY Test on 12 rows
INFO  [2023-01-26 18:10:09,509] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast REUSED_QUERY Test
INFO  [2023-01-26 18:10:09,510] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=REUSED_QUERY Test, name=REUSED_QUERY Test]
INFO  [2023-01-26 18:10:09,510] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=REUSED_QUERY Test, name=REUSED_QUERY Test]
INFO  [2023-01-26 18:10:09,510] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_REUSED_QUERY Test_5a2bb622-cc7a-4207-8325-61541e74acf8
INFO  [2023-01-26 18:10:09,510] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_REUSED_QUERY Test_21be9db6-ee22-4e71-98a8-a32db473cad1
INFO  [2023-01-26 18:10:09,527] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow REUSED_QUERY Test
INFO  [2023-01-26 18:10:09,528] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_REUSED_QUERY Test_5a2bb622-cc7a-4207-8325-61541e74acf8
INFO  [2023-01-26 18:10:09,528] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_REUSED_QUERY Test_21be9db6-ee22-4e71-98a8-a32db473cad1
INFO  [2023-01-26 18:10:09,621] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of REUSED_QUERY$20Test
INFO  [2023-01-26 18:10:09,621] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:09,653] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test REUSED_QUERY Test
INFO  [2023-01-26 18:10:09,653] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test SECONDARY_ID Test
INFO  [2023-01-26 18:10:09,653] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:09,653] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:09,656] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SECONDARY_ID Test, name=SECONDARY_ID Test]
INFO  [2023-01-26 18:10:09,656] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SECONDARY_ID Test, name=SECONDARY_ID Test]
INFO  [2023-01-26 18:10:09,656] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:09,656] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:09,657] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:09,657] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SECONDARY_ID$20Test.worker_SECONDARY_ID$20Test_1dea8e09-3574-4929-bb99-d34c51d82ac0 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:09,657] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SECONDARY_ID$20Test.worker_SECONDARY_ID$20Test_1dea8e09-3574-4929-bb99-d34c51d82ac0 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:09,657] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:09,657] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SECONDARY_ID$20Test.worker_SECONDARY_ID$20Test_a422a7ac-6c84-4231-9db2-24e41fe25bbd are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:09,657] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SECONDARY_ID$20Test.worker_SECONDARY_ID$20Test_a422a7ac-6c84-4231-9db2-24e41fe25bbd are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:09,657] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:09,762] com.bakdata.conquery.resources.admin.rest.AdminDatasetProcessor: Received new SecondaryId[SECONDARY_ID$20Test.secondary]
INFO  [2023-01-26 18:10:09,762] com.bakdata.conquery.resources.admin.rest.AdminDatasetProcessor: Received new SecondaryId[SECONDARY_ID$20Test.ignored]
INFO  [2023-01-26 18:10:09,762] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:09,762] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId SECONDARY_ID$20Test.secondary
INFO  [2023-01-26 18:10:09,763] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId SECONDARY_ID$20Test.ignored
INFO  [2023-01-26 18:10:09,763] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId SECONDARY_ID$20Test.secondary
INFO  [2023-01-26 18:10:09,804] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId SECONDARY_ID$20Test.ignored
INFO  [2023-01-26 18:10:09,910] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:09,910] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SECONDARY_ID$20Test.table1
INFO  [2023-01-26 18:10:09,910] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SECONDARY_ID$20Test.table1
INFO  [2023-01-26 18:10:09,910] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SECONDARY_ID$20Test.table12
INFO  [2023-01-26 18:10:09,910] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SECONDARY_ID$20Test.table12
INFO  [2023-01-26 18:10:10,031] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:10,141] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:10,141] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:10,141] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:10,142] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 433 B in total
INFO  [2023-01-26 18:10:10,142] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SECONDARY_ID Test/table1.import.json, tag=Optional.empty)
████████████████████████▌                         ▌  49%	est. time remaining: 0.01783584sINFO  [2023-01-26 18:10:10,159] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=2, sum=6, min=1, average=3.000000, max=5}
INFO  [2023-01-26 18:10:10,159] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with RealParser(super=Parser(lines=6, nullLines=0), requiredPrecision=4.9E-324, floatULP=1.1920928955078125E-7)
INFO  [2023-01-26 18:10:10,159] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[sid] with StringParser(super=Parser(lines=6, nullLines=1), encoding=null, prefix=f_, suffix=)
INFO  [2023-01-26 18:10:10,159] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=6, nullLines=0), minParser=DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=14790, maxValue=16982), dateReader=com.bakdata.conquery.util.DateReader@69036d82), maxParser=DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=14790, maxValue=16982), dateReader=com.bakdata.conquery.util.DateReader@4ffb474d), dateReader=com.bakdata.conquery.util.DateReader@24a8b34a, onlyQuarters=false, maxValue=16982, minValue=14790, anyOpen=false)
INFO  [2023-01-26 18:10:10,163] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SECONDARY_ID Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:10,163] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SECONDARY_ID Test/table12.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000396768sINFO  [2023-01-26 18:10:10,182] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=2, sum=6, min=1, average=3.000000, max=5}
INFO  [2023-01-26 18:10:10,182] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with RealParser(super=Parser(lines=6, nullLines=0), requiredPrecision=4.9E-324, floatULP=9.5367431640625E-7)
INFO  [2023-01-26 18:10:10,182] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[sid] with StringParser(super=Parser(lines=6, nullLines=1), encoding=null, prefix=f_, suffix=)
INFO  [2023-01-26 18:10:10,182] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=6, nullLines=0), minParser=DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=18443, maxValue=20634), dateReader=com.bakdata.conquery.util.DateReader@396a7d4b), maxParser=DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=18443, maxValue=20634), dateReader=com.bakdata.conquery.util.DateReader@4b776899), dateReader=com.bakdata.conquery.util.DateReader@5e238f95, onlyQuarters=false, maxValue=20634, minValue=18443, anyOpen=false)
INFO  [2023-01-26 18:10:10,185] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SECONDARY_ID Test/table12.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:10,185] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 2 Jobs:
INFO  [2023-01-26 18:10:10,185] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SECONDARY_ID Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:10,185] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SECONDARY_ID Test/table12.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:10,205] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into SECONDARY_ID$20Test.table1
127.0.0.1 - - [26/Jan/2023:18:10:10 +0000] "POST /admin/datasets/SECONDARY_ID%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_SECONDARY_ID+Test%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 11
INFO  [2023-01-26 18:10:10,206] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:10,206] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:10,206] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:10,208] com.bakdata.conquery.models.jobs.ImportJob: Start sending 1 Buckets
INFO  [2023-01-26 18:10:10,209] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SECONDARY_ID$20Test.table1.table1], containing 6 entries.
INFO  [2023-01-26 18:10:10,209] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SECONDARY_ID$20Test.table1.table1], containing 6 entries.
WARN  [2023-01-26 18:10:10,209] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:10,210] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SECONDARY_ID$20Test.table1.table1.0
INFO  [2023-01-26 18:10:10,220] com.bakdata.conquery.models.jobs.ImportJob: Importing table12 into SECONDARY_ID$20Test.table12
INFO  [2023-01-26 18:10:10,220] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
127.0.0.1 - - [26/Jan/2023:18:10:10 +0000] "POST /admin/datasets/SECONDARY_ID%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_SECONDARY_ID+Test%2Ftable12.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:10:10,221] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:10,221] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:10,221] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:10,221] com.bakdata.conquery.models.jobs.ImportJob: Start sending 1 Buckets
INFO  [2023-01-26 18:10:10,221] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SECONDARY_ID$20Test.table12.table12], containing 6 entries.
WARN  [2023-01-26 18:10:10,221] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:10,221] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SECONDARY_ID$20Test.table12.table12], containing 6 entries.
INFO  [2023-01-26 18:10:10,221] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SECONDARY_ID$20Test.table12.table12.0
INFO  [2023-01-26 18:10:10,343] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:10,348] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:10,359] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:10,360] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:10,465] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: SECONDARY_ID Test QUERY INIT
INFO  [2023-01-26 18:10:10,482] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[SECONDARY_ID$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:10,482] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[269c12ad-81e6-493b-8d6b-12ba11d01936] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_SECONDARY_ID Test))]]
INFO  [2023-01-26 18:10:10,487] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started SecondaryIdQuery SECONDARY_ID$20Test.269c12ad-81e6-493b-8d6b-12ba11d01936
INFO  [2023-01-26 18:10:10,487] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started SecondaryIdQuery SECONDARY_ID$20Test.269c12ad-81e6-493b-8d6b-12ba11d01936
WARN  [2023-01-26 18:10:10,487] com.bakdata.conquery.models.query.QueryExecutor: Entities for query are empty
INFO  [2023-01-26 18:10:10,487] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SECONDARY_ID$20Test.269c12ad-81e6-493b-8d6b-12ba11d01936] with 0 results within PT0.000256S
127.0.0.1 - - [26/Jan/2023:18:10:10 +0000] "POST /api/datasets/SECONDARY_ID$20Test/queries HTTP/1.1" 201 1683 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:10:10,488] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SECONDARY_ID$20Test.269c12ad-81e6-493b-8d6b-12ba11d01936, workerId=SECONDARY_ID$20Test.worker_SECONDARY_ID$20Test_1dea8e09-3574-4929-bb99-d34c51d82ac0, startTime=2023-01-26T18:10:10.487574, finishTime=2023-01-26T18:10:10.487830) of size 0
INFO  [2023-01-26 18:10:10,489] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SECONDARY_ID$20Test.269c12ad-81e6-493b-8d6b-12ba11d01936] with 2 results within PT0.002153S
INFO  [2023-01-26 18:10:10,490] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SECONDARY_ID$20Test.269c12ad-81e6-493b-8d6b-12ba11d01936, workerId=SECONDARY_ID$20Test.worker_SECONDARY_ID$20Test_a422a7ac-6c84-4231-9db2-24e41fe25bbd, startTime=2023-01-26T18:10:10.487574, finishTime=2023-01-26T18:10:10.489727) of size 2
INFO  [2023-01-26 18:10:10,490] com.bakdata.conquery.models.execution.ManagedExecution: DONE 269c12ad-81e6-493b-8d6b-12ba11d01936 ManagedQuery within PT0.007507S
127.0.0.1 - - [26/Jan/2023:18:10:10 +0000] "GET /api/datasets/SECONDARY_ID$20Test/queries/SECONDARY_ID$20Test.269c12ad-81e6-493b-8d6b-12ba11d01936 HTTP/1.1" 200 1950 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:10:10,513] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SECONDARY_ID Test], queryId=269c12ad-81e6-493b-8d6b-12ba11d01936, label=number	@§$, creationTime=2023-01-26T18:10:10.482419, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@5e3d7a66[Count = 0], startTime=2023-01-26T18:10:10.482792, finishTime=2023-01-26T18:10:10.490299, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@e99071), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SECONDARY_ID Test)), query=com.bakdata.conquery.apiv1.query.SecondaryIdQuery@1, lastResultCount=5, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@386e5b41, com.bakdata.conquery.models.query.ColumnDescriptor@57eaf87e, com.bakdata.conquery.models.query.ColumnDescriptor@623156af]) download on dataset Dataset[label=null, name=SECONDARY_ID Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:10,513] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SECONDARY_ID Test], queryId=269c12ad-81e6-493b-8d6b-12ba11d01936, label=number	@§$, creationTime=2023-01-26T18:10:10.482419, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@5e3d7a66[Count = 0], startTime=2023-01-26T18:10:10.482792, finishTime=2023-01-26T18:10:10.490299, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@e99071), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SECONDARY_ID Test)), query=com.bakdata.conquery.apiv1.query.SecondaryIdQuery@1, lastResultCount=5, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@386e5b41, com.bakdata.conquery.models.query.ColumnDescriptor@57eaf87e, com.bakdata.conquery.models.query.ColumnDescriptor@623156af]) on dataset Dataset[label=null, name=SECONDARY_ID Test]
127.0.0.1 - - [26/Jan/2023:18:10:10 +0000] "GET /api/datasets/SECONDARY_ID%20Test/result/SECONDARY_ID$20Test.269c12ad-81e6-493b-8d6b-12ba11d01936.csv?pretty=false HTTP/1.1" 200 226 "-" "Conquery (test client)" 21
INFO  [2023-01-26 18:10:10,533] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest SECONDARY_ID Test on 6 rows
INFO  [2023-01-26 18:10:10,533] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast SECONDARY_ID Test
INFO  [2023-01-26 18:10:10,534] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SECONDARY_ID Test, name=SECONDARY_ID Test]
INFO  [2023-01-26 18:10:10,534] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SECONDARY_ID Test, name=SECONDARY_ID Test]
INFO  [2023-01-26 18:10:10,534] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SECONDARY_ID Test_1dea8e09-3574-4929-bb99-d34c51d82ac0
INFO  [2023-01-26 18:10:10,534] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SECONDARY_ID Test_a422a7ac-6c84-4231-9db2-24e41fe25bbd
INFO  [2023-01-26 18:10:10,556] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow SECONDARY_ID Test
INFO  [2023-01-26 18:10:10,557] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SECONDARY_ID Test_a422a7ac-6c84-4231-9db2-24e41fe25bbd
INFO  [2023-01-26 18:10:10,557] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SECONDARY_ID Test_1dea8e09-3574-4929-bb99-d34c51d82ac0
INFO  [2023-01-26 18:10:10,639] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of SECONDARY_ID$20Test
INFO  [2023-01-26 18:10:10,639] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:10,665] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test SECONDARY_ID Test
INFO  [2023-01-26 18:10:10,665] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test SECONDARY_ID Test
INFO  [2023-01-26 18:10:10,666] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:10,666] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:10,667] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SECONDARY_ID Test[1], name=SECONDARY_ID Test[1]]
INFO  [2023-01-26 18:10:10,667] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SECONDARY_ID Test[1], name=SECONDARY_ID Test[1]]
INFO  [2023-01-26 18:10:10,667] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:10,667] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:10,669] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SECONDARY_ID$20Test[1].worker_SECONDARY_ID$20Test[1]_bbb96f2a-29f2-4740-9572-06c90f2ade4f are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:10,669] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SECONDARY_ID$20Test[1].worker_SECONDARY_ID$20Test[1]_bbb96f2a-29f2-4740-9572-06c90f2ade4f are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:10,669] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:10,669] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SECONDARY_ID$20Test[1].worker_SECONDARY_ID$20Test[1]_0dd6dd99-8df1-4800-ad4f-f55e69f4b7db are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:10,669] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SECONDARY_ID$20Test[1].worker_SECONDARY_ID$20Test[1]_0dd6dd99-8df1-4800-ad4f-f55e69f4b7db are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:10,669] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:10,671] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:10,772] com.bakdata.conquery.resources.admin.rest.AdminDatasetProcessor: Received new SecondaryId[SECONDARY_ID$20Test[1].secondary]
INFO  [2023-01-26 18:10:10,774] com.bakdata.conquery.resources.admin.rest.AdminDatasetProcessor: Received new SecondaryId[SECONDARY_ID$20Test[1].ignored]
INFO  [2023-01-26 18:10:10,774] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:10,774] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId SECONDARY_ID$20Test[1].secondary
INFO  [2023-01-26 18:10:10,774] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId SECONDARY_ID$20Test[1].secondary
INFO  [2023-01-26 18:10:10,815] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId SECONDARY_ID$20Test[1].ignored
INFO  [2023-01-26 18:10:10,815] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId SECONDARY_ID$20Test[1].ignored
INFO  [2023-01-26 18:10:10,922] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:10,923] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SECONDARY_ID$20Test[1].table1
INFO  [2023-01-26 18:10:10,923] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SECONDARY_ID$20Test[1].table1
INFO  [2023-01-26 18:10:10,923] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SECONDARY_ID$20Test[1].table12
INFO  [2023-01-26 18:10:10,923] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SECONDARY_ID$20Test[1].table12
INFO  [2023-01-26 18:10:11,038] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:11,147] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:11,147] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:11,147] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:11,147] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 295 B in total
INFO  [2023-01-26 18:10:11,148] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SECONDARY_ID Test[1]/table1.import.json, tag=Optional.empty)
████████████████████████▌                         ▌  49%	est. time remaining: 0.029556566sINFO  [2023-01-26 18:10:11,176] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=1, sum=4, min=4, average=4.000000, max=4}
INFO  [2023-01-26 18:10:11,176] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with RealParser(super=Parser(lines=4, nullLines=0), requiredPrecision=4.9E-324, floatULP=1.1920928955078125E-7)
INFO  [2023-01-26 18:10:11,176] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[sid] with StringParser(super=Parser(lines=4, nullLines=1), encoding=null, prefix=f_a, suffix=)
INFO  [2023-01-26 18:10:11,176] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=4, nullLines=0), minParser=DateParser(super=Parser(lines=4, nullLines=0), subType=IntegerParser(super=Parser(lines=4, nullLines=0), minValue=14790, maxValue=16982), dateReader=com.bakdata.conquery.util.DateReader@3ff045f8), maxParser=DateParser(super=Parser(lines=4, nullLines=0), subType=IntegerParser(super=Parser(lines=4, nullLines=0), minValue=14790, maxValue=20999), dateReader=com.bakdata.conquery.util.DateReader@551ae768), dateReader=com.bakdata.conquery.util.DateReader@25d97ef2, onlyQuarters=false, maxValue=20999, minValue=14790, anyOpen=false)
INFO  [2023-01-26 18:10:11,181] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SECONDARY_ID Test[1]/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:11,181] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SECONDARY_ID Test[1]/table12.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000494901sINFO  [2023-01-26 18:10:11,198] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=1, sum=4, min=4, average=4.000000, max=4}
INFO  [2023-01-26 18:10:11,198] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[sid] with StringParser(super=Parser(lines=4, nullLines=1), encoding=null, prefix=f_a, suffix=)
INFO  [2023-01-26 18:10:11,198] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with RealParser(super=Parser(lines=4, nullLines=0), requiredPrecision=4.9E-324, floatULP=9.5367431640625E-7)
INFO  [2023-01-26 18:10:11,198] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=4, nullLines=0), minParser=DateParser(super=Parser(lines=4, nullLines=0), subType=IntegerParser(super=Parser(lines=4, nullLines=0), minValue=18443, maxValue=20634), dateReader=com.bakdata.conquery.util.DateReader@674412fb), maxParser=DateParser(super=Parser(lines=4, nullLines=0), subType=IntegerParser(super=Parser(lines=4, nullLines=0), minValue=18443, maxValue=20634), dateReader=com.bakdata.conquery.util.DateReader@5a26446e), dateReader=com.bakdata.conquery.util.DateReader@5885d9e5, onlyQuarters=false, maxValue=20634, minValue=18443, anyOpen=false)
INFO  [2023-01-26 18:10:11,201] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SECONDARY_ID Test[1]/table12.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:11,201] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 2 Jobs:
INFO  [2023-01-26 18:10:11,201] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SECONDARY_ID Test[1]/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:11,201] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SECONDARY_ID Test[1]/table12.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:11,217] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into SECONDARY_ID$20Test[1].table1
127.0.0.1 - - [26/Jan/2023:18:10:11 +0000] "POST /admin/datasets/SECONDARY_ID%20Test%5B1%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_SECONDARY_ID+Test%5B1%5D%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:10:11,218] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:11,219] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:11,219] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:11,221] com.bakdata.conquery.models.jobs.ImportJob: Start sending 1 Buckets
INFO  [2023-01-26 18:10:11,221] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SECONDARY_ID$20Test[1].table1.table1], containing 4 entries.
INFO  [2023-01-26 18:10:11,221] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SECONDARY_ID$20Test[1].table1.table1], containing 4 entries.
WARN  [2023-01-26 18:10:11,222] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:11,222] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SECONDARY_ID$20Test[1].table1.table1.0
INFO  [2023-01-26 18:10:11,234] com.bakdata.conquery.models.jobs.ImportJob: Importing table12 into SECONDARY_ID$20Test[1].table12
INFO  [2023-01-26 18:10:11,234] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
127.0.0.1 - - [26/Jan/2023:18:10:11 +0000] "POST /admin/datasets/SECONDARY_ID%20Test%5B1%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_SECONDARY_ID+Test%5B1%5D%2Ftable12.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:10:11,234] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:11,234] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:11,234] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:11,234] com.bakdata.conquery.models.jobs.ImportJob: Start sending 1 Buckets
WARN  [2023-01-26 18:10:11,235] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:11,235] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SECONDARY_ID$20Test[1].table12.table12], containing 4 entries.
INFO  [2023-01-26 18:10:11,235] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SECONDARY_ID$20Test[1].table12.table12], containing 4 entries.
INFO  [2023-01-26 18:10:11,235] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SECONDARY_ID$20Test[1].table12.table12.0
INFO  [2023-01-26 18:10:11,340] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:11,345] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:11,391] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:11,392] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:11,497] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: SECONDARY_ID Test QUERY INIT
INFO  [2023-01-26 18:10:11,510] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[SECONDARY_ID$20Test[1]] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:11,510] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[c5ebe61b-9134-4f91-afb1-dcdbd917f921] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_SECONDARY_ID Test[1]))]]
INFO  [2023-01-26 18:10:11,514] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started SecondaryIdQuery SECONDARY_ID$20Test[1].c5ebe61b-9134-4f91-afb1-dcdbd917f921
INFO  [2023-01-26 18:10:11,514] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started SecondaryIdQuery SECONDARY_ID$20Test[1].c5ebe61b-9134-4f91-afb1-dcdbd917f921
WARN  [2023-01-26 18:10:11,514] com.bakdata.conquery.models.query.QueryExecutor: Entities for query are empty
INFO  [2023-01-26 18:10:11,514] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SECONDARY_ID$20Test[1].c5ebe61b-9134-4f91-afb1-dcdbd917f921] with 0 results within PT0.000293S
INFO  [2023-01-26 18:10:11,515] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SECONDARY_ID$20Test[1].c5ebe61b-9134-4f91-afb1-dcdbd917f921, workerId=SECONDARY_ID$20Test[1].worker_SECONDARY_ID$20Test[1]_0dd6dd99-8df1-4800-ad4f-f55e69f4b7db, startTime=2023-01-26T18:10:11.514640, finishTime=2023-01-26T18:10:11.514933) of size 0
127.0.0.1 - - [26/Jan/2023:18:10:11 +0000] "POST /api/datasets/SECONDARY_ID$20Test%5B1%5D/queries HTTP/1.1" 201 1870 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:10:11,516] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SECONDARY_ID$20Test[1].c5ebe61b-9134-4f91-afb1-dcdbd917f921] with 1 results within PT0.001503S
INFO  [2023-01-26 18:10:11,516] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SECONDARY_ID$20Test[1].c5ebe61b-9134-4f91-afb1-dcdbd917f921, workerId=SECONDARY_ID$20Test[1].worker_SECONDARY_ID$20Test[1]_bbb96f2a-29f2-4740-9572-06c90f2ade4f, startTime=2023-01-26T18:10:11.514645, finishTime=2023-01-26T18:10:11.516148) of size 1
INFO  [2023-01-26 18:10:11,516] com.bakdata.conquery.models.execution.ManagedExecution: DONE c5ebe61b-9134-4f91-afb1-dcdbd917f921 ManagedQuery within PT0.006253S
127.0.0.1 - - [26/Jan/2023:18:10:11 +0000] "GET /api/datasets/SECONDARY_ID$20Test%5B1%5D/queries/SECONDARY_ID$20Test%5B1%5D.c5ebe61b-9134-4f91-afb1-dcdbd917f921 HTTP/1.1" 200 2389 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:10:11,536] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SECONDARY_ID Test[1]], queryId=c5ebe61b-9134-4f91-afb1-dcdbd917f921, label=vs	@§$, creationTime=2023-01-26T18:10:11.510323, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@25d3bf01[Count = 0], startTime=2023-01-26T18:10:11.510506, finishTime=2023-01-26T18:10:11.516759, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@437768f), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SECONDARY_ID Test[1])), query=com.bakdata.conquery.apiv1.query.SecondaryIdQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@70995070, com.bakdata.conquery.models.query.ColumnDescriptor@70d9427d, com.bakdata.conquery.models.query.ColumnDescriptor@48cac0d0]) download on dataset Dataset[label=null, name=SECONDARY_ID Test[1]] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:11,536] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SECONDARY_ID Test[1]], queryId=c5ebe61b-9134-4f91-afb1-dcdbd917f921, label=vs	@§$, creationTime=2023-01-26T18:10:11.510323, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@25d3bf01[Count = 0], startTime=2023-01-26T18:10:11.510506, finishTime=2023-01-26T18:10:11.516759, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@437768f), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SECONDARY_ID Test[1])), query=com.bakdata.conquery.apiv1.query.SecondaryIdQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@70995070, com.bakdata.conquery.models.query.ColumnDescriptor@70d9427d, com.bakdata.conquery.models.query.ColumnDescriptor@48cac0d0]) on dataset Dataset[label=null, name=SECONDARY_ID Test[1]]
127.0.0.1 - - [26/Jan/2023:18:10:11 +0000] "GET /api/datasets/SECONDARY_ID%20Test%5B1%5D/result/SECONDARY_ID$20Test%5B1%5D.c5ebe61b-9134-4f91-afb1-dcdbd917f921.csv?pretty=false HTTP/1.1" 200 88 "-" "Conquery (test client)" 24
INFO  [2023-01-26 18:10:11,559] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest SECONDARY_ID Test on 3 rows
INFO  [2023-01-26 18:10:11,559] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast SECONDARY_ID Test[1]
INFO  [2023-01-26 18:10:11,560] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SECONDARY_ID Test[1], name=SECONDARY_ID Test[1]]
INFO  [2023-01-26 18:10:11,560] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SECONDARY_ID Test[1], name=SECONDARY_ID Test[1]]
INFO  [2023-01-26 18:10:11,560] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SECONDARY_ID Test[1]_0dd6dd99-8df1-4800-ad4f-f55e69f4b7db
INFO  [2023-01-26 18:10:11,560] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SECONDARY_ID Test[1]_bbb96f2a-29f2-4740-9572-06c90f2ade4f
INFO  [2023-01-26 18:10:11,591] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow SECONDARY_ID Test[1]
INFO  [2023-01-26 18:10:11,591] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SECONDARY_ID Test[1]_bbb96f2a-29f2-4740-9572-06c90f2ade4f
INFO  [2023-01-26 18:10:11,591] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SECONDARY_ID Test[1]_0dd6dd99-8df1-4800-ad4f-f55e69f4b7db
INFO  [2023-01-26 18:10:11,635] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of SECONDARY_ID$20Test[1]
INFO  [2023-01-26 18:10:11,635] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:11,697] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test SECONDARY_ID Test
INFO  [2023-01-26 18:10:11,697] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test SECONDARY_ID_EXCLUDED Test
INFO  [2023-01-26 18:10:11,697] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:11,697] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:11,698] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SECONDARY_ID_EXCLUDED Test, name=SECONDARY_ID_EXCLUDED Test]
INFO  [2023-01-26 18:10:11,698] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SECONDARY_ID_EXCLUDED Test, name=SECONDARY_ID_EXCLUDED Test]
INFO  [2023-01-26 18:10:11,698] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:11,698] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:11,699] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SECONDARY_ID_EXCLUDED$20Test.worker_SECONDARY_ID_EXCLUDED$20Test_207c4bd0-83b6-47a8-9bc9-7f16cd0e34db are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:11,699] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SECONDARY_ID_EXCLUDED$20Test.worker_SECONDARY_ID_EXCLUDED$20Test_207c4bd0-83b6-47a8-9bc9-7f16cd0e34db are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:11,699] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:11,699] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SECONDARY_ID_EXCLUDED$20Test.worker_SECONDARY_ID_EXCLUDED$20Test_568e993f-da3b-4a9a-92a7-7817a33feea1 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:11,699] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SECONDARY_ID_EXCLUDED$20Test.worker_SECONDARY_ID_EXCLUDED$20Test_568e993f-da3b-4a9a-92a7-7817a33feea1 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:11,699] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:11,704] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:11,804] com.bakdata.conquery.resources.admin.rest.AdminDatasetProcessor: Received new SecondaryId[SECONDARY_ID_EXCLUDED$20Test.secondary]
INFO  [2023-01-26 18:10:11,805] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:11,805] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId SECONDARY_ID_EXCLUDED$20Test.secondary
INFO  [2023-01-26 18:10:11,805] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId SECONDARY_ID_EXCLUDED$20Test.secondary
INFO  [2023-01-26 18:10:11,911] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:11,912] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SECONDARY_ID_EXCLUDED$20Test.table1
INFO  [2023-01-26 18:10:11,912] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SECONDARY_ID_EXCLUDED$20Test.table1
INFO  [2023-01-26 18:10:12,033] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:12,151] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:12,151] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:12,151] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 135 B in total
INFO  [2023-01-26 18:10:12,151] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SECONDARY_ID_EXCLUDED Test/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000440511sINFO  [2023-01-26 18:10:12,196] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=3, sum=6, min=2, average=2.000000, max=2}
INFO  [2023-01-26 18:10:12,196] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with StringParser(super=Parser(lines=6, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:12,196] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[sid] with StringParser(super=Parser(lines=6, nullLines=0), encoding=null, prefix=f, suffix=)
INFO  [2023-01-26 18:10:12,196] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=18262, maxValue=18262), dateReader=com.bakdata.conquery.util.DateReader@36c512e9)
INFO  [2023-01-26 18:10:12,199] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SECONDARY_ID_EXCLUDED Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:12,199] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:12,200] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SECONDARY_ID_EXCLUDED Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:12,219] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into SECONDARY_ID_EXCLUDED$20Test.table1
INFO  [2023-01-26 18:10:12,219] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:10:12 +0000] "POST /admin/datasets/SECONDARY_ID_EXCLUDED%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_SECONDARY_ID_EXCLUDED+Test%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 11
INFO  [2023-01-26 18:10:12,220] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:12,220] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:12,220] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:12,221] com.bakdata.conquery.models.jobs.ImportJob: Start sending 1 Buckets
WARN  [2023-01-26 18:10:12,222] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:12,222] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SECONDARY_ID_EXCLUDED$20Test.table1.table1], containing 6 entries.
INFO  [2023-01-26 18:10:12,222] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SECONDARY_ID_EXCLUDED$20Test.table1.table1], containing 6 entries.
INFO  [2023-01-26 18:10:12,222] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SECONDARY_ID_EXCLUDED$20Test.table1.table1.0
INFO  [2023-01-26 18:10:12,327] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:12,332] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:12,345] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:12,345] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:12,451] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: SECONDARY_ID_EXCLUDED Test QUERY INIT
INFO  [2023-01-26 18:10:12,461] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[SECONDARY_ID_EXCLUDED$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:12,462] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[1a661753-cf05-43cf-af3d-572931a31983] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_SECONDARY_ID_EXCLUDED Test))]]
INFO  [2023-01-26 18:10:12,467] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started SecondaryIdQuery SECONDARY_ID_EXCLUDED$20Test.1a661753-cf05-43cf-af3d-572931a31983
INFO  [2023-01-26 18:10:12,467] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started SecondaryIdQuery SECONDARY_ID_EXCLUDED$20Test.1a661753-cf05-43cf-af3d-572931a31983
WARN  [2023-01-26 18:10:12,467] com.bakdata.conquery.models.query.QueryExecutor: Entities for query are empty
INFO  [2023-01-26 18:10:12,467] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SECONDARY_ID_EXCLUDED$20Test.1a661753-cf05-43cf-af3d-572931a31983] with 0 results within PT0.000134S
INFO  [2023-01-26 18:10:12,468] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SECONDARY_ID_EXCLUDED$20Test.1a661753-cf05-43cf-af3d-572931a31983, workerId=SECONDARY_ID_EXCLUDED$20Test.worker_SECONDARY_ID_EXCLUDED$20Test_568e993f-da3b-4a9a-92a7-7817a33feea1, startTime=2023-01-26T18:10:12.467719, finishTime=2023-01-26T18:10:12.467853) of size 0
127.0.0.1 - - [26/Jan/2023:18:10:12 +0000] "POST /api/datasets/SECONDARY_ID_EXCLUDED$20Test/queries HTTP/1.1" 201 1809 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:10:12,472] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SECONDARY_ID_EXCLUDED$20Test.1a661753-cf05-43cf-af3d-572931a31983] with 3 results within PT0.005059S
INFO  [2023-01-26 18:10:12,473] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SECONDARY_ID_EXCLUDED$20Test.1a661753-cf05-43cf-af3d-572931a31983, workerId=SECONDARY_ID_EXCLUDED$20Test.worker_SECONDARY_ID_EXCLUDED$20Test_207c4bd0-83b6-47a8-9bc9-7f16cd0e34db, startTime=2023-01-26T18:10:12.467614, finishTime=2023-01-26T18:10:12.472673) of size 3
INFO  [2023-01-26 18:10:12,473] com.bakdata.conquery.models.execution.ManagedExecution: DONE 1a661753-cf05-43cf-af3d-572931a31983 ManagedQuery within PT0.011277S
127.0.0.1 - - [26/Jan/2023:18:10:12 +0000] "GET /api/datasets/SECONDARY_ID_EXCLUDED$20Test/queries/SECONDARY_ID_EXCLUDED$20Test.1a661753-cf05-43cf-af3d-572931a31983 HTTP/1.1" 200 2113 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:10:12,487] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SECONDARY_ID_EXCLUDED Test], queryId=1a661753-cf05-43cf-af3d-572931a31983, label=vs concept	@§$, creationTime=2023-01-26T18:10:12.461775, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@4a8212b7[Count = 0], startTime=2023-01-26T18:10:12.462078, finishTime=2023-01-26T18:10:12.473355, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@5a803ef4), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SECONDARY_ID_EXCLUDED Test)), query=com.bakdata.conquery.apiv1.query.SecondaryIdQuery@1, lastResultCount=5, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@183ffacb, com.bakdata.conquery.models.query.ColumnDescriptor@8e04b68, com.bakdata.conquery.models.query.ColumnDescriptor@522df769]) download on dataset Dataset[label=null, name=SECONDARY_ID_EXCLUDED Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:12,487] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SECONDARY_ID_EXCLUDED Test], queryId=1a661753-cf05-43cf-af3d-572931a31983, label=vs concept	@§$, creationTime=2023-01-26T18:10:12.461775, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@4a8212b7[Count = 0], startTime=2023-01-26T18:10:12.462078, finishTime=2023-01-26T18:10:12.473355, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@5a803ef4), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SECONDARY_ID_EXCLUDED Test)), query=com.bakdata.conquery.apiv1.query.SecondaryIdQuery@1, lastResultCount=5, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@183ffacb, com.bakdata.conquery.models.query.ColumnDescriptor@8e04b68, com.bakdata.conquery.models.query.ColumnDescriptor@522df769]) on dataset Dataset[label=null, name=SECONDARY_ID_EXCLUDED Test]
127.0.0.1 - - [26/Jan/2023:18:10:12 +0000] "GET /api/datasets/SECONDARY_ID_EXCLUDED%20Test/result/SECONDARY_ID_EXCLUDED$20Test.1a661753-cf05-43cf-af3d-572931a31983.csv?pretty=false HTTP/1.1" 200 173 "-" "Conquery (test client)" 16
INFO  [2023-01-26 18:10:12,502] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest SECONDARY_ID_EXCLUDED Test on 6 rows
INFO  [2023-01-26 18:10:12,502] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast SECONDARY_ID_EXCLUDED Test
INFO  [2023-01-26 18:10:12,502] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SECONDARY_ID_EXCLUDED Test, name=SECONDARY_ID_EXCLUDED Test]
INFO  [2023-01-26 18:10:12,502] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SECONDARY_ID_EXCLUDED Test, name=SECONDARY_ID_EXCLUDED Test]
INFO  [2023-01-26 18:10:12,502] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SECONDARY_ID_EXCLUDED Test_568e993f-da3b-4a9a-92a7-7817a33feea1
INFO  [2023-01-26 18:10:12,502] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SECONDARY_ID_EXCLUDED Test_207c4bd0-83b6-47a8-9bc9-7f16cd0e34db
INFO  [2023-01-26 18:10:12,508] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SECONDARY_ID_EXCLUDED Test_207c4bd0-83b6-47a8-9bc9-7f16cd0e34db
INFO  [2023-01-26 18:10:12,508] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow SECONDARY_ID_EXCLUDED Test
INFO  [2023-01-26 18:10:12,508] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SECONDARY_ID_EXCLUDED Test_568e993f-da3b-4a9a-92a7-7817a33feea1
INFO  [2023-01-26 18:10:12,522] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of SECONDARY_ID_EXCLUDED$20Test
INFO  [2023-01-26 18:10:12,522] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:12,650] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test SECONDARY_ID_EXCLUDED Test
INFO  [2023-01-26 18:10:12,650] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test SECONDARY_ID Test
INFO  [2023-01-26 18:10:12,651] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:12,651] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:12,652] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SECONDARY_ID Test[2], name=SECONDARY_ID Test[2]]
INFO  [2023-01-26 18:10:12,652] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SECONDARY_ID Test[2], name=SECONDARY_ID Test[2]]
INFO  [2023-01-26 18:10:12,652] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:12,652] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:12,653] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:12,653] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SECONDARY_ID$20Test[2].worker_SECONDARY_ID$20Test[2]_90cd0931-ef14-4900-901e-3d7bf685e723 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:12,653] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SECONDARY_ID$20Test[2].worker_SECONDARY_ID$20Test[2]_90cd0931-ef14-4900-901e-3d7bf685e723 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:12,653] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:12,653] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SECONDARY_ID$20Test[2].worker_SECONDARY_ID$20Test[2]_0f665592-9eb1-41a6-be3c-a0af0f8a2b00 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:12,653] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SECONDARY_ID$20Test[2].worker_SECONDARY_ID$20Test[2]_0f665592-9eb1-41a6-be3c-a0af0f8a2b00 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:12,653] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:12,758] com.bakdata.conquery.resources.admin.rest.AdminDatasetProcessor: Received new SecondaryId[SECONDARY_ID$20Test[2].secondary]
INFO  [2023-01-26 18:10:12,758] com.bakdata.conquery.resources.admin.rest.AdminDatasetProcessor: Received new SecondaryId[SECONDARY_ID$20Test[2].ignored]
INFO  [2023-01-26 18:10:12,758] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:12,759] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId SECONDARY_ID$20Test[2].secondary
INFO  [2023-01-26 18:10:12,759] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId SECONDARY_ID$20Test[2].secondary
INFO  [2023-01-26 18:10:12,759] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId SECONDARY_ID$20Test[2].ignored
INFO  [2023-01-26 18:10:12,759] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId SECONDARY_ID$20Test[2].ignored
INFO  [2023-01-26 18:10:12,865] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:12,865] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SECONDARY_ID$20Test[2].table1
INFO  [2023-01-26 18:10:12,865] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SECONDARY_ID$20Test[2].table1
INFO  [2023-01-26 18:10:12,979] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:13,088] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:13,088] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:13,088] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 180 B in total
INFO  [2023-01-26 18:10:13,088] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SECONDARY_ID Test[2]/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000317065sINFO  [2023-01-26 18:10:13,121] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=2, sum=5, min=1, average=2.500000, max=4}
INFO  [2023-01-26 18:10:13,121] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[sid] with StringParser(super=Parser(lines=5, nullLines=1), encoding=null, prefix=f_, suffix=)
INFO  [2023-01-26 18:10:13,121] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=5, nullLines=0), minParser=DateParser(super=Parser(lines=5, nullLines=0), subType=IntegerParser(super=Parser(lines=5, nullLines=0), minValue=14790, maxValue=16982), dateReader=com.bakdata.conquery.util.DateReader@71510d00), maxParser=DateParser(super=Parser(lines=5, nullLines=0), subType=IntegerParser(super=Parser(lines=5, nullLines=0), minValue=14790, maxValue=16982), dateReader=com.bakdata.conquery.util.DateReader@19bc3270), dateReader=com.bakdata.conquery.util.DateReader@6f809a53, onlyQuarters=false, maxValue=16982, minValue=14790, anyOpen=false)
INFO  [2023-01-26 18:10:13,121] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with RealParser(super=Parser(lines=5, nullLines=0), requiredPrecision=4.9E-324, floatULP=1.1920928955078125E-7)
INFO  [2023-01-26 18:10:13,125] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SECONDARY_ID Test[2]/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:13,125] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:13,125] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SECONDARY_ID Test[2]/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:13,150] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into SECONDARY_ID$20Test[2].table1
127.0.0.1 - - [26/Jan/2023:18:10:13 +0000] "POST /admin/datasets/SECONDARY_ID%20Test%5B2%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_SECONDARY_ID+Test%5B2%5D%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:10:13,150] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:13,151] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:13,151] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:13,151] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:13,153] com.bakdata.conquery.models.jobs.ImportJob: Start sending 1 Buckets
INFO  [2023-01-26 18:10:13,153] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SECONDARY_ID$20Test[2].table1.table1], containing 5 entries.
INFO  [2023-01-26 18:10:13,153] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SECONDARY_ID$20Test[2].table1.table1], containing 5 entries.
WARN  [2023-01-26 18:10:13,154] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:13,154] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SECONDARY_ID$20Test[2].table1.table1.0
INFO  [2023-01-26 18:10:13,259] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:13,264] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:13,276] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:13,276] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:13,382] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: SECONDARY_ID Test QUERY INIT
INFO  [2023-01-26 18:10:13,392] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[SECONDARY_ID$20Test[2]] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:13,394] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[bea6844c-36cf-4c2d-8f99-85aefda3defd] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_SECONDARY_ID Test[2]))]]
INFO  [2023-01-26 18:10:13,399] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started SecondaryIdQuery SECONDARY_ID$20Test[2].bea6844c-36cf-4c2d-8f99-85aefda3defd
INFO  [2023-01-26 18:10:13,399] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started SecondaryIdQuery SECONDARY_ID$20Test[2].bea6844c-36cf-4c2d-8f99-85aefda3defd
WARN  [2023-01-26 18:10:13,399] com.bakdata.conquery.models.query.QueryExecutor: Entities for query are empty
INFO  [2023-01-26 18:10:13,400] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SECONDARY_ID$20Test[2].bea6844c-36cf-4c2d-8f99-85aefda3defd] with 0 results within PT0.000283S
INFO  [2023-01-26 18:10:13,400] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SECONDARY_ID$20Test[2].bea6844c-36cf-4c2d-8f99-85aefda3defd, workerId=SECONDARY_ID$20Test[2].worker_SECONDARY_ID$20Test[2]_0f665592-9eb1-41a6-be3c-a0af0f8a2b00, startTime=2023-01-26T18:10:13.399781, finishTime=2023-01-26T18:10:13.400064) of size 0
INFO  [2023-01-26 18:10:13,400] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SECONDARY_ID$20Test[2].bea6844c-36cf-4c2d-8f99-85aefda3defd] with 1 results within PT0.001067S
127.0.0.1 - - [26/Jan/2023:18:10:13 +0000] "POST /api/datasets/SECONDARY_ID$20Test%5B2%5D/queries HTTP/1.1" 201 1552 "-" "Conquery (test client)" 11
INFO  [2023-01-26 18:10:13,401] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SECONDARY_ID$20Test[2].bea6844c-36cf-4c2d-8f99-85aefda3defd, workerId=SECONDARY_ID$20Test[2].worker_SECONDARY_ID$20Test[2]_90cd0931-ef14-4900-901e-3d7bf685e723, startTime=2023-01-26T18:10:13.399784, finishTime=2023-01-26T18:10:13.400851) of size 1
INFO  [2023-01-26 18:10:13,401] com.bakdata.conquery.models.execution.ManagedExecution: DONE bea6844c-36cf-4c2d-8f99-85aefda3defd ManagedQuery within PT0.007158S
127.0.0.1 - - [26/Jan/2023:18:10:13 +0000] "GET /api/datasets/SECONDARY_ID$20Test%5B2%5D/queries/SECONDARY_ID$20Test%5B2%5D.bea6844c-36cf-4c2d-8f99-85aefda3defd HTTP/1.1" 200 2070 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:10:13,433] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SECONDARY_ID Test[2]], queryId=bea6844c-36cf-4c2d-8f99-85aefda3defd, label=Uploaded-List number	@§$, creationTime=2023-01-26T18:10:13.393256, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@2ab21c90[Count = 0], startTime=2023-01-26T18:10:13.394192, finishTime=2023-01-26T18:10:13.401350, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@7ec7711f), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SECONDARY_ID Test[2])), query=com.bakdata.conquery.apiv1.query.SecondaryIdQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@619c8721, com.bakdata.conquery.models.query.ColumnDescriptor@13c45021, com.bakdata.conquery.models.query.ColumnDescriptor@29288855]) download on dataset Dataset[label=null, name=SECONDARY_ID Test[2]] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:13,433] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SECONDARY_ID Test[2]], queryId=bea6844c-36cf-4c2d-8f99-85aefda3defd, label=Uploaded-List number	@§$, creationTime=2023-01-26T18:10:13.393256, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@2ab21c90[Count = 0], startTime=2023-01-26T18:10:13.394192, finishTime=2023-01-26T18:10:13.401350, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@7ec7711f), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SECONDARY_ID Test[2])), query=com.bakdata.conquery.apiv1.query.SecondaryIdQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@619c8721, com.bakdata.conquery.models.query.ColumnDescriptor@13c45021, com.bakdata.conquery.models.query.ColumnDescriptor@29288855]) on dataset Dataset[label=null, name=SECONDARY_ID Test[2]]
127.0.0.1 - - [26/Jan/2023:18:10:13 +0000] "GET /api/datasets/SECONDARY_ID%20Test%5B2%5D/result/SECONDARY_ID$20Test%5B2%5D.bea6844c-36cf-4c2d-8f99-85aefda3defd.csv?pretty=false HTTP/1.1" 200 64 "-" "Conquery (test client)" 20
INFO  [2023-01-26 18:10:13,452] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest SECONDARY_ID Test on 3 rows
INFO  [2023-01-26 18:10:13,452] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast SECONDARY_ID Test[2]
INFO  [2023-01-26 18:10:13,453] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow SECONDARY_ID Test[2]
INFO  [2023-01-26 18:10:13,453] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SECONDARY_ID Test[2], name=SECONDARY_ID Test[2]]
INFO  [2023-01-26 18:10:13,453] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SECONDARY_ID Test[2], name=SECONDARY_ID Test[2]]
INFO  [2023-01-26 18:10:13,453] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SECONDARY_ID Test[2]_0f665592-9eb1-41a6-be3c-a0af0f8a2b00
INFO  [2023-01-26 18:10:13,453] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SECONDARY_ID Test[2]_90cd0931-ef14-4900-901e-3d7bf685e723
INFO  [2023-01-26 18:10:13,453] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SECONDARY_ID Test[2]_90cd0931-ef14-4900-901e-3d7bf685e723
INFO  [2023-01-26 18:10:13,454] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of SECONDARY_ID$20Test[2]
INFO  [2023-01-26 18:10:13,454] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:13,454] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SECONDARY_ID Test[2]_0f665592-9eb1-41a6-be3c-a0af0f8a2b00
INFO  [2023-01-26 18:10:13,582] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test SECONDARY_ID Test
INFO  [2023-01-26 18:10:13,582] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test SECONDARY_ID_MIXED Test
INFO  [2023-01-26 18:10:13,582] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:13,582] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:13,583] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SECONDARY_ID_MIXED Test, name=SECONDARY_ID_MIXED Test]
INFO  [2023-01-26 18:10:13,583] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SECONDARY_ID_MIXED Test, name=SECONDARY_ID_MIXED Test]
INFO  [2023-01-26 18:10:13,583] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:13,583] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:13,588] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SECONDARY_ID_MIXED$20Test.worker_SECONDARY_ID_MIXED$20Test_85e2619f-2388-4d0a-b417-64759e76605b are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:13,588] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SECONDARY_ID_MIXED$20Test.worker_SECONDARY_ID_MIXED$20Test_85e2619f-2388-4d0a-b417-64759e76605b are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:13,588] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:13,588] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SECONDARY_ID_MIXED$20Test.worker_SECONDARY_ID_MIXED$20Test_d42cb18a-d78e-4a0d-a735-b97aee4f914a are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:13,588] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SECONDARY_ID_MIXED$20Test.worker_SECONDARY_ID_MIXED$20Test_d42cb18a-d78e-4a0d-a735-b97aee4f914a are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:13,588] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:13,589] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:13,693] com.bakdata.conquery.resources.admin.rest.AdminDatasetProcessor: Received new SecondaryId[SECONDARY_ID_MIXED$20Test.secondary]
INFO  [2023-01-26 18:10:13,693] com.bakdata.conquery.resources.admin.rest.AdminDatasetProcessor: Received new SecondaryId[SECONDARY_ID_MIXED$20Test.ignored]
INFO  [2023-01-26 18:10:13,694] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:13,694] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId SECONDARY_ID_MIXED$20Test.secondary
INFO  [2023-01-26 18:10:13,694] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId SECONDARY_ID_MIXED$20Test.secondary
INFO  [2023-01-26 18:10:13,694] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId SECONDARY_ID_MIXED$20Test.ignored
INFO  [2023-01-26 18:10:13,736] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId SECONDARY_ID_MIXED$20Test.ignored
INFO  [2023-01-26 18:10:13,842] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:13,842] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SECONDARY_ID_MIXED$20Test.table
INFO  [2023-01-26 18:10:13,842] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SECONDARY_ID_MIXED$20Test.table
INFO  [2023-01-26 18:10:13,842] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SECONDARY_ID_MIXED$20Test.table2
INFO  [2023-01-26 18:10:13,842] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SECONDARY_ID_MIXED$20Test.table2
INFO  [2023-01-26 18:10:13,962] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:14,070] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:14,070] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:14,070] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:14,070] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 465 B in total
INFO  [2023-01-26 18:10:14,070] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SECONDARY_ID_MIXED Test/table.import.json, tag=Optional.empty)
██████████████████████████▌                       ▌  53%	est. time remaining: 0.030648723sINFO  [2023-01-26 18:10:14,105] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=2, sum=6, min=1, average=3.000000, max=5}
INFO  [2023-01-26 18:10:14,105] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[ignored] with StringParser(super=Parser(lines=6, nullLines=0), encoding=null, prefix=a, suffix=a)
INFO  [2023-01-26 18:10:14,105] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=6, nullLines=0), minParser=DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=14790, maxValue=16982), dateReader=com.bakdata.conquery.util.DateReader@571046e5), maxParser=DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=14790, maxValue=16982), dateReader=com.bakdata.conquery.util.DateReader@2d6ba45d), dateReader=com.bakdata.conquery.util.DateReader@31ba5eb7, onlyQuarters=false, maxValue=16982, minValue=14790, anyOpen=false)
INFO  [2023-01-26 18:10:14,105] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with RealParser(super=Parser(lines=6, nullLines=0), requiredPrecision=4.9E-324, floatULP=1.1920928955078125E-7)
INFO  [2023-01-26 18:10:14,105] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[sid] with StringParser(super=Parser(lines=6, nullLines=1), encoding=null, prefix=f_, suffix=)
INFO  [2023-01-26 18:10:14,110] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SECONDARY_ID_MIXED Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:14,110] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SECONDARY_ID_MIXED Test/table2.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000562682sINFO  [2023-01-26 18:10:14,127] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=2, sum=6, min=1, average=3.000000, max=5}
INFO  [2023-01-26 18:10:14,128] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with RealParser(super=Parser(lines=6, nullLines=0), requiredPrecision=4.9E-324, floatULP=9.5367431640625E-7)
INFO  [2023-01-26 18:10:14,128] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[sid] with StringParser(super=Parser(lines=6, nullLines=1), encoding=null, prefix=f_, suffix=)
INFO  [2023-01-26 18:10:14,128] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=6, nullLines=0), minParser=DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=18443, maxValue=20634), dateReader=com.bakdata.conquery.util.DateReader@3d8185a6), maxParser=DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=18443, maxValue=20634), dateReader=com.bakdata.conquery.util.DateReader@21a0e16c), dateReader=com.bakdata.conquery.util.DateReader@5747564c, onlyQuarters=false, maxValue=20634, minValue=18443, anyOpen=false)
INFO  [2023-01-26 18:10:14,131] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SECONDARY_ID_MIXED Test/table2.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:14,131] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 2 Jobs:
INFO  [2023-01-26 18:10:14,131] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SECONDARY_ID_MIXED Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:14,131] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SECONDARY_ID_MIXED Test/table2.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:14,148] com.bakdata.conquery.models.jobs.ImportJob: Importing table into SECONDARY_ID_MIXED$20Test.table
127.0.0.1 - - [26/Jan/2023:18:10:14 +0000] "POST /admin/datasets/SECONDARY_ID_MIXED%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_SECONDARY_ID_MIXED+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:10:14,149] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:14,150] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:14,150] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:14,153] com.bakdata.conquery.models.jobs.ImportJob: Start sending 1 Buckets
INFO  [2023-01-26 18:10:14,153] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SECONDARY_ID_MIXED$20Test.table.table], containing 6 entries.
INFO  [2023-01-26 18:10:14,153] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SECONDARY_ID_MIXED$20Test.table.table], containing 6 entries.
WARN  [2023-01-26 18:10:14,154] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:14,154] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SECONDARY_ID_MIXED$20Test.table.table.0
INFO  [2023-01-26 18:10:14,166] com.bakdata.conquery.models.jobs.ImportJob: Importing table2 into SECONDARY_ID_MIXED$20Test.table2
INFO  [2023-01-26 18:10:14,166] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:14,166] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:14,166] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:14,167] com.bakdata.conquery.models.jobs.ImportJob: Start sending 1 Buckets
WARN  [2023-01-26 18:10:14,167] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:14,167] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SECONDARY_ID_MIXED$20Test.table2.table2], containing 6 entries.
INFO  [2023-01-26 18:10:14,167] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SECONDARY_ID_MIXED$20Test.table2.table2], containing 6 entries.
INFO  [2023-01-26 18:10:14,167] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SECONDARY_ID_MIXED$20Test.table2.table2.0
127.0.0.1 - - [26/Jan/2023:18:10:14 +0000] "POST /admin/datasets/SECONDARY_ID_MIXED%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_SECONDARY_ID_MIXED+Test%2Ftable2.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:10:14,167] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:14,272] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:14,277] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:14,303] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:14,303] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:14,409] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: SECONDARY_ID_MIXED Test QUERY INIT
INFO  [2023-01-26 18:10:14,424] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[SECONDARY_ID_MIXED$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:14,425] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[519e66ec-6c3d-4723-ae23-44a7a0ee5409] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_SECONDARY_ID_MIXED Test))]]
INFO  [2023-01-26 18:10:14,428] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started SecondaryIdQuery SECONDARY_ID_MIXED$20Test.519e66ec-6c3d-4723-ae23-44a7a0ee5409
INFO  [2023-01-26 18:10:14,429] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started SecondaryIdQuery SECONDARY_ID_MIXED$20Test.519e66ec-6c3d-4723-ae23-44a7a0ee5409
WARN  [2023-01-26 18:10:14,429] com.bakdata.conquery.models.query.QueryExecutor: Entities for query are empty
INFO  [2023-01-26 18:10:14,429] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SECONDARY_ID_MIXED$20Test.519e66ec-6c3d-4723-ae23-44a7a0ee5409] with 0 results within PT0.00016S
INFO  [2023-01-26 18:10:14,429] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SECONDARY_ID_MIXED$20Test.519e66ec-6c3d-4723-ae23-44a7a0ee5409, workerId=SECONDARY_ID_MIXED$20Test.worker_SECONDARY_ID_MIXED$20Test_85e2619f-2388-4d0a-b417-64759e76605b, startTime=2023-01-26T18:10:14.428988, finishTime=2023-01-26T18:10:14.429148) of size 0
INFO  [2023-01-26 18:10:14,430] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SECONDARY_ID_MIXED$20Test.519e66ec-6c3d-4723-ae23-44a7a0ee5409] with 2 results within PT0.001015S
127.0.0.1 - - [26/Jan/2023:18:10:14 +0000] "POST /api/datasets/SECONDARY_ID_MIXED$20Test/queries HTTP/1.1" 201 1694 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:10:14,430] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SECONDARY_ID_MIXED$20Test.519e66ec-6c3d-4723-ae23-44a7a0ee5409, workerId=SECONDARY_ID_MIXED$20Test.worker_SECONDARY_ID_MIXED$20Test_d42cb18a-d78e-4a0d-a735-b97aee4f914a, startTime=2023-01-26T18:10:14.429096, finishTime=2023-01-26T18:10:14.430111) of size 2
INFO  [2023-01-26 18:10:14,430] com.bakdata.conquery.models.execution.ManagedExecution: DONE 519e66ec-6c3d-4723-ae23-44a7a0ee5409 ManagedQuery within PT0.005437S
127.0.0.1 - - [26/Jan/2023:18:10:14 +0000] "GET /api/datasets/SECONDARY_ID_MIXED$20Test/queries/SECONDARY_ID_MIXED$20Test.519e66ec-6c3d-4723-ae23-44a7a0ee5409 HTTP/1.1" 200 1985 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:10:14,458] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SECONDARY_ID_MIXED Test], queryId=519e66ec-6c3d-4723-ae23-44a7a0ee5409, label=concept	@§$, creationTime=2023-01-26T18:10:14.425187, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@236d43c8[Count = 0], startTime=2023-01-26T18:10:14.425379, finishTime=2023-01-26T18:10:14.430816, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2a3d8f76), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SECONDARY_ID_MIXED Test)), query=com.bakdata.conquery.apiv1.query.SecondaryIdQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@60a1279a, com.bakdata.conquery.models.query.ColumnDescriptor@1c54c8f4, com.bakdata.conquery.models.query.ColumnDescriptor@55eebbb5]) download on dataset Dataset[label=null, name=SECONDARY_ID_MIXED Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:14,458] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SECONDARY_ID_MIXED Test], queryId=519e66ec-6c3d-4723-ae23-44a7a0ee5409, label=concept	@§$, creationTime=2023-01-26T18:10:14.425187, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@236d43c8[Count = 0], startTime=2023-01-26T18:10:14.425379, finishTime=2023-01-26T18:10:14.430816, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2a3d8f76), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SECONDARY_ID_MIXED Test)), query=com.bakdata.conquery.apiv1.query.SecondaryIdQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@60a1279a, com.bakdata.conquery.models.query.ColumnDescriptor@1c54c8f4, com.bakdata.conquery.models.query.ColumnDescriptor@55eebbb5]) on dataset Dataset[label=null, name=SECONDARY_ID_MIXED Test]
127.0.0.1 - - [26/Jan/2023:18:10:14 +0000] "GET /api/datasets/SECONDARY_ID_MIXED%20Test/result/SECONDARY_ID_MIXED$20Test.519e66ec-6c3d-4723-ae23-44a7a0ee5409.csv?pretty=false HTTP/1.1" 200 309 "-" "Conquery (test client)" 24
INFO  [2023-01-26 18:10:14,481] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest SECONDARY_ID_MIXED Test on 5 rows
INFO  [2023-01-26 18:10:14,481] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast SECONDARY_ID_MIXED Test
INFO  [2023-01-26 18:10:14,482] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SECONDARY_ID_MIXED Test, name=SECONDARY_ID_MIXED Test]
INFO  [2023-01-26 18:10:14,482] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SECONDARY_ID_MIXED Test, name=SECONDARY_ID_MIXED Test]
INFO  [2023-01-26 18:10:14,482] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SECONDARY_ID_MIXED Test_85e2619f-2388-4d0a-b417-64759e76605b
INFO  [2023-01-26 18:10:14,482] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SECONDARY_ID_MIXED Test_d42cb18a-d78e-4a0d-a735-b97aee4f914a
INFO  [2023-01-26 18:10:14,483] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow SECONDARY_ID_MIXED Test
INFO  [2023-01-26 18:10:14,496] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SECONDARY_ID_MIXED Test_d42cb18a-d78e-4a0d-a735-b97aee4f914a
INFO  [2023-01-26 18:10:14,496] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SECONDARY_ID_MIXED Test_85e2619f-2388-4d0a-b417-64759e76605b
INFO  [2023-01-26 18:10:14,580] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of SECONDARY_ID_MIXED$20Test
INFO  [2023-01-26 18:10:14,580] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:14,609] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test SECONDARY_ID_MIXED Test
INFO  [2023-01-26 18:10:14,609] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test SIMPLE_CQEXTERNAL_QUERY Test
INFO  [2023-01-26 18:10:14,609] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:14,609] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:14,610] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SIMPLE_CQEXTERNAL_QUERY Test, name=SIMPLE_CQEXTERNAL_QUERY Test]
INFO  [2023-01-26 18:10:14,610] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SIMPLE_CQEXTERNAL_QUERY Test, name=SIMPLE_CQEXTERNAL_QUERY Test]
INFO  [2023-01-26 18:10:14,610] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:14,610] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:14,612] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SIMPLE_CQEXTERNAL_QUERY$20Test.worker_SIMPLE_CQEXTERNAL_QUERY$20Test_d4bf5f32-e2ea-4afb-8ae8-69eeaca2e3e6 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:14,612] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SIMPLE_CQEXTERNAL_QUERY$20Test.worker_SIMPLE_CQEXTERNAL_QUERY$20Test_d4bf5f32-e2ea-4afb-8ae8-69eeaca2e3e6 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:14,612] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:14,636] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SIMPLE_CQEXTERNAL_QUERY$20Test.worker_SIMPLE_CQEXTERNAL_QUERY$20Test_aae911f8-52d4-4f11-b378-80310b18a5fb are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:14,636] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SIMPLE_CQEXTERNAL_QUERY$20Test.worker_SIMPLE_CQEXTERNAL_QUERY$20Test_aae911f8-52d4-4f11-b378-80310b18a5fb are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:14,636] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:14,637] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:14,740] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:14,746] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:14,747] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SIMPLE_CQEXTERNAL_QUERY$20Test.test_table
INFO  [2023-01-26 18:10:14,747] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SIMPLE_CQEXTERNAL_QUERY$20Test.test_table
INFO  [2023-01-26 18:10:14,856] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:14,963] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:14,963] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:14,963] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 87 B in total
INFO  [2023-01-26 18:10:14,963] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SIMPLE_CQEXTERNAL_QUERY Test/test_table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000391531sINFO  [2023-01-26 18:10:15,003] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=6, sum=6, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:10:15,003] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=15340, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@3d78eeb2)
INFO  [2023-01-26 18:10:15,005] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SIMPLE_CQEXTERNAL_QUERY Test/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:15,005] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:15,005] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SIMPLE_CQEXTERNAL_QUERY Test/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:15,019] com.bakdata.conquery.models.jobs.ImportJob: Importing test_table into SIMPLE_CQEXTERNAL_QUERY$20Test.test_table
127.0.0.1 - - [26/Jan/2023:18:10:15 +0000] "POST /admin/datasets/SIMPLE_CQEXTERNAL_QUERY%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_SIMPLE_CQEXTERNAL_QUERY+Test%2Ftest_table.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:10:15,019] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:15,020] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:15,020] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:15,020] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:15,021] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:15,021] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SIMPLE_CQEXTERNAL_QUERY$20Test.test_table.test_table], containing 6 entries.
INFO  [2023-01-26 18:10:15,021] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SIMPLE_CQEXTERNAL_QUERY$20Test.test_table.test_table], containing 6 entries.
WARN  [2023-01-26 18:10:15,022] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:15,022] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SIMPLE_CQEXTERNAL_QUERY$20Test.test_table.test_table.0
INFO  [2023-01-26 18:10:15,022] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SIMPLE_CQEXTERNAL_QUERY$20Test.test_table.test_table.1
INFO  [2023-01-26 18:10:15,127] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:15,133] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:15,140] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:15,140] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:15,140] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:15,246] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: SIMPLE_CQEXTERNAL_QUERY Test QUERY INIT
INFO  [2023-01-26 18:10:15,269] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[SIMPLE_CQEXTERNAL_QUERY$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:15,269] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[20e30b12-c638-4ad7-826c-44739954d181] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_SIMPLE_CQEXTERNAL_QUERY Test))]]
INFO  [2023-01-26 18:10:15,271] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SIMPLE_CQEXTERNAL_QUERY$20Test.20e30b12-c638-4ad7-826c-44739954d181
INFO  [2023-01-26 18:10:15,271] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SIMPLE_CQEXTERNAL_QUERY$20Test.20e30b12-c638-4ad7-826c-44739954d181
127.0.0.1 - - [26/Jan/2023:18:10:15 +0000] "POST /api/datasets/SIMPLE_CQEXTERNAL_QUERY$20Test/queries HTTP/1.1" 201 984 "-" "Conquery (test client)" 5
INFO  [2023-01-26 18:10:15,287] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SIMPLE_CQEXTERNAL_QUERY$20Test.20e30b12-c638-4ad7-826c-44739954d181] with 0 results within PT0.016277S
INFO  [2023-01-26 18:10:15,288] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SIMPLE_CQEXTERNAL_QUERY$20Test.20e30b12-c638-4ad7-826c-44739954d181, workerId=SIMPLE_CQEXTERNAL_QUERY$20Test.worker_SIMPLE_CQEXTERNAL_QUERY$20Test_d4bf5f32-e2ea-4afb-8ae8-69eeaca2e3e6, startTime=2023-01-26T18:10:15.271523, finishTime=2023-01-26T18:10:15.287800) of size 0
INFO  [2023-01-26 18:10:15,290] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SIMPLE_CQEXTERNAL_QUERY$20Test.20e30b12-c638-4ad7-826c-44739954d181] with 2 results within PT0.019416S
INFO  [2023-01-26 18:10:15,291] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SIMPLE_CQEXTERNAL_QUERY$20Test.20e30b12-c638-4ad7-826c-44739954d181, workerId=SIMPLE_CQEXTERNAL_QUERY$20Test.worker_SIMPLE_CQEXTERNAL_QUERY$20Test_aae911f8-52d4-4f11-b378-80310b18a5fb, startTime=2023-01-26T18:10:15.271522, finishTime=2023-01-26T18:10:15.290938) of size 2
INFO  [2023-01-26 18:10:15,291] com.bakdata.conquery.models.execution.ManagedExecution: DONE 20e30b12-c638-4ad7-826c-44739954d181 ManagedQuery within PT0.021795S
127.0.0.1 - - [26/Jan/2023:18:10:15 +0000] "GET /api/datasets/SIMPLE_CQEXTERNAL_QUERY$20Test/queries/SIMPLE_CQEXTERNAL_QUERY$20Test.20e30b12-c638-4ad7-826c-44739954d181 HTTP/1.1" 200 1296 "-" "Conquery (test client)" 10
INFO  [2023-01-26 18:10:15,305] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SIMPLE_CQEXTERNAL_QUERY Test], queryId=20e30b12-c638-4ad7-826c-44739954d181, label=Uploaded-List	@§$, creationTime=2023-01-26T18:10:15.269316, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@26262641[Count = 0], startTime=2023-01-26T18:10:15.269768, finishTime=2023-01-26T18:10:15.291563, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2b20f48b), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SIMPLE_CQEXTERNAL_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@52c9710a, com.bakdata.conquery.models.query.ColumnDescriptor@1e164aa0]) download on dataset Dataset[label=null, name=SIMPLE_CQEXTERNAL_QUERY Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:15,305] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SIMPLE_CQEXTERNAL_QUERY Test], queryId=20e30b12-c638-4ad7-826c-44739954d181, label=Uploaded-List	@§$, creationTime=2023-01-26T18:10:15.269316, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@26262641[Count = 0], startTime=2023-01-26T18:10:15.269768, finishTime=2023-01-26T18:10:15.291563, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2b20f48b), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SIMPLE_CQEXTERNAL_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@52c9710a, com.bakdata.conquery.models.query.ColumnDescriptor@1e164aa0]) on dataset Dataset[label=null, name=SIMPLE_CQEXTERNAL_QUERY Test]
127.0.0.1 - - [26/Jan/2023:18:10:15 +0000] "GET /api/datasets/SIMPLE_CQEXTERNAL_QUERY%20Test/result/SIMPLE_CQEXTERNAL_QUERY$20Test.20e30b12-c638-4ad7-826c-44739954d181.csv?pretty=false HTTP/1.1" 200 65 "-" "Conquery (test client)" 18
INFO  [2023-01-26 18:10:15,321] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest SIMPLE_CQEXTERNAL_QUERY Test on 3 rows
INFO  [2023-01-26 18:10:15,321] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast SIMPLE_CQEXTERNAL_QUERY Test
INFO  [2023-01-26 18:10:15,322] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SIMPLE_CQEXTERNAL_QUERY Test, name=SIMPLE_CQEXTERNAL_QUERY Test]
INFO  [2023-01-26 18:10:15,322] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SIMPLE_CQEXTERNAL_QUERY Test, name=SIMPLE_CQEXTERNAL_QUERY Test]
INFO  [2023-01-26 18:10:15,322] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SIMPLE_CQEXTERNAL_QUERY Test_aae911f8-52d4-4f11-b378-80310b18a5fb
INFO  [2023-01-26 18:10:15,322] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SIMPLE_CQEXTERNAL_QUERY Test_d4bf5f32-e2ea-4afb-8ae8-69eeaca2e3e6
INFO  [2023-01-26 18:10:15,336] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SIMPLE_CQEXTERNAL_QUERY Test_aae911f8-52d4-4f11-b378-80310b18a5fb
INFO  [2023-01-26 18:10:15,429] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow SIMPLE_CQEXTERNAL_QUERY Test
INFO  [2023-01-26 18:10:15,429] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SIMPLE_CQEXTERNAL_QUERY Test_d4bf5f32-e2ea-4afb-8ae8-69eeaca2e3e6
INFO  [2023-01-26 18:10:15,529] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of SIMPLE_CQEXTERNAL_QUERY$20Test
INFO  [2023-01-26 18:10:15,529] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:15,546] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test SIMPLE_CQEXTERNAL_QUERY Test
INFO  [2023-01-26 18:10:15,546] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test SIMPLE_CQEXTERNAL_QUERY Test
INFO  [2023-01-26 18:10:15,546] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:15,546] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:15,547] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SIMPLE_CQEXTERNAL_QUERY Test[1], name=SIMPLE_CQEXTERNAL_QUERY Test[1]]
INFO  [2023-01-26 18:10:15,547] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SIMPLE_CQEXTERNAL_QUERY Test[1], name=SIMPLE_CQEXTERNAL_QUERY Test[1]]
INFO  [2023-01-26 18:10:15,547] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:15,547] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:15,549] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SIMPLE_CQEXTERNAL_QUERY$20Test[1].worker_SIMPLE_CQEXTERNAL_QUERY$20Test[1]_bf952786-dd3c-43a5-98a6-77e9c93d95ff are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:15,549] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SIMPLE_CQEXTERNAL_QUERY$20Test[1].worker_SIMPLE_CQEXTERNAL_QUERY$20Test[1]_bf952786-dd3c-43a5-98a6-77e9c93d95ff are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:15,549] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:15,549] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:15,549] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SIMPLE_CQEXTERNAL_QUERY$20Test[1].worker_SIMPLE_CQEXTERNAL_QUERY$20Test[1]_c748eb13-c218-4b11-9814-2ac2cc923cdc are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:15,549] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SIMPLE_CQEXTERNAL_QUERY$20Test[1].worker_SIMPLE_CQEXTERNAL_QUERY$20Test[1]_c748eb13-c218-4b11-9814-2ac2cc923cdc are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:15,549] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:15,653] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:15,660] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:15,660] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SIMPLE_CQEXTERNAL_QUERY$20Test[1].test_table
INFO  [2023-01-26 18:10:15,660] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SIMPLE_CQEXTERNAL_QUERY$20Test[1].test_table
INFO  [2023-01-26 18:10:15,786] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:15,896] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:15,896] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:15,896] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 87 B in total
INFO  [2023-01-26 18:10:15,896] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SIMPLE_CQEXTERNAL_QUERY Test[1]/test_table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000164566sINFO  [2023-01-26 18:10:15,913] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=6, sum=6, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:10:15,913] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=15340, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@5202a53a)
INFO  [2023-01-26 18:10:15,914] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SIMPLE_CQEXTERNAL_QUERY Test[1]/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:15,914] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:15,914] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SIMPLE_CQEXTERNAL_QUERY Test[1]/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:15,928] com.bakdata.conquery.models.jobs.ImportJob: Importing test_table into SIMPLE_CQEXTERNAL_QUERY$20Test[1].test_table
INFO  [2023-01-26 18:10:15,928] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:10:15 +0000] "POST /admin/datasets/SIMPLE_CQEXTERNAL_QUERY%20Test%5B1%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_SIMPLE_CQEXTERNAL_QUERY+Test%5B1%5D%2Ftest_table.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:10:15,929] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:15,929] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:15,929] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:15,930] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:15,930] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SIMPLE_CQEXTERNAL_QUERY$20Test[1].test_table.test_table], containing 6 entries.
INFO  [2023-01-26 18:10:15,930] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SIMPLE_CQEXTERNAL_QUERY$20Test[1].test_table.test_table], containing 6 entries.
WARN  [2023-01-26 18:10:15,930] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:15,931] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SIMPLE_CQEXTERNAL_QUERY$20Test[1].test_table.test_table.0
INFO  [2023-01-26 18:10:15,931] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SIMPLE_CQEXTERNAL_QUERY$20Test[1].test_table.test_table.1
INFO  [2023-01-26 18:10:16,048] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:16,053] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:16,060] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:16,060] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:16,060] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:16,166] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: SIMPLE_CQEXTERNAL_QUERY Test QUERY INIT
INFO  [2023-01-26 18:10:16,179] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[SIMPLE_CQEXTERNAL_QUERY$20Test[1]] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:16,180] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[d4ab3445-741a-4903-9cc1-6c1f1b951783] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_SIMPLE_CQEXTERNAL_QUERY Test[1]))]]
INFO  [2023-01-26 18:10:16,182] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SIMPLE_CQEXTERNAL_QUERY$20Test[1].d4ab3445-741a-4903-9cc1-6c1f1b951783
INFO  [2023-01-26 18:10:16,182] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SIMPLE_CQEXTERNAL_QUERY$20Test[1].d4ab3445-741a-4903-9cc1-6c1f1b951783
INFO  [2023-01-26 18:10:16,182] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SIMPLE_CQEXTERNAL_QUERY$20Test[1].d4ab3445-741a-4903-9cc1-6c1f1b951783] with 2 results within PT0.000596S
INFO  [2023-01-26 18:10:16,182] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SIMPLE_CQEXTERNAL_QUERY$20Test[1].d4ab3445-741a-4903-9cc1-6c1f1b951783] with 0 results within PT0.000656S
127.0.0.1 - - [26/Jan/2023:18:10:16 +0000] "POST /api/datasets/SIMPLE_CQEXTERNAL_QUERY$20Test%5B1%5D/queries HTTP/1.1" 201 1030 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:10:16,183] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SIMPLE_CQEXTERNAL_QUERY$20Test[1].d4ab3445-741a-4903-9cc1-6c1f1b951783, workerId=SIMPLE_CQEXTERNAL_QUERY$20Test[1].worker_SIMPLE_CQEXTERNAL_QUERY$20Test[1]_c748eb13-c218-4b11-9814-2ac2cc923cdc, startTime=2023-01-26T18:10:16.182116, finishTime=2023-01-26T18:10:16.182712) of size 2
INFO  [2023-01-26 18:10:16,183] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SIMPLE_CQEXTERNAL_QUERY$20Test[1].d4ab3445-741a-4903-9cc1-6c1f1b951783, workerId=SIMPLE_CQEXTERNAL_QUERY$20Test[1].worker_SIMPLE_CQEXTERNAL_QUERY$20Test[1]_bf952786-dd3c-43a5-98a6-77e9c93d95ff, startTime=2023-01-26T18:10:16.182269, finishTime=2023-01-26T18:10:16.182925) of size 0
INFO  [2023-01-26 18:10:16,183] com.bakdata.conquery.models.execution.ManagedExecution: DONE d4ab3445-741a-4903-9cc1-6c1f1b951783 ManagedQuery within PT0.003324S
127.0.0.1 - - [26/Jan/2023:18:10:16 +0000] "GET /api/datasets/SIMPLE_CQEXTERNAL_QUERY$20Test%5B1%5D/queries/SIMPLE_CQEXTERNAL_QUERY$20Test%5B1%5D.d4ab3445-741a-4903-9cc1-6c1f1b951783 HTTP/1.1" 200 1637 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:10:16,204] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SIMPLE_CQEXTERNAL_QUERY Test[1]], queryId=d4ab3445-741a-4903-9cc1-6c1f1b951783, label=Uploaded-List	@§$, creationTime=2023-01-26T18:10:16.179607, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@3af58bd1[Count = 0], startTime=2023-01-26T18:10:16.180175, finishTime=2023-01-26T18:10:16.183499, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@7eed1609), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SIMPLE_CQEXTERNAL_QUERY Test[1])), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@4d873e23, com.bakdata.conquery.models.query.ColumnDescriptor@241d0ee7]) download on dataset Dataset[label=null, name=SIMPLE_CQEXTERNAL_QUERY Test[1]] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:16,204] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SIMPLE_CQEXTERNAL_QUERY Test[1]], queryId=d4ab3445-741a-4903-9cc1-6c1f1b951783, label=Uploaded-List	@§$, creationTime=2023-01-26T18:10:16.179607, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@3af58bd1[Count = 0], startTime=2023-01-26T18:10:16.180175, finishTime=2023-01-26T18:10:16.183499, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@7eed1609), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SIMPLE_CQEXTERNAL_QUERY Test[1])), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@4d873e23, com.bakdata.conquery.models.query.ColumnDescriptor@241d0ee7]) on dataset Dataset[label=null, name=SIMPLE_CQEXTERNAL_QUERY Test[1]]
127.0.0.1 - - [26/Jan/2023:18:10:16 +0000] "GET /api/datasets/SIMPLE_CQEXTERNAL_QUERY%20Test%5B1%5D/result/SIMPLE_CQEXTERNAL_QUERY$20Test%5B1%5D.d4ab3445-741a-4903-9cc1-6c1f1b951783.csv?pretty=false HTTP/1.1" 200 65 "-" "Conquery (test client)" 19
INFO  [2023-01-26 18:10:16,222] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest SIMPLE_CQEXTERNAL_QUERY Test on 3 rows
INFO  [2023-01-26 18:10:16,222] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast SIMPLE_CQEXTERNAL_QUERY Test[1]
INFO  [2023-01-26 18:10:16,222] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SIMPLE_CQEXTERNAL_QUERY Test[1], name=SIMPLE_CQEXTERNAL_QUERY Test[1]]
INFO  [2023-01-26 18:10:16,222] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SIMPLE_CQEXTERNAL_QUERY Test[1], name=SIMPLE_CQEXTERNAL_QUERY Test[1]]
INFO  [2023-01-26 18:10:16,223] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SIMPLE_CQEXTERNAL_QUERY Test[1]_bf952786-dd3c-43a5-98a6-77e9c93d95ff
INFO  [2023-01-26 18:10:16,223] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SIMPLE_CQEXTERNAL_QUERY Test[1]_c748eb13-c218-4b11-9814-2ac2cc923cdc
INFO  [2023-01-26 18:10:16,248] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow SIMPLE_CQEXTERNAL_QUERY Test[1]
INFO  [2023-01-26 18:10:16,248] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SIMPLE_CQEXTERNAL_QUERY Test[1]_c748eb13-c218-4b11-9814-2ac2cc923cdc
INFO  [2023-01-26 18:10:16,248] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SIMPLE_CQEXTERNAL_QUERY Test[1]_bf952786-dd3c-43a5-98a6-77e9c93d95ff
INFO  [2023-01-26 18:10:16,337] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of SIMPLE_CQEXTERNAL_QUERY$20Test[1]
INFO  [2023-01-26 18:10:16,337] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:16,366] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test SIMPLE_CQEXTERNAL_QUERY Test
INFO  [2023-01-26 18:10:16,367] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test SIMPLE_TREECONCEPT_QUERY Test
INFO  [2023-01-26 18:10:16,367] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:16,367] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:16,368] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SIMPLE_TREECONCEPT_QUERY Test[1], name=SIMPLE_TREECONCEPT_QUERY Test[1]]
INFO  [2023-01-26 18:10:16,368] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SIMPLE_TREECONCEPT_QUERY Test[1], name=SIMPLE_TREECONCEPT_QUERY Test[1]]
INFO  [2023-01-26 18:10:16,368] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:16,368] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:16,370] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:16,371] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SIMPLE_TREECONCEPT_QUERY$20Test[1].worker_SIMPLE_TREECONCEPT_QUERY$20Test[1]_0f8cdd7f-50a0-4c9a-b426-5afeb2b1e7a8 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:16,371] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SIMPLE_TREECONCEPT_QUERY$20Test[1].worker_SIMPLE_TREECONCEPT_QUERY$20Test[1]_0f8cdd7f-50a0-4c9a-b426-5afeb2b1e7a8 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:16,371] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:16,371] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SIMPLE_TREECONCEPT_QUERY$20Test[1].worker_SIMPLE_TREECONCEPT_QUERY$20Test[1]_4e212587-d052-4ad9-88e4-fdfd24610289 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:16,371] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SIMPLE_TREECONCEPT_QUERY$20Test[1].worker_SIMPLE_TREECONCEPT_QUERY$20Test[1]_4e212587-d052-4ad9-88e4-fdfd24610289 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:16,371] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:16,473] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:16,481] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:16,481] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SIMPLE_TREECONCEPT_QUERY$20Test[1].table
INFO  [2023-01-26 18:10:16,481] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SIMPLE_TREECONCEPT_QUERY$20Test[1].table
INFO  [2023-01-26 18:10:16,600] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:16,711] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:16,712] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:16,712] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 194 B in total
INFO  [2023-01-26 18:10:16,712] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SIMPLE_TREECONCEPT_QUERY Test[1]/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000310458sINFO  [2023-01-26 18:10:16,743] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=7, sum=8, min=1, average=1.142857, max=2}
INFO  [2023-01-26 18:10:16,743] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[column] with StringParser(super=Parser(lines=8, nullLines=1), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:16,743] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[include] with StringParser(super=Parser(lines=8, nullLines=1), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:16,743] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=8, nullLines=0), subType=IntegerParser(super=Parser(lines=8, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@71cc8f10)
INFO  [2023-01-26 18:10:16,748] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SIMPLE_TREECONCEPT_QUERY Test[1]/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:16,748] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:16,748] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SIMPLE_TREECONCEPT_QUERY Test[1]/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:16,765] com.bakdata.conquery.models.jobs.ImportJob: Importing table into SIMPLE_TREECONCEPT_QUERY$20Test[1].table
INFO  [2023-01-26 18:10:16,766] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:10:16 +0000] "POST /admin/datasets/SIMPLE_TREECONCEPT_QUERY%20Test%5B1%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_SIMPLE_TREECONCEPT_QUERY+Test%5B1%5D%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 10
INFO  [2023-01-26 18:10:16,767] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:16,767] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:16,767] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:16,770] com.bakdata.conquery.models.jobs.ImportJob: Start sending 3 Buckets
INFO  [2023-01-26 18:10:16,770] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SIMPLE_TREECONCEPT_QUERY$20Test[1].table.table], containing 8 entries.
INFO  [2023-01-26 18:10:16,770] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SIMPLE_TREECONCEPT_QUERY$20Test[1].table.table], containing 8 entries.
INFO  [2023-01-26 18:10:16,771] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SIMPLE_TREECONCEPT_QUERY$20Test[1].table.table.0
WARN  [2023-01-26 18:10:16,771] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:16,771] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SIMPLE_TREECONCEPT_QUERY$20Test[1].table.table.1
INFO  [2023-01-26 18:10:16,772] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SIMPLE_TREECONCEPT_QUERY$20Test[1].table.table.2
INFO  [2023-01-26 18:10:16,877] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:16,882] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:16,897] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:16,897] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:16,897] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:17,025] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: SIMPLE_TREECONCEPT_QUERY Test QUERY INIT
INFO  [2023-01-26 18:10:17,035] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[SIMPLE_TREECONCEPT_QUERY$20Test[1]] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:17,035] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[f34b5a59-431d-4946-82ef-8151f8cbfe2f] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_SIMPLE_TREECONCEPT_QUERY Test[1]))]]
INFO  [2023-01-26 18:10:17,037] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SIMPLE_TREECONCEPT_QUERY$20Test[1].f34b5a59-431d-4946-82ef-8151f8cbfe2f
INFO  [2023-01-26 18:10:17,037] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SIMPLE_TREECONCEPT_QUERY$20Test[1].f34b5a59-431d-4946-82ef-8151f8cbfe2f
127.0.0.1 - - [26/Jan/2023:18:10:17 +0000] "POST /api/datasets/SIMPLE_TREECONCEPT_QUERY$20Test%5B1%5D/queries HTTP/1.1" 201 1138 "-" "Conquery (test client)" 5
INFO  [2023-01-26 18:10:17,038] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SIMPLE_TREECONCEPT_QUERY$20Test[1].f34b5a59-431d-4946-82ef-8151f8cbfe2f] with 0 results within PT0.001069S
INFO  [2023-01-26 18:10:17,038] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SIMPLE_TREECONCEPT_QUERY$20Test[1].f34b5a59-431d-4946-82ef-8151f8cbfe2f] with 2 results within PT0.001187S
INFO  [2023-01-26 18:10:17,038] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SIMPLE_TREECONCEPT_QUERY$20Test[1].f34b5a59-431d-4946-82ef-8151f8cbfe2f, workerId=SIMPLE_TREECONCEPT_QUERY$20Test[1].worker_SIMPLE_TREECONCEPT_QUERY$20Test[1]_0f8cdd7f-50a0-4c9a-b426-5afeb2b1e7a8, startTime=2023-01-26T18:10:17.037288, finishTime=2023-01-26T18:10:17.038357) of size 0
INFO  [2023-01-26 18:10:17,039] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SIMPLE_TREECONCEPT_QUERY$20Test[1].f34b5a59-431d-4946-82ef-8151f8cbfe2f, workerId=SIMPLE_TREECONCEPT_QUERY$20Test[1].worker_SIMPLE_TREECONCEPT_QUERY$20Test[1]_4e212587-d052-4ad9-88e4-fdfd24610289, startTime=2023-01-26T18:10:17.037289, finishTime=2023-01-26T18:10:17.038476) of size 2
INFO  [2023-01-26 18:10:17,039] com.bakdata.conquery.models.execution.ManagedExecution: DONE f34b5a59-431d-4946-82ef-8151f8cbfe2f ManagedQuery within PT0.003769S
127.0.0.1 - - [26/Jan/2023:18:10:17 +0000] "GET /api/datasets/SIMPLE_TREECONCEPT_QUERY$20Test%5B1%5D/queries/SIMPLE_TREECONCEPT_QUERY$20Test%5B1%5D.f34b5a59-431d-4946-82ef-8151f8cbfe2f HTTP/1.1" 200 1753 "-" "Conquery (test client)" 4
INFO  [2023-01-26 18:10:17,067] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SIMPLE_TREECONCEPT_QUERY Test[1]], queryId=f34b5a59-431d-4946-82ef-8151f8cbfe2f, label=concept---a1	@§$, creationTime=2023-01-26T18:10:17.035202, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@c2c41a2[Count = 0], startTime=2023-01-26T18:10:17.035375, finishTime=2023-01-26T18:10:17.039144, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@1be83b8f), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SIMPLE_TREECONCEPT_QUERY Test[1])), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@317959e8, com.bakdata.conquery.models.query.ColumnDescriptor@52670dc3]) download on dataset Dataset[label=null, name=SIMPLE_TREECONCEPT_QUERY Test[1]] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:17,067] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SIMPLE_TREECONCEPT_QUERY Test[1]], queryId=f34b5a59-431d-4946-82ef-8151f8cbfe2f, label=concept---a1	@§$, creationTime=2023-01-26T18:10:17.035202, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@c2c41a2[Count = 0], startTime=2023-01-26T18:10:17.035375, finishTime=2023-01-26T18:10:17.039144, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@1be83b8f), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SIMPLE_TREECONCEPT_QUERY Test[1])), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@317959e8, com.bakdata.conquery.models.query.ColumnDescriptor@52670dc3]) on dataset Dataset[label=null, name=SIMPLE_TREECONCEPT_QUERY Test[1]]
127.0.0.1 - - [26/Jan/2023:18:10:17 +0000] "GET /api/datasets/SIMPLE_TREECONCEPT_QUERY%20Test%5B1%5D/result/SIMPLE_TREECONCEPT_QUERY$20Test%5B1%5D.f34b5a59-431d-4946-82ef-8151f8cbfe2f.csv?pretty=false HTTP/1.1" 200 65 "-" "Conquery (test client)" 35
INFO  [2023-01-26 18:10:17,101] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest SIMPLE_TREECONCEPT_QUERY Test on 3 rows
INFO  [2023-01-26 18:10:17,101] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast SIMPLE_TREECONCEPT_QUERY Test[1]
INFO  [2023-01-26 18:10:17,102] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SIMPLE_TREECONCEPT_QUERY Test[1], name=SIMPLE_TREECONCEPT_QUERY Test[1]]
INFO  [2023-01-26 18:10:17,102] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SIMPLE_TREECONCEPT_QUERY Test[1], name=SIMPLE_TREECONCEPT_QUERY Test[1]]
INFO  [2023-01-26 18:10:17,102] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SIMPLE_TREECONCEPT_QUERY Test[1]_0f8cdd7f-50a0-4c9a-b426-5afeb2b1e7a8
INFO  [2023-01-26 18:10:17,102] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SIMPLE_TREECONCEPT_QUERY Test[1]_4e212587-d052-4ad9-88e4-fdfd24610289
INFO  [2023-01-26 18:10:17,205] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow SIMPLE_TREECONCEPT_QUERY Test[1]
INFO  [2023-01-26 18:10:17,205] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SIMPLE_TREECONCEPT_QUERY Test[1]_4e212587-d052-4ad9-88e4-fdfd24610289
INFO  [2023-01-26 18:10:17,205] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SIMPLE_TREECONCEPT_QUERY Test[1]_0f8cdd7f-50a0-4c9a-b426-5afeb2b1e7a8
INFO  [2023-01-26 18:10:17,305] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of SIMPLE_TREECONCEPT_QUERY$20Test[1]
INFO  [2023-01-26 18:10:17,305] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:17,330] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test SIMPLE_TREECONCEPT_QUERY Test
INFO  [2023-01-26 18:10:17,331] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test SIMPLE_TREECONCEPT_GROOVY_QUERY Test
INFO  [2023-01-26 18:10:17,331] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:17,331] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:17,331] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SIMPLE_TREECONCEPT_GROOVY_QUERY Test, name=SIMPLE_TREECONCEPT_GROOVY_QUERY Test]
INFO  [2023-01-26 18:10:17,331] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SIMPLE_TREECONCEPT_GROOVY_QUERY Test, name=SIMPLE_TREECONCEPT_GROOVY_QUERY Test]
INFO  [2023-01-26 18:10:17,331] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:17,331] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:17,332] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:17,333] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SIMPLE_TREECONCEPT_GROOVY_QUERY$20Test.worker_SIMPLE_TREECONCEPT_GROOVY_QUERY$20Test_34ce4d78-ccd4-4e6c-8142-7d0d3a48f419 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:17,333] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SIMPLE_TREECONCEPT_GROOVY_QUERY$20Test.worker_SIMPLE_TREECONCEPT_GROOVY_QUERY$20Test_34ce4d78-ccd4-4e6c-8142-7d0d3a48f419 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:17,333] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:17,333] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SIMPLE_TREECONCEPT_GROOVY_QUERY$20Test.worker_SIMPLE_TREECONCEPT_GROOVY_QUERY$20Test_d8f2ca0e-9f1c-4bdb-8466-a9aef65e2f4c are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:17,333] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SIMPLE_TREECONCEPT_GROOVY_QUERY$20Test.worker_SIMPLE_TREECONCEPT_GROOVY_QUERY$20Test_d8f2ca0e-9f1c-4bdb-8466-a9aef65e2f4c are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:17,333] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:17,437] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:17,443] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:17,443] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SIMPLE_TREECONCEPT_GROOVY_QUERY$20Test.test_table_groovy
INFO  [2023-01-26 18:10:17,444] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SIMPLE_TREECONCEPT_GROOVY_QUERY$20Test.test_table_groovy
INFO  [2023-01-26 18:10:17,569] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:17,700] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:17,701] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:17,701] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 112 B in total
INFO  [2023-01-26 18:10:17,701] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SIMPLE_TREECONCEPT_GROOVY_QUERY Test/test_table_groovy.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000152979sINFO  [2023-01-26 18:10:17,716] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=4, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:10:17,716] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=4, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:17,716] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[groovy_column] with IntegerParser(super=Parser(lines=4, nullLines=0), minValue=1, maxValue=2)
INFO  [2023-01-26 18:10:17,716] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=4, nullLines=0), subType=IntegerParser(super=Parser(lines=4, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@4e4bc403)
INFO  [2023-01-26 18:10:17,719] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SIMPLE_TREECONCEPT_GROOVY_QUERY Test/test_table_groovy.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:17,719] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:17,719] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SIMPLE_TREECONCEPT_GROOVY_QUERY Test/test_table_groovy.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:17,733] com.bakdata.conquery.models.jobs.ImportJob: Importing test_table_groovy into SIMPLE_TREECONCEPT_GROOVY_QUERY$20Test.test_table_groovy
INFO  [2023-01-26 18:10:17,733] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:10:17 +0000] "POST /admin/datasets/SIMPLE_TREECONCEPT_GROOVY_QUERY%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_SIMPLE_TREECONCEPT_GROOVY_QUERY+Test%2Ftest_table_groovy.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:10:17,734] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:17,734] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:17,734] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:17,735] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:17,735] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SIMPLE_TREECONCEPT_GROOVY_QUERY$20Test.test_table_groovy.test_table_groovy], containing 4 entries.
INFO  [2023-01-26 18:10:17,735] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SIMPLE_TREECONCEPT_GROOVY_QUERY$20Test.test_table_groovy.test_table_groovy], containing 4 entries.
WARN  [2023-01-26 18:10:17,736] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:17,736] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SIMPLE_TREECONCEPT_GROOVY_QUERY$20Test.test_table_groovy.test_table_groovy.0
INFO  [2023-01-26 18:10:17,736] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SIMPLE_TREECONCEPT_GROOVY_QUERY$20Test.test_table_groovy.test_table_groovy.1
INFO  [2023-01-26 18:10:17,841] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:17,846] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:17,860] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:17,860] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:17,860] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:17,966] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: SIMPLE_TREECONCEPT_GROOVY_QUERY Test QUERY INIT
INFO  [2023-01-26 18:10:17,977] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[SIMPLE_TREECONCEPT_GROOVY_QUERY$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:17,977] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[d16226ae-26cd-4835-af95-4ba510809ecc] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_SIMPLE_TREECONCEPT_GROOVY_QUERY Test))]]
INFO  [2023-01-26 18:10:17,981] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SIMPLE_TREECONCEPT_GROOVY_QUERY$20Test.d16226ae-26cd-4835-af95-4ba510809ecc
INFO  [2023-01-26 18:10:17,981] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SIMPLE_TREECONCEPT_GROOVY_QUERY$20Test.d16226ae-26cd-4835-af95-4ba510809ecc
INFO  [2023-01-26 18:10:17,982] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SIMPLE_TREECONCEPT_GROOVY_QUERY$20Test.d16226ae-26cd-4835-af95-4ba510809ecc] with 0 results within PT0.00047S
INFO  [2023-01-26 18:10:17,982] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SIMPLE_TREECONCEPT_GROOVY_QUERY$20Test.d16226ae-26cd-4835-af95-4ba510809ecc] with 1 results within PT0.000817S
INFO  [2023-01-26 18:10:17,982] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SIMPLE_TREECONCEPT_GROOVY_QUERY$20Test.d16226ae-26cd-4835-af95-4ba510809ecc, workerId=SIMPLE_TREECONCEPT_GROOVY_QUERY$20Test.worker_SIMPLE_TREECONCEPT_GROOVY_QUERY$20Test_d8f2ca0e-9f1c-4bdb-8466-a9aef65e2f4c, startTime=2023-01-26T18:10:17.981617, finishTime=2023-01-26T18:10:17.982087) of size 0
INFO  [2023-01-26 18:10:17,982] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SIMPLE_TREECONCEPT_GROOVY_QUERY$20Test.d16226ae-26cd-4835-af95-4ba510809ecc, workerId=SIMPLE_TREECONCEPT_GROOVY_QUERY$20Test.worker_SIMPLE_TREECONCEPT_GROOVY_QUERY$20Test_34ce4d78-ccd4-4e6c-8142-7d0d3a48f419, startTime=2023-01-26T18:10:17.981650, finishTime=2023-01-26T18:10:17.982467) of size 1
INFO  [2023-01-26 18:10:17,983] com.bakdata.conquery.models.execution.ManagedExecution: DONE d16226ae-26cd-4835-af95-4ba510809ecc ManagedQuery within PT0.005062S
127.0.0.1 - - [26/Jan/2023:18:10:17 +0000] "POST /api/datasets/SIMPLE_TREECONCEPT_GROOVY_QUERY$20Test/queries HTTP/1.1" 201 1194 "-" "Conquery (test client)" 9
127.0.0.1 - - [26/Jan/2023:18:10:17 +0000] "GET /api/datasets/SIMPLE_TREECONCEPT_GROOVY_QUERY$20Test/queries/SIMPLE_TREECONCEPT_GROOVY_QUERY$20Test.d16226ae-26cd-4835-af95-4ba510809ecc HTTP/1.1" 200 1537 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:10:18,003] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SIMPLE_TREECONCEPT_GROOVY_QUERY Test], queryId=d16226ae-26cd-4835-af95-4ba510809ecc, label=test_child1_1	@§$, creationTime=2023-01-26T18:10:17.977751, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@69f47b0f[Count = 0], startTime=2023-01-26T18:10:17.977992, finishTime=2023-01-26T18:10:17.983054, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2c65366d), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SIMPLE_TREECONCEPT_GROOVY_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@55cad5d7, com.bakdata.conquery.models.query.ColumnDescriptor@15e793b4]) download on dataset Dataset[label=null, name=SIMPLE_TREECONCEPT_GROOVY_QUERY Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:18,004] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SIMPLE_TREECONCEPT_GROOVY_QUERY Test], queryId=d16226ae-26cd-4835-af95-4ba510809ecc, label=test_child1_1	@§$, creationTime=2023-01-26T18:10:17.977751, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@69f47b0f[Count = 0], startTime=2023-01-26T18:10:17.977992, finishTime=2023-01-26T18:10:17.983054, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2c65366d), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SIMPLE_TREECONCEPT_GROOVY_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@55cad5d7, com.bakdata.conquery.models.query.ColumnDescriptor@15e793b4]) on dataset Dataset[label=null, name=SIMPLE_TREECONCEPT_GROOVY_QUERY Test]
127.0.0.1 - - [26/Jan/2023:18:10:18 +0000] "GET /api/datasets/SIMPLE_TREECONCEPT_GROOVY_QUERY%20Test/result/SIMPLE_TREECONCEPT_GROOVY_QUERY$20Test.d16226ae-26cd-4835-af95-4ba510809ecc.csv?pretty=false HTTP/1.1" 200 39 "-" "Conquery (test client)" 24
INFO  [2023-01-26 18:10:18,026] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest SIMPLE_TREECONCEPT_GROOVY_QUERY Test on 2 rows
INFO  [2023-01-26 18:10:18,026] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast SIMPLE_TREECONCEPT_GROOVY_QUERY Test
INFO  [2023-01-26 18:10:18,027] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SIMPLE_TREECONCEPT_GROOVY_QUERY Test, name=SIMPLE_TREECONCEPT_GROOVY_QUERY Test]
INFO  [2023-01-26 18:10:18,027] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SIMPLE_TREECONCEPT_GROOVY_QUERY Test, name=SIMPLE_TREECONCEPT_GROOVY_QUERY Test]
INFO  [2023-01-26 18:10:18,027] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SIMPLE_TREECONCEPT_GROOVY_QUERY Test_d8f2ca0e-9f1c-4bdb-8466-a9aef65e2f4c
INFO  [2023-01-26 18:10:18,027] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SIMPLE_TREECONCEPT_GROOVY_QUERY Test_34ce4d78-ccd4-4e6c-8142-7d0d3a48f419
INFO  [2023-01-26 18:10:18,032] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow SIMPLE_TREECONCEPT_GROOVY_QUERY Test
INFO  [2023-01-26 18:10:18,032] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SIMPLE_TREECONCEPT_GROOVY_QUERY Test_34ce4d78-ccd4-4e6c-8142-7d0d3a48f419
INFO  [2023-01-26 18:10:18,032] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SIMPLE_TREECONCEPT_GROOVY_QUERY Test_d8f2ca0e-9f1c-4bdb-8466-a9aef65e2f4c
INFO  [2023-01-26 18:10:18,036] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of SIMPLE_TREECONCEPT_GROOVY_QUERY$20Test
INFO  [2023-01-26 18:10:18,036] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:18,165] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test SIMPLE_TREECONCEPT_GROOVY_QUERY Test
INFO  [2023-01-26 18:10:18,166] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test Concept Condition is Present
INFO  [2023-01-26 18:10:18,166] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:18,166] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:18,166] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=Concept Condition is Present, name=Concept Condition is Present]
INFO  [2023-01-26 18:10:18,166] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=Concept Condition is Present, name=Concept Condition is Present]
INFO  [2023-01-26 18:10:18,166] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:18,166] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:18,168] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker Concept$20Condition$20is$20Present.worker_Concept$20Condition$20is$20Present_92f4cb82-6934-48d7-a847-af9eafcd4410 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:18,168] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker Concept$20Condition$20is$20Present.worker_Concept$20Condition$20is$20Present_92f4cb82-6934-48d7-a847-af9eafcd4410 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:18,168] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:18,168] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker Concept$20Condition$20is$20Present.worker_Concept$20Condition$20is$20Present_f5d74f4c-a030-4976-b382-c0b0092a8f6b are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:18,168] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker Concept$20Condition$20is$20Present.worker_Concept$20Condition$20is$20Present_f5d74f4c-a030-4976-b382-c0b0092a8f6b are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:18,168] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:18,172] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:18,272] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:18,279] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:18,284] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table Concept$20Condition$20is$20Present.table
INFO  [2023-01-26 18:10:18,284] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table Concept$20Condition$20is$20Present.table
INFO  [2023-01-26 18:10:18,398] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:18,507] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:18,508] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:18,508] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 173 B in total
INFO  [2023-01-26 18:10:18,508] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_Concept Condition is Present/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000268767sINFO  [2023-01-26 18:10:18,535] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=6, sum=7, min=1, average=1.166667, max=2}
INFO  [2023-01-26 18:10:18,535] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=7, nullLines=1), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:18,535] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[include] with StringParser(super=Parser(lines=7, nullLines=3), encoding=null, prefix=1, suffix=1)
INFO  [2023-01-26 18:10:18,535] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=7, nullLines=0), subType=IntegerParser(super=Parser(lines=7, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@1fc534a4)
INFO  [2023-01-26 18:10:18,539] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_Concept Condition is Present/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:18,539] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:18,539] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_Concept Condition is Present/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:18,557] com.bakdata.conquery.models.jobs.ImportJob: Importing table into Concept$20Condition$20is$20Present.table
127.0.0.1 - - [26/Jan/2023:18:10:18 +0000] "POST /admin/datasets/Concept%20Condition%20is%20Present/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_Concept+Condition+is+Present%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:10:18,558] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:18,558] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:18,559] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:18,559] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:18,561] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:18,561] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[Concept$20Condition$20is$20Present.table.table], containing 7 entries.
INFO  [2023-01-26 18:10:18,561] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[Concept$20Condition$20is$20Present.table.table], containing 7 entries.
WARN  [2023-01-26 18:10:18,562] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:18,562] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received Concept$20Condition$20is$20Present.table.table.0
INFO  [2023-01-26 18:10:18,562] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received Concept$20Condition$20is$20Present.table.table.1
INFO  [2023-01-26 18:10:18,667] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:18,673] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:18,684] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:18,685] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:18,685] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:18,800] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: Concept Condition is Present QUERY INIT
INFO  [2023-01-26 18:10:18,809] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[Concept$20Condition$20is$20Present] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:18,809] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[fd709e8f-7ea3-4261-b4cf-f95aad2bd03c] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_Concept Condition is Present))]]
INFO  [2023-01-26 18:10:18,812] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery Concept$20Condition$20is$20Present.fd709e8f-7ea3-4261-b4cf-f95aad2bd03c
INFO  [2023-01-26 18:10:18,812] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery Concept$20Condition$20is$20Present.fd709e8f-7ea3-4261-b4cf-f95aad2bd03c
127.0.0.1 - - [26/Jan/2023:18:10:18 +0000] "POST /api/datasets/Concept$20Condition$20is$20Present/queries HTTP/1.1" 201 1141 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:10:18,814] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[Concept$20Condition$20is$20Present.fd709e8f-7ea3-4261-b4cf-f95aad2bd03c] with 0 results within PT0.001924S
INFO  [2023-01-26 18:10:18,814] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=Concept$20Condition$20is$20Present.fd709e8f-7ea3-4261-b4cf-f95aad2bd03c, workerId=Concept$20Condition$20is$20Present.worker_Concept$20Condition$20is$20Present_f5d74f4c-a030-4976-b382-c0b0092a8f6b, startTime=2023-01-26T18:10:18.812426, finishTime=2023-01-26T18:10:18.814350) of size 0
INFO  [2023-01-26 18:10:18,815] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[Concept$20Condition$20is$20Present.fd709e8f-7ea3-4261-b4cf-f95aad2bd03c] with 2 results within PT0.002575S
INFO  [2023-01-26 18:10:18,815] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=Concept$20Condition$20is$20Present.fd709e8f-7ea3-4261-b4cf-f95aad2bd03c, workerId=Concept$20Condition$20is$20Present.worker_Concept$20Condition$20is$20Present_92f4cb82-6934-48d7-a847-af9eafcd4410, startTime=2023-01-26T18:10:18.812423, finishTime=2023-01-26T18:10:18.814998) of size 2
INFO  [2023-01-26 18:10:18,815] com.bakdata.conquery.models.execution.ManagedExecution: DONE fd709e8f-7ea3-4261-b4cf-f95aad2bd03c ManagedQuery within PT0.005732S
127.0.0.1 - - [26/Jan/2023:18:10:18 +0000] "GET /api/datasets/Concept$20Condition$20is$20Present/queries/Concept$20Condition$20is$20Present.fd709e8f-7ea3-4261-b4cf-f95aad2bd03c HTTP/1.1" 200 1468 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:10:18,835] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=Concept Condition is Present], queryId=fd709e8f-7ea3-4261-b4cf-f95aad2bd03c, label=concept---a1	@§$, creationTime=2023-01-26T18:10:18.809518, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@5995c6ec[Count = 0], startTime=2023-01-26T18:10:18.809701, finishTime=2023-01-26T18:10:18.815433, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@5837caac), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_Concept Condition is Present)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@4cdc1883, com.bakdata.conquery.models.query.ColumnDescriptor@5fec393e]) download on dataset Dataset[label=null, name=Concept Condition is Present] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:18,835] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=Concept Condition is Present], queryId=fd709e8f-7ea3-4261-b4cf-f95aad2bd03c, label=concept---a1	@§$, creationTime=2023-01-26T18:10:18.809518, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@5995c6ec[Count = 0], startTime=2023-01-26T18:10:18.809701, finishTime=2023-01-26T18:10:18.815433, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@5837caac), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_Concept Condition is Present)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@4cdc1883, com.bakdata.conquery.models.query.ColumnDescriptor@5fec393e]) on dataset Dataset[label=null, name=Concept Condition is Present]
127.0.0.1 - - [26/Jan/2023:18:10:18 +0000] "GET /api/datasets/Concept%20Condition%20is%20Present/result/Concept$20Condition$20is$20Present.fd709e8f-7ea3-4261-b4cf-f95aad2bd03c.csv?pretty=false HTTP/1.1" 200 65 "-" "Conquery (test client)" 18
INFO  [2023-01-26 18:10:18,851] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest Concept Condition is Present on 3 rows
INFO  [2023-01-26 18:10:18,851] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast Concept Condition is Present
INFO  [2023-01-26 18:10:18,851] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=Concept Condition is Present, name=Concept Condition is Present]
INFO  [2023-01-26 18:10:18,851] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=Concept Condition is Present, name=Concept Condition is Present]
INFO  [2023-01-26 18:10:18,852] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_Concept Condition is Present_f5d74f4c-a030-4976-b382-c0b0092a8f6b
INFO  [2023-01-26 18:10:18,852] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_Concept Condition is Present_92f4cb82-6934-48d7-a847-af9eafcd4410
INFO  [2023-01-26 18:10:18,867] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow Concept Condition is Present
INFO  [2023-01-26 18:10:18,867] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_Concept Condition is Present_92f4cb82-6934-48d7-a847-af9eafcd4410
INFO  [2023-01-26 18:10:18,868] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_Concept Condition is Present_f5d74f4c-a030-4976-b382-c0b0092a8f6b
INFO  [2023-01-26 18:10:18,962] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of Concept$20Condition$20is$20Present
INFO  [2023-01-26 18:10:18,962] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:19,003] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test Concept Condition is Present
INFO  [2023-01-26 18:10:19,004] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test SIMPLE_TREECONCEPT_QUERY Test
INFO  [2023-01-26 18:10:19,004] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:19,004] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:19,005] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SIMPLE_TREECONCEPT_QUERY Test[2], name=SIMPLE_TREECONCEPT_QUERY Test[2]]
INFO  [2023-01-26 18:10:19,005] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SIMPLE_TREECONCEPT_QUERY Test[2], name=SIMPLE_TREECONCEPT_QUERY Test[2]]
INFO  [2023-01-26 18:10:19,005] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:19,005] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:19,011] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SIMPLE_TREECONCEPT_QUERY$20Test[2].worker_SIMPLE_TREECONCEPT_QUERY$20Test[2]_391d155a-6af2-468b-aceb-583306c1296c are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:19,011] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SIMPLE_TREECONCEPT_QUERY$20Test[2].worker_SIMPLE_TREECONCEPT_QUERY$20Test[2]_391d155a-6af2-468b-aceb-583306c1296c are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:19,011] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:19,016] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SIMPLE_TREECONCEPT_QUERY$20Test[2].worker_SIMPLE_TREECONCEPT_QUERY$20Test[2]_7788ac3b-f17f-40cc-9835-7c310f806a66 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:19,016] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SIMPLE_TREECONCEPT_QUERY$20Test[2].worker_SIMPLE_TREECONCEPT_QUERY$20Test[2]_7788ac3b-f17f-40cc-9835-7c310f806a66 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:19,016] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:19,016] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:19,120] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:19,126] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:19,126] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SIMPLE_TREECONCEPT_QUERY$20Test[2].test_table
INFO  [2023-01-26 18:10:19,126] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SIMPLE_TREECONCEPT_QUERY$20Test[2].test_table
INFO  [2023-01-26 18:10:19,236] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:19,344] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:19,344] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:19,344] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 94 B in total
INFO  [2023-01-26 18:10:19,344] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SIMPLE_TREECONCEPT_QUERY Test[2]/test_table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000322438sINFO  [2023-01-26 18:10:19,377] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=4, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:10:19,377] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=4, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:19,377] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=4, nullLines=0), subType=IntegerParser(super=Parser(lines=4, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@80ca524)
INFO  [2023-01-26 18:10:19,380] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SIMPLE_TREECONCEPT_QUERY Test[2]/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:19,380] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:19,380] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SIMPLE_TREECONCEPT_QUERY Test[2]/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:19,396] com.bakdata.conquery.models.jobs.ImportJob: Importing test_table into SIMPLE_TREECONCEPT_QUERY$20Test[2].test_table
INFO  [2023-01-26 18:10:19,396] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:10:19 +0000] "POST /admin/datasets/SIMPLE_TREECONCEPT_QUERY%20Test%5B2%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_SIMPLE_TREECONCEPT_QUERY+Test%5B2%5D%2Ftest_table.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:10:19,397] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:19,398] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:19,398] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:19,399] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:19,399] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SIMPLE_TREECONCEPT_QUERY$20Test[2].test_table.test_table], containing 4 entries.
INFO  [2023-01-26 18:10:19,399] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SIMPLE_TREECONCEPT_QUERY$20Test[2].test_table.test_table], containing 4 entries.
WARN  [2023-01-26 18:10:19,400] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:19,400] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SIMPLE_TREECONCEPT_QUERY$20Test[2].test_table.test_table.0
INFO  [2023-01-26 18:10:19,400] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SIMPLE_TREECONCEPT_QUERY$20Test[2].test_table.test_table.1
INFO  [2023-01-26 18:10:19,505] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:19,511] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:19,521] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:19,522] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:19,522] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:19,679] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: SIMPLE_TREECONCEPT_QUERY Test QUERY INIT
127.0.0.1 - - [26/Jan/2023:18:10:19 +0000] "POST /api/datasets/SIMPLE_TREECONCEPT_QUERY$20Test%5B2%5D/queries HTTP/1.1" 201 1167 "-" "Conquery (test client)" 4
INFO  [2023-01-26 18:10:19,695] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[SIMPLE_TREECONCEPT_QUERY$20Test[2]] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:19,696] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[9ddd3aa9-c0a9-4353-9424-72b9dd8a08c3] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_SIMPLE_TREECONCEPT_QUERY Test[2]))]]
INFO  [2023-01-26 18:10:19,698] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SIMPLE_TREECONCEPT_QUERY$20Test[2].9ddd3aa9-c0a9-4353-9424-72b9dd8a08c3
INFO  [2023-01-26 18:10:19,698] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SIMPLE_TREECONCEPT_QUERY$20Test[2].9ddd3aa9-c0a9-4353-9424-72b9dd8a08c3
INFO  [2023-01-26 18:10:19,747] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SIMPLE_TREECONCEPT_QUERY$20Test[2].9ddd3aa9-c0a9-4353-9424-72b9dd8a08c3] with 2 results within PT0.04961S
INFO  [2023-01-26 18:10:19,748] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SIMPLE_TREECONCEPT_QUERY$20Test[2].9ddd3aa9-c0a9-4353-9424-72b9dd8a08c3] with 0 results within PT0.049326S
INFO  [2023-01-26 18:10:19,749] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SIMPLE_TREECONCEPT_QUERY$20Test[2].9ddd3aa9-c0a9-4353-9424-72b9dd8a08c3, workerId=SIMPLE_TREECONCEPT_QUERY$20Test[2].worker_SIMPLE_TREECONCEPT_QUERY$20Test[2]_7788ac3b-f17f-40cc-9835-7c310f806a66, startTime=2023-01-26T18:10:19.699219, finishTime=2023-01-26T18:10:19.748545) of size 0
INFO  [2023-01-26 18:10:19,752] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SIMPLE_TREECONCEPT_QUERY$20Test[2].9ddd3aa9-c0a9-4353-9424-72b9dd8a08c3, workerId=SIMPLE_TREECONCEPT_QUERY$20Test[2].worker_SIMPLE_TREECONCEPT_QUERY$20Test[2]_391d155a-6af2-468b-aceb-583306c1296c, startTime=2023-01-26T18:10:19.698266, finishTime=2023-01-26T18:10:19.747876) of size 2
INFO  [2023-01-26 18:10:19,752] com.bakdata.conquery.models.execution.ManagedExecution: DONE 9ddd3aa9-c0a9-4353-9424-72b9dd8a08c3 ManagedQuery within PT0.05607S
127.0.0.1 - - [26/Jan/2023:18:10:19 +0000] "GET /api/datasets/SIMPLE_TREECONCEPT_QUERY$20Test%5B2%5D/queries/SIMPLE_TREECONCEPT_QUERY$20Test%5B2%5D.9ddd3aa9-c0a9-4353-9424-72b9dd8a08c3 HTTP/1.1" 200 1783 "-" "Conquery (test client)" 45
INFO  [2023-01-26 18:10:19,764] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SIMPLE_TREECONCEPT_QUERY Test[2]], queryId=9ddd3aa9-c0a9-4353-9424-72b9dd8a08c3, label=test_tree---test_child1	@§$, creationTime=2023-01-26T18:10:19.696107, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@35f12dfe[Count = 0], startTime=2023-01-26T18:10:19.696282, finishTime=2023-01-26T18:10:19.752352, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@4bf22ddd), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SIMPLE_TREECONCEPT_QUERY Test[2])), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@316c4c63, com.bakdata.conquery.models.query.ColumnDescriptor@5a150c1f]) download on dataset Dataset[label=null, name=SIMPLE_TREECONCEPT_QUERY Test[2]] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:19,764] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SIMPLE_TREECONCEPT_QUERY Test[2]], queryId=9ddd3aa9-c0a9-4353-9424-72b9dd8a08c3, label=test_tree---test_child1	@§$, creationTime=2023-01-26T18:10:19.696107, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@35f12dfe[Count = 0], startTime=2023-01-26T18:10:19.696282, finishTime=2023-01-26T18:10:19.752352, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@4bf22ddd), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SIMPLE_TREECONCEPT_QUERY Test[2])), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@316c4c63, com.bakdata.conquery.models.query.ColumnDescriptor@5a150c1f]) on dataset Dataset[label=null, name=SIMPLE_TREECONCEPT_QUERY Test[2]]
INFO  [2023-01-26 18:10:19,827] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest SIMPLE_TREECONCEPT_QUERY Test on 3 rows
INFO  [2023-01-26 18:10:19,827] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast SIMPLE_TREECONCEPT_QUERY Test[2]
127.0.0.1 - - [26/Jan/2023:18:10:19 +0000] "GET /api/datasets/SIMPLE_TREECONCEPT_QUERY%20Test%5B2%5D/result/SIMPLE_TREECONCEPT_QUERY$20Test%5B2%5D.9ddd3aa9-c0a9-4353-9424-72b9dd8a08c3.csv?pretty=false HTTP/1.1" 200 65 "-" "Conquery (test client)" 63
INFO  [2023-01-26 18:10:19,831] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SIMPLE_TREECONCEPT_QUERY Test[2], name=SIMPLE_TREECONCEPT_QUERY Test[2]]
INFO  [2023-01-26 18:10:19,831] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SIMPLE_TREECONCEPT_QUERY Test[2], name=SIMPLE_TREECONCEPT_QUERY Test[2]]
INFO  [2023-01-26 18:10:19,831] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SIMPLE_TREECONCEPT_QUERY Test[2]_7788ac3b-f17f-40cc-9835-7c310f806a66
INFO  [2023-01-26 18:10:19,831] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SIMPLE_TREECONCEPT_QUERY Test[2]_391d155a-6af2-468b-aceb-583306c1296c
INFO  [2023-01-26 18:10:19,931] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SIMPLE_TREECONCEPT_QUERY Test[2]_391d155a-6af2-468b-aceb-583306c1296c
INFO  [2023-01-26 18:10:19,931] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow SIMPLE_TREECONCEPT_QUERY Test[2]
INFO  [2023-01-26 18:10:19,931] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SIMPLE_TREECONCEPT_QUERY Test[2]_7788ac3b-f17f-40cc-9835-7c310f806a66
INFO  [2023-01-26 18:10:20,031] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of SIMPLE_TREECONCEPT_QUERY$20Test[2]
INFO  [2023-01-26 18:10:20,031] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:20,037] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test SIMPLE_TREECONCEPT_QUERY Test
INFO  [2023-01-26 18:10:20,037] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA Test
INFO  [2023-01-26 18:10:20,037] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:20,037] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:20,038] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA Test, name=SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA Test]
INFO  [2023-01-26 18:10:20,038] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA Test, name=SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA Test]
INFO  [2023-01-26 18:10:20,038] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:20,038] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:20,040] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA$20Test.worker_SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA$20Test_3e31bf8c-2695-4a08-9ac9-c4e288ad83c3 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:20,040] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA$20Test.worker_SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA$20Test_3e31bf8c-2695-4a08-9ac9-c4e288ad83c3 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:20,040] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:20,040] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA$20Test.worker_SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA$20Test_9a6668e8-a66e-433a-af1e-6e797501bedd are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:20,040] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA$20Test.worker_SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA$20Test_9a6668e8-a66e-433a-af1e-6e797501bedd are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:20,040] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:20,045] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:20,145] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:20,152] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:20,152] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA$20Test.test_table
INFO  [2023-01-26 18:10:20,152] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA$20Test.test_table
INFO  [2023-01-26 18:10:20,269] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:20,378] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:20,379] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:20,379] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 96 B in total
INFO  [2023-01-26 18:10:20,379] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA Test/test_table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000179014sINFO  [2023-01-26 18:10:20,397] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=4, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:10:20,397] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=4, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:20,397] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=4, nullLines=0), subType=IntegerParser(super=Parser(lines=4, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@705b39e7)
INFO  [2023-01-26 18:10:20,400] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA Test/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:20,400] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:20,400] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA Test/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:20,416] com.bakdata.conquery.models.jobs.ImportJob: Importing test_table into SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA$20Test.test_table
127.0.0.1 - - [26/Jan/2023:18:10:20 +0000] "POST /admin/datasets/SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA+Test%2Ftest_table.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:10:20,417] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:20,417] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:20,417] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:20,418] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:20,419] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:20,419] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA$20Test.test_table.test_table], containing 4 entries.
INFO  [2023-01-26 18:10:20,419] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA$20Test.test_table.test_table], containing 4 entries.
WARN  [2023-01-26 18:10:20,420] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:20,420] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA$20Test.test_table.test_table.0
INFO  [2023-01-26 18:10:20,420] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA$20Test.test_table.test_table.1
INFO  [2023-01-26 18:10:20,525] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:20,531] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:20,540] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:20,540] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:20,540] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:20,645] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA Test QUERY INIT
INFO  [2023-01-26 18:10:20,656] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:20,656] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[ee1d378d-7391-42a0-95c7-1a396d1062eb] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA Test))]]
INFO  [2023-01-26 18:10:20,659] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA$20Test.ee1d378d-7391-42a0-95c7-1a396d1062eb
INFO  [2023-01-26 18:10:20,659] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA$20Test.ee1d378d-7391-42a0-95c7-1a396d1062eb
127.0.0.1 - - [26/Jan/2023:18:10:20 +0000] "POST /api/datasets/SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA$20Test/queries HTTP/1.1" 201 1200 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:10:20,681] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA$20Test.ee1d378d-7391-42a0-95c7-1a396d1062eb] with 0 results within PT0.021819S
INFO  [2023-01-26 18:10:20,681] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA$20Test.ee1d378d-7391-42a0-95c7-1a396d1062eb, workerId=SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA$20Test.worker_SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA$20Test_9a6668e8-a66e-433a-af1e-6e797501bedd, startTime=2023-01-26T18:10:20.659197, finishTime=2023-01-26T18:10:20.681016) of size 0
INFO  [2023-01-26 18:10:20,687] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA$20Test.ee1d378d-7391-42a0-95c7-1a396d1062eb] with 2 results within PT0.028322S
INFO  [2023-01-26 18:10:20,688] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA$20Test.ee1d378d-7391-42a0-95c7-1a396d1062eb, workerId=SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA$20Test.worker_SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA$20Test_3e31bf8c-2695-4a08-9ac9-c4e288ad83c3, startTime=2023-01-26T18:10:20.659205, finishTime=2023-01-26T18:10:20.687527) of size 2
INFO  [2023-01-26 18:10:20,688] com.bakdata.conquery.models.execution.ManagedExecution: DONE ee1d378d-7391-42a0-95c7-1a396d1062eb ManagedQuery within PT0.03109S
127.0.0.1 - - [26/Jan/2023:18:10:20 +0000] "GET /api/datasets/SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA$20Test/queries/SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA$20Test.ee1d378d-7391-42a0-95c7-1a396d1062eb HTTP/1.1" 200 1588 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:10:20,700] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA Test], queryId=ee1d378d-7391-42a0-95c7-1a396d1062eb, label=test_tree---Ä1	@§$, creationTime=2023-01-26T18:10:20.656845, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@445c4ce[Count = 0], startTime=2023-01-26T18:10:20.657017, finishTime=2023-01-26T18:10:20.688107, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@29e90f94), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@606ead8d, com.bakdata.conquery.models.query.ColumnDescriptor@16b0bf92]) download on dataset Dataset[label=null, name=SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:20,700] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA Test], queryId=ee1d378d-7391-42a0-95c7-1a396d1062eb, label=test_tree---Ä1	@§$, creationTime=2023-01-26T18:10:20.656845, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@445c4ce[Count = 0], startTime=2023-01-26T18:10:20.657017, finishTime=2023-01-26T18:10:20.688107, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@29e90f94), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@606ead8d, com.bakdata.conquery.models.query.ColumnDescriptor@16b0bf92]) on dataset Dataset[label=null, name=SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA Test]
127.0.0.1 - - [26/Jan/2023:18:10:20 +0000] "GET /api/datasets/SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA%20Test/result/SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA$20Test.ee1d378d-7391-42a0-95c7-1a396d1062eb.csv?pretty=false HTTP/1.1" 200 65 "-" "Conquery (test client)" 20
INFO  [2023-01-26 18:10:20,719] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA Test on 3 rows
INFO  [2023-01-26 18:10:20,719] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA Test
INFO  [2023-01-26 18:10:20,719] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA Test, name=SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA Test]
INFO  [2023-01-26 18:10:20,719] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA Test, name=SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA Test]
INFO  [2023-01-26 18:10:20,719] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA Test_9a6668e8-a66e-433a-af1e-6e797501bedd
INFO  [2023-01-26 18:10:20,719] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA Test_3e31bf8c-2695-4a08-9ac9-c4e288ad83c3
INFO  [2023-01-26 18:10:20,739] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA Test
INFO  [2023-01-26 18:10:20,740] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA Test_3e31bf8c-2695-4a08-9ac9-c4e288ad83c3
INFO  [2023-01-26 18:10:20,740] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA Test_9a6668e8-a66e-433a-af1e-6e797501bedd
INFO  [2023-01-26 18:10:20,821] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA$20Test
INFO  [2023-01-26 18:10:20,821] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:20,846] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test SIMPLE_TREECONCEPT_QUERY_SPECIAL_CHAR_DATA Test
INFO  [2023-01-26 18:10:20,846] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test SIMPLE_VIRTUAL_CONCEPT_QUERY Test
INFO  [2023-01-26 18:10:20,846] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:20,846] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:20,850] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SIMPLE_VIRTUAL_CONCEPT_QUERY Test, name=SIMPLE_VIRTUAL_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:10:20,850] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SIMPLE_VIRTUAL_CONCEPT_QUERY Test, name=SIMPLE_VIRTUAL_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:10:20,850] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:20,850] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:20,862] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SIMPLE_VIRTUAL_CONCEPT_QUERY$20Test.worker_SIMPLE_VIRTUAL_CONCEPT_QUERY$20Test_7f23f3df-a9de-45e6-9bbe-666274a2be95 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:20,862] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SIMPLE_VIRTUAL_CONCEPT_QUERY$20Test.worker_SIMPLE_VIRTUAL_CONCEPT_QUERY$20Test_7f23f3df-a9de-45e6-9bbe-666274a2be95 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:20,862] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:20,862] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SIMPLE_VIRTUAL_CONCEPT_QUERY$20Test.worker_SIMPLE_VIRTUAL_CONCEPT_QUERY$20Test_87153348-49a1-4b2c-8f0e-cbe08591da46 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:20,862] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SIMPLE_VIRTUAL_CONCEPT_QUERY$20Test.worker_SIMPLE_VIRTUAL_CONCEPT_QUERY$20Test_87153348-49a1-4b2c-8f0e-cbe08591da46 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:20,862] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:20,866] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:20,967] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:20,975] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:20,975] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SIMPLE_VIRTUAL_CONCEPT_QUERY$20Test.table1
INFO  [2023-01-26 18:10:20,975] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SIMPLE_VIRTUAL_CONCEPT_QUERY$20Test.table1
INFO  [2023-01-26 18:10:21,087] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:21,198] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:21,198] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:21,198] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 89 B in total
INFO  [2023-01-26 18:10:21,198] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SIMPLE_VIRTUAL_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000364436sINFO  [2023-01-26 18:10:21,235] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=4, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:10:21,235] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=4, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:21,235] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=4, nullLines=0), subType=IntegerParser(super=Parser(lines=4, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@1be267bd)
INFO  [2023-01-26 18:10:21,238] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SIMPLE_VIRTUAL_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:21,238] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:21,238] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SIMPLE_VIRTUAL_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:21,256] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into SIMPLE_VIRTUAL_CONCEPT_QUERY$20Test.table1
127.0.0.1 - - [26/Jan/2023:18:10:21 +0000] "POST /admin/datasets/SIMPLE_VIRTUAL_CONCEPT_QUERY%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_SIMPLE_VIRTUAL_CONCEPT_QUERY+Test%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:10:21,256] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:21,257] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:21,257] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:21,257] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:21,259] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:21,259] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SIMPLE_VIRTUAL_CONCEPT_QUERY$20Test.table1.table1], containing 4 entries.
INFO  [2023-01-26 18:10:21,259] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SIMPLE_VIRTUAL_CONCEPT_QUERY$20Test.table1.table1], containing 4 entries.
WARN  [2023-01-26 18:10:21,260] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:21,260] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SIMPLE_VIRTUAL_CONCEPT_QUERY$20Test.table1.table1.0
INFO  [2023-01-26 18:10:21,260] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SIMPLE_VIRTUAL_CONCEPT_QUERY$20Test.table1.table1.1
INFO  [2023-01-26 18:10:21,365] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:21,370] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:21,380] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:21,381] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:21,381] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:21,486] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: SIMPLE_VIRTUAL_CONCEPT_QUERY Test QUERY INIT
INFO  [2023-01-26 18:10:21,496] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[SIMPLE_VIRTUAL_CONCEPT_QUERY$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:21,496] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[d5b8f0a2-5f80-4c72-bdef-62896ef5e62b] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_SIMPLE_VIRTUAL_CONCEPT_QUERY Test))]]
INFO  [2023-01-26 18:10:21,498] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SIMPLE_VIRTUAL_CONCEPT_QUERY$20Test.d5b8f0a2-5f80-4c72-bdef-62896ef5e62b
INFO  [2023-01-26 18:10:21,498] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SIMPLE_VIRTUAL_CONCEPT_QUERY$20Test.d5b8f0a2-5f80-4c72-bdef-62896ef5e62b
127.0.0.1 - - [26/Jan/2023:18:10:21 +0000] "POST /api/datasets/SIMPLE_VIRTUAL_CONCEPT_QUERY$20Test/queries HTTP/1.1" 201 1326 "-" "Conquery (test client)" 4
INFO  [2023-01-26 18:10:21,498] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SIMPLE_VIRTUAL_CONCEPT_QUERY$20Test.d5b8f0a2-5f80-4c72-bdef-62896ef5e62b] with 0 results within PT0.000502S
INFO  [2023-01-26 18:10:21,498] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SIMPLE_VIRTUAL_CONCEPT_QUERY$20Test.d5b8f0a2-5f80-4c72-bdef-62896ef5e62b] with 2 results within PT0.000634S
INFO  [2023-01-26 18:10:21,499] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SIMPLE_VIRTUAL_CONCEPT_QUERY$20Test.d5b8f0a2-5f80-4c72-bdef-62896ef5e62b, workerId=SIMPLE_VIRTUAL_CONCEPT_QUERY$20Test.worker_SIMPLE_VIRTUAL_CONCEPT_QUERY$20Test_7f23f3df-a9de-45e6-9bbe-666274a2be95, startTime=2023-01-26T18:10:21.498160, finishTime=2023-01-26T18:10:21.498662) of size 0
INFO  [2023-01-26 18:10:21,499] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SIMPLE_VIRTUAL_CONCEPT_QUERY$20Test.d5b8f0a2-5f80-4c72-bdef-62896ef5e62b, workerId=SIMPLE_VIRTUAL_CONCEPT_QUERY$20Test.worker_SIMPLE_VIRTUAL_CONCEPT_QUERY$20Test_87153348-49a1-4b2c-8f0e-cbe08591da46, startTime=2023-01-26T18:10:21.498062, finishTime=2023-01-26T18:10:21.498696) of size 2
INFO  [2023-01-26 18:10:21,499] com.bakdata.conquery.models.execution.ManagedExecution: DONE d5b8f0a2-5f80-4c72-bdef-62896ef5e62b ManagedQuery within PT0.003022S
127.0.0.1 - - [26/Jan/2023:18:10:21 +0000] "GET /api/datasets/SIMPLE_VIRTUAL_CONCEPT_QUERY$20Test/queries/SIMPLE_VIRTUAL_CONCEPT_QUERY$20Test.d5b8f0a2-5f80-4c72-bdef-62896ef5e62b HTTP/1.1" 200 1657 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:10:21,521] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SIMPLE_VIRTUAL_CONCEPT_QUERY Test], queryId=d5b8f0a2-5f80-4c72-bdef-62896ef5e62b, label=geschlecht_select	@§$, creationTime=2023-01-26T18:10:21.496186, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@108a30e2[Count = 0], startTime=2023-01-26T18:10:21.496295, finishTime=2023-01-26T18:10:21.499317, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@32a524e5), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SIMPLE_VIRTUAL_CONCEPT_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@7d874523, com.bakdata.conquery.models.query.ColumnDescriptor@68034519]) download on dataset Dataset[label=null, name=SIMPLE_VIRTUAL_CONCEPT_QUERY Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:21,521] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SIMPLE_VIRTUAL_CONCEPT_QUERY Test], queryId=d5b8f0a2-5f80-4c72-bdef-62896ef5e62b, label=geschlecht_select	@§$, creationTime=2023-01-26T18:10:21.496186, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@108a30e2[Count = 0], startTime=2023-01-26T18:10:21.496295, finishTime=2023-01-26T18:10:21.499317, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@32a524e5), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SIMPLE_VIRTUAL_CONCEPT_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@7d874523, com.bakdata.conquery.models.query.ColumnDescriptor@68034519]) on dataset Dataset[label=null, name=SIMPLE_VIRTUAL_CONCEPT_QUERY Test]
127.0.0.1 - - [26/Jan/2023:18:10:21 +0000] "GET /api/datasets/SIMPLE_VIRTUAL_CONCEPT_QUERY%20Test/result/SIMPLE_VIRTUAL_CONCEPT_QUERY$20Test.d5b8f0a2-5f80-4c72-bdef-62896ef5e62b.csv?pretty=false HTTP/1.1" 200 65 "-" "Conquery (test client)" 18
INFO  [2023-01-26 18:10:21,538] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest SIMPLE_VIRTUAL_CONCEPT_QUERY Test on 3 rows
INFO  [2023-01-26 18:10:21,538] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast SIMPLE_VIRTUAL_CONCEPT_QUERY Test
INFO  [2023-01-26 18:10:21,538] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SIMPLE_VIRTUAL_CONCEPT_QUERY Test, name=SIMPLE_VIRTUAL_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:10:21,538] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SIMPLE_VIRTUAL_CONCEPT_QUERY Test, name=SIMPLE_VIRTUAL_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:10:21,538] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SIMPLE_VIRTUAL_CONCEPT_QUERY Test_7f23f3df-a9de-45e6-9bbe-666274a2be95
INFO  [2023-01-26 18:10:21,538] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SIMPLE_VIRTUAL_CONCEPT_QUERY Test_87153348-49a1-4b2c-8f0e-cbe08591da46
INFO  [2023-01-26 18:10:21,550] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow SIMPLE_VIRTUAL_CONCEPT_QUERY Test
INFO  [2023-01-26 18:10:21,560] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of SIMPLE_VIRTUAL_CONCEPT_QUERY$20Test
INFO  [2023-01-26 18:10:21,560] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:21,562] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SIMPLE_VIRTUAL_CONCEPT_QUERY Test_7f23f3df-a9de-45e6-9bbe-666274a2be95
INFO  [2023-01-26 18:10:21,562] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SIMPLE_VIRTUAL_CONCEPT_QUERY Test_87153348-49a1-4b2c-8f0e-cbe08591da46
INFO  [2023-01-26 18:10:21,686] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test SIMPLE_VIRTUAL_CONCEPT_QUERY Test
INFO  [2023-01-26 18:10:21,686] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test
INFO  [2023-01-26 18:10:21,686] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:21,686] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:21,687] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test, name=SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:10:21,687] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test, name=SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:10:21,687] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:21,687] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:21,688] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_96ebfdac-5dfb-4c57-804e-2b47e05913b2 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:21,688] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_96ebfdac-5dfb-4c57-804e-2b47e05913b2 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:21,688] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:21,688] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_aaeeb609-bf57-4d98-bccd-1f8593979ebf are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:21,688] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_aaeeb609-bf57-4d98-bccd-1f8593979ebf are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:21,688] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:21,693] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:21,792] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:21,799] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:21,799] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1
INFO  [2023-01-26 18:10:21,799] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1
INFO  [2023-01-26 18:10:21,912] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:22,021] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:22,021] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:22,021] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 158 B in total
INFO  [2023-01-26 18:10:22,021] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000271999sINFO  [2023-01-26 18:10:22,049] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=8, sum=8, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:10:22,049] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=8, nullLines=2), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:22,049] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=8, nullLines=0), subType=IntegerParser(super=Parser(lines=8, nullLines=0), minValue=13828, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@ec3cfde)
INFO  [2023-01-26 18:10:22,052] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:22,052] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:22,052] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:22,069] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1
INFO  [2023-01-26 18:10:22,070] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:10:22 +0000] "POST /admin/datasets/SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY+Test%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:10:22,070] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:22,071] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:22,071] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:22,072] com.bakdata.conquery.models.jobs.ImportJob: Start sending 3 Buckets
INFO  [2023-01-26 18:10:22,073] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1.table1], containing 8 entries.
INFO  [2023-01-26 18:10:22,073] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1.table1], containing 8 entries.
WARN  [2023-01-26 18:10:22,073] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:22,073] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1.table1.0
INFO  [2023-01-26 18:10:22,073] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1.table1.1
INFO  [2023-01-26 18:10:22,074] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1.table1.2
INFO  [2023-01-26 18:10:22,178] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:22,184] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:22,195] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:22,195] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:22,195] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:22,301] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test QUERY INIT
INFO  [2023-01-26 18:10:22,310] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:22,311] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[3aa83c43-2445-42e4-968c-2263baaaffe3] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test))]]
INFO  [2023-01-26 18:10:22,313] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.3aa83c43-2445-42e4-968c-2263baaaffe3
INFO  [2023-01-26 18:10:22,313] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.3aa83c43-2445-42e4-968c-2263baaaffe3
127.0.0.1 - - [26/Jan/2023:18:10:22 +0000] "POST /api/datasets/SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test/queries HTTP/1.1" 201 1555 "-" "Conquery (test client)" 5
INFO  [2023-01-26 18:10:22,314] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.3aa83c43-2445-42e4-968c-2263baaaffe3] with 0 results within PT0.000985S
INFO  [2023-01-26 18:10:22,315] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.3aa83c43-2445-42e4-968c-2263baaaffe3, workerId=SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_aaeeb609-bf57-4d98-bccd-1f8593979ebf, startTime=2023-01-26T18:10:22.313833, finishTime=2023-01-26T18:10:22.314818) of size 0
INFO  [2023-01-26 18:10:22,315] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.3aa83c43-2445-42e4-968c-2263baaaffe3] with 1 results within PT0.001416S
INFO  [2023-01-26 18:10:22,315] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.3aa83c43-2445-42e4-968c-2263baaaffe3, workerId=SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_96ebfdac-5dfb-4c57-804e-2b47e05913b2, startTime=2023-01-26T18:10:22.313844, finishTime=2023-01-26T18:10:22.315260) of size 1
INFO  [2023-01-26 18:10:22,315] com.bakdata.conquery.models.execution.ManagedExecution: DONE 3aa83c43-2445-42e4-968c-2263baaaffe3 ManagedQuery within PT0.004616S
127.0.0.1 - - [26/Jan/2023:18:10:22 +0000] "GET /api/datasets/SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test/queries/SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.3aa83c43-2445-42e4-968c-2263baaaffe3 HTTP/1.1" 200 1962 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:10:22,334] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test], queryId=3aa83c43-2445-42e4-968c-2263baaaffe3, label=Geschlecht-SELECT	@§$, creationTime=2023-01-26T18:10:22.310923, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@1ccfb5f1[Count = 0], startTime=2023-01-26T18:10:22.311048, finishTime=2023-01-26T18:10:22.315664, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2b4d11cc), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@52e2cd1f, com.bakdata.conquery.models.query.ColumnDescriptor@4d8dacf5]) download on dataset Dataset[label=null, name=SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:22,334] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test], queryId=3aa83c43-2445-42e4-968c-2263baaaffe3, label=Geschlecht-SELECT	@§$, creationTime=2023-01-26T18:10:22.310923, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@1ccfb5f1[Count = 0], startTime=2023-01-26T18:10:22.311048, finishTime=2023-01-26T18:10:22.315664, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2b4d11cc), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@52e2cd1f, com.bakdata.conquery.models.query.ColumnDescriptor@4d8dacf5]) on dataset Dataset[label=null, name=SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test]
127.0.0.1 - - [26/Jan/2023:18:10:22 +0000] "GET /api/datasets/SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY%20Test/result/SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.3aa83c43-2445-42e4-968c-2263baaaffe3.csv?pretty=false HTTP/1.1" 200 39 "-" "Conquery (test client)" 18
INFO  [2023-01-26 18:10:22,350] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test on 2 rows
INFO  [2023-01-26 18:10:22,350] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test
INFO  [2023-01-26 18:10:22,351] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test, name=SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:10:22,351] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test, name=SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:10:22,351] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test_aaeeb609-bf57-4d98-bccd-1f8593979ebf
INFO  [2023-01-26 18:10:22,351] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test_96ebfdac-5dfb-4c57-804e-2b47e05913b2
INFO  [2023-01-26 18:10:22,387] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test
INFO  [2023-01-26 18:10:22,388] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test_96ebfdac-5dfb-4c57-804e-2b47e05913b2
INFO  [2023-01-26 18:10:22,388] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test_aaeeb609-bf57-4d98-bccd-1f8593979ebf
INFO  [2023-01-26 18:10:22,474] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test
INFO  [2023-01-26 18:10:22,474] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:22,500] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test SINGLE_SELECT_DATE_RESTRICTION_OR_CONCEPT_QUERY Test
INFO  [2023-01-26 18:10:22,501] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test
INFO  [2023-01-26 18:10:22,501] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:22,501] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:22,504] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test, name=SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:10:22,504] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:22,504] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test, name=SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:10:22,504] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:22,510] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_3412b802-bb10-49c7-86f0-ecabc86891b3 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:22,510] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_3412b802-bb10-49c7-86f0-ecabc86891b3 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:22,510] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:22,512] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_8269a34c-af9d-415b-9f91-46c2ffc66030 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:22,512] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_8269a34c-af9d-415b-9f91-46c2ffc66030 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:22,512] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:22,515] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:22,616] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:22,622] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:22,623] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1
INFO  [2023-01-26 18:10:22,623] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1
INFO  [2023-01-26 18:10:22,737] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:22,846] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:22,846] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:22,846] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 158 B in total
INFO  [2023-01-26 18:10:22,846] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000290808sINFO  [2023-01-26 18:10:22,875] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=8, sum=8, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:10:22,875] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=8, nullLines=2), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:22,876] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=8, nullLines=0), subType=IntegerParser(super=Parser(lines=8, nullLines=0), minValue=13828, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@638b6ea7)
INFO  [2023-01-26 18:10:22,878] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:22,878] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:22,878] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:22,895] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1
INFO  [2023-01-26 18:10:22,896] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:10:22 +0000] "POST /admin/datasets/SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY+Test%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:10:22,897] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:22,897] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:22,897] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:22,899] com.bakdata.conquery.models.jobs.ImportJob: Start sending 3 Buckets
INFO  [2023-01-26 18:10:22,899] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1.table1], containing 8 entries.
INFO  [2023-01-26 18:10:22,899] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1.table1], containing 8 entries.
WARN  [2023-01-26 18:10:22,900] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:22,900] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1.table1.0
INFO  [2023-01-26 18:10:22,900] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1.table1.1
INFO  [2023-01-26 18:10:22,900] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.table1.table1.2
INFO  [2023-01-26 18:10:23,005] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:23,011] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:23,022] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:23,022] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:23,022] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:23,129] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test QUERY INIT
INFO  [2023-01-26 18:10:23,140] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:23,140] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[2d6a641e-2f51-4d91-b5ff-1eba1c7a2873] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test))]]
INFO  [2023-01-26 18:10:23,144] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.2d6a641e-2f51-4d91-b5ff-1eba1c7a2873
INFO  [2023-01-26 18:10:23,144] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.2d6a641e-2f51-4d91-b5ff-1eba1c7a2873
127.0.0.1 - - [26/Jan/2023:18:10:23 +0000] "POST /api/datasets/SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test/queries HTTP/1.1" 201 1632 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:10:23,186] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.2d6a641e-2f51-4d91-b5ff-1eba1c7a2873] with 3 results within PT0.042289S
INFO  [2023-01-26 18:10:23,187] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.2d6a641e-2f51-4d91-b5ff-1eba1c7a2873, workerId=SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_8269a34c-af9d-415b-9f91-46c2ffc66030, startTime=2023-01-26T18:10:23.144252, finishTime=2023-01-26T18:10:23.186541) of size 3
INFO  [2023-01-26 18:10:23,194] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.2d6a641e-2f51-4d91-b5ff-1eba1c7a2873] with 4 results within PT0.050163S
INFO  [2023-01-26 18:10:23,194] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.2d6a641e-2f51-4d91-b5ff-1eba1c7a2873, workerId=SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.worker_SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test_3412b802-bb10-49c7-86f0-ecabc86891b3, startTime=2023-01-26T18:10:23.144270, finishTime=2023-01-26T18:10:23.194433) of size 4
INFO  [2023-01-26 18:10:23,195] com.bakdata.conquery.models.execution.ManagedExecution: DONE 2d6a641e-2f51-4d91-b5ff-1eba1c7a2873 ManagedQuery within PT0.054046S
127.0.0.1 - - [26/Jan/2023:18:10:23 +0000] "GET /api/datasets/SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test/queries/SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.2d6a641e-2f51-4d91-b5ff-1eba1c7a2873 HTTP/1.1" 200 2076 "-" "Conquery (test client)" 42
INFO  [2023-01-26 18:10:23,205] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test], queryId=2d6a641e-2f51-4d91-b5ff-1eba1c7a2873, label=Geschlecht-SELECT	@§$, creationTime=2023-01-26T18:10:23.140832, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@7768ab7b[Count = 0], startTime=2023-01-26T18:10:23.140998, finishTime=2023-01-26T18:10:23.195044, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@884316d), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=7, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@5e2d70e7, com.bakdata.conquery.models.query.ColumnDescriptor@1e46847a]) download on dataset Dataset[label=null, name=SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:23,205] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test], queryId=2d6a641e-2f51-4d91-b5ff-1eba1c7a2873, label=Geschlecht-SELECT	@§$, creationTime=2023-01-26T18:10:23.140832, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@7768ab7b[Count = 0], startTime=2023-01-26T18:10:23.140998, finishTime=2023-01-26T18:10:23.195044, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@884316d), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=7, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@5e2d70e7, com.bakdata.conquery.models.query.ColumnDescriptor@1e46847a]) on dataset Dataset[label=null, name=SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test]
127.0.0.1 - - [26/Jan/2023:18:10:23 +0000] "GET /api/datasets/SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY%20Test/result/SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test.2d6a641e-2f51-4d91-b5ff-1eba1c7a2873.csv?pretty=false HTTP/1.1" 200 48 "-" "Conquery (test client)" 21
INFO  [2023-01-26 18:10:23,225] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test on 8 rows
INFO  [2023-01-26 18:10:23,225] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test
INFO  [2023-01-26 18:10:23,226] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test, name=SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:10:23,226] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test, name=SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:10:23,226] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test_8269a34c-af9d-415b-9f91-46c2ffc66030
INFO  [2023-01-26 18:10:23,226] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test_3412b802-bb10-49c7-86f0-ecabc86891b3
INFO  [2023-01-26 18:10:23,304] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test
INFO  [2023-01-26 18:10:23,324] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test_8269a34c-af9d-415b-9f91-46c2ffc66030
INFO  [2023-01-26 18:10:23,324] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test_3412b802-bb10-49c7-86f0-ecabc86891b3
INFO  [2023-01-26 18:10:23,401] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY$20Test
INFO  [2023-01-26 18:10:23,401] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:23,530] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test SINGLE_SELECT_NEGATION_DATE_RESTRICTION_OR_CONCEPT_QUERY Test
INFO  [2023-01-26 18:10:23,530] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test SUM_EMPTY_DATE_CONCEPT_QUERY Test
INFO  [2023-01-26 18:10:23,531] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:23,531] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:23,531] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SUM_EMPTY_DATE_CONCEPT_QUERY Test, name=SUM_EMPTY_DATE_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:10:23,531] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SUM_EMPTY_DATE_CONCEPT_QUERY Test, name=SUM_EMPTY_DATE_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:10:23,531] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:23,531] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:23,536] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.worker_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test_dde5d3ad-5114-41c9-bfae-500d7d8b75c4 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:23,536] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.worker_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test_dde5d3ad-5114-41c9-bfae-500d7d8b75c4 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:23,536] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:23,536] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.worker_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test_003152d3-edb1-4a3a-ab03-3d2031843924 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:23,536] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.worker_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test_003152d3-edb1-4a3a-ab03-3d2031843924 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:23,536] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:23,537] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:23,641] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:23,648] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:23,648] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.table1
INFO  [2023-01-26 18:10:23,648] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.table1
INFO  [2023-01-26 18:10:23,761] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:23,869] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:23,870] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:23,870] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 197 B in total
INFO  [2023-01-26 18:10:23,870] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SUM_EMPTY_DATE_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.00030741sINFO  [2023-01-26 18:10:23,901] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=6, sum=13, min=2, average=2.166667, max=3}
INFO  [2023-01-26 18:10:23,901] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=13, nullLines=4), subType=IntegerParser(super=Parser(lines=13, nullLines=4), minValue=14246, maxValue=14642), dateReader=com.bakdata.conquery.util.DateReader@6e623931)
INFO  [2023-01-26 18:10:23,901] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with RealParser(super=Parser(lines=13, nullLines=0), requiredPrecision=4.9E-324, floatULP=1.1920928955078125E-7)
INFO  [2023-01-26 18:10:23,904] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SUM_EMPTY_DATE_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:23,904] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:23,904] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SUM_EMPTY_DATE_CONCEPT_QUERY Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:23,924] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.table1
127.0.0.1 - - [26/Jan/2023:18:10:23 +0000] "POST /admin/datasets/SUM_EMPTY_DATE_CONCEPT_QUERY%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_SUM_EMPTY_DATE_CONCEPT_QUERY+Test%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 11
INFO  [2023-01-26 18:10:23,925] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:23,926] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:23,926] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:23,926] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:23,928] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:23,928] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.table1.table1], containing 13 entries.
INFO  [2023-01-26 18:10:23,928] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.table1.table1], containing 13 entries.
WARN  [2023-01-26 18:10:23,929] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:23,929] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.table1.table1.0
INFO  [2023-01-26 18:10:23,929] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.table1.table1.1
INFO  [2023-01-26 18:10:24,034] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:24,039] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:24,050] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:24,050] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:24,051] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:24,156] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: SUM_EMPTY_DATE_CONCEPT_QUERY Test QUERY INIT
INFO  [2023-01-26 18:10:24,166] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[SUM_EMPTY_DATE_CONCEPT_QUERY$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:24,166] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[b0e099d1-6e0c-41ed-b915-546a9feb8cba] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_SUM_EMPTY_DATE_CONCEPT_QUERY Test))]]
INFO  [2023-01-26 18:10:24,170] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.b0e099d1-6e0c-41ed-b915-546a9feb8cba
INFO  [2023-01-26 18:10:24,170] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.b0e099d1-6e0c-41ed-b915-546a9feb8cba
INFO  [2023-01-26 18:10:24,170] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.b0e099d1-6e0c-41ed-b915-546a9feb8cba] with 1 results within PT0.00074S
127.0.0.1 - - [26/Jan/2023:18:10:24 +0000] "POST /api/datasets/SUM_EMPTY_DATE_CONCEPT_QUERY$20Test/queries HTTP/1.1" 201 1407 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:10:24,171] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.b0e099d1-6e0c-41ed-b915-546a9feb8cba] with 1 results within PT0.000792S
INFO  [2023-01-26 18:10:24,171] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.b0e099d1-6e0c-41ed-b915-546a9feb8cba, workerId=SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.worker_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test_dde5d3ad-5114-41c9-bfae-500d7d8b75c4, startTime=2023-01-26T18:10:24.170189, finishTime=2023-01-26T18:10:24.170929) of size 1
INFO  [2023-01-26 18:10:24,171] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.b0e099d1-6e0c-41ed-b915-546a9feb8cba, workerId=SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.worker_SUM_EMPTY_DATE_CONCEPT_QUERY$20Test_003152d3-edb1-4a3a-ab03-3d2031843924, startTime=2023-01-26T18:10:24.170289, finishTime=2023-01-26T18:10:24.171081) of size 1
INFO  [2023-01-26 18:10:24,171] com.bakdata.conquery.models.execution.ManagedExecution: DONE b0e099d1-6e0c-41ed-b915-546a9feb8cba ManagedQuery within PT0.00473S
127.0.0.1 - - [26/Jan/2023:18:10:24 +0000] "GET /api/datasets/SUM_EMPTY_DATE_CONCEPT_QUERY$20Test/queries/SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.b0e099d1-6e0c-41ed-b915-546a9feb8cba HTTP/1.1" 200 1738 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:10:24,191] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SUM_EMPTY_DATE_CONCEPT_QUERY Test], queryId=b0e099d1-6e0c-41ed-b915-546a9feb8cba, label=vs	@§$, creationTime=2023-01-26T18:10:24.166837, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@70e67d96[Count = 0], startTime=2023-01-26T18:10:24.166971, finishTime=2023-01-26T18:10:24.171701, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@22c50c10), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SUM_EMPTY_DATE_CONCEPT_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@6932a10a, com.bakdata.conquery.models.query.ColumnDescriptor@198e671c]) download on dataset Dataset[label=null, name=SUM_EMPTY_DATE_CONCEPT_QUERY Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:24,191] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SUM_EMPTY_DATE_CONCEPT_QUERY Test], queryId=b0e099d1-6e0c-41ed-b915-546a9feb8cba, label=vs	@§$, creationTime=2023-01-26T18:10:24.166837, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@70e67d96[Count = 0], startTime=2023-01-26T18:10:24.166971, finishTime=2023-01-26T18:10:24.171701, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@22c50c10), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SUM_EMPTY_DATE_CONCEPT_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@6932a10a, com.bakdata.conquery.models.query.ColumnDescriptor@198e671c]) on dataset Dataset[label=null, name=SUM_EMPTY_DATE_CONCEPT_QUERY Test]
127.0.0.1 - - [26/Jan/2023:18:10:24 +0000] "GET /api/datasets/SUM_EMPTY_DATE_CONCEPT_QUERY%20Test/result/SUM_EMPTY_DATE_CONCEPT_QUERY$20Test.b0e099d1-6e0c-41ed-b915-546a9feb8cba.csv?pretty=false HTTP/1.1" 200 114 "-" "Conquery (test client)" 27
INFO  [2023-01-26 18:10:24,217] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest SUM_EMPTY_DATE_CONCEPT_QUERY Test on 3 rows
INFO  [2023-01-26 18:10:24,217] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast SUM_EMPTY_DATE_CONCEPT_QUERY Test
INFO  [2023-01-26 18:10:24,217] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SUM_EMPTY_DATE_CONCEPT_QUERY Test, name=SUM_EMPTY_DATE_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:10:24,217] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SUM_EMPTY_DATE_CONCEPT_QUERY Test, name=SUM_EMPTY_DATE_CONCEPT_QUERY Test]
INFO  [2023-01-26 18:10:24,218] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SUM_EMPTY_DATE_CONCEPT_QUERY Test_003152d3-edb1-4a3a-ab03-3d2031843924
INFO  [2023-01-26 18:10:24,218] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SUM_EMPTY_DATE_CONCEPT_QUERY Test_dde5d3ad-5114-41c9-bfae-500d7d8b75c4
INFO  [2023-01-26 18:10:24,232] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow SUM_EMPTY_DATE_CONCEPT_QUERY Test
INFO  [2023-01-26 18:10:24,236] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SUM_EMPTY_DATE_CONCEPT_QUERY Test_dde5d3ad-5114-41c9-bfae-500d7d8b75c4
INFO  [2023-01-26 18:10:24,236] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SUM_EMPTY_DATE_CONCEPT_QUERY Test_003152d3-edb1-4a3a-ab03-3d2031843924
INFO  [2023-01-26 18:10:24,329] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of SUM_EMPTY_DATE_CONCEPT_QUERY$20Test
INFO  [2023-01-26 18:10:24,329] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:24,356] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test SUM_EMPTY_DATE_CONCEPT_QUERY Test
INFO  [2023-01-26 18:10:24,356] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test TABLE_EXPORT Test
INFO  [2023-01-26 18:10:24,356] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:24,356] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:24,357] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=TABLE_EXPORT Test, name=TABLE_EXPORT Test]
INFO  [2023-01-26 18:10:24,357] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:24,357] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=TABLE_EXPORT Test, name=TABLE_EXPORT Test]
INFO  [2023-01-26 18:10:24,357] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:24,359] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker TABLE_EXPORT$20Test.worker_TABLE_EXPORT$20Test_1bb0882d-b80b-44f4-b55a-a1cc4898369f are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:24,359] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker TABLE_EXPORT$20Test.worker_TABLE_EXPORT$20Test_1bb0882d-b80b-44f4-b55a-a1cc4898369f are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:24,359] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:24,359] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker TABLE_EXPORT$20Test.worker_TABLE_EXPORT$20Test_6028dedd-0734-4432-8676-2b7ad28ad72f are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:24,359] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker TABLE_EXPORT$20Test.worker_TABLE_EXPORT$20Test_6028dedd-0734-4432-8676-2b7ad28ad72f are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:24,359] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:24,363] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:24,462] com.bakdata.conquery.resources.admin.rest.AdminDatasetProcessor: Received new SecondaryId[TABLE_EXPORT$20Test.sid]
INFO  [2023-01-26 18:10:24,463] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:24,464] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId TABLE_EXPORT$20Test.sid
INFO  [2023-01-26 18:10:24,464] com.bakdata.conquery.models.messages.namespaces.specific.UpdateSecondaryId: Received update of SecondaryId TABLE_EXPORT$20Test.sid
INFO  [2023-01-26 18:10:24,571] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:24,571] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table TABLE_EXPORT$20Test.table1
INFO  [2023-01-26 18:10:24,571] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table TABLE_EXPORT$20Test.table2
INFO  [2023-01-26 18:10:24,571] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table TABLE_EXPORT$20Test.table1
INFO  [2023-01-26 18:10:24,571] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table TABLE_EXPORT$20Test.table2
INFO  [2023-01-26 18:10:24,684] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:24,792] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:24,792] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:24,792] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:24,793] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 433 B in total
INFO  [2023-01-26 18:10:24,793] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_TABLE_EXPORT Test/table1.import.json, tag=Optional.empty)
████████████████████████▌                         ▌  49%	est. time remaining: 0.020954391sINFO  [2023-01-26 18:10:24,813] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=2, sum=6, min=1, average=3.000000, max=5}
INFO  [2023-01-26 18:10:24,813] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with RealParser(super=Parser(lines=6, nullLines=0), requiredPrecision=4.9E-324, floatULP=1.1920928955078125E-7)
INFO  [2023-01-26 18:10:24,813] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[sid] with StringParser(super=Parser(lines=6, nullLines=1), encoding=null, prefix=f_, suffix=)
INFO  [2023-01-26 18:10:24,813] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=6, nullLines=0), minParser=DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=14790, maxValue=16982), dateReader=com.bakdata.conquery.util.DateReader@70cc8854), maxParser=DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=14790, maxValue=16982), dateReader=com.bakdata.conquery.util.DateReader@23fa772), dateReader=com.bakdata.conquery.util.DateReader@124400ea, onlyQuarters=false, maxValue=16982, minValue=14790, anyOpen=false)
INFO  [2023-01-26 18:10:24,816] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_TABLE_EXPORT Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:24,816] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_TABLE_EXPORT Test/table2.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000415671sINFO  [2023-01-26 18:10:24,835] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=2, sum=6, min=1, average=3.000000, max=5}
INFO  [2023-01-26 18:10:24,835] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[sid] with StringParser(super=Parser(lines=6, nullLines=1), encoding=null, prefix=f_, suffix=)
INFO  [2023-01-26 18:10:24,835] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with RealParser(super=Parser(lines=6, nullLines=0), requiredPrecision=4.9E-324, floatULP=9.5367431640625E-7)
INFO  [2023-01-26 18:10:24,835] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=6, nullLines=0), minParser=DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=18443, maxValue=20634), dateReader=com.bakdata.conquery.util.DateReader@24926612), maxParser=DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=18443, maxValue=20634), dateReader=com.bakdata.conquery.util.DateReader@3008c4fc), dateReader=com.bakdata.conquery.util.DateReader@4f73f1b8, onlyQuarters=false, maxValue=20634, minValue=18443, anyOpen=false)
INFO  [2023-01-26 18:10:24,838] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_TABLE_EXPORT Test/table2.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:24,838] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 2 Jobs:
INFO  [2023-01-26 18:10:24,838] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_TABLE_EXPORT Test/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:24,838] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_TABLE_EXPORT Test/table2.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:24,858] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into TABLE_EXPORT$20Test.table1
INFO  [2023-01-26 18:10:24,859] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
127.0.0.1 - - [26/Jan/2023:18:10:24 +0000] "POST /admin/datasets/TABLE_EXPORT%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_TABLE_EXPORT+Test%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:10:24,860] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:24,860] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:24,861] com.bakdata.conquery.models.jobs.ImportJob: Start sending 1 Buckets
INFO  [2023-01-26 18:10:24,861] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[TABLE_EXPORT$20Test.table1.table1], containing 6 entries.
INFO  [2023-01-26 18:10:24,861] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[TABLE_EXPORT$20Test.table1.table1], containing 6 entries.
WARN  [2023-01-26 18:10:24,862] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:24,862] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received TABLE_EXPORT$20Test.table1.table1.0
INFO  [2023-01-26 18:10:24,873] com.bakdata.conquery.models.jobs.ImportJob: Importing table2 into TABLE_EXPORT$20Test.table2
INFO  [2023-01-26 18:10:24,873] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:24,873] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:24,873] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:24,873] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:10:24 +0000] "POST /admin/datasets/TABLE_EXPORT%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_TABLE_EXPORT+Test%2Ftable2.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:10:24,874] com.bakdata.conquery.models.jobs.ImportJob: Start sending 1 Buckets
WARN  [2023-01-26 18:10:24,874] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:24,874] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[TABLE_EXPORT$20Test.table2.table2], containing 6 entries.
INFO  [2023-01-26 18:10:24,874] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[TABLE_EXPORT$20Test.table2.table2], containing 6 entries.
INFO  [2023-01-26 18:10:24,874] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received TABLE_EXPORT$20Test.table2.table2.0
INFO  [2023-01-26 18:10:24,979] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:24,984] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:24,997] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:24,997] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:25,104] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: TABLE_EXPORT Test QUERY INIT
INFO  [2023-01-26 18:10:25,117] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[TABLE_EXPORT$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:25,117] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[0b10ecb8-7f88-4959-9f93-2aca1c9c9276] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_TABLE_EXPORT Test))]]
INFO  [2023-01-26 18:10:25,121] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started TableExportQuery TABLE_EXPORT$20Test.0b10ecb8-7f88-4959-9f93-2aca1c9c9276
INFO  [2023-01-26 18:10:25,121] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started TableExportQuery TABLE_EXPORT$20Test.0b10ecb8-7f88-4959-9f93-2aca1c9c9276
WARN  [2023-01-26 18:10:25,121] com.bakdata.conquery.models.query.QueryExecutor: Entities for query are empty
INFO  [2023-01-26 18:10:25,121] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[TABLE_EXPORT$20Test.0b10ecb8-7f88-4959-9f93-2aca1c9c9276] with 0 results within PT0.000134S
INFO  [2023-01-26 18:10:25,121] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=TABLE_EXPORT$20Test.0b10ecb8-7f88-4959-9f93-2aca1c9c9276, workerId=TABLE_EXPORT$20Test.worker_TABLE_EXPORT$20Test_1bb0882d-b80b-44f4-b55a-a1cc4898369f, startTime=2023-01-26T18:10:25.121187, finishTime=2023-01-26T18:10:25.121321) of size 0
127.0.0.1 - - [26/Jan/2023:18:10:25 +0000] "POST /api/datasets/TABLE_EXPORT$20Test/queries HTTP/1.1" 201 2075 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:10:25,122] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[TABLE_EXPORT$20Test.0b10ecb8-7f88-4959-9f93-2aca1c9c9276] with 2 results within PT0.001159S
INFO  [2023-01-26 18:10:25,123] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=TABLE_EXPORT$20Test.0b10ecb8-7f88-4959-9f93-2aca1c9c9276, workerId=TABLE_EXPORT$20Test.worker_TABLE_EXPORT$20Test_6028dedd-0734-4432-8676-2b7ad28ad72f, startTime=2023-01-26T18:10:25.121121, finishTime=2023-01-26T18:10:25.122280) of size 2
INFO  [2023-01-26 18:10:25,123] com.bakdata.conquery.models.execution.ManagedExecution: DONE 0b10ecb8-7f88-4959-9f93-2aca1c9c9276 ManagedQuery within PT0.005888S
127.0.0.1 - - [26/Jan/2023:18:10:25 +0000] "GET /api/datasets/TABLE_EXPORT$20Test/queries/TABLE_EXPORT$20Test.0b10ecb8-7f88-4959-9f93-2aca1c9c9276 HTTP/1.1" 200 2342 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:10:25,142] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=TABLE_EXPORT Test], queryId=0b10ecb8-7f88-4959-9f93-2aca1c9c9276, label=concept	@§$, creationTime=2023-01-26T18:10:25.117523, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@197de134[Count = 0], startTime=2023-01-26T18:10:25.117714, finishTime=2023-01-26T18:10:25.123602, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@674003b), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_TABLE_EXPORT Test)), query=com.bakdata.conquery.apiv1.query.TableExportQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@2486614b, com.bakdata.conquery.models.query.ColumnDescriptor@2dc72d91, com.bakdata.conquery.models.query.ColumnDescriptor@5bc51d5c, com.bakdata.conquery.models.query.ColumnDescriptor@7d16bbc7, com.bakdata.conquery.models.query.ColumnDescriptor@6a8d1117]) download on dataset Dataset[label=null, name=TABLE_EXPORT Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:25,142] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=TABLE_EXPORT Test], queryId=0b10ecb8-7f88-4959-9f93-2aca1c9c9276, label=concept	@§$, creationTime=2023-01-26T18:10:25.117523, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@197de134[Count = 0], startTime=2023-01-26T18:10:25.117714, finishTime=2023-01-26T18:10:25.123602, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@674003b), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_TABLE_EXPORT Test)), query=com.bakdata.conquery.apiv1.query.TableExportQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@2486614b, com.bakdata.conquery.models.query.ColumnDescriptor@2dc72d91, com.bakdata.conquery.models.query.ColumnDescriptor@5bc51d5c, com.bakdata.conquery.models.query.ColumnDescriptor@7d16bbc7, com.bakdata.conquery.models.query.ColumnDescriptor@6a8d1117]) on dataset Dataset[label=null, name=TABLE_EXPORT Test]
127.0.0.1 - - [26/Jan/2023:18:10:25 +0000] "GET /api/datasets/TABLE_EXPORT%20Test/result/TABLE_EXPORT$20Test.0b10ecb8-7f88-4959-9f93-2aca1c9c9276.csv?pretty=false HTTP/1.1" 200 301 "-" "Conquery (test client)" 30
INFO  [2023-01-26 18:10:25,171] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest TABLE_EXPORT Test on 8 rows
INFO  [2023-01-26 18:10:25,171] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast TABLE_EXPORT Test
INFO  [2023-01-26 18:10:25,171] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=TABLE_EXPORT Test, name=TABLE_EXPORT Test]
INFO  [2023-01-26 18:10:25,171] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=TABLE_EXPORT Test, name=TABLE_EXPORT Test]
INFO  [2023-01-26 18:10:25,171] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_TABLE_EXPORT Test_1bb0882d-b80b-44f4-b55a-a1cc4898369f
INFO  [2023-01-26 18:10:25,172] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_TABLE_EXPORT Test_6028dedd-0734-4432-8676-2b7ad28ad72f
INFO  [2023-01-26 18:10:25,275] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_TABLE_EXPORT Test_6028dedd-0734-4432-8676-2b7ad28ad72f
INFO  [2023-01-26 18:10:25,275] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow TABLE_EXPORT Test
INFO  [2023-01-26 18:10:25,275] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_TABLE_EXPORT Test_1bb0882d-b80b-44f4-b55a-a1cc4898369f
INFO  [2023-01-26 18:10:25,375] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of TABLE_EXPORT$20Test
INFO  [2023-01-26 18:10:25,375] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:25,404] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test TABLE_EXPORT Test
INFO  [2023-01-26 18:10:25,404] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test Temporal Before (with Aggregation)
INFO  [2023-01-26 18:10:25,404] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:25,404] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:25,405] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=Temporal Before (with Aggregation), name=Temporal Before (with Aggregation)]
INFO  [2023-01-26 18:10:25,405] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=Temporal Before (with Aggregation), name=Temporal Before (with Aggregation)]
INFO  [2023-01-26 18:10:25,405] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:25,405] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:25,407] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker Temporal$20Before$20(with$20Aggregation).worker_Temporal$20Before$20(with$20Aggregation)_7a8cb1e1-94a9-4ddd-90bf-d8268bb42425 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:25,407] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker Temporal$20Before$20(with$20Aggregation).worker_Temporal$20Before$20(with$20Aggregation)_7a8cb1e1-94a9-4ddd-90bf-d8268bb42425 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:25,407] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:25,407] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker Temporal$20Before$20(with$20Aggregation).worker_Temporal$20Before$20(with$20Aggregation)_88959116-0d54-4b25-ad91-5eff50cd409b are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:25,407] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker Temporal$20Before$20(with$20Aggregation).worker_Temporal$20Before$20(with$20Aggregation)_88959116-0d54-4b25-ad91-5eff50cd409b are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:25,407] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:25,411] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:25,511] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:25,518] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:25,518] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table Temporal$20Before$20(with$20Aggregation).table
INFO  [2023-01-26 18:10:25,518] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table Temporal$20Before$20(with$20Aggregation).table
INFO  [2023-01-26 18:10:25,638] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:25,749] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:25,750] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:25,750] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 153 B in total
INFO  [2023-01-26 18:10:25,750] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_Temporal Before (with Aggregation)/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000420679sINFO  [2023-01-26 18:10:25,792] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=8, min=2, average=2.000000, max=2}
INFO  [2023-01-26 18:10:25,792] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with StringParser(super=Parser(lines=8, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:25,793] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=8, nullLines=0), subType=IntegerParser(super=Parser(lines=8, nullLines=0), minValue=14975, maxValue=14980), dateReader=com.bakdata.conquery.util.DateReader@4ab6f730)
INFO  [2023-01-26 18:10:25,795] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_Temporal Before (with Aggregation)/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:25,795] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:25,795] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_Temporal Before (with Aggregation)/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:25,808] com.bakdata.conquery.models.jobs.ImportJob: Importing table into Temporal$20Before$20(with$20Aggregation).table
127.0.0.1 - - [26/Jan/2023:18:10:25 +0000] "POST /admin/datasets/Temporal%20Before%20(with%20Aggregation)/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_Temporal+Before+%28with+Aggregation%29%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:10:25,808] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:25,809] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:25,810] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:25,810] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:25,812] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:25,812] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[Temporal$20Before$20(with$20Aggregation).table.table], containing 8 entries.
INFO  [2023-01-26 18:10:25,812] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[Temporal$20Before$20(with$20Aggregation).table.table], containing 8 entries.
WARN  [2023-01-26 18:10:25,813] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:25,813] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received Temporal$20Before$20(with$20Aggregation).table.table.0
INFO  [2023-01-26 18:10:25,813] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received Temporal$20Before$20(with$20Aggregation).table.table.1
INFO  [2023-01-26 18:10:25,918] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:25,923] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:25,936] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:25,936] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:25,936] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:26,041] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: Temporal Before (with Aggregation) QUERY INIT
INFO  [2023-01-26 18:10:26,054] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[Temporal$20Before$20(with$20Aggregation)] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:26,054] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[9264c95e-ecc3-4859-92a5-77f5a9060f28] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_Temporal Before (with Aggregation)))]]
INFO  [2023-01-26 18:10:26,075] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery Temporal$20Before$20(with$20Aggregation).9264c95e-ecc3-4859-92a5-77f5a9060f28
INFO  [2023-01-26 18:10:26,075] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery Temporal$20Before$20(with$20Aggregation).9264c95e-ecc3-4859-92a5-77f5a9060f28
INFO  [2023-01-26 18:10:26,084] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[Temporal$20Before$20(with$20Aggregation).9264c95e-ecc3-4859-92a5-77f5a9060f28] with 0 results within PT0.008495S
INFO  [2023-01-26 18:10:26,084] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=Temporal$20Before$20(with$20Aggregation).9264c95e-ecc3-4859-92a5-77f5a9060f28, workerId=Temporal$20Before$20(with$20Aggregation).worker_Temporal$20Before$20(with$20Aggregation)_88959116-0d54-4b25-ad91-5eff50cd409b, startTime=2023-01-26T18:10:26.075670, finishTime=2023-01-26T18:10:26.084165) of size 0
127.0.0.1 - - [26/Jan/2023:18:10:26 +0000] "POST /api/datasets/Temporal$20Before$20(with$20Aggregation)/queries HTTP/1.1" 201 2259 "-" "Conquery (test client)" 32
INFO  [2023-01-26 18:10:26,092] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[Temporal$20Before$20(with$20Aggregation).9264c95e-ecc3-4859-92a5-77f5a9060f28] with 1 results within PT0.016008S
INFO  [2023-01-26 18:10:26,092] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=Temporal$20Before$20(with$20Aggregation).9264c95e-ecc3-4859-92a5-77f5a9060f28, workerId=Temporal$20Before$20(with$20Aggregation).worker_Temporal$20Before$20(with$20Aggregation)_7a8cb1e1-94a9-4ddd-90bf-d8268bb42425, startTime=2023-01-26T18:10:26.075981, finishTime=2023-01-26T18:10:26.091989) of size 1
INFO  [2023-01-26 18:10:26,092] com.bakdata.conquery.models.execution.ManagedExecution: DONE 9264c95e-ecc3-4859-92a5-77f5a9060f28 ManagedQuery within PT0.03764S
127.0.0.1 - - [26/Jan/2023:18:10:26 +0000] "GET /api/datasets/Temporal$20Before$20(with$20Aggregation)/queries/Temporal$20Before$20(with$20Aggregation).9264c95e-ecc3-4859-92a5-77f5a9060f28 HTTP/1.1" 200 2611 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:10:26,103] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=Temporal Before (with Aggregation)], queryId=9264c95e-ecc3-4859-92a5-77f5a9060f28, label=concept	@§$, creationTime=2023-01-26T18:10:26.054773, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@1d2ac107[Count = 0], startTime=2023-01-26T18:10:26.054919, finishTime=2023-01-26T18:10:26.092559, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@41626268), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_Temporal Before (with Aggregation))), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@75aa17e5, com.bakdata.conquery.models.query.ColumnDescriptor@706ad9dc, com.bakdata.conquery.models.query.ColumnDescriptor@3b030c2f, com.bakdata.conquery.models.query.ColumnDescriptor@69205805]) download on dataset Dataset[label=null, name=Temporal Before (with Aggregation)] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:26,103] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=Temporal Before (with Aggregation)], queryId=9264c95e-ecc3-4859-92a5-77f5a9060f28, label=concept	@§$, creationTime=2023-01-26T18:10:26.054773, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@1d2ac107[Count = 0], startTime=2023-01-26T18:10:26.054919, finishTime=2023-01-26T18:10:26.092559, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@41626268), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_Temporal Before (with Aggregation))), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@75aa17e5, com.bakdata.conquery.models.query.ColumnDescriptor@706ad9dc, com.bakdata.conquery.models.query.ColumnDescriptor@3b030c2f, com.bakdata.conquery.models.query.ColumnDescriptor@69205805]) on dataset Dataset[label=null, name=Temporal Before (with Aggregation)]
127.0.0.1 - - [26/Jan/2023:18:10:26 +0000] "GET /api/datasets/Temporal%20Before%20(with%20Aggregation)/result/Temporal$20Before$20(with$20Aggregation).9264c95e-ecc3-4859-92a5-77f5a9060f28.csv?pretty=false HTTP/1.1" 200 77 "-" "Conquery (test client)" 33
INFO  [2023-01-26 18:10:26,135] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest Temporal Before (with Aggregation) on 2 rows
INFO  [2023-01-26 18:10:26,135] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast Temporal Before (with Aggregation)
INFO  [2023-01-26 18:10:26,136] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=Temporal Before (with Aggregation), name=Temporal Before (with Aggregation)]
INFO  [2023-01-26 18:10:26,136] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=Temporal Before (with Aggregation), name=Temporal Before (with Aggregation)]
INFO  [2023-01-26 18:10:26,136] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_Temporal Before (with Aggregation)_88959116-0d54-4b25-ad91-5eff50cd409b
INFO  [2023-01-26 18:10:26,136] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_Temporal Before (with Aggregation)_7a8cb1e1-94a9-4ddd-90bf-d8268bb42425
INFO  [2023-01-26 18:10:26,238] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow Temporal Before (with Aggregation)
INFO  [2023-01-26 18:10:26,238] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_Temporal Before (with Aggregation)_7a8cb1e1-94a9-4ddd-90bf-d8268bb42425
INFO  [2023-01-26 18:10:26,238] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_Temporal Before (with Aggregation)_88959116-0d54-4b25-ad91-5eff50cd409b
INFO  [2023-01-26 18:10:26,338] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of Temporal$20Before$20(with$20Aggregation)
INFO  [2023-01-26 18:10:26,338] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:26,442] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test Temporal Before (with Aggregation)
INFO  [2023-01-26 18:10:26,443] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test Temporal Before
INFO  [2023-01-26 18:10:26,443] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:26,443] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:26,443] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=Temporal Before, name=Temporal Before]
INFO  [2023-01-26 18:10:26,443] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=Temporal Before, name=Temporal Before]
INFO  [2023-01-26 18:10:26,444] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:26,444] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:26,445] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker Temporal$20Before.worker_Temporal$20Before_95e93ea3-82ed-42af-b674-8d516b5d3aeb are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:26,445] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker Temporal$20Before.worker_Temporal$20Before_95e93ea3-82ed-42af-b674-8d516b5d3aeb are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:26,445] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:26,445] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker Temporal$20Before.worker_Temporal$20Before_c6734cde-bddc-4db1-949a-0ada47121281 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:26,445] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker Temporal$20Before.worker_Temporal$20Before_c6734cde-bddc-4db1-949a-0ada47121281 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:26,445] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:26,449] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:26,549] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:26,555] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:26,556] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table Temporal$20Before.table
INFO  [2023-01-26 18:10:26,556] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table Temporal$20Before.table
INFO  [2023-01-26 18:10:26,667] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:26,775] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:26,775] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:26,775] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 153 B in total
INFO  [2023-01-26 18:10:26,775] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_Temporal Before/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000318255sINFO  [2023-01-26 18:10:26,808] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=8, min=2, average=2.000000, max=2}
INFO  [2023-01-26 18:10:26,808] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with StringParser(super=Parser(lines=8, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:26,808] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=8, nullLines=0), subType=IntegerParser(super=Parser(lines=8, nullLines=0), minValue=14975, maxValue=14980), dateReader=com.bakdata.conquery.util.DateReader@42e1be54)
INFO  [2023-01-26 18:10:26,811] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_Temporal Before/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:26,811] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:26,811] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_Temporal Before/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:26,825] com.bakdata.conquery.models.jobs.ImportJob: Importing table into Temporal$20Before.table
127.0.0.1 - - [26/Jan/2023:18:10:26 +0000] "POST /admin/datasets/Temporal%20Before/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_Temporal+Before%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:10:26,825] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:26,826] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:26,826] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:26,826] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:26,828] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:26,828] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[Temporal$20Before.table.table], containing 8 entries.
INFO  [2023-01-26 18:10:26,828] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[Temporal$20Before.table.table], containing 8 entries.
WARN  [2023-01-26 18:10:26,829] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:26,829] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received Temporal$20Before.table.table.0
INFO  [2023-01-26 18:10:26,829] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received Temporal$20Before.table.table.1
INFO  [2023-01-26 18:10:26,934] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:26,940] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:26,949] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:26,950] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:26,950] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:27,055] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: Temporal Before QUERY INIT
INFO  [2023-01-26 18:10:27,067] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[Temporal$20Before] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:27,068] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[d8bac5d0-b498-44d6-96f3-93de9ffe04f7] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_Temporal Before))]]
INFO  [2023-01-26 18:10:27,070] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery Temporal$20Before.d8bac5d0-b498-44d6-96f3-93de9ffe04f7
INFO  [2023-01-26 18:10:27,070] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery Temporal$20Before.d8bac5d0-b498-44d6-96f3-93de9ffe04f7
127.0.0.1 - - [26/Jan/2023:18:10:27 +0000] "POST /api/datasets/Temporal$20Before/queries HTTP/1.1" 201 1604 "-" "Conquery (test client)" 4
INFO  [2023-01-26 18:10:27,071] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[Temporal$20Before.d8bac5d0-b498-44d6-96f3-93de9ffe04f7] with 0 results within PT0.00077S
INFO  [2023-01-26 18:10:27,071] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=Temporal$20Before.d8bac5d0-b498-44d6-96f3-93de9ffe04f7, workerId=Temporal$20Before.worker_Temporal$20Before_95e93ea3-82ed-42af-b674-8d516b5d3aeb, startTime=2023-01-26T18:10:27.070255, finishTime=2023-01-26T18:10:27.071025) of size 0
INFO  [2023-01-26 18:10:27,071] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[Temporal$20Before.d8bac5d0-b498-44d6-96f3-93de9ffe04f7] with 1 results within PT0.001449S
INFO  [2023-01-26 18:10:27,072] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=Temporal$20Before.d8bac5d0-b498-44d6-96f3-93de9ffe04f7, workerId=Temporal$20Before.worker_Temporal$20Before_c6734cde-bddc-4db1-949a-0ada47121281, startTime=2023-01-26T18:10:27.070184, finishTime=2023-01-26T18:10:27.071633) of size 1
INFO  [2023-01-26 18:10:27,072] com.bakdata.conquery.models.execution.ManagedExecution: DONE d8bac5d0-b498-44d6-96f3-93de9ffe04f7 ManagedQuery within PT0.004077S
127.0.0.1 - - [26/Jan/2023:18:10:27 +0000] "GET /api/datasets/Temporal$20Before/queries/Temporal$20Before.d8bac5d0-b498-44d6-96f3-93de9ffe04f7 HTTP/1.1" 200 1863 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:10:27,096] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=Temporal Before], queryId=d8bac5d0-b498-44d6-96f3-93de9ffe04f7, label=concept	@§$, creationTime=2023-01-26T18:10:27.067946, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@7e6a31c[Count = 0], startTime=2023-01-26T18:10:27.068069, finishTime=2023-01-26T18:10:27.072146, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@55d56f86), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_Temporal Before)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@50f6e511, com.bakdata.conquery.models.query.ColumnDescriptor@5d9d6ad3]) download on dataset Dataset[label=null, name=Temporal Before] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:27,096] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=Temporal Before], queryId=d8bac5d0-b498-44d6-96f3-93de9ffe04f7, label=concept	@§$, creationTime=2023-01-26T18:10:27.067946, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@7e6a31c[Count = 0], startTime=2023-01-26T18:10:27.068069, finishTime=2023-01-26T18:10:27.072146, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@55d56f86), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_Temporal Before)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@50f6e511, com.bakdata.conquery.models.query.ColumnDescriptor@5d9d6ad3]) on dataset Dataset[label=null, name=Temporal Before]
127.0.0.1 - - [26/Jan/2023:18:10:27 +0000] "GET /api/datasets/Temporal%20Before/result/Temporal$20Before.d8bac5d0-b498-44d6-96f3-93de9ffe04f7.csv?pretty=false HTTP/1.1" 200 39 "-" "Conquery (test client)" 14
INFO  [2023-01-26 18:10:27,108] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest Temporal Before on 2 rows
INFO  [2023-01-26 18:10:27,108] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast Temporal Before
INFO  [2023-01-26 18:10:27,108] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=Temporal Before, name=Temporal Before]
INFO  [2023-01-26 18:10:27,108] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=Temporal Before, name=Temporal Before]
INFO  [2023-01-26 18:10:27,108] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_Temporal Before_95e93ea3-82ed-42af-b674-8d516b5d3aeb
INFO  [2023-01-26 18:10:27,108] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_Temporal Before_c6734cde-bddc-4db1-949a-0ada47121281
INFO  [2023-01-26 18:10:27,144] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow Temporal Before
INFO  [2023-01-26 18:10:27,144] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_Temporal Before_95e93ea3-82ed-42af-b674-8d516b5d3aeb
INFO  [2023-01-26 18:10:27,144] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_Temporal Before_c6734cde-bddc-4db1-949a-0ada47121281
INFO  [2023-01-26 18:10:27,230] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of Temporal$20Before
INFO  [2023-01-26 18:10:27,230] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:27,255] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test Temporal Before
INFO  [2023-01-26 18:10:27,255] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test Temporal Before or Same
INFO  [2023-01-26 18:10:27,256] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:27,256] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:27,256] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=Temporal Before or Same, name=Temporal Before or Same]
INFO  [2023-01-26 18:10:27,256] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=Temporal Before or Same, name=Temporal Before or Same]
INFO  [2023-01-26 18:10:27,256] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:27,256] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:27,257] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:27,258] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker Temporal$20Before$20or$20Same.worker_Temporal$20Before$20or$20Same_a75373fa-a283-477e-b3d9-79b2685b333f are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:27,258] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker Temporal$20Before$20or$20Same.worker_Temporal$20Before$20or$20Same_a75373fa-a283-477e-b3d9-79b2685b333f are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:27,258] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:27,258] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker Temporal$20Before$20or$20Same.worker_Temporal$20Before$20or$20Same_8cebf660-27d1-4549-a894-437574d53cc1 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:27,258] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker Temporal$20Before$20or$20Same.worker_Temporal$20Before$20or$20Same_8cebf660-27d1-4549-a894-437574d53cc1 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:27,258] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:27,362] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:27,369] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:27,369] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table Temporal$20Before$20or$20Same.table1
INFO  [2023-01-26 18:10:27,369] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table Temporal$20Before$20or$20Same.table1
INFO  [2023-01-26 18:10:27,482] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:27,591] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:27,591] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:27,591] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 231 B in total
INFO  [2023-01-26 18:10:27,592] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_Temporal Before or Same/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000433959sINFO  [2023-01-26 18:10:27,636] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=5, sum=12, min=2, average=2.400000, max=4}
INFO  [2023-01-26 18:10:27,636] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=12, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:27,636] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=12, nullLines=0), subType=IntegerParser(super=Parser(lines=12, nullLines=0), minValue=14442, maxValue=15655), dateReader=com.bakdata.conquery.util.DateReader@524c34e9)
INFO  [2023-01-26 18:10:27,639] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_Temporal Before or Same/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:27,639] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:27,639] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_Temporal Before or Same/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:27,656] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into Temporal$20Before$20or$20Same.table1
INFO  [2023-01-26 18:10:27,657] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:27,657] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:27,657] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:27,658] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:27,659] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[Temporal$20Before$20or$20Same.table1.table1], containing 12 entries.
INFO  [2023-01-26 18:10:27,659] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[Temporal$20Before$20or$20Same.table1.table1], containing 12 entries.
WARN  [2023-01-26 18:10:27,659] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:27,659] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received Temporal$20Before$20or$20Same.table1.table1.0
127.0.0.1 - - [26/Jan/2023:18:10:27 +0000] "POST /admin/datasets/Temporal%20Before%20or%20Same/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_Temporal+Before+or+Same%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 12
INFO  [2023-01-26 18:10:27,660] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:27,660] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received Temporal$20Before$20or$20Same.table1.table1.1
INFO  [2023-01-26 18:10:27,764] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:27,770] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:27,782] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:27,783] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:27,783] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:27,888] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: Temporal Before or Same QUERY INIT
INFO  [2023-01-26 18:10:27,901] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[Temporal$20Before$20or$20Same] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:27,901] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[0a2538bc-c3b9-4608-9832-6559c7d073f8] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_Temporal Before or Same))]]
INFO  [2023-01-26 18:10:27,904] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery Temporal$20Before$20or$20Same.0a2538bc-c3b9-4608-9832-6559c7d073f8
INFO  [2023-01-26 18:10:27,904] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery Temporal$20Before$20or$20Same.0a2538bc-c3b9-4608-9832-6559c7d073f8
127.0.0.1 - - [26/Jan/2023:18:10:27 +0000] "POST /api/datasets/Temporal$20Before$20or$20Same/queries HTTP/1.1" 201 1848 "-" "Conquery (test client)" 5
INFO  [2023-01-26 18:10:27,906] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[Temporal$20Before$20or$20Same.0a2538bc-c3b9-4608-9832-6559c7d073f8] with 0 results within PT0.002083S
INFO  [2023-01-26 18:10:27,924] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=Temporal$20Before$20or$20Same.0a2538bc-c3b9-4608-9832-6559c7d073f8, workerId=Temporal$20Before$20or$20Same.worker_Temporal$20Before$20or$20Same_8cebf660-27d1-4549-a894-437574d53cc1, startTime=2023-01-26T18:10:27.904276, finishTime=2023-01-26T18:10:27.906359) of size 0
INFO  [2023-01-26 18:10:27,924] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[Temporal$20Before$20or$20Same.0a2538bc-c3b9-4608-9832-6559c7d073f8] with 3 results within PT0.020042S
INFO  [2023-01-26 18:10:27,925] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=Temporal$20Before$20or$20Same.0a2538bc-c3b9-4608-9832-6559c7d073f8, workerId=Temporal$20Before$20or$20Same.worker_Temporal$20Before$20or$20Same_a75373fa-a283-477e-b3d9-79b2685b333f, startTime=2023-01-26T18:10:27.904666, finishTime=2023-01-26T18:10:27.924708) of size 3
INFO  [2023-01-26 18:10:27,925] com.bakdata.conquery.models.execution.ManagedExecution: DONE 0a2538bc-c3b9-4608-9832-6559c7d073f8 ManagedQuery within PT0.023456S
127.0.0.1 - - [26/Jan/2023:18:10:27 +0000] "GET /api/datasets/Temporal$20Before$20or$20Same/queries/Temporal$20Before$20or$20Same.0a2538bc-c3b9-4608-9832-6559c7d073f8 HTTP/1.1" 200 2156 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:10:27,939] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=Temporal Before or Same], queryId=0a2538bc-c3b9-4608-9832-6559c7d073f8, label=Geschlecht-SELECT	@§$, creationTime=2023-01-26T18:10:27.901589, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@5bc5e1dd[Count = 0], startTime=2023-01-26T18:10:27.901736, finishTime=2023-01-26T18:10:27.925192, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2c9ac811), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_Temporal Before or Same)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=3, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@1b1c7b1f, com.bakdata.conquery.models.query.ColumnDescriptor@741ba1c]) download on dataset Dataset[label=null, name=Temporal Before or Same] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:27,940] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=Temporal Before or Same], queryId=0a2538bc-c3b9-4608-9832-6559c7d073f8, label=Geschlecht-SELECT	@§$, creationTime=2023-01-26T18:10:27.901589, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@5bc5e1dd[Count = 0], startTime=2023-01-26T18:10:27.901736, finishTime=2023-01-26T18:10:27.925192, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2c9ac811), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_Temporal Before or Same)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=3, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@1b1c7b1f, com.bakdata.conquery.models.query.ColumnDescriptor@741ba1c]) on dataset Dataset[label=null, name=Temporal Before or Same]
127.0.0.1 - - [26/Jan/2023:18:10:27 +0000] "GET /api/datasets/Temporal%20Before%20or%20Same/result/Temporal$20Before$20or$20Same.0a2538bc-c3b9-4608-9832-6559c7d073f8.csv?pretty=false HTTP/1.1" 200 115 "-" "Conquery (test client)" 16
INFO  [2023-01-26 18:10:27,955] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest Temporal Before or Same on 4 rows
INFO  [2023-01-26 18:10:27,955] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast Temporal Before or Same
INFO  [2023-01-26 18:10:27,955] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=Temporal Before or Same, name=Temporal Before or Same]
INFO  [2023-01-26 18:10:27,955] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=Temporal Before or Same, name=Temporal Before or Same]
INFO  [2023-01-26 18:10:27,955] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_Temporal Before or Same_a75373fa-a283-477e-b3d9-79b2685b333f
INFO  [2023-01-26 18:10:27,955] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_Temporal Before or Same_8cebf660-27d1-4549-a894-437574d53cc1
INFO  [2023-01-26 18:10:27,957] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow Temporal Before or Same
INFO  [2023-01-26 18:10:27,957] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_Temporal Before or Same_8cebf660-27d1-4549-a894-437574d53cc1
INFO  [2023-01-26 18:10:27,957] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_Temporal Before or Same_a75373fa-a283-477e-b3d9-79b2685b333f
INFO  [2023-01-26 18:10:27,960] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of Temporal$20Before$20or$20Same
INFO  [2023-01-26 18:10:27,960] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:28,095] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test Temporal Before or Same
INFO  [2023-01-26 18:10:28,095] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test Temporal Days Before
INFO  [2023-01-26 18:10:28,096] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:28,096] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:28,100] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=Temporal Days Before, name=Temporal Days Before]
INFO  [2023-01-26 18:10:28,100] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=Temporal Days Before, name=Temporal Days Before]
INFO  [2023-01-26 18:10:28,100] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:28,100] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:28,103] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker Temporal$20Days$20Before.worker_Temporal$20Days$20Before_63bdd8fa-1418-483c-89c1-8a1299198e02 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:28,103] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker Temporal$20Days$20Before.worker_Temporal$20Days$20Before_63bdd8fa-1418-483c-89c1-8a1299198e02 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:28,103] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:28,116] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:28,116] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker Temporal$20Days$20Before.worker_Temporal$20Days$20Before_0572108d-9811-4e59-a80e-916f9dd222b4 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:28,116] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker Temporal$20Days$20Before.worker_Temporal$20Days$20Before_0572108d-9811-4e59-a80e-916f9dd222b4 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:28,116] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:28,220] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:28,227] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:28,227] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table Temporal$20Days$20Before.table1
INFO  [2023-01-26 18:10:28,227] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table Temporal$20Days$20Before.table1
INFO  [2023-01-26 18:10:28,340] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:28,449] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:28,449] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:28,449] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 158 B in total
INFO  [2023-01-26 18:10:28,449] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_Temporal Days Before/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000298057sINFO  [2023-01-26 18:10:28,479] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=8, min=2, average=2.000000, max=2}
INFO  [2023-01-26 18:10:28,479] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=8, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:28,479] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=8, nullLines=0), subType=IntegerParser(super=Parser(lines=8, nullLines=0), minValue=14975, maxValue=14980), dateReader=com.bakdata.conquery.util.DateReader@6a8a9651)
INFO  [2023-01-26 18:10:28,483] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_Temporal Days Before/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:28,483] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:28,483] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_Temporal Days Before/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:28,500] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into Temporal$20Days$20Before.table1
127.0.0.1 - - [26/Jan/2023:18:10:28 +0000] "POST /admin/datasets/Temporal%20Days%20Before/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_Temporal+Days+Before%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:10:28,500] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:28,501] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:28,502] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:28,502] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:28,505] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:28,505] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[Temporal$20Days$20Before.table1.table1], containing 8 entries.
INFO  [2023-01-26 18:10:28,505] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[Temporal$20Days$20Before.table1.table1], containing 8 entries.
WARN  [2023-01-26 18:10:28,507] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:28,507] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received Temporal$20Days$20Before.table1.table1.0
INFO  [2023-01-26 18:10:28,507] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received Temporal$20Days$20Before.table1.table1.1
INFO  [2023-01-26 18:10:28,612] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:28,618] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:28,630] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:28,630] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:28,630] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:28,752] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: Temporal Days Before QUERY INIT
INFO  [2023-01-26 18:10:28,761] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[Temporal$20Days$20Before] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:28,761] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[872d480d-b3c2-4bcd-aaed-4a7046f8d0c6] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_Temporal Days Before))]]
INFO  [2023-01-26 18:10:28,764] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery Temporal$20Days$20Before.872d480d-b3c2-4bcd-aaed-4a7046f8d0c6
INFO  [2023-01-26 18:10:28,764] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery Temporal$20Days$20Before.872d480d-b3c2-4bcd-aaed-4a7046f8d0c6
127.0.0.1 - - [26/Jan/2023:18:10:28 +0000] "POST /api/datasets/Temporal$20Days$20Before/queries HTTP/1.1" 201 1834 "-" "Conquery (test client)" 5
INFO  [2023-01-26 18:10:28,765] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[Temporal$20Days$20Before.872d480d-b3c2-4bcd-aaed-4a7046f8d0c6] with 1 results within PT0.001183S
INFO  [2023-01-26 18:10:28,765] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[Temporal$20Days$20Before.872d480d-b3c2-4bcd-aaed-4a7046f8d0c6] with 0 results within PT0.001266S
INFO  [2023-01-26 18:10:28,765] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=Temporal$20Days$20Before.872d480d-b3c2-4bcd-aaed-4a7046f8d0c6, workerId=Temporal$20Days$20Before.worker_Temporal$20Days$20Before_0572108d-9811-4e59-a80e-916f9dd222b4, startTime=2023-01-26T18:10:28.764043, finishTime=2023-01-26T18:10:28.765226) of size 1
INFO  [2023-01-26 18:10:28,765] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=Temporal$20Days$20Before.872d480d-b3c2-4bcd-aaed-4a7046f8d0c6, workerId=Temporal$20Days$20Before.worker_Temporal$20Days$20Before_63bdd8fa-1418-483c-89c1-8a1299198e02, startTime=2023-01-26T18:10:28.764058, finishTime=2023-01-26T18:10:28.765324) of size 0
INFO  [2023-01-26 18:10:28,765] com.bakdata.conquery.models.execution.ManagedExecution: DONE 872d480d-b3c2-4bcd-aaed-4a7046f8d0c6 ManagedQuery within PT0.004019S
127.0.0.1 - - [26/Jan/2023:18:10:28 +0000] "GET /api/datasets/Temporal$20Days$20Before/queries/Temporal$20Days$20Before.872d480d-b3c2-4bcd-aaed-4a7046f8d0c6 HTTP/1.1" 200 2121 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:10:28,781] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=Temporal Days Before], queryId=872d480d-b3c2-4bcd-aaed-4a7046f8d0c6, label=Geschlecht-SELECT	@§$, creationTime=2023-01-26T18:10:28.761599, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@b8816e6[Count = 0], startTime=2023-01-26T18:10:28.761710, finishTime=2023-01-26T18:10:28.765729, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@408b77b7), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_Temporal Days Before)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@4d77716d, com.bakdata.conquery.models.query.ColumnDescriptor@71624439]) download on dataset Dataset[label=null, name=Temporal Days Before] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:28,782] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=Temporal Days Before], queryId=872d480d-b3c2-4bcd-aaed-4a7046f8d0c6, label=Geschlecht-SELECT	@§$, creationTime=2023-01-26T18:10:28.761599, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@b8816e6[Count = 0], startTime=2023-01-26T18:10:28.761710, finishTime=2023-01-26T18:10:28.765729, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@408b77b7), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_Temporal Days Before)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=1, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@4d77716d, com.bakdata.conquery.models.query.ColumnDescriptor@71624439]) on dataset Dataset[label=null, name=Temporal Days Before]
127.0.0.1 - - [26/Jan/2023:18:10:28 +0000] "GET /api/datasets/Temporal%20Days%20Before/result/Temporal$20Days$20Before.872d480d-b3c2-4bcd-aaed-4a7046f8d0c6.csv?pretty=false HTTP/1.1" 200 39 "-" "Conquery (test client)" 37
INFO  [2023-01-26 18:10:28,817] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest Temporal Days Before on 2 rows
INFO  [2023-01-26 18:10:28,817] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast Temporal Days Before
INFO  [2023-01-26 18:10:28,818] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=Temporal Days Before, name=Temporal Days Before]
INFO  [2023-01-26 18:10:28,818] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=Temporal Days Before, name=Temporal Days Before]
INFO  [2023-01-26 18:10:28,818] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_Temporal Days Before_0572108d-9811-4e59-a80e-916f9dd222b4
INFO  [2023-01-26 18:10:28,818] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_Temporal Days Before_63bdd8fa-1418-483c-89c1-8a1299198e02
INFO  [2023-01-26 18:10:28,916] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow Temporal Days Before
INFO  [2023-01-26 18:10:28,916] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_Temporal Days Before_0572108d-9811-4e59-a80e-916f9dd222b4
INFO  [2023-01-26 18:10:28,916] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_Temporal Days Before_63bdd8fa-1418-483c-89c1-8a1299198e02
INFO  [2023-01-26 18:10:29,016] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of Temporal$20Days$20Before
INFO  [2023-01-26 18:10:29,016] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:29,052] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test Temporal Days Before
INFO  [2023-01-26 18:10:29,053] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test Temporal Before or Never
INFO  [2023-01-26 18:10:29,053] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:29,053] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:29,053] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=Temporal Before or Never, name=Temporal Before or Never]
INFO  [2023-01-26 18:10:29,053] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=Temporal Before or Never, name=Temporal Before or Never]
INFO  [2023-01-26 18:10:29,053] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:29,053] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:29,054] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:29,055] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker Temporal$20Before$20or$20Never.worker_Temporal$20Before$20or$20Never_81e04831-7c7a-4c53-b059-d424669f3d8d are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:29,055] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker Temporal$20Before$20or$20Never.worker_Temporal$20Before$20or$20Never_81e04831-7c7a-4c53-b059-d424669f3d8d are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:29,055] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:29,055] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker Temporal$20Before$20or$20Never.worker_Temporal$20Before$20or$20Never_bb79b356-8013-4734-8152-4e3d5b6f3c54 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:29,055] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker Temporal$20Before$20or$20Never.worker_Temporal$20Before$20or$20Never_bb79b356-8013-4734-8152-4e3d5b6f3c54 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:29,055] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:29,159] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:29,166] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:29,166] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table Temporal$20Before$20or$20Never.table1
INFO  [2023-01-26 18:10:29,166] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table Temporal$20Before$20or$20Never.table1
INFO  [2023-01-26 18:10:29,278] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:29,400] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:29,400] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:29,400] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 144 B in total
INFO  [2023-01-26 18:10:29,400] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_Temporal Before or Never/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000232311sINFO  [2023-01-26 18:10:29,424] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=7, min=1, average=1.750000, max=2}
INFO  [2023-01-26 18:10:29,424] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=7, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:29,424] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=7, nullLines=0), subType=IntegerParser(super=Parser(lines=7, nullLines=0), minValue=14976, maxValue=15656), dateReader=com.bakdata.conquery.util.DateReader@17f8e347)
INFO  [2023-01-26 18:10:29,427] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_Temporal Before or Never/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:29,427] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:29,427] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_Temporal Before or Never/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:29,444] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into Temporal$20Before$20or$20Never.table1
127.0.0.1 - - [26/Jan/2023:18:10:29 +0000] "POST /admin/datasets/Temporal%20Before%20or%20Never/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_Temporal+Before+or+Never%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:10:29,445] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:29,445] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:29,446] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:29,446] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:29,448] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:29,448] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[Temporal$20Before$20or$20Never.table1.table1], containing 7 entries.
INFO  [2023-01-26 18:10:29,448] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[Temporal$20Before$20or$20Never.table1.table1], containing 7 entries.
INFO  [2023-01-26 18:10:29,449] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received Temporal$20Before$20or$20Never.table1.table1.0
INFO  [2023-01-26 18:10:29,449] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received Temporal$20Before$20or$20Never.table1.table1.1
WARN  [2023-01-26 18:10:29,450] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:29,554] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:29,560] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:29,573] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:29,573] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:29,573] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:29,679] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: Temporal Before or Never QUERY INIT
INFO  [2023-01-26 18:10:29,689] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[Temporal$20Before$20or$20Never] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:29,690] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[0e8e6f50-275f-4216-a2fa-2c44dc931fbc] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_Temporal Before or Never))]]
INFO  [2023-01-26 18:10:29,692] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery Temporal$20Before$20or$20Never.0e8e6f50-275f-4216-a2fa-2c44dc931fbc
INFO  [2023-01-26 18:10:29,692] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery Temporal$20Before$20or$20Never.0e8e6f50-275f-4216-a2fa-2c44dc931fbc
127.0.0.1 - - [26/Jan/2023:18:10:29 +0000] "POST /api/datasets/Temporal$20Before$20or$20Never/queries HTTP/1.1" 201 1873 "-" "Conquery (test client)" 5
INFO  [2023-01-26 18:10:29,693] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[Temporal$20Before$20or$20Never.0e8e6f50-275f-4216-a2fa-2c44dc931fbc] with 0 results within PT0.001133S
INFO  [2023-01-26 18:10:29,693] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[Temporal$20Before$20or$20Never.0e8e6f50-275f-4216-a2fa-2c44dc931fbc] with 2 results within PT0.00127S
INFO  [2023-01-26 18:10:29,694] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=Temporal$20Before$20or$20Never.0e8e6f50-275f-4216-a2fa-2c44dc931fbc, workerId=Temporal$20Before$20or$20Never.worker_Temporal$20Before$20or$20Never_81e04831-7c7a-4c53-b059-d424669f3d8d, startTime=2023-01-26T18:10:29.692593, finishTime=2023-01-26T18:10:29.693726) of size 0
INFO  [2023-01-26 18:10:29,694] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=Temporal$20Before$20or$20Never.0e8e6f50-275f-4216-a2fa-2c44dc931fbc, workerId=Temporal$20Before$20or$20Never.worker_Temporal$20Before$20or$20Never_bb79b356-8013-4734-8152-4e3d5b6f3c54, startTime=2023-01-26T18:10:29.692583, finishTime=2023-01-26T18:10:29.693853) of size 2
INFO  [2023-01-26 18:10:29,694] com.bakdata.conquery.models.execution.ManagedExecution: DONE 0e8e6f50-275f-4216-a2fa-2c44dc931fbc ManagedQuery within PT0.004126S
127.0.0.1 - - [26/Jan/2023:18:10:29 +0000] "GET /api/datasets/Temporal$20Before$20or$20Never/queries/Temporal$20Before$20or$20Never.0e8e6f50-275f-4216-a2fa-2c44dc931fbc HTTP/1.1" 200 2183 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:10:29,714] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=Temporal Before or Never], queryId=0e8e6f50-275f-4216-a2fa-2c44dc931fbc, label=geschlecht_select	@§$, creationTime=2023-01-26T18:10:29.690013, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@6a694f08[Count = 0], startTime=2023-01-26T18:10:29.690154, finishTime=2023-01-26T18:10:29.694280, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@53138ae3), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_Temporal Before or Never)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@6243c7bf, com.bakdata.conquery.models.query.ColumnDescriptor@6268705c]) download on dataset Dataset[label=null, name=Temporal Before or Never] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:29,714] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=Temporal Before or Never], queryId=0e8e6f50-275f-4216-a2fa-2c44dc931fbc, label=geschlecht_select	@§$, creationTime=2023-01-26T18:10:29.690013, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@6a694f08[Count = 0], startTime=2023-01-26T18:10:29.690154, finishTime=2023-01-26T18:10:29.694280, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@53138ae3), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_Temporal Before or Never)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@6243c7bf, com.bakdata.conquery.models.query.ColumnDescriptor@6268705c]) on dataset Dataset[label=null, name=Temporal Before or Never]
127.0.0.1 - - [26/Jan/2023:18:10:29 +0000] "GET /api/datasets/Temporal%20Before%20or%20Never/result/Temporal$20Before$20or$20Never.0e8e6f50-275f-4216-a2fa-2c44dc931fbc.csv?pretty=false HTTP/1.1" 200 65 "-" "Conquery (test client)" 23
INFO  [2023-01-26 18:10:29,736] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest Temporal Before or Never on 3 rows
INFO  [2023-01-26 18:10:29,736] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast Temporal Before or Never
INFO  [2023-01-26 18:10:29,736] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=Temporal Before or Never, name=Temporal Before or Never]
INFO  [2023-01-26 18:10:29,736] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=Temporal Before or Never, name=Temporal Before or Never]
INFO  [2023-01-26 18:10:29,737] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_Temporal Before or Never_81e04831-7c7a-4c53-b059-d424669f3d8d
INFO  [2023-01-26 18:10:29,737] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_Temporal Before or Never_bb79b356-8013-4734-8152-4e3d5b6f3c54
INFO  [2023-01-26 18:10:29,755] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow Temporal Before or Never
INFO  [2023-01-26 18:10:29,755] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_Temporal Before or Never_bb79b356-8013-4734-8152-4e3d5b6f3c54
INFO  [2023-01-26 18:10:29,759] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_Temporal Before or Never_81e04831-7c7a-4c53-b059-d424669f3d8d
INFO  [2023-01-26 18:10:29,851] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of Temporal$20Before$20or$20Never
INFO  [2023-01-26 18:10:29,851] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:29,878] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test Temporal Before or Never
INFO  [2023-01-26 18:10:29,878] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test Temporal Same
INFO  [2023-01-26 18:10:29,878] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:29,878] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:29,879] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=Temporal Same, name=Temporal Same]
INFO  [2023-01-26 18:10:29,879] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=Temporal Same, name=Temporal Same]
INFO  [2023-01-26 18:10:29,879] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:29,879] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:29,880] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:29,880] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker Temporal$20Same.worker_Temporal$20Same_f9ae82eb-3c95-4d66-87e8-e2dcb31ba6cf are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:29,880] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker Temporal$20Same.worker_Temporal$20Same_f9ae82eb-3c95-4d66-87e8-e2dcb31ba6cf are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:29,880] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:29,880] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker Temporal$20Same.worker_Temporal$20Same_7d9ee3f5-279c-4927-a460-a8f22e498ee8 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:29,880] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker Temporal$20Same.worker_Temporal$20Same_7d9ee3f5-279c-4927-a460-a8f22e498ee8 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:29,880] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:29,985] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:29,991] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:29,991] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table Temporal$20Same.table1
INFO  [2023-01-26 18:10:29,991] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table Temporal$20Same.table1
INFO  [2023-01-26 18:10:30,103] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:30,224] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:30,224] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:30,224] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 178 B in total
INFO  [2023-01-26 18:10:30,224] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_Temporal Same/table1.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000168696sINFO  [2023-01-26 18:10:30,242] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=9, min=2, average=2.250000, max=3}
INFO  [2023-01-26 18:10:30,242] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geschlecht] with StringParser(super=Parser(lines=9, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:30,242] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=9, nullLines=0), subType=IntegerParser(super=Parser(lines=9, nullLines=0), minValue=14975, maxValue=15006), dateReader=com.bakdata.conquery.util.DateReader@58a4ecf2)
INFO  [2023-01-26 18:10:30,245] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_Temporal Same/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:30,245] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:30,245] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_Temporal Same/table1.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:30,262] com.bakdata.conquery.models.jobs.ImportJob: Importing table1 into Temporal$20Same.table1
127.0.0.1 - - [26/Jan/2023:18:10:30 +0000] "POST /admin/datasets/Temporal%20Same/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_Temporal+Same%2Ftable1.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:10:30,263] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:30,263] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:30,264] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:30,264] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:30,266] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:30,266] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[Temporal$20Same.table1.table1], containing 9 entries.
INFO  [2023-01-26 18:10:30,266] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[Temporal$20Same.table1.table1], containing 9 entries.
WARN  [2023-01-26 18:10:30,267] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:30,267] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received Temporal$20Same.table1.table1.0
INFO  [2023-01-26 18:10:30,267] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received Temporal$20Same.table1.table1.1
INFO  [2023-01-26 18:10:30,383] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:30,388] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:30,398] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:30,398] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:30,398] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:30,503] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: Temporal Same QUERY INIT
INFO  [2023-01-26 18:10:30,513] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[Temporal$20Same] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:30,513] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[36224afa-3bc9-4761-aea2-006a13f59bc3] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_Temporal Same))]]
INFO  [2023-01-26 18:10:30,516] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery Temporal$20Same.36224afa-3bc9-4761-aea2-006a13f59bc3
INFO  [2023-01-26 18:10:30,516] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery Temporal$20Same.36224afa-3bc9-4761-aea2-006a13f59bc3
127.0.0.1 - - [26/Jan/2023:18:10:30 +0000] "POST /api/datasets/Temporal$20Same/queries HTTP/1.1" 201 1744 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:10:30,517] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[Temporal$20Same.36224afa-3bc9-4761-aea2-006a13f59bc3] with 0 results within PT0.000679S
INFO  [2023-01-26 18:10:30,517] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[Temporal$20Same.36224afa-3bc9-4761-aea2-006a13f59bc3] with 2 results within PT0.000784S
INFO  [2023-01-26 18:10:30,517] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=Temporal$20Same.36224afa-3bc9-4761-aea2-006a13f59bc3, workerId=Temporal$20Same.worker_Temporal$20Same_f9ae82eb-3c95-4d66-87e8-e2dcb31ba6cf, startTime=2023-01-26T18:10:30.516588, finishTime=2023-01-26T18:10:30.517267) of size 0
INFO  [2023-01-26 18:10:30,517] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=Temporal$20Same.36224afa-3bc9-4761-aea2-006a13f59bc3, workerId=Temporal$20Same.worker_Temporal$20Same_7d9ee3f5-279c-4927-a460-a8f22e498ee8, startTime=2023-01-26T18:10:30.516586, finishTime=2023-01-26T18:10:30.517370) of size 2
INFO  [2023-01-26 18:10:30,517] com.bakdata.conquery.models.execution.ManagedExecution: DONE 36224afa-3bc9-4761-aea2-006a13f59bc3 ManagedQuery within PT0.003923S
127.0.0.1 - - [26/Jan/2023:18:10:30 +0000] "GET /api/datasets/Temporal$20Same/queries/Temporal$20Same.36224afa-3bc9-4761-aea2-006a13f59bc3 HTTP/1.1" 200 1995 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:10:30,534] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=Temporal Same], queryId=36224afa-3bc9-4761-aea2-006a13f59bc3, label=Geschlecht-SELECT	@§$, creationTime=2023-01-26T18:10:30.513789, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@46f2644a[Count = 0], startTime=2023-01-26T18:10:30.513929, finishTime=2023-01-26T18:10:30.517852, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2149a3e1), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_Temporal Same)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@353853eb, com.bakdata.conquery.models.query.ColumnDescriptor@6b4a1978]) download on dataset Dataset[label=null, name=Temporal Same] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:30,534] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=Temporal Same], queryId=36224afa-3bc9-4761-aea2-006a13f59bc3, label=Geschlecht-SELECT	@§$, creationTime=2023-01-26T18:10:30.513789, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@46f2644a[Count = 0], startTime=2023-01-26T18:10:30.513929, finishTime=2023-01-26T18:10:30.517852, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2149a3e1), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_Temporal Same)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@353853eb, com.bakdata.conquery.models.query.ColumnDescriptor@6b4a1978]) on dataset Dataset[label=null, name=Temporal Same]
127.0.0.1 - - [26/Jan/2023:18:10:30 +0000] "GET /api/datasets/Temporal%20Same/result/Temporal$20Same.36224afa-3bc9-4761-aea2-006a13f59bc3.csv?pretty=false HTTP/1.1" 200 65 "-" "Conquery (test client)" 14
INFO  [2023-01-26 18:10:30,546] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest Temporal Same on 3 rows
INFO  [2023-01-26 18:10:30,546] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast Temporal Same
INFO  [2023-01-26 18:10:30,546] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=Temporal Same, name=Temporal Same]
INFO  [2023-01-26 18:10:30,546] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=Temporal Same, name=Temporal Same]
INFO  [2023-01-26 18:10:30,547] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_Temporal Same_f9ae82eb-3c95-4d66-87e8-e2dcb31ba6cf
INFO  [2023-01-26 18:10:30,547] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_Temporal Same_7d9ee3f5-279c-4927-a460-a8f22e498ee8
INFO  [2023-01-26 18:10:30,581] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow Temporal Same
INFO  [2023-01-26 18:10:30,581] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_Temporal Same_f9ae82eb-3c95-4d66-87e8-e2dcb31ba6cf
INFO  [2023-01-26 18:10:30,581] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_Temporal Same_7d9ee3f5-279c-4927-a460-a8f22e498ee8
INFO  [2023-01-26 18:10:30,667] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of Temporal$20Same
INFO  [2023-01-26 18:10:30,667] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:30,703] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test Temporal Same
INFO  [2023-01-26 18:10:30,704] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test VALIDITY_DATE_QUERY Test
INFO  [2023-01-26 18:10:30,704] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:30,704] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:30,705] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=VALIDITY_DATE_QUERY Test, name=VALIDITY_DATE_QUERY Test]
INFO  [2023-01-26 18:10:30,705] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=VALIDITY_DATE_QUERY Test, name=VALIDITY_DATE_QUERY Test]
INFO  [2023-01-26 18:10:30,705] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:30,705] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:30,706] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker VALIDITY_DATE_QUERY$20Test.worker_VALIDITY_DATE_QUERY$20Test_1e222eaf-dc96-4fba-a5fa-b82e283108fb are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:30,706] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker VALIDITY_DATE_QUERY$20Test.worker_VALIDITY_DATE_QUERY$20Test_1e222eaf-dc96-4fba-a5fa-b82e283108fb are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:30,706] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:30,708] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker VALIDITY_DATE_QUERY$20Test.worker_VALIDITY_DATE_QUERY$20Test_b2a07e9d-dfe6-4112-a105-e51888330e34 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:30,708] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker VALIDITY_DATE_QUERY$20Test.worker_VALIDITY_DATE_QUERY$20Test_b2a07e9d-dfe6-4112-a105-e51888330e34 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:30,708] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:30,711] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:30,812] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:30,818] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:30,819] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table VALIDITY_DATE_QUERY$20Test.table
INFO  [2023-01-26 18:10:30,819] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table VALIDITY_DATE_QUERY$20Test.table
INFO  [2023-01-26 18:10:30,929] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:31,037] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:31,037] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:31,037] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 149 B in total
INFO  [2023-01-26 18:10:31,037] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_VALIDITY_DATE_QUERY Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000208098sINFO  [2023-01-26 18:10:31,058] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=4, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:10:31,058] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[other_date] with DateParser(super=Parser(lines=4, nullLines=0), subType=IntegerParser(super=Parser(lines=4, nullLines=0), minValue=15170, maxValue=16384), dateReader=com.bakdata.conquery.util.DateReader@4e158de7)
INFO  [2023-01-26 18:10:31,058] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=4, nullLines=0), subType=IntegerParser(super=Parser(lines=4, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@6b7c7073)
INFO  [2023-01-26 18:10:31,058] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=4, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:31,062] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_VALIDITY_DATE_QUERY Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:31,062] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:31,062] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_VALIDITY_DATE_QUERY Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:31,079] com.bakdata.conquery.models.jobs.ImportJob: Importing table into VALIDITY_DATE_QUERY$20Test.table
INFO  [2023-01-26 18:10:31,081] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:31,081] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:31,081] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:31,083] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:31,083] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[VALIDITY_DATE_QUERY$20Test.table.table], containing 4 entries.
INFO  [2023-01-26 18:10:31,083] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[VALIDITY_DATE_QUERY$20Test.table.table], containing 4 entries.
WARN  [2023-01-26 18:10:31,084] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:31,084] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received VALIDITY_DATE_QUERY$20Test.table.table.1
127.0.0.1 - - [26/Jan/2023:18:10:31 +0000] "POST /admin/datasets/VALIDITY_DATE_QUERY%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_VALIDITY_DATE_QUERY+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 15
INFO  [2023-01-26 18:10:31,085] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:31,085] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received VALIDITY_DATE_QUERY$20Test.table.table.0
INFO  [2023-01-26 18:10:31,190] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:31,195] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:31,208] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:31,208] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:31,208] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:31,315] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: VALIDITY_DATE_QUERY Test QUERY INIT
INFO  [2023-01-26 18:10:31,326] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[VALIDITY_DATE_QUERY$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:31,326] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[1a96752c-4e68-4e72-864b-d190941e5353] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_VALIDITY_DATE_QUERY Test))]]
INFO  [2023-01-26 18:10:31,328] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery VALIDITY_DATE_QUERY$20Test.1a96752c-4e68-4e72-864b-d190941e5353
INFO  [2023-01-26 18:10:31,328] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery VALIDITY_DATE_QUERY$20Test.1a96752c-4e68-4e72-864b-d190941e5353
127.0.0.1 - - [26/Jan/2023:18:10:31 +0000] "POST /api/datasets/VALIDITY_DATE_QUERY$20Test/queries HTTP/1.1" 201 1198 "-" "Conquery (test client)" 4
INFO  [2023-01-26 18:10:31,329] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[VALIDITY_DATE_QUERY$20Test.1a96752c-4e68-4e72-864b-d190941e5353] with 0 results within PT0.001303S
INFO  [2023-01-26 18:10:31,329] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[VALIDITY_DATE_QUERY$20Test.1a96752c-4e68-4e72-864b-d190941e5353] with 2 results within PT0.001402S
INFO  [2023-01-26 18:10:31,329] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=VALIDITY_DATE_QUERY$20Test.1a96752c-4e68-4e72-864b-d190941e5353, workerId=VALIDITY_DATE_QUERY$20Test.worker_VALIDITY_DATE_QUERY$20Test_b2a07e9d-dfe6-4112-a105-e51888330e34, startTime=2023-01-26T18:10:31.328207, finishTime=2023-01-26T18:10:31.329510) of size 0
INFO  [2023-01-26 18:10:31,330] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=VALIDITY_DATE_QUERY$20Test.1a96752c-4e68-4e72-864b-d190941e5353, workerId=VALIDITY_DATE_QUERY$20Test.worker_VALIDITY_DATE_QUERY$20Test_1e222eaf-dc96-4fba-a5fa-b82e283108fb, startTime=2023-01-26T18:10:31.328202, finishTime=2023-01-26T18:10:31.329604) of size 2
INFO  [2023-01-26 18:10:31,330] com.bakdata.conquery.models.execution.ManagedExecution: DONE 1a96752c-4e68-4e72-864b-d190941e5353 ManagedQuery within PT0.003658S
127.0.0.1 - - [26/Jan/2023:18:10:31 +0000] "GET /api/datasets/VALIDITY_DATE_QUERY$20Test/queries/VALIDITY_DATE_QUERY$20Test.1a96752c-4e68-4e72-864b-d190941e5353 HTTP/1.1" 200 1493 "-" "Conquery (test client)" 1
INFO  [2023-01-26 18:10:31,345] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=VALIDITY_DATE_QUERY Test], queryId=1a96752c-4e68-4e72-864b-d190941e5353, label=concept---test_child1	@§$, creationTime=2023-01-26T18:10:31.326305, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@4228f639[Count = 0], startTime=2023-01-26T18:10:31.326431, finishTime=2023-01-26T18:10:31.330089, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@8936680), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_VALIDITY_DATE_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@55e4780f, com.bakdata.conquery.models.query.ColumnDescriptor@6b5f1555]) download on dataset Dataset[label=null, name=VALIDITY_DATE_QUERY Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:31,345] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=VALIDITY_DATE_QUERY Test], queryId=1a96752c-4e68-4e72-864b-d190941e5353, label=concept---test_child1	@§$, creationTime=2023-01-26T18:10:31.326305, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@4228f639[Count = 0], startTime=2023-01-26T18:10:31.326431, finishTime=2023-01-26T18:10:31.330089, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@8936680), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_VALIDITY_DATE_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@55e4780f, com.bakdata.conquery.models.query.ColumnDescriptor@6b5f1555]) on dataset Dataset[label=null, name=VALIDITY_DATE_QUERY Test]
127.0.0.1 - - [26/Jan/2023:18:10:31 +0000] "GET /api/datasets/VALIDITY_DATE_QUERY%20Test/result/VALIDITY_DATE_QUERY$20Test.1a96752c-4e68-4e72-864b-d190941e5353.csv?pretty=false HTTP/1.1" 200 65 "-" "Conquery (test client)" 27
INFO  [2023-01-26 18:10:31,371] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest VALIDITY_DATE_QUERY Test on 3 rows
INFO  [2023-01-26 18:10:31,372] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast VALIDITY_DATE_QUERY Test
INFO  [2023-01-26 18:10:31,372] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=VALIDITY_DATE_QUERY Test, name=VALIDITY_DATE_QUERY Test]
INFO  [2023-01-26 18:10:31,372] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_VALIDITY_DATE_QUERY Test_b2a07e9d-dfe6-4112-a105-e51888330e34
INFO  [2023-01-26 18:10:31,372] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=VALIDITY_DATE_QUERY Test, name=VALIDITY_DATE_QUERY Test]
INFO  [2023-01-26 18:10:31,372] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_VALIDITY_DATE_QUERY Test_1e222eaf-dc96-4fba-a5fa-b82e283108fb
INFO  [2023-01-26 18:10:31,411] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_VALIDITY_DATE_QUERY Test_1e222eaf-dc96-4fba-a5fa-b82e283108fb
INFO  [2023-01-26 18:10:31,411] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow VALIDITY_DATE_QUERY Test
INFO  [2023-01-26 18:10:31,411] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_VALIDITY_DATE_QUERY Test_b2a07e9d-dfe6-4112-a105-e51888330e34
INFO  [2023-01-26 18:10:31,484] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of VALIDITY_DATE_QUERY$20Test
INFO  [2023-01-26 18:10:31,484] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:31,616] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test VALIDITY_DATE_QUERY Test
INFO  [2023-01-26 18:10:31,617] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test VIRTUAL_CONCEPT_REUSED_QUERY Test
INFO  [2023-01-26 18:10:31,617] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:31,617] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:31,620] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=VIRTUAL_CONCEPT_REUSED_QUERY Test, name=VIRTUAL_CONCEPT_REUSED_QUERY Test]
INFO  [2023-01-26 18:10:31,620] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=VIRTUAL_CONCEPT_REUSED_QUERY Test, name=VIRTUAL_CONCEPT_REUSED_QUERY Test]
INFO  [2023-01-26 18:10:31,620] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:31,620] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:31,624] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker VIRTUAL_CONCEPT_REUSED_QUERY$20Test.worker_VIRTUAL_CONCEPT_REUSED_QUERY$20Test_6ee5caae-a43f-431f-ad90-7cecfd853b3e are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:31,624] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker VIRTUAL_CONCEPT_REUSED_QUERY$20Test.worker_VIRTUAL_CONCEPT_REUSED_QUERY$20Test_6ee5caae-a43f-431f-ad90-7cecfd853b3e are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:31,624] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:31,632] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker VIRTUAL_CONCEPT_REUSED_QUERY$20Test.worker_VIRTUAL_CONCEPT_REUSED_QUERY$20Test_2a36726d-408f-4959-adab-a2dc7e7e3250 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:31,632] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker VIRTUAL_CONCEPT_REUSED_QUERY$20Test.worker_VIRTUAL_CONCEPT_REUSED_QUERY$20Test_2a36726d-408f-4959-adab-a2dc7e7e3250 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:31,632] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:31,636] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:31,736] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:31,743] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:31,744] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table VIRTUAL_CONCEPT_REUSED_QUERY$20Test.test_table
INFO  [2023-01-26 18:10:31,744] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table VIRTUAL_CONCEPT_REUSED_QUERY$20Test.test_table
INFO  [2023-01-26 18:10:31,857] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:31,970] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:31,970] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:31,970] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 390 B in total
INFO  [2023-01-26 18:10:31,970] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_VIRTUAL_CONCEPT_REUSED_QUERY Test/test_table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000213412sINFO  [2023-01-26 18:10:31,992] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=22, sum=22, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:10:31,992] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[test_column] with StringParser(super=Parser(lines=22, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:31,992] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=22, nullLines=0), subType=IntegerParser(super=Parser(lines=22, nullLines=0), minValue=13149, maxValue=16071), dateReader=com.bakdata.conquery.util.DateReader@7d82ebec)
INFO  [2023-01-26 18:10:31,995] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_VIRTUAL_CONCEPT_REUSED_QUERY Test/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:31,995] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:31,995] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_VIRTUAL_CONCEPT_REUSED_QUERY Test/test_table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:32,012] com.bakdata.conquery.models.jobs.ImportJob: Importing test_table into VIRTUAL_CONCEPT_REUSED_QUERY$20Test.test_table
INFO  [2023-01-26 18:10:32,012] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:10:32 +0000] "POST /admin/datasets/VIRTUAL_CONCEPT_REUSED_QUERY%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_VIRTUAL_CONCEPT_REUSED_QUERY+Test%2Ftest_table.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:10:32,013] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:32,013] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:32,013] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:32,014] com.bakdata.conquery.models.jobs.ImportJob: Start sending 8 Buckets
INFO  [2023-01-26 18:10:32,015] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[VIRTUAL_CONCEPT_REUSED_QUERY$20Test.test_table.test_table], containing 22 entries.
INFO  [2023-01-26 18:10:32,015] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[VIRTUAL_CONCEPT_REUSED_QUERY$20Test.test_table.test_table], containing 22 entries.
WARN  [2023-01-26 18:10:32,015] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:32,015] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received VIRTUAL_CONCEPT_REUSED_QUERY$20Test.test_table.test_table.2
INFO  [2023-01-26 18:10:32,015] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received VIRTUAL_CONCEPT_REUSED_QUERY$20Test.test_table.test_table.0
INFO  [2023-01-26 18:10:32,016] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received VIRTUAL_CONCEPT_REUSED_QUERY$20Test.test_table.test_table.3
INFO  [2023-01-26 18:10:32,016] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received VIRTUAL_CONCEPT_REUSED_QUERY$20Test.test_table.test_table.5
INFO  [2023-01-26 18:10:32,016] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received VIRTUAL_CONCEPT_REUSED_QUERY$20Test.test_table.test_table.1
INFO  [2023-01-26 18:10:32,016] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received VIRTUAL_CONCEPT_REUSED_QUERY$20Test.test_table.test_table.7
INFO  [2023-01-26 18:10:32,016] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received VIRTUAL_CONCEPT_REUSED_QUERY$20Test.test_table.test_table.4
INFO  [2023-01-26 18:10:32,016] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received VIRTUAL_CONCEPT_REUSED_QUERY$20Test.test_table.test_table.6
INFO  [2023-01-26 18:10:32,121] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:32,166] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:32,171] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:32,182] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:32,182] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:32,182] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:32,287] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: VIRTUAL_CONCEPT_REUSED_QUERY Test QUERY INIT
INFO  [2023-01-26 18:10:32,298] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[VIRTUAL_CONCEPT_REUSED_QUERY$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:32,299] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[e70b6af4-5489-4378-aa1f-fa5cc8d4d733] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_VIRTUAL_CONCEPT_REUSED_QUERY Test))]]
INFO  [2023-01-26 18:10:32,302] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery VIRTUAL_CONCEPT_REUSED_QUERY$20Test.e70b6af4-5489-4378-aa1f-fa5cc8d4d733
INFO  [2023-01-26 18:10:32,302] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery VIRTUAL_CONCEPT_REUSED_QUERY$20Test.e70b6af4-5489-4378-aa1f-fa5cc8d4d733
127.0.0.1 - - [26/Jan/2023:18:10:32 +0000] "POST /api/datasets/VIRTUAL_CONCEPT_REUSED_QUERY$20Test/queries HTTP/1.1" 201 1507 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:10:32,312] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[VIRTUAL_CONCEPT_REUSED_QUERY$20Test.e70b6af4-5489-4378-aa1f-fa5cc8d4d733] with 2 results within PT0.00954S
INFO  [2023-01-26 18:10:32,312] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=VIRTUAL_CONCEPT_REUSED_QUERY$20Test.e70b6af4-5489-4378-aa1f-fa5cc8d4d733, workerId=VIRTUAL_CONCEPT_REUSED_QUERY$20Test.worker_VIRTUAL_CONCEPT_REUSED_QUERY$20Test_2a36726d-408f-4959-adab-a2dc7e7e3250, startTime=2023-01-26T18:10:32.302951, finishTime=2023-01-26T18:10:32.312491) of size 2
INFO  [2023-01-26 18:10:32,315] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[VIRTUAL_CONCEPT_REUSED_QUERY$20Test.e70b6af4-5489-4378-aa1f-fa5cc8d4d733] with 2 results within PT0.01292S
INFO  [2023-01-26 18:10:32,316] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=VIRTUAL_CONCEPT_REUSED_QUERY$20Test.e70b6af4-5489-4378-aa1f-fa5cc8d4d733, workerId=VIRTUAL_CONCEPT_REUSED_QUERY$20Test.worker_VIRTUAL_CONCEPT_REUSED_QUERY$20Test_6ee5caae-a43f-431f-ad90-7cecfd853b3e, startTime=2023-01-26T18:10:32.302934, finishTime=2023-01-26T18:10:32.315854) of size 2
INFO  [2023-01-26 18:10:32,316] com.bakdata.conquery.models.execution.ManagedExecution: DONE e70b6af4-5489-4378-aa1f-fa5cc8d4d733 ManagedQuery within PT0.016702S
127.0.0.1 - - [26/Jan/2023:18:10:32 +0000] "GET /api/datasets/VIRTUAL_CONCEPT_REUSED_QUERY$20Test/queries/VIRTUAL_CONCEPT_REUSED_QUERY$20Test.e70b6af4-5489-4378-aa1f-fa5cc8d4d733 HTTP/1.1" 200 1839 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:10:32,326] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=VIRTUAL_CONCEPT_REUSED_QUERY Test], queryId=e70b6af4-5489-4378-aa1f-fa5cc8d4d733, label=Query test_concept	@§$, creationTime=2023-01-26T18:10:32.299075, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@22d879ca[Count = 0], startTime=2023-01-26T18:10:32.299644, finishTime=2023-01-26T18:10:32.316346, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@6df8a5cd), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_VIRTUAL_CONCEPT_REUSED_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@104bed65, com.bakdata.conquery.models.query.ColumnDescriptor@46ca70a1]) download on dataset Dataset[label=null, name=VIRTUAL_CONCEPT_REUSED_QUERY Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:32,326] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=VIRTUAL_CONCEPT_REUSED_QUERY Test], queryId=e70b6af4-5489-4378-aa1f-fa5cc8d4d733, label=Query test_concept	@§$, creationTime=2023-01-26T18:10:32.299075, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@22d879ca[Count = 0], startTime=2023-01-26T18:10:32.299644, finishTime=2023-01-26T18:10:32.316346, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@6df8a5cd), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_VIRTUAL_CONCEPT_REUSED_QUERY Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@104bed65, com.bakdata.conquery.models.query.ColumnDescriptor@46ca70a1]) on dataset Dataset[label=null, name=VIRTUAL_CONCEPT_REUSED_QUERY Test]
127.0.0.1 - - [26/Jan/2023:18:10:32 +0000] "GET /api/datasets/VIRTUAL_CONCEPT_REUSED_QUERY%20Test/result/VIRTUAL_CONCEPT_REUSED_QUERY$20Test.e70b6af4-5489-4378-aa1f-fa5cc8d4d733.csv?pretty=false HTTP/1.1" 200 120 "-" "Conquery (test client)" 4
INFO  [2023-01-26 18:10:32,329] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest VIRTUAL_CONCEPT_REUSED_QUERY Test on 5 rows
INFO  [2023-01-26 18:10:32,329] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast VIRTUAL_CONCEPT_REUSED_QUERY Test
INFO  [2023-01-26 18:10:32,330] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=VIRTUAL_CONCEPT_REUSED_QUERY Test, name=VIRTUAL_CONCEPT_REUSED_QUERY Test]
INFO  [2023-01-26 18:10:32,330] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=VIRTUAL_CONCEPT_REUSED_QUERY Test, name=VIRTUAL_CONCEPT_REUSED_QUERY Test]
INFO  [2023-01-26 18:10:32,330] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_VIRTUAL_CONCEPT_REUSED_QUERY Test_6ee5caae-a43f-431f-ad90-7cecfd853b3e
INFO  [2023-01-26 18:10:32,330] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_VIRTUAL_CONCEPT_REUSED_QUERY Test_2a36726d-408f-4959-adab-a2dc7e7e3250
INFO  [2023-01-26 18:10:32,332] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_VIRTUAL_CONCEPT_REUSED_QUERY Test_2a36726d-408f-4959-adab-a2dc7e7e3250
INFO  [2023-01-26 18:10:32,420] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow VIRTUAL_CONCEPT_REUSED_QUERY Test
INFO  [2023-01-26 18:10:32,424] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_VIRTUAL_CONCEPT_REUSED_QUERY Test_6ee5caae-a43f-431f-ad90-7cecfd853b3e
INFO  [2023-01-26 18:10:32,519] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of VIRTUAL_CONCEPT_REUSED_QUERY$20Test
INFO  [2023-01-26 18:10:32,519] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:32,588] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test VIRTUAL_CONCEPT_REUSED_QUERY Test
INFO  [2023-01-26 18:10:32,588] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test COUNT_AGGREGATOR Test
INFO  [2023-01-26 18:10:32,589] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:32,589] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:32,589] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=COUNT_AGGREGATOR Test, name=COUNT_AGGREGATOR Test]
INFO  [2023-01-26 18:10:32,589] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:32,589] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=COUNT_AGGREGATOR Test, name=COUNT_AGGREGATOR Test]
INFO  [2023-01-26 18:10:32,589] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:32,591] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker COUNT_AGGREGATOR$20Test.worker_COUNT_AGGREGATOR$20Test_3f5ee12c-6386-496b-8892-7c39cf89c8ea are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:32,591] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker COUNT_AGGREGATOR$20Test.worker_COUNT_AGGREGATOR$20Test_3f5ee12c-6386-496b-8892-7c39cf89c8ea are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:32,591] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:32,591] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker COUNT_AGGREGATOR$20Test.worker_COUNT_AGGREGATOR$20Test_725f64ea-ef5d-4da2-b310-b8eb351e59eb are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:32,591] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker COUNT_AGGREGATOR$20Test.worker_COUNT_AGGREGATOR$20Test_725f64ea-ef5d-4da2-b310-b8eb351e59eb are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:32,591] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:32,595] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:32,695] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:32,701] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:32,702] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table COUNT_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:32,702] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table COUNT_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:32,814] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:32,922] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:32,922] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:32,922] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 98 B in total
INFO  [2023-01-26 18:10:32,922] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COUNT_AGGREGATOR Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000374516sINFO  [2023-01-26 18:10:32,960] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=5, min=1, average=1.250000, max=2}
INFO  [2023-01-26 18:10:32,960] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with StringParser(super=Parser(lines=5, nullLines=1), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:32,960] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=5, nullLines=0), subType=IntegerParser(super=Parser(lines=5, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@4a97a0b8)
INFO  [2023-01-26 18:10:32,963] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COUNT_AGGREGATOR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:32,963] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:32,963] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COUNT_AGGREGATOR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:32,980] com.bakdata.conquery.models.jobs.ImportJob: Importing table into COUNT_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:32,981] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:10:32 +0000] "POST /admin/datasets/COUNT_AGGREGATOR%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_COUNT_AGGREGATOR+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 10
INFO  [2023-01-26 18:10:32,981] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:32,982] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:32,982] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:32,984] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:32,984] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[COUNT_AGGREGATOR$20Test.table.table], containing 5 entries.
INFO  [2023-01-26 18:10:32,984] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[COUNT_AGGREGATOR$20Test.table.table], containing 5 entries.
WARN  [2023-01-26 18:10:32,985] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:32,985] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received COUNT_AGGREGATOR$20Test.table.table.0
INFO  [2023-01-26 18:10:32,985] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received COUNT_AGGREGATOR$20Test.table.table.1
INFO  [2023-01-26 18:10:33,090] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:33,095] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:33,105] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:33,105] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:33,105] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:33,211] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: COUNT_AGGREGATOR Test QUERY INIT
INFO  [2023-01-26 18:10:33,225] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[COUNT_AGGREGATOR$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:33,225] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[fa94c8e9-e159-41aa-b547-0854f3f61a03] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_COUNT_AGGREGATOR Test))]]
INFO  [2023-01-26 18:10:33,228] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery COUNT_AGGREGATOR$20Test.fa94c8e9-e159-41aa-b547-0854f3f61a03
INFO  [2023-01-26 18:10:33,228] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery COUNT_AGGREGATOR$20Test.fa94c8e9-e159-41aa-b547-0854f3f61a03
INFO  [2023-01-26 18:10:33,228] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[COUNT_AGGREGATOR$20Test.fa94c8e9-e159-41aa-b547-0854f3f61a03] with 1 results within PT0.000531S
127.0.0.1 - - [26/Jan/2023:18:10:33 +0000] "POST /api/datasets/COUNT_AGGREGATOR$20Test/queries HTTP/1.1" 201 1316 "-" "Conquery (test client)" 5
INFO  [2023-01-26 18:10:33,229] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[COUNT_AGGREGATOR$20Test.fa94c8e9-e159-41aa-b547-0854f3f61a03] with 3 results within PT0.001022S
INFO  [2023-01-26 18:10:33,229] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=COUNT_AGGREGATOR$20Test.fa94c8e9-e159-41aa-b547-0854f3f61a03, workerId=COUNT_AGGREGATOR$20Test.worker_COUNT_AGGREGATOR$20Test_3f5ee12c-6386-496b-8892-7c39cf89c8ea, startTime=2023-01-26T18:10:33.228234, finishTime=2023-01-26T18:10:33.228765) of size 1
INFO  [2023-01-26 18:10:33,229] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=COUNT_AGGREGATOR$20Test.fa94c8e9-e159-41aa-b547-0854f3f61a03, workerId=COUNT_AGGREGATOR$20Test.worker_COUNT_AGGREGATOR$20Test_725f64ea-ef5d-4da2-b310-b8eb351e59eb, startTime=2023-01-26T18:10:33.228033, finishTime=2023-01-26T18:10:33.229055) of size 3
INFO  [2023-01-26 18:10:33,229] com.bakdata.conquery.models.execution.ManagedExecution: DONE fa94c8e9-e159-41aa-b547-0854f3f61a03 ManagedQuery within PT0.003737S
127.0.0.1 - - [26/Jan/2023:18:10:33 +0000] "GET /api/datasets/COUNT_AGGREGATOR$20Test/queries/COUNT_AGGREGATOR$20Test.fa94c8e9-e159-41aa-b547-0854f3f61a03 HTTP/1.1" 200 1599 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:10:33,260] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=COUNT_AGGREGATOR Test], queryId=fa94c8e9-e159-41aa-b547-0854f3f61a03, label=concept	@§$, creationTime=2023-01-26T18:10:33.225827, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@4042a1a6[Count = 0], startTime=2023-01-26T18:10:33.225985, finishTime=2023-01-26T18:10:33.229722, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2113adb5), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_COUNT_AGGREGATOR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@10dd05c, com.bakdata.conquery.models.query.ColumnDescriptor@b0acbab, com.bakdata.conquery.models.query.ColumnDescriptor@5e9004fd]) download on dataset Dataset[label=null, name=COUNT_AGGREGATOR Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:33,260] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=COUNT_AGGREGATOR Test], queryId=fa94c8e9-e159-41aa-b547-0854f3f61a03, label=concept	@§$, creationTime=2023-01-26T18:10:33.225827, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@4042a1a6[Count = 0], startTime=2023-01-26T18:10:33.225985, finishTime=2023-01-26T18:10:33.229722, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2113adb5), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_COUNT_AGGREGATOR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@10dd05c, com.bakdata.conquery.models.query.ColumnDescriptor@b0acbab, com.bakdata.conquery.models.query.ColumnDescriptor@5e9004fd]) on dataset Dataset[label=null, name=COUNT_AGGREGATOR Test]
127.0.0.1 - - [26/Jan/2023:18:10:33 +0000] "GET /api/datasets/COUNT_AGGREGATOR%20Test/result/COUNT_AGGREGATOR$20Test.fa94c8e9-e159-41aa-b547-0854f3f61a03.csv?pretty=false HTTP/1.1" 200 141 "-" "Conquery (test client)" 16
INFO  [2023-01-26 18:10:33,275] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest COUNT_AGGREGATOR Test on 5 rows
INFO  [2023-01-26 18:10:33,275] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast COUNT_AGGREGATOR Test
INFO  [2023-01-26 18:10:33,275] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=COUNT_AGGREGATOR Test, name=COUNT_AGGREGATOR Test]
INFO  [2023-01-26 18:10:33,275] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=COUNT_AGGREGATOR Test, name=COUNT_AGGREGATOR Test]
INFO  [2023-01-26 18:10:33,275] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_COUNT_AGGREGATOR Test_3f5ee12c-6386-496b-8892-7c39cf89c8ea
INFO  [2023-01-26 18:10:33,275] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_COUNT_AGGREGATOR Test_725f64ea-ef5d-4da2-b310-b8eb351e59eb
INFO  [2023-01-26 18:10:33,290] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow COUNT_AGGREGATOR Test
INFO  [2023-01-26 18:10:33,290] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_COUNT_AGGREGATOR Test_3f5ee12c-6386-496b-8892-7c39cf89c8ea
INFO  [2023-01-26 18:10:33,290] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_COUNT_AGGREGATOR Test_725f64ea-ef5d-4da2-b310-b8eb351e59eb
INFO  [2023-01-26 18:10:33,395] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of COUNT_AGGREGATOR$20Test
INFO  [2023-01-26 18:10:33,395] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:33,410] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test COUNT_AGGREGATOR Test
INFO  [2023-01-26 18:10:33,411] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test COUNT_DISTINCT_AGGREGATOR Test
INFO  [2023-01-26 18:10:33,411] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:33,411] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:33,412] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=COUNT_DISTINCT_AGGREGATOR Test, name=COUNT_DISTINCT_AGGREGATOR Test]
INFO  [2023-01-26 18:10:33,412] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:33,413] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=COUNT_DISTINCT_AGGREGATOR Test, name=COUNT_DISTINCT_AGGREGATOR Test]
INFO  [2023-01-26 18:10:33,413] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:33,420] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker COUNT_DISTINCT_AGGREGATOR$20Test.worker_COUNT_DISTINCT_AGGREGATOR$20Test_a28b888d-ecdd-4757-8631-49af27eed5a3 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:33,420] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker COUNT_DISTINCT_AGGREGATOR$20Test.worker_COUNT_DISTINCT_AGGREGATOR$20Test_a28b888d-ecdd-4757-8631-49af27eed5a3 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:33,420] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:33,438] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:33,438] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker COUNT_DISTINCT_AGGREGATOR$20Test.worker_COUNT_DISTINCT_AGGREGATOR$20Test_25ed060d-16f4-4a88-a669-add2bca58b3f are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:33,438] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker COUNT_DISTINCT_AGGREGATOR$20Test.worker_COUNT_DISTINCT_AGGREGATOR$20Test_25ed060d-16f4-4a88-a669-add2bca58b3f are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:33,438] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:33,542] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:33,549] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:33,549] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table COUNT_DISTINCT_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:33,549] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table COUNT_DISTINCT_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:33,665] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:33,774] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:33,774] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:33,774] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 115 B in total
INFO  [2023-01-26 18:10:33,774] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COUNT_DISTINCT_AGGREGATOR Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000867024sINFO  [2023-01-26 18:10:33,862] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=6, min=1, average=1.500000, max=2}
INFO  [2023-01-26 18:10:33,862] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with StringParser(super=Parser(lines=6, nullLines=1), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:33,862] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@3ccea232)
INFO  [2023-01-26 18:10:33,865] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COUNT_DISTINCT_AGGREGATOR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:33,865] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:33,865] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COUNT_DISTINCT_AGGREGATOR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:33,883] com.bakdata.conquery.models.jobs.ImportJob: Importing table into COUNT_DISTINCT_AGGREGATOR$20Test.table
127.0.0.1 - - [26/Jan/2023:18:10:33 +0000] "POST /admin/datasets/COUNT_DISTINCT_AGGREGATOR%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_COUNT_DISTINCT_AGGREGATOR+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 11
INFO  [2023-01-26 18:10:33,883] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:33,884] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:33,884] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:33,884] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:33,886] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:33,886] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[COUNT_DISTINCT_AGGREGATOR$20Test.table.table], containing 6 entries.
INFO  [2023-01-26 18:10:33,886] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[COUNT_DISTINCT_AGGREGATOR$20Test.table.table], containing 6 entries.
WARN  [2023-01-26 18:10:33,887] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:33,887] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received COUNT_DISTINCT_AGGREGATOR$20Test.table.table.0
INFO  [2023-01-26 18:10:33,887] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received COUNT_DISTINCT_AGGREGATOR$20Test.table.table.1
INFO  [2023-01-26 18:10:33,992] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:33,998] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:34,007] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:34,008] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:34,008] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:34,113] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: COUNT_DISTINCT_AGGREGATOR Test QUERY INIT
INFO  [2023-01-26 18:10:34,137] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[COUNT_DISTINCT_AGGREGATOR$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:34,137] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[706af0d7-2bac-44d8-bd6a-361d44e105dc] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_COUNT_DISTINCT_AGGREGATOR Test))]]
INFO  [2023-01-26 18:10:34,139] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery COUNT_DISTINCT_AGGREGATOR$20Test.706af0d7-2bac-44d8-bd6a-361d44e105dc
INFO  [2023-01-26 18:10:34,139] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery COUNT_DISTINCT_AGGREGATOR$20Test.706af0d7-2bac-44d8-bd6a-361d44e105dc
INFO  [2023-01-26 18:10:34,139] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[COUNT_DISTINCT_AGGREGATOR$20Test.706af0d7-2bac-44d8-bd6a-361d44e105dc] with 1 results within PT0.000369S
127.0.0.1 - - [26/Jan/2023:18:10:34 +0000] "POST /api/datasets/COUNT_DISTINCT_AGGREGATOR$20Test/queries HTTP/1.1" 201 1360 "-" "Conquery (test client)" 4
INFO  [2023-01-26 18:10:34,139] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=COUNT_DISTINCT_AGGREGATOR$20Test.706af0d7-2bac-44d8-bd6a-361d44e105dc, workerId=COUNT_DISTINCT_AGGREGATOR$20Test.worker_COUNT_DISTINCT_AGGREGATOR$20Test_a28b888d-ecdd-4757-8631-49af27eed5a3, startTime=2023-01-26T18:10:34.139044, finishTime=2023-01-26T18:10:34.139413) of size 1
INFO  [2023-01-26 18:10:34,143] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[COUNT_DISTINCT_AGGREGATOR$20Test.706af0d7-2bac-44d8-bd6a-361d44e105dc] with 3 results within PT0.004754S
INFO  [2023-01-26 18:10:34,144] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=COUNT_DISTINCT_AGGREGATOR$20Test.706af0d7-2bac-44d8-bd6a-361d44e105dc, workerId=COUNT_DISTINCT_AGGREGATOR$20Test.worker_COUNT_DISTINCT_AGGREGATOR$20Test_25ed060d-16f4-4a88-a669-add2bca58b3f, startTime=2023-01-26T18:10:34.139062, finishTime=2023-01-26T18:10:34.143816) of size 3
INFO  [2023-01-26 18:10:34,144] com.bakdata.conquery.models.execution.ManagedExecution: DONE 706af0d7-2bac-44d8-bd6a-361d44e105dc ManagedQuery within PT0.006822S
127.0.0.1 - - [26/Jan/2023:18:10:34 +0000] "GET /api/datasets/COUNT_DISTINCT_AGGREGATOR$20Test/queries/COUNT_DISTINCT_AGGREGATOR$20Test.706af0d7-2bac-44d8-bd6a-361d44e105dc HTTP/1.1" 200 1679 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:10:34,159] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=COUNT_DISTINCT_AGGREGATOR Test], queryId=706af0d7-2bac-44d8-bd6a-361d44e105dc, label=concept	@§$, creationTime=2023-01-26T18:10:34.137390, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@7b796fc3[Count = 0], startTime=2023-01-26T18:10:34.137496, finishTime=2023-01-26T18:10:34.144318, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@7bc627f4), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_COUNT_DISTINCT_AGGREGATOR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@5069a1e, com.bakdata.conquery.models.query.ColumnDescriptor@61d54f65, com.bakdata.conquery.models.query.ColumnDescriptor@516233eb]) download on dataset Dataset[label=null, name=COUNT_DISTINCT_AGGREGATOR Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:34,159] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=COUNT_DISTINCT_AGGREGATOR Test], queryId=706af0d7-2bac-44d8-bd6a-361d44e105dc, label=concept	@§$, creationTime=2023-01-26T18:10:34.137390, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@7b796fc3[Count = 0], startTime=2023-01-26T18:10:34.137496, finishTime=2023-01-26T18:10:34.144318, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@7bc627f4), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_COUNT_DISTINCT_AGGREGATOR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@5069a1e, com.bakdata.conquery.models.query.ColumnDescriptor@61d54f65, com.bakdata.conquery.models.query.ColumnDescriptor@516233eb]) on dataset Dataset[label=null, name=COUNT_DISTINCT_AGGREGATOR Test]
127.0.0.1 - - [26/Jan/2023:18:10:34 +0000] "GET /api/datasets/COUNT_DISTINCT_AGGREGATOR%20Test/result/COUNT_DISTINCT_AGGREGATOR$20Test.706af0d7-2bac-44d8-bd6a-361d44e105dc.csv?pretty=false HTTP/1.1" 200 141 "-" "Conquery (test client)" 19
INFO  [2023-01-26 18:10:34,177] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest COUNT_DISTINCT_AGGREGATOR Test on 5 rows
INFO  [2023-01-26 18:10:34,178] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast COUNT_DISTINCT_AGGREGATOR Test
INFO  [2023-01-26 18:10:34,178] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=COUNT_DISTINCT_AGGREGATOR Test, name=COUNT_DISTINCT_AGGREGATOR Test]
INFO  [2023-01-26 18:10:34,178] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=COUNT_DISTINCT_AGGREGATOR Test, name=COUNT_DISTINCT_AGGREGATOR Test]
INFO  [2023-01-26 18:10:34,178] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_COUNT_DISTINCT_AGGREGATOR Test_a28b888d-ecdd-4757-8631-49af27eed5a3
INFO  [2023-01-26 18:10:34,178] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_COUNT_DISTINCT_AGGREGATOR Test_25ed060d-16f4-4a88-a669-add2bca58b3f
INFO  [2023-01-26 18:10:34,213] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow COUNT_DISTINCT_AGGREGATOR Test
INFO  [2023-01-26 18:10:34,232] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_COUNT_DISTINCT_AGGREGATOR Test_a28b888d-ecdd-4757-8631-49af27eed5a3
INFO  [2023-01-26 18:10:34,238] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_COUNT_DISTINCT_AGGREGATOR Test_25ed060d-16f4-4a88-a669-add2bca58b3f
INFO  [2023-01-26 18:10:34,288] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of COUNT_DISTINCT_AGGREGATOR$20Test
INFO  [2023-01-26 18:10:34,288] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:34,413] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test COUNT_DISTINCT_AGGREGATOR Test
INFO  [2023-01-26 18:10:34,414] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test COUNT_QUARTERS_AGGREGATOR Test
INFO  [2023-01-26 18:10:34,414] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:34,414] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:34,414] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=COUNT_QUARTERS_AGGREGATOR Test, name=COUNT_QUARTERS_AGGREGATOR Test]
INFO  [2023-01-26 18:10:34,414] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=COUNT_QUARTERS_AGGREGATOR Test, name=COUNT_QUARTERS_AGGREGATOR Test]
INFO  [2023-01-26 18:10:34,414] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:34,414] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:34,420] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker COUNT_QUARTERS_AGGREGATOR$20Test.worker_COUNT_QUARTERS_AGGREGATOR$20Test_92ed8db7-bc24-46a5-b9e9-630b920da167 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:34,420] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker COUNT_QUARTERS_AGGREGATOR$20Test.worker_COUNT_QUARTERS_AGGREGATOR$20Test_92ed8db7-bc24-46a5-b9e9-630b920da167 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:34,420] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:34,420] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker COUNT_QUARTERS_AGGREGATOR$20Test.worker_COUNT_QUARTERS_AGGREGATOR$20Test_c5343096-6164-4082-9997-916104d41147 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:34,420] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker COUNT_QUARTERS_AGGREGATOR$20Test.worker_COUNT_QUARTERS_AGGREGATOR$20Test_c5343096-6164-4082-9997-916104d41147 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:34,420] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:34,420] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:34,525] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:34,531] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:34,531] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table COUNT_QUARTERS_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:34,532] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table COUNT_QUARTERS_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:34,649] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:34,760] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:34,760] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:34,761] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 460 B in total
INFO  [2023-01-26 18:10:34,761] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COUNT_QUARTERS_AGGREGATOR Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000389345sINFO  [2023-01-26 18:10:34,800] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=5, sum=12, min=1, average=2.400000, max=4}
INFO  [2023-01-26 18:10:34,800] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[behandlungsdatum] with DateParser(super=Parser(lines=12, nullLines=1), subType=IntegerParser(super=Parser(lines=12, nullLines=1), minValue=16467, maxValue=16740), dateReader=com.bakdata.conquery.util.DateReader@6ce06a22)
INFO  [2023-01-26 18:10:34,800] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=12, nullLines=0), minParser=DateParser(super=Parser(lines=12, nullLines=0), subType=IntegerParser(super=Parser(lines=12, nullLines=0), minValue=16436, maxValue=16436), dateReader=com.bakdata.conquery.util.DateReader@5af9ded6), maxParser=DateParser(super=Parser(lines=12, nullLines=0), subType=IntegerParser(super=Parser(lines=12, nullLines=0), minValue=17166, maxValue=17166), dateReader=com.bakdata.conquery.util.DateReader@22f7c0e4), dateReader=com.bakdata.conquery.util.DateReader@7adc1691, onlyQuarters=false, maxValue=17166, minValue=16436, anyOpen=false)
INFO  [2023-01-26 18:10:34,803] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COUNT_QUARTERS_AGGREGATOR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:34,803] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:34,803] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_COUNT_QUARTERS_AGGREGATOR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:34,821] com.bakdata.conquery.models.jobs.ImportJob: Importing table into COUNT_QUARTERS_AGGREGATOR$20Test.table
127.0.0.1 - - [26/Jan/2023:18:10:34 +0000] "POST /admin/datasets/COUNT_QUARTERS_AGGREGATOR%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_COUNT_QUARTERS_AGGREGATOR+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:10:34,821] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:34,822] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:34,822] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:34,822] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:34,823] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:34,823] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[COUNT_QUARTERS_AGGREGATOR$20Test.table.table], containing 12 entries.
INFO  [2023-01-26 18:10:34,823] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[COUNT_QUARTERS_AGGREGATOR$20Test.table.table], containing 12 entries.
WARN  [2023-01-26 18:10:34,824] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:34,825] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received COUNT_QUARTERS_AGGREGATOR$20Test.table.table.1
INFO  [2023-01-26 18:10:34,825] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received COUNT_QUARTERS_AGGREGATOR$20Test.table.table.0
INFO  [2023-01-26 18:10:34,929] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:34,935] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:34,947] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:34,947] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:34,947] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:35,052] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: COUNT_QUARTERS_AGGREGATOR Test QUERY INIT
INFO  [2023-01-26 18:10:35,062] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[COUNT_QUARTERS_AGGREGATOR$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:35,062] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[0d38bdc0-222b-4ce4-8e62-d0a245a8e25f] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_COUNT_QUARTERS_AGGREGATOR Test))]]
INFO  [2023-01-26 18:10:35,065] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery COUNT_QUARTERS_AGGREGATOR$20Test.0d38bdc0-222b-4ce4-8e62-d0a245a8e25f
INFO  [2023-01-26 18:10:35,065] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery COUNT_QUARTERS_AGGREGATOR$20Test.0d38bdc0-222b-4ce4-8e62-d0a245a8e25f
127.0.0.1 - - [26/Jan/2023:18:10:35 +0000] "POST /api/datasets/COUNT_QUARTERS_AGGREGATOR$20Test/queries HTTP/1.1" 201 1361 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:10:35,066] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[COUNT_QUARTERS_AGGREGATOR$20Test.0d38bdc0-222b-4ce4-8e62-d0a245a8e25f] with 2 results within PT0.001786S
INFO  [2023-01-26 18:10:35,067] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[COUNT_QUARTERS_AGGREGATOR$20Test.0d38bdc0-222b-4ce4-8e62-d0a245a8e25f] with 3 results within PT0.002182S
INFO  [2023-01-26 18:10:35,067] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=COUNT_QUARTERS_AGGREGATOR$20Test.0d38bdc0-222b-4ce4-8e62-d0a245a8e25f, workerId=COUNT_QUARTERS_AGGREGATOR$20Test.worker_COUNT_QUARTERS_AGGREGATOR$20Test_92ed8db7-bc24-46a5-b9e9-630b920da167, startTime=2023-01-26T18:10:35.065059, finishTime=2023-01-26T18:10:35.066845) of size 2
INFO  [2023-01-26 18:10:35,067] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=COUNT_QUARTERS_AGGREGATOR$20Test.0d38bdc0-222b-4ce4-8e62-d0a245a8e25f, workerId=COUNT_QUARTERS_AGGREGATOR$20Test.worker_COUNT_QUARTERS_AGGREGATOR$20Test_c5343096-6164-4082-9997-916104d41147, startTime=2023-01-26T18:10:35.065053, finishTime=2023-01-26T18:10:35.067235) of size 3
INFO  [2023-01-26 18:10:35,067] com.bakdata.conquery.models.execution.ManagedExecution: DONE 0d38bdc0-222b-4ce4-8e62-d0a245a8e25f ManagedQuery within PT0.004717S
127.0.0.1 - - [26/Jan/2023:18:10:35 +0000] "GET /api/datasets/COUNT_QUARTERS_AGGREGATOR$20Test/queries/COUNT_QUARTERS_AGGREGATOR$20Test.0d38bdc0-222b-4ce4-8e62-d0a245a8e25f HTTP/1.1" 200 1680 "-" "Conquery (test client)" 1
INFO  [2023-01-26 18:10:35,084] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=COUNT_QUARTERS_AGGREGATOR Test], queryId=0d38bdc0-222b-4ce4-8e62-d0a245a8e25f, label=concept	@§$, creationTime=2023-01-26T18:10:35.062844, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@341199ef[Count = 0], startTime=2023-01-26T18:10:35.062987, finishTime=2023-01-26T18:10:35.067704, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@3c117c53), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_COUNT_QUARTERS_AGGREGATOR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=5, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@40397aeb, com.bakdata.conquery.models.query.ColumnDescriptor@1db09a6c, com.bakdata.conquery.models.query.ColumnDescriptor@25d6b6d4]) download on dataset Dataset[label=null, name=COUNT_QUARTERS_AGGREGATOR Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:35,084] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=COUNT_QUARTERS_AGGREGATOR Test], queryId=0d38bdc0-222b-4ce4-8e62-d0a245a8e25f, label=concept	@§$, creationTime=2023-01-26T18:10:35.062844, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@341199ef[Count = 0], startTime=2023-01-26T18:10:35.062987, finishTime=2023-01-26T18:10:35.067704, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@3c117c53), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_COUNT_QUARTERS_AGGREGATOR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=5, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@40397aeb, com.bakdata.conquery.models.query.ColumnDescriptor@1db09a6c, com.bakdata.conquery.models.query.ColumnDescriptor@25d6b6d4]) on dataset Dataset[label=null, name=COUNT_QUARTERS_AGGREGATOR Test]
127.0.0.1 - - [26/Jan/2023:18:10:35 +0000] "GET /api/datasets/COUNT_QUARTERS_AGGREGATOR%20Test/result/COUNT_QUARTERS_AGGREGATOR$20Test.0d38bdc0-222b-4ce4-8e62-d0a245a8e25f.csv?pretty=false HTTP/1.1" 200 169 "-" "Conquery (test client)" 14
INFO  [2023-01-26 18:10:35,097] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest COUNT_QUARTERS_AGGREGATOR Test on 6 rows
INFO  [2023-01-26 18:10:35,097] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast COUNT_QUARTERS_AGGREGATOR Test
INFO  [2023-01-26 18:10:35,098] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=COUNT_QUARTERS_AGGREGATOR Test, name=COUNT_QUARTERS_AGGREGATOR Test]
INFO  [2023-01-26 18:10:35,098] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_COUNT_QUARTERS_AGGREGATOR Test_92ed8db7-bc24-46a5-b9e9-630b920da167
INFO  [2023-01-26 18:10:35,098] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=COUNT_QUARTERS_AGGREGATOR Test, name=COUNT_QUARTERS_AGGREGATOR Test]
INFO  [2023-01-26 18:10:35,098] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_COUNT_QUARTERS_AGGREGATOR Test_c5343096-6164-4082-9997-916104d41147
INFO  [2023-01-26 18:10:35,116] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow COUNT_QUARTERS_AGGREGATOR Test
INFO  [2023-01-26 18:10:35,120] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_COUNT_QUARTERS_AGGREGATOR Test_92ed8db7-bc24-46a5-b9e9-630b920da167
INFO  [2023-01-26 18:10:35,120] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_COUNT_QUARTERS_AGGREGATOR Test_c5343096-6164-4082-9997-916104d41147
INFO  [2023-01-26 18:10:35,125] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of COUNT_QUARTERS_AGGREGATOR$20Test
INFO  [2023-01-26 18:10:35,125] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:35,253] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test COUNT_QUARTERS_AGGREGATOR Test
INFO  [2023-01-26 18:10:35,253] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test DATE_DISTANCE_AGGREGATOR Test
INFO  [2023-01-26 18:10:35,254] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:35,254] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:35,259] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DATE_DISTANCE_AGGREGATOR Test, name=DATE_DISTANCE_AGGREGATOR Test]
INFO  [2023-01-26 18:10:35,259] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DATE_DISTANCE_AGGREGATOR Test, name=DATE_DISTANCE_AGGREGATOR Test]
INFO  [2023-01-26 18:10:35,259] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:35,259] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:35,266] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DATE_DISTANCE_AGGREGATOR$20Test.worker_DATE_DISTANCE_AGGREGATOR$20Test_cf04cd8e-cdea-4ce4-9278-3893cc17d82e are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:35,266] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DATE_DISTANCE_AGGREGATOR$20Test.worker_DATE_DISTANCE_AGGREGATOR$20Test_cf04cd8e-cdea-4ce4-9278-3893cc17d82e are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:35,266] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:35,266] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DATE_DISTANCE_AGGREGATOR$20Test.worker_DATE_DISTANCE_AGGREGATOR$20Test_63540730-d3a3-46b5-8d94-f4b283eddd52 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:35,266] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DATE_DISTANCE_AGGREGATOR$20Test.worker_DATE_DISTANCE_AGGREGATOR$20Test_63540730-d3a3-46b5-8d94-f4b283eddd52 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:35,266] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:35,270] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:35,368] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:35,375] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:35,375] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DATE_DISTANCE_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:35,375] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DATE_DISTANCE_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:35,488] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:35,598] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:35,598] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:35,598] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 381 B in total
INFO  [2023-01-26 18:10:35,598] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_AGGREGATOR Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000381329sINFO  [2023-01-26 18:10:35,637] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=10, sum=10, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:10:35,637] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=10, nullLines=1), subType=IntegerParser(super=Parser(lines=10, nullLines=1), minValue=10226, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@60e11994)
INFO  [2023-01-26 18:10:35,637] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[indexdatum] with DateRangeParser(super=Parser(lines=10, nullLines=0), minParser=DateParser(super=Parser(lines=10, nullLines=0), subType=IntegerParser(super=Parser(lines=10, nullLines=0), minValue=14610, maxValue=14610), dateReader=com.bakdata.conquery.util.DateReader@6d721d9), maxParser=DateParser(super=Parser(lines=10, nullLines=0), subType=IntegerParser(super=Parser(lines=10, nullLines=0), minValue=14699, maxValue=14699), dateReader=com.bakdata.conquery.util.DateReader@71b2d3db), dateReader=com.bakdata.conquery.util.DateReader@382420ed, onlyQuarters=true, maxValue=14699, minValue=14610, anyOpen=false)
INFO  [2023-01-26 18:10:35,639] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_AGGREGATOR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:35,640] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:35,640] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_AGGREGATOR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:35,656] com.bakdata.conquery.models.jobs.ImportJob: Importing table into DATE_DISTANCE_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:35,657] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:35,657] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:35,657] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:35,658] com.bakdata.conquery.models.jobs.ImportJob: Start sending 4 Buckets
INFO  [2023-01-26 18:10:35,659] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DATE_DISTANCE_AGGREGATOR$20Test.table.table], containing 10 entries.
WARN  [2023-01-26 18:10:35,659] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:35,659] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGGREGATOR$20Test.table.table.1
INFO  [2023-01-26 18:10:35,660] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGGREGATOR$20Test.table.table.3
127.0.0.1 - - [26/Jan/2023:18:10:35 +0000] "POST /admin/datasets/DATE_DISTANCE_AGGREGATOR%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_DATE_DISTANCE_AGGREGATOR+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 11
INFO  [2023-01-26 18:10:35,660] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DATE_DISTANCE_AGGREGATOR$20Test.table.table], containing 10 entries.
INFO  [2023-01-26 18:10:35,660] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGGREGATOR$20Test.table.table.0
INFO  [2023-01-26 18:10:35,660] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGGREGATOR$20Test.table.table.2
INFO  [2023-01-26 18:10:35,660] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:35,765] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:35,770] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:35,780] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:35,781] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:35,781] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:35,886] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: DATE_DISTANCE_AGGREGATOR Test QUERY INIT
INFO  [2023-01-26 18:10:35,899] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[DATE_DISTANCE_AGGREGATOR$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:35,899] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[59e0cb5c-6e3c-4084-b61d-ace28cfed6e6] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_AGGREGATOR Test))]]
INFO  [2023-01-26 18:10:35,902] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DATE_DISTANCE_AGGREGATOR$20Test.59e0cb5c-6e3c-4084-b61d-ace28cfed6e6
INFO  [2023-01-26 18:10:35,902] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DATE_DISTANCE_AGGREGATOR$20Test.59e0cb5c-6e3c-4084-b61d-ace28cfed6e6
127.0.0.1 - - [26/Jan/2023:18:10:35 +0000] "POST /api/datasets/DATE_DISTANCE_AGGREGATOR$20Test/queries HTTP/1.1" 201 1457 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:10:35,918] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DATE_DISTANCE_AGGREGATOR$20Test.59e0cb5c-6e3c-4084-b61d-ace28cfed6e6] with 6 results within PT0.016399S
INFO  [2023-01-26 18:10:35,919] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DATE_DISTANCE_AGGREGATOR$20Test.59e0cb5c-6e3c-4084-b61d-ace28cfed6e6, workerId=DATE_DISTANCE_AGGREGATOR$20Test.worker_DATE_DISTANCE_AGGREGATOR$20Test_cf04cd8e-cdea-4ce4-9278-3893cc17d82e, startTime=2023-01-26T18:10:35.902558, finishTime=2023-01-26T18:10:35.918957) of size 6
INFO  [2023-01-26 18:10:35,923] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DATE_DISTANCE_AGGREGATOR$20Test.59e0cb5c-6e3c-4084-b61d-ace28cfed6e6] with 4 results within PT0.020533S
INFO  [2023-01-26 18:10:35,923] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DATE_DISTANCE_AGGREGATOR$20Test.59e0cb5c-6e3c-4084-b61d-ace28cfed6e6, workerId=DATE_DISTANCE_AGGREGATOR$20Test.worker_DATE_DISTANCE_AGGREGATOR$20Test_63540730-d3a3-46b5-8d94-f4b283eddd52, startTime=2023-01-26T18:10:35.902620, finishTime=2023-01-26T18:10:35.923153) of size 4
INFO  [2023-01-26 18:10:35,923] com.bakdata.conquery.models.execution.ManagedExecution: DONE 59e0cb5c-6e3c-4084-b61d-ace28cfed6e6 ManagedQuery within PT0.024033S
127.0.0.1 - - [26/Jan/2023:18:10:35 +0000] "GET /api/datasets/DATE_DISTANCE_AGGREGATOR$20Test/queries/DATE_DISTANCE_AGGREGATOR$20Test.59e0cb5c-6e3c-4084-b61d-ace28cfed6e6 HTTP/1.1" 200 1774 "-" "Conquery (test client)" 13
INFO  [2023-01-26 18:10:35,933] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DATE_DISTANCE_AGGREGATOR Test], queryId=59e0cb5c-6e3c-4084-b61d-ace28cfed6e6, label=concept	@§$, creationTime=2023-01-26T18:10:35.899572, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@509b98f0[Count = 0], startTime=2023-01-26T18:10:35.899794, finishTime=2023-01-26T18:10:35.923827, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@595b8927), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_AGGREGATOR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=10, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@41f0fd7c, com.bakdata.conquery.models.query.ColumnDescriptor@37368908, com.bakdata.conquery.models.query.ColumnDescriptor@3be6cb06]) download on dataset Dataset[label=null, name=DATE_DISTANCE_AGGREGATOR Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:35,933] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DATE_DISTANCE_AGGREGATOR Test], queryId=59e0cb5c-6e3c-4084-b61d-ace28cfed6e6, label=concept	@§$, creationTime=2023-01-26T18:10:35.899572, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@509b98f0[Count = 0], startTime=2023-01-26T18:10:35.899794, finishTime=2023-01-26T18:10:35.923827, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@595b8927), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_AGGREGATOR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=10, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@41f0fd7c, com.bakdata.conquery.models.query.ColumnDescriptor@37368908, com.bakdata.conquery.models.query.ColumnDescriptor@3be6cb06]) on dataset Dataset[label=null, name=DATE_DISTANCE_AGGREGATOR Test]
127.0.0.1 - - [26/Jan/2023:18:10:35 +0000] "GET /api/datasets/DATE_DISTANCE_AGGREGATOR%20Test/result/DATE_DISTANCE_AGGREGATOR$20Test.59e0cb5c-6e3c-4084-b61d-ace28cfed6e6.csv?pretty=false HTTP/1.1" 200 316 "-" "Conquery (test client)" 17
INFO  [2023-01-26 18:10:35,950] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest DATE_DISTANCE_AGGREGATOR Test on 11 rows
INFO  [2023-01-26 18:10:35,950] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast DATE_DISTANCE_AGGREGATOR Test
INFO  [2023-01-26 18:10:35,950] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DATE_DISTANCE_AGGREGATOR Test, name=DATE_DISTANCE_AGGREGATOR Test]
INFO  [2023-01-26 18:10:35,950] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DATE_DISTANCE_AGGREGATOR Test, name=DATE_DISTANCE_AGGREGATOR Test]
INFO  [2023-01-26 18:10:35,950] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DATE_DISTANCE_AGGREGATOR Test_63540730-d3a3-46b5-8d94-f4b283eddd52
INFO  [2023-01-26 18:10:35,950] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DATE_DISTANCE_AGGREGATOR Test_cf04cd8e-cdea-4ce4-9278-3893cc17d82e
INFO  [2023-01-26 18:10:35,959] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow DATE_DISTANCE_AGGREGATOR Test
INFO  [2023-01-26 18:10:35,959] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of DATE_DISTANCE_AGGREGATOR$20Test
INFO  [2023-01-26 18:10:35,959] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:35,964] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DATE_DISTANCE_AGGREGATOR Test_63540730-d3a3-46b5-8d94-f4b283eddd52
INFO  [2023-01-26 18:10:35,964] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DATE_DISTANCE_AGGREGATOR Test_cf04cd8e-cdea-4ce4-9278-3893cc17d82e
INFO  [2023-01-26 18:10:36,086] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test DATE_DISTANCE_AGGREGATOR Test
INFO  [2023-01-26 18:10:36,086] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test DATE_DISTANCE_AGGREGATOR2 Test
INFO  [2023-01-26 18:10:36,086] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:36,086] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:36,087] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DATE_DISTANCE_AGGREGATOR2 Test, name=DATE_DISTANCE_AGGREGATOR2 Test]
INFO  [2023-01-26 18:10:36,087] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DATE_DISTANCE_AGGREGATOR2 Test, name=DATE_DISTANCE_AGGREGATOR2 Test]
INFO  [2023-01-26 18:10:36,087] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:36,087] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:36,090] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DATE_DISTANCE_AGGREGATOR2$20Test.worker_DATE_DISTANCE_AGGREGATOR2$20Test_a22e2599-dea9-400b-832c-5f1a59019ece are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:36,090] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DATE_DISTANCE_AGGREGATOR2$20Test.worker_DATE_DISTANCE_AGGREGATOR2$20Test_a22e2599-dea9-400b-832c-5f1a59019ece are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:36,090] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:36,090] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DATE_DISTANCE_AGGREGATOR2$20Test.worker_DATE_DISTANCE_AGGREGATOR2$20Test_990719db-5326-469e-8279-fd5106472999 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:36,090] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DATE_DISTANCE_AGGREGATOR2$20Test.worker_DATE_DISTANCE_AGGREGATOR2$20Test_990719db-5326-469e-8279-fd5106472999 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:36,090] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:36,093] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:36,195] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:36,201] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:36,201] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DATE_DISTANCE_AGGREGATOR2$20Test.table
INFO  [2023-01-26 18:10:36,201] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DATE_DISTANCE_AGGREGATOR2$20Test.table
INFO  [2023-01-26 18:10:36,321] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:36,431] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:36,431] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:36,431] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 381 B in total
INFO  [2023-01-26 18:10:36,431] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_AGGREGATOR2 Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000264485sINFO  [2023-01-26 18:10:36,458] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=10, sum=10, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:10:36,458] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=10, nullLines=1), subType=IntegerParser(super=Parser(lines=10, nullLines=1), minValue=10226, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@5bce3482)
INFO  [2023-01-26 18:10:36,458] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[indexdatum] with DateRangeParser(super=Parser(lines=10, nullLines=0), minParser=DateParser(super=Parser(lines=10, nullLines=0), subType=IntegerParser(super=Parser(lines=10, nullLines=0), minValue=14610, maxValue=14610), dateReader=com.bakdata.conquery.util.DateReader@577afcb1), maxParser=DateParser(super=Parser(lines=10, nullLines=0), subType=IntegerParser(super=Parser(lines=10, nullLines=0), minValue=14699, maxValue=14699), dateReader=com.bakdata.conquery.util.DateReader@681cc66e), dateReader=com.bakdata.conquery.util.DateReader@f57fcbd, onlyQuarters=true, maxValue=14699, minValue=14610, anyOpen=false)
INFO  [2023-01-26 18:10:36,461] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_AGGREGATOR2 Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:36,461] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:36,461] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DATE_DISTANCE_AGGREGATOR2 Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:36,484] com.bakdata.conquery.models.jobs.ImportJob: Importing table into DATE_DISTANCE_AGGREGATOR2$20Test.table
INFO  [2023-01-26 18:10:36,484] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:10:36 +0000] "POST /admin/datasets/DATE_DISTANCE_AGGREGATOR2%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_DATE_DISTANCE_AGGREGATOR2+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 14
INFO  [2023-01-26 18:10:36,485] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:36,485] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:36,485] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:36,486] com.bakdata.conquery.models.jobs.ImportJob: Start sending 4 Buckets
INFO  [2023-01-26 18:10:36,487] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DATE_DISTANCE_AGGREGATOR2$20Test.table.table], containing 10 entries.
INFO  [2023-01-26 18:10:36,487] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DATE_DISTANCE_AGGREGATOR2$20Test.table.table], containing 10 entries.
WARN  [2023-01-26 18:10:36,488] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:36,488] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGGREGATOR2$20Test.table.table.1
INFO  [2023-01-26 18:10:36,488] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGGREGATOR2$20Test.table.table.0
INFO  [2023-01-26 18:10:36,488] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGGREGATOR2$20Test.table.table.3
INFO  [2023-01-26 18:10:36,488] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DATE_DISTANCE_AGGREGATOR2$20Test.table.table.2
INFO  [2023-01-26 18:10:36,593] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:36,598] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:36,611] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:36,611] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:36,611] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:36,717] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: DATE_DISTANCE_AGGREGATOR2 Test QUERY INIT
INFO  [2023-01-26 18:10:36,749] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[DATE_DISTANCE_AGGREGATOR2$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:36,749] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[8207a388-c85d-4b3e-8e20-09172aa513da] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_AGGREGATOR2 Test))]]
INFO  [2023-01-26 18:10:36,751] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DATE_DISTANCE_AGGREGATOR2$20Test.8207a388-c85d-4b3e-8e20-09172aa513da
INFO  [2023-01-26 18:10:36,751] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DATE_DISTANCE_AGGREGATOR2$20Test.8207a388-c85d-4b3e-8e20-09172aa513da
127.0.0.1 - - [26/Jan/2023:18:10:36 +0000] "POST /api/datasets/DATE_DISTANCE_AGGREGATOR2$20Test/queries HTTP/1.1" 201 1457 "-" "Conquery (test client)" 4
INFO  [2023-01-26 18:10:36,755] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DATE_DISTANCE_AGGREGATOR2$20Test.8207a388-c85d-4b3e-8e20-09172aa513da] with 4 results within PT0.003449S
INFO  [2023-01-26 18:10:36,755] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DATE_DISTANCE_AGGREGATOR2$20Test.8207a388-c85d-4b3e-8e20-09172aa513da] with 6 results within PT0.003499S
INFO  [2023-01-26 18:10:36,755] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DATE_DISTANCE_AGGREGATOR2$20Test.8207a388-c85d-4b3e-8e20-09172aa513da, workerId=DATE_DISTANCE_AGGREGATOR2$20Test.worker_DATE_DISTANCE_AGGREGATOR2$20Test_a22e2599-dea9-400b-832c-5f1a59019ece, startTime=2023-01-26T18:10:36.751906, finishTime=2023-01-26T18:10:36.755405) of size 6
INFO  [2023-01-26 18:10:36,755] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DATE_DISTANCE_AGGREGATOR2$20Test.8207a388-c85d-4b3e-8e20-09172aa513da, workerId=DATE_DISTANCE_AGGREGATOR2$20Test.worker_DATE_DISTANCE_AGGREGATOR2$20Test_990719db-5326-469e-8279-fd5106472999, startTime=2023-01-26T18:10:36.751902, finishTime=2023-01-26T18:10:36.755351) of size 4
INFO  [2023-01-26 18:10:36,756] com.bakdata.conquery.models.execution.ManagedExecution: DONE 8207a388-c85d-4b3e-8e20-09172aa513da ManagedQuery within PT0.006009S
127.0.0.1 - - [26/Jan/2023:18:10:36 +0000] "GET /api/datasets/DATE_DISTANCE_AGGREGATOR2$20Test/queries/DATE_DISTANCE_AGGREGATOR2$20Test.8207a388-c85d-4b3e-8e20-09172aa513da HTTP/1.1" 200 1777 "-" "Conquery (test client)" 1
INFO  [2023-01-26 18:10:36,767] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DATE_DISTANCE_AGGREGATOR2 Test], queryId=8207a388-c85d-4b3e-8e20-09172aa513da, label=concept	@§$, creationTime=2023-01-26T18:10:36.749880, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@1e9ff047[Count = 0], startTime=2023-01-26T18:10:36.750, finishTime=2023-01-26T18:10:36.756009, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@5f92b763), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_AGGREGATOR2 Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=10, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@254a7487, com.bakdata.conquery.models.query.ColumnDescriptor@2d859b40, com.bakdata.conquery.models.query.ColumnDescriptor@4cf95b7f]) download on dataset Dataset[label=null, name=DATE_DISTANCE_AGGREGATOR2 Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:36,768] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DATE_DISTANCE_AGGREGATOR2 Test], queryId=8207a388-c85d-4b3e-8e20-09172aa513da, label=concept	@§$, creationTime=2023-01-26T18:10:36.749880, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@1e9ff047[Count = 0], startTime=2023-01-26T18:10:36.750, finishTime=2023-01-26T18:10:36.756009, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@5f92b763), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DATE_DISTANCE_AGGREGATOR2 Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=10, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@254a7487, com.bakdata.conquery.models.query.ColumnDescriptor@2d859b40, com.bakdata.conquery.models.query.ColumnDescriptor@4cf95b7f]) on dataset Dataset[label=null, name=DATE_DISTANCE_AGGREGATOR2 Test]
127.0.0.1 - - [26/Jan/2023:18:10:36 +0000] "GET /api/datasets/DATE_DISTANCE_AGGREGATOR2%20Test/result/DATE_DISTANCE_AGGREGATOR2$20Test.8207a388-c85d-4b3e-8e20-09172aa513da.csv?pretty=false HTTP/1.1" 200 316 "-" "Conquery (test client)" 14
INFO  [2023-01-26 18:10:36,781] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest DATE_DISTANCE_AGGREGATOR2 Test on 11 rows
INFO  [2023-01-26 18:10:36,781] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast DATE_DISTANCE_AGGREGATOR2 Test
INFO  [2023-01-26 18:10:36,782] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DATE_DISTANCE_AGGREGATOR2 Test, name=DATE_DISTANCE_AGGREGATOR2 Test]
INFO  [2023-01-26 18:10:36,782] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DATE_DISTANCE_AGGREGATOR2 Test, name=DATE_DISTANCE_AGGREGATOR2 Test]
INFO  [2023-01-26 18:10:36,782] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DATE_DISTANCE_AGGREGATOR2 Test_990719db-5326-469e-8279-fd5106472999
INFO  [2023-01-26 18:10:36,782] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DATE_DISTANCE_AGGREGATOR2 Test_a22e2599-dea9-400b-832c-5f1a59019ece
INFO  [2023-01-26 18:10:36,787] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow DATE_DISTANCE_AGGREGATOR2 Test
INFO  [2023-01-26 18:10:36,788] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of DATE_DISTANCE_AGGREGATOR2$20Test
INFO  [2023-01-26 18:10:36,788] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:36,790] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DATE_DISTANCE_AGGREGATOR2 Test_990719db-5326-469e-8279-fd5106472999
INFO  [2023-01-26 18:10:36,790] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DATE_DISTANCE_AGGREGATOR2 Test_a22e2599-dea9-400b-832c-5f1a59019ece
INFO  [2023-01-26 18:10:36,916] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test DATE_DISTANCE_AGGREGATOR2 Test
INFO  [2023-01-26 18:10:36,917] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test DURATION_SUM_AGGREGATOR Test
INFO  [2023-01-26 18:10:36,917] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:36,917] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:36,918] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DURATION_SUM_AGGREGATOR Test, name=DURATION_SUM_AGGREGATOR Test]
INFO  [2023-01-26 18:10:36,918] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=DURATION_SUM_AGGREGATOR Test, name=DURATION_SUM_AGGREGATOR Test]
INFO  [2023-01-26 18:10:36,919] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:36,919] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:36,923] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DURATION_SUM_AGGREGATOR$20Test.worker_DURATION_SUM_AGGREGATOR$20Test_4c76fda8-39cb-4c3f-bf49-2efcc2919538 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:36,923] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DURATION_SUM_AGGREGATOR$20Test.worker_DURATION_SUM_AGGREGATOR$20Test_4c76fda8-39cb-4c3f-bf49-2efcc2919538 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:36,923] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:36,923] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker DURATION_SUM_AGGREGATOR$20Test.worker_DURATION_SUM_AGGREGATOR$20Test_9884d27b-e005-47cb-8dac-1764a327f629 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:36,923] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker DURATION_SUM_AGGREGATOR$20Test.worker_DURATION_SUM_AGGREGATOR$20Test_9884d27b-e005-47cb-8dac-1764a327f629 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:36,923] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:36,925] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:37,028] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:37,035] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:37,035] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DURATION_SUM_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:37,035] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table DURATION_SUM_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:37,147] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:37,255] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:37,255] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:37,255] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 166 B in total
INFO  [2023-01-26 18:10:37,255] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DURATION_SUM_AGGREGATOR Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000273638sINFO  [2023-01-26 18:10:37,283] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=6, min=1, average=1.500000, max=2}
INFO  [2023-01-26 18:10:37,283] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=6, nullLines=0), minParser=DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=14610, maxValue=15927), dateReader=com.bakdata.conquery.util.DateReader@221a14c3), maxParser=DateParser(super=Parser(lines=6, nullLines=0), subType=IntegerParser(super=Parser(lines=6, nullLines=0), minValue=14640, maxValue=15928), dateReader=com.bakdata.conquery.util.DateReader@57e7857e), dateReader=com.bakdata.conquery.util.DateReader@2d8a8771, onlyQuarters=false, maxValue=15928, minValue=14610, anyOpen=false)
INFO  [2023-01-26 18:10:37,285] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DURATION_SUM_AGGREGATOR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:37,286] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:37,286] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_DURATION_SUM_AGGREGATOR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:37,301] com.bakdata.conquery.models.jobs.ImportJob: Importing table into DURATION_SUM_AGGREGATOR$20Test.table
127.0.0.1 - - [26/Jan/2023:18:10:37 +0000] "POST /admin/datasets/DURATION_SUM_AGGREGATOR%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_DURATION_SUM_AGGREGATOR+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:10:37,301] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:37,302] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:37,302] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:37,302] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:37,303] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
WARN  [2023-01-26 18:10:37,304] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:37,305] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DURATION_SUM_AGGREGATOR$20Test.table.table], containing 6 entries.
INFO  [2023-01-26 18:10:37,305] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[DURATION_SUM_AGGREGATOR$20Test.table.table], containing 6 entries.
INFO  [2023-01-26 18:10:37,305] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DURATION_SUM_AGGREGATOR$20Test.table.table.0
INFO  [2023-01-26 18:10:37,305] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received DURATION_SUM_AGGREGATOR$20Test.table.table.1
INFO  [2023-01-26 18:10:37,410] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:37,415] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:37,425] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:37,425] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:37,425] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:37,531] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: DURATION_SUM_AGGREGATOR Test QUERY INIT
INFO  [2023-01-26 18:10:37,546] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[DURATION_SUM_AGGREGATOR$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:37,546] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[dfd135cc-0f1c-4301-94c5-2af888aa67bc] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_DURATION_SUM_AGGREGATOR Test))]]
INFO  [2023-01-26 18:10:37,549] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DURATION_SUM_AGGREGATOR$20Test.dfd135cc-0f1c-4301-94c5-2af888aa67bc
INFO  [2023-01-26 18:10:37,549] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery DURATION_SUM_AGGREGATOR$20Test.dfd135cc-0f1c-4301-94c5-2af888aa67bc
INFO  [2023-01-26 18:10:37,549] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DURATION_SUM_AGGREGATOR$20Test.dfd135cc-0f1c-4301-94c5-2af888aa67bc] with 1 results within PT0.000676S
127.0.0.1 - - [26/Jan/2023:18:10:37 +0000] "POST /api/datasets/DURATION_SUM_AGGREGATOR$20Test/queries HTTP/1.1" 201 1351 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:10:37,550] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DURATION_SUM_AGGREGATOR$20Test.dfd135cc-0f1c-4301-94c5-2af888aa67bc, workerId=DURATION_SUM_AGGREGATOR$20Test.worker_DURATION_SUM_AGGREGATOR$20Test_9884d27b-e005-47cb-8dac-1764a327f629, startTime=2023-01-26T18:10:37.549060, finishTime=2023-01-26T18:10:37.549736) of size 1
INFO  [2023-01-26 18:10:37,550] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[DURATION_SUM_AGGREGATOR$20Test.dfd135cc-0f1c-4301-94c5-2af888aa67bc] with 3 results within PT0.001258S
INFO  [2023-01-26 18:10:37,550] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=DURATION_SUM_AGGREGATOR$20Test.dfd135cc-0f1c-4301-94c5-2af888aa67bc, workerId=DURATION_SUM_AGGREGATOR$20Test.worker_DURATION_SUM_AGGREGATOR$20Test_4c76fda8-39cb-4c3f-bf49-2efcc2919538, startTime=2023-01-26T18:10:37.549081, finishTime=2023-01-26T18:10:37.550339) of size 3
INFO  [2023-01-26 18:10:37,550] com.bakdata.conquery.models.execution.ManagedExecution: DONE dfd135cc-0f1c-4301-94c5-2af888aa67bc ManagedQuery within PT0.003968S
127.0.0.1 - - [26/Jan/2023:18:10:37 +0000] "GET /api/datasets/DURATION_SUM_AGGREGATOR$20Test/queries/DURATION_SUM_AGGREGATOR$20Test.dfd135cc-0f1c-4301-94c5-2af888aa67bc HTTP/1.1" 200 1662 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:10:37,580] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DURATION_SUM_AGGREGATOR Test], queryId=dfd135cc-0f1c-4301-94c5-2af888aa67bc, label=concept	@§$, creationTime=2023-01-26T18:10:37.546709, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@1843112a[Count = 0], startTime=2023-01-26T18:10:37.546864, finishTime=2023-01-26T18:10:37.550832, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@6b0a4f7c), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DURATION_SUM_AGGREGATOR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@2d23f6d1, com.bakdata.conquery.models.query.ColumnDescriptor@c627b2b, com.bakdata.conquery.models.query.ColumnDescriptor@ca8f1cc]) download on dataset Dataset[label=null, name=DURATION_SUM_AGGREGATOR Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:37,580] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=DURATION_SUM_AGGREGATOR Test], queryId=dfd135cc-0f1c-4301-94c5-2af888aa67bc, label=concept	@§$, creationTime=2023-01-26T18:10:37.546709, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@1843112a[Count = 0], startTime=2023-01-26T18:10:37.546864, finishTime=2023-01-26T18:10:37.550832, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@6b0a4f7c), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_DURATION_SUM_AGGREGATOR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@2d23f6d1, com.bakdata.conquery.models.query.ColumnDescriptor@c627b2b, com.bakdata.conquery.models.query.ColumnDescriptor@ca8f1cc]) on dataset Dataset[label=null, name=DURATION_SUM_AGGREGATOR Test]
127.0.0.1 - - [26/Jan/2023:18:10:37 +0000] "GET /api/datasets/DURATION_SUM_AGGREGATOR%20Test/result/DURATION_SUM_AGGREGATOR$20Test.dfd135cc-0f1c-4301-94c5-2af888aa67bc.csv?pretty=false HTTP/1.1" 200 144 "-" "Conquery (test client)" 17
INFO  [2023-01-26 18:10:37,595] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest DURATION_SUM_AGGREGATOR Test on 5 rows
INFO  [2023-01-26 18:10:37,595] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast DURATION_SUM_AGGREGATOR Test
INFO  [2023-01-26 18:10:37,596] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DURATION_SUM_AGGREGATOR Test, name=DURATION_SUM_AGGREGATOR Test]
INFO  [2023-01-26 18:10:37,596] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=DURATION_SUM_AGGREGATOR Test, name=DURATION_SUM_AGGREGATOR Test]
INFO  [2023-01-26 18:10:37,596] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DURATION_SUM_AGGREGATOR Test_9884d27b-e005-47cb-8dac-1764a327f629
INFO  [2023-01-26 18:10:37,596] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_DURATION_SUM_AGGREGATOR Test_4c76fda8-39cb-4c3f-bf49-2efcc2919538
INFO  [2023-01-26 18:10:37,619] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow DURATION_SUM_AGGREGATOR Test
INFO  [2023-01-26 18:10:37,623] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DURATION_SUM_AGGREGATOR Test_4c76fda8-39cb-4c3f-bf49-2efcc2919538
INFO  [2023-01-26 18:10:37,623] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_DURATION_SUM_AGGREGATOR Test_9884d27b-e005-47cb-8dac-1764a327f629
INFO  [2023-01-26 18:10:37,704] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of DURATION_SUM_AGGREGATOR$20Test
INFO  [2023-01-26 18:10:37,704] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:37,731] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test DURATION_SUM_AGGREGATOR Test
INFO  [2023-01-26 18:10:37,732] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test EVENT_DATE_AGGREGATOR_NO_RESTRICTION Test
INFO  [2023-01-26 18:10:37,732] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:37,732] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:37,733] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=EVENT_DATE_AGGREGATOR_NO_RESTRICTION Test, name=EVENT_DATE_AGGREGATOR_NO_RESTRICTION Test]
INFO  [2023-01-26 18:10:37,733] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=EVENT_DATE_AGGREGATOR_NO_RESTRICTION Test, name=EVENT_DATE_AGGREGATOR_NO_RESTRICTION Test]
INFO  [2023-01-26 18:10:37,733] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:37,733] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:37,735] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test.worker_EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test_6a11b711-1500-46fd-88d1-28b5dfade6d2 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:37,735] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test.worker_EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test_6a11b711-1500-46fd-88d1-28b5dfade6d2 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:37,735] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:37,735] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test.worker_EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test_2b9b392a-ed69-4915-95dc-ae770ab27b3d are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:37,735] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test.worker_EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test_2b9b392a-ed69-4915-95dc-ae770ab27b3d are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:37,735] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:37,738] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:37,839] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:37,847] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:37,847] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test.table
INFO  [2023-01-26 18:10:37,847] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test.table
INFO  [2023-01-26 18:10:37,965] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:38,074] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:38,075] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:38,075] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 388 B in total
INFO  [2023-01-26 18:10:38,075] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_EVENT_DATE_AGGREGATOR_NO_RESTRICTION Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000291445sINFO  [2023-01-26 18:10:38,104] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=10, sum=10, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:10:38,104] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geburtsdatum] with DateParser(super=Parser(lines=10, nullLines=1), subType=IntegerParser(super=Parser(lines=10, nullLines=1), minValue=10226, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@1172c25)
INFO  [2023-01-26 18:10:38,104] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[indexdatum] with DateRangeParser(super=Parser(lines=10, nullLines=0), minParser=DateParser(super=Parser(lines=10, nullLines=0), subType=IntegerParser(super=Parser(lines=10, nullLines=0), minValue=14610, maxValue=14610), dateReader=com.bakdata.conquery.util.DateReader@16ed86f2), maxParser=DateParser(super=Parser(lines=10, nullLines=0), subType=IntegerParser(super=Parser(lines=10, nullLines=0), minValue=14699, maxValue=14699), dateReader=com.bakdata.conquery.util.DateReader@16f26fea), dateReader=com.bakdata.conquery.util.DateReader@18d3e4ec, onlyQuarters=true, maxValue=14699, minValue=14610, anyOpen=false)
INFO  [2023-01-26 18:10:38,107] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_EVENT_DATE_AGGREGATOR_NO_RESTRICTION Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:38,107] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:38,107] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_EVENT_DATE_AGGREGATOR_NO_RESTRICTION Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:38,121] com.bakdata.conquery.models.jobs.ImportJob: Importing table into EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test.table
127.0.0.1 - - [26/Jan/2023:18:10:38 +0000] "POST /admin/datasets/EVENT_DATE_AGGREGATOR_NO_RESTRICTION%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_EVENT_DATE_AGGREGATOR_NO_RESTRICTION+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:10:38,122] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:38,122] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:38,122] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:38,122] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:38,123] com.bakdata.conquery.models.jobs.ImportJob: Start sending 4 Buckets
INFO  [2023-01-26 18:10:38,124] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test.table.table], containing 10 entries.
INFO  [2023-01-26 18:10:38,124] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test.table.table], containing 10 entries.
WARN  [2023-01-26 18:10:38,124] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:38,124] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test.table.table.0
INFO  [2023-01-26 18:10:38,124] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test.table.table.1
INFO  [2023-01-26 18:10:38,124] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test.table.table.2
INFO  [2023-01-26 18:10:38,125] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test.table.table.3
INFO  [2023-01-26 18:10:38,229] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:38,235] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:38,246] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:38,246] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:38,246] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:38,351] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: EVENT_DATE_AGGREGATOR_NO_RESTRICTION Test QUERY INIT
INFO  [2023-01-26 18:10:38,361] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:38,362] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[f1cbc2c6-2e44-4474-9b1d-cc5a5f2dd1da] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_EVENT_DATE_AGGREGATOR_NO_RESTRICTION Test))]]
INFO  [2023-01-26 18:10:38,364] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test.f1cbc2c6-2e44-4474-9b1d-cc5a5f2dd1da
INFO  [2023-01-26 18:10:38,364] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test.f1cbc2c6-2e44-4474-9b1d-cc5a5f2dd1da
127.0.0.1 - - [26/Jan/2023:18:10:38 +0000] "POST /api/datasets/EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test/queries HTTP/1.1" 201 1684 "-" "Conquery (test client)" 5
INFO  [2023-01-26 18:10:38,366] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test.f1cbc2c6-2e44-4474-9b1d-cc5a5f2dd1da] with 4 results within PT0.002689S
INFO  [2023-01-26 18:10:38,366] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test.f1cbc2c6-2e44-4474-9b1d-cc5a5f2dd1da] with 6 results within PT0.002865S
INFO  [2023-01-26 18:10:38,367] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test.f1cbc2c6-2e44-4474-9b1d-cc5a5f2dd1da, workerId=EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test.worker_EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test_6a11b711-1500-46fd-88d1-28b5dfade6d2, startTime=2023-01-26T18:10:38.364036, finishTime=2023-01-26T18:10:38.366725) of size 4
INFO  [2023-01-26 18:10:38,367] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test.f1cbc2c6-2e44-4474-9b1d-cc5a5f2dd1da, workerId=EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test.worker_EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test_2b9b392a-ed69-4915-95dc-ae770ab27b3d, startTime=2023-01-26T18:10:38.364028, finishTime=2023-01-26T18:10:38.366893) of size 6
INFO  [2023-01-26 18:10:38,367] com.bakdata.conquery.models.execution.ManagedExecution: DONE f1cbc2c6-2e44-4474-9b1d-cc5a5f2dd1da ManagedQuery within PT0.005158S
127.0.0.1 - - [26/Jan/2023:18:10:38 +0000] "GET /api/datasets/EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test/queries/EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test.f1cbc2c6-2e44-4474-9b1d-cc5a5f2dd1da HTTP/1.1" 200 2048 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:10:38,384] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=EVENT_DATE_AGGREGATOR_NO_RESTRICTION Test], queryId=f1cbc2c6-2e44-4474-9b1d-cc5a5f2dd1da, label=concept	@§$, creationTime=2023-01-26T18:10:38.362013, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@557693e8[Count = 0], startTime=2023-01-26T18:10:38.362145, finishTime=2023-01-26T18:10:38.367303, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@183a0752), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_EVENT_DATE_AGGREGATOR_NO_RESTRICTION Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=10, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@d2fac01, com.bakdata.conquery.models.query.ColumnDescriptor@28c7ec0c, com.bakdata.conquery.models.query.ColumnDescriptor@494fd32f, com.bakdata.conquery.models.query.ColumnDescriptor@1074dc3]) download on dataset Dataset[label=null, name=EVENT_DATE_AGGREGATOR_NO_RESTRICTION Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:38,385] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=EVENT_DATE_AGGREGATOR_NO_RESTRICTION Test], queryId=f1cbc2c6-2e44-4474-9b1d-cc5a5f2dd1da, label=concept	@§$, creationTime=2023-01-26T18:10:38.362013, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@557693e8[Count = 0], startTime=2023-01-26T18:10:38.362145, finishTime=2023-01-26T18:10:38.367303, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@183a0752), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_EVENT_DATE_AGGREGATOR_NO_RESTRICTION Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=10, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@d2fac01, com.bakdata.conquery.models.query.ColumnDescriptor@28c7ec0c, com.bakdata.conquery.models.query.ColumnDescriptor@494fd32f, com.bakdata.conquery.models.query.ColumnDescriptor@1074dc3]) on dataset Dataset[label=null, name=EVENT_DATE_AGGREGATOR_NO_RESTRICTION Test]
127.0.0.1 - - [26/Jan/2023:18:10:38 +0000] "GET /api/datasets/EVENT_DATE_AGGREGATOR_NO_RESTRICTION%20Test/result/EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test.f1cbc2c6-2e44-4474-9b1d-cc5a5f2dd1da.csv?pretty=false HTTP/1.1" 200 788 "-" "Conquery (test client)" 15
INFO  [2023-01-26 18:10:38,398] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest EVENT_DATE_AGGREGATOR_NO_RESTRICTION Test on 11 rows
INFO  [2023-01-26 18:10:38,399] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast EVENT_DATE_AGGREGATOR_NO_RESTRICTION Test
INFO  [2023-01-26 18:10:38,399] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=EVENT_DATE_AGGREGATOR_NO_RESTRICTION Test, name=EVENT_DATE_AGGREGATOR_NO_RESTRICTION Test]
INFO  [2023-01-26 18:10:38,399] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=EVENT_DATE_AGGREGATOR_NO_RESTRICTION Test, name=EVENT_DATE_AGGREGATOR_NO_RESTRICTION Test]
INFO  [2023-01-26 18:10:38,399] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_EVENT_DATE_AGGREGATOR_NO_RESTRICTION Test_6a11b711-1500-46fd-88d1-28b5dfade6d2
INFO  [2023-01-26 18:10:38,399] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_EVENT_DATE_AGGREGATOR_NO_RESTRICTION Test_2b9b392a-ed69-4915-95dc-ae770ab27b3d
INFO  [2023-01-26 18:10:38,433] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow EVENT_DATE_AGGREGATOR_NO_RESTRICTION Test
INFO  [2023-01-26 18:10:38,434] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_EVENT_DATE_AGGREGATOR_NO_RESTRICTION Test_6a11b711-1500-46fd-88d1-28b5dfade6d2
INFO  [2023-01-26 18:10:38,435] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_EVENT_DATE_AGGREGATOR_NO_RESTRICTION Test_2b9b392a-ed69-4915-95dc-ae770ab27b3d
INFO  [2023-01-26 18:10:38,525] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of EVENT_DATE_AGGREGATOR_NO_RESTRICTION$20Test
INFO  [2023-01-26 18:10:38,525] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:38,551] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test EVENT_DATE_AGGREGATOR_NO_RESTRICTION Test
INFO  [2023-01-26 18:10:38,551] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test EVENT_DATE_AGGREGATOR_RESTRICTION Test
INFO  [2023-01-26 18:10:38,551] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:38,552] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:38,552] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=EVENT_DATE_AGGREGATOR_RESTRICTION Test, name=EVENT_DATE_AGGREGATOR_RESTRICTION Test]
INFO  [2023-01-26 18:10:38,552] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=EVENT_DATE_AGGREGATOR_RESTRICTION Test, name=EVENT_DATE_AGGREGATOR_RESTRICTION Test]
INFO  [2023-01-26 18:10:38,552] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:38,552] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:38,553] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker EVENT_DATE_AGGREGATOR_RESTRICTION$20Test.worker_EVENT_DATE_AGGREGATOR_RESTRICTION$20Test_47c687b3-2240-4b7d-a51d-032405ce6d91 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:38,553] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker EVENT_DATE_AGGREGATOR_RESTRICTION$20Test.worker_EVENT_DATE_AGGREGATOR_RESTRICTION$20Test_47c687b3-2240-4b7d-a51d-032405ce6d91 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:38,553] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:38,560] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker EVENT_DATE_AGGREGATOR_RESTRICTION$20Test.worker_EVENT_DATE_AGGREGATOR_RESTRICTION$20Test_a1b58a14-4249-4ea8-a67c-baa6918fd71b are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:38,560] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker EVENT_DATE_AGGREGATOR_RESTRICTION$20Test.worker_EVENT_DATE_AGGREGATOR_RESTRICTION$20Test_a1b58a14-4249-4ea8-a67c-baa6918fd71b are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:38,560] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:38,563] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:38,664] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:38,671] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:38,672] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table EVENT_DATE_AGGREGATOR_RESTRICTION$20Test.table
INFO  [2023-01-26 18:10:38,672] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table EVENT_DATE_AGGREGATOR_RESTRICTION$20Test.table
INFO  [2023-01-26 18:10:38,789] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:38,899] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:38,899] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:38,899] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 388 B in total
INFO  [2023-01-26 18:10:38,899] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_EVENT_DATE_AGGREGATOR_RESTRICTION Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000362355sINFO  [2023-01-26 18:10:38,936] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=10, sum=10, min=1, average=1.000000, max=1}
INFO  [2023-01-26 18:10:38,936] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[geburtsdatum] with DateParser(super=Parser(lines=10, nullLines=1), subType=IntegerParser(super=Parser(lines=10, nullLines=1), minValue=10226, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@76e571f5)
INFO  [2023-01-26 18:10:38,936] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[indexdatum] with DateRangeParser(super=Parser(lines=10, nullLines=0), minParser=DateParser(super=Parser(lines=10, nullLines=0), subType=IntegerParser(super=Parser(lines=10, nullLines=0), minValue=14610, maxValue=14610), dateReader=com.bakdata.conquery.util.DateReader@2851515f), maxParser=DateParser(super=Parser(lines=10, nullLines=0), subType=IntegerParser(super=Parser(lines=10, nullLines=0), minValue=14699, maxValue=14699), dateReader=com.bakdata.conquery.util.DateReader@52f188b1), dateReader=com.bakdata.conquery.util.DateReader@5779203a, onlyQuarters=true, maxValue=14699, minValue=14610, anyOpen=false)
INFO  [2023-01-26 18:10:38,938] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_EVENT_DATE_AGGREGATOR_RESTRICTION Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:38,938] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:38,938] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_EVENT_DATE_AGGREGATOR_RESTRICTION Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:38,953] com.bakdata.conquery.models.jobs.ImportJob: Importing table into EVENT_DATE_AGGREGATOR_RESTRICTION$20Test.table
INFO  [2023-01-26 18:10:38,953] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:10:38 +0000] "POST /admin/datasets/EVENT_DATE_AGGREGATOR_RESTRICTION%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_EVENT_DATE_AGGREGATOR_RESTRICTION+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:10:38,954] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:38,954] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:38,954] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:38,955] com.bakdata.conquery.models.jobs.ImportJob: Start sending 4 Buckets
INFO  [2023-01-26 18:10:38,955] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[EVENT_DATE_AGGREGATOR_RESTRICTION$20Test.table.table], containing 10 entries.
INFO  [2023-01-26 18:10:38,955] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[EVENT_DATE_AGGREGATOR_RESTRICTION$20Test.table.table], containing 10 entries.
WARN  [2023-01-26 18:10:38,957] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:38,957] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received EVENT_DATE_AGGREGATOR_RESTRICTION$20Test.table.table.0
INFO  [2023-01-26 18:10:38,957] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received EVENT_DATE_AGGREGATOR_RESTRICTION$20Test.table.table.2
INFO  [2023-01-26 18:10:38,957] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received EVENT_DATE_AGGREGATOR_RESTRICTION$20Test.table.table.1
INFO  [2023-01-26 18:10:38,957] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received EVENT_DATE_AGGREGATOR_RESTRICTION$20Test.table.table.3
INFO  [2023-01-26 18:10:39,062] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:39,067] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:39,079] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:39,080] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:39,080] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:39,196] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: EVENT_DATE_AGGREGATOR_RESTRICTION Test QUERY INIT
INFO  [2023-01-26 18:10:39,206] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[EVENT_DATE_AGGREGATOR_RESTRICTION$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:39,207] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[be372dd4-688e-41ee-8844-f350019e5d1e] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_EVENT_DATE_AGGREGATOR_RESTRICTION Test))]]
INFO  [2023-01-26 18:10:39,210] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery EVENT_DATE_AGGREGATOR_RESTRICTION$20Test.be372dd4-688e-41ee-8844-f350019e5d1e
INFO  [2023-01-26 18:10:39,210] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery EVENT_DATE_AGGREGATOR_RESTRICTION$20Test.be372dd4-688e-41ee-8844-f350019e5d1e
INFO  [2023-01-26 18:10:39,211] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[EVENT_DATE_AGGREGATOR_RESTRICTION$20Test.be372dd4-688e-41ee-8844-f350019e5d1e] with 6 results within PT0.000934S
INFO  [2023-01-26 18:10:39,211] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[EVENT_DATE_AGGREGATOR_RESTRICTION$20Test.be372dd4-688e-41ee-8844-f350019e5d1e] with 4 results within PT0.001003S
INFO  [2023-01-26 18:10:39,212] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=EVENT_DATE_AGGREGATOR_RESTRICTION$20Test.be372dd4-688e-41ee-8844-f350019e5d1e, workerId=EVENT_DATE_AGGREGATOR_RESTRICTION$20Test.worker_EVENT_DATE_AGGREGATOR_RESTRICTION$20Test_a1b58a14-4249-4ea8-a67c-baa6918fd71b, startTime=2023-01-26T18:10:39.210877, finishTime=2023-01-26T18:10:39.211811) of size 6
INFO  [2023-01-26 18:10:39,212] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=EVENT_DATE_AGGREGATOR_RESTRICTION$20Test.be372dd4-688e-41ee-8844-f350019e5d1e, workerId=EVENT_DATE_AGGREGATOR_RESTRICTION$20Test.worker_EVENT_DATE_AGGREGATOR_RESTRICTION$20Test_47c687b3-2240-4b7d-a51d-032405ce6d91, startTime=2023-01-26T18:10:39.210877, finishTime=2023-01-26T18:10:39.211880) of size 4
INFO  [2023-01-26 18:10:39,212] com.bakdata.conquery.models.execution.ManagedExecution: DONE be372dd4-688e-41ee-8844-f350019e5d1e ManagedQuery within PT0.005149S
127.0.0.1 - - [26/Jan/2023:18:10:39 +0000] "POST /api/datasets/EVENT_DATE_AGGREGATOR_RESTRICTION$20Test/queries HTTP/1.1" 201 1764 "-" "Conquery (test client)" 8
127.0.0.1 - - [26/Jan/2023:18:10:39 +0000] "GET /api/datasets/EVENT_DATE_AGGREGATOR_RESTRICTION$20Test/queries/EVENT_DATE_AGGREGATOR_RESTRICTION$20Test.be372dd4-688e-41ee-8844-f350019e5d1e HTTP/1.1" 200 2116 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:10:39,230] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=EVENT_DATE_AGGREGATOR_RESTRICTION Test], queryId=be372dd4-688e-41ee-8844-f350019e5d1e, label=concept	@§$, creationTime=2023-01-26T18:10:39.207316, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@ed14331[Count = 0], startTime=2023-01-26T18:10:39.207493, finishTime=2023-01-26T18:10:39.212642, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@7f56b8f8), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_EVENT_DATE_AGGREGATOR_RESTRICTION Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=10, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@64c22734, com.bakdata.conquery.models.query.ColumnDescriptor@747b3821, com.bakdata.conquery.models.query.ColumnDescriptor@70373554, com.bakdata.conquery.models.query.ColumnDescriptor@3aecc2d2]) download on dataset Dataset[label=null, name=EVENT_DATE_AGGREGATOR_RESTRICTION Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:39,230] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=EVENT_DATE_AGGREGATOR_RESTRICTION Test], queryId=be372dd4-688e-41ee-8844-f350019e5d1e, label=concept	@§$, creationTime=2023-01-26T18:10:39.207316, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@ed14331[Count = 0], startTime=2023-01-26T18:10:39.207493, finishTime=2023-01-26T18:10:39.212642, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@7f56b8f8), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_EVENT_DATE_AGGREGATOR_RESTRICTION Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=10, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@64c22734, com.bakdata.conquery.models.query.ColumnDescriptor@747b3821, com.bakdata.conquery.models.query.ColumnDescriptor@70373554, com.bakdata.conquery.models.query.ColumnDescriptor@3aecc2d2]) on dataset Dataset[label=null, name=EVENT_DATE_AGGREGATOR_RESTRICTION Test]
127.0.0.1 - - [26/Jan/2023:18:10:39 +0000] "GET /api/datasets/EVENT_DATE_AGGREGATOR_RESTRICTION%20Test/result/EVENT_DATE_AGGREGATOR_RESTRICTION$20Test.be372dd4-688e-41ee-8844-f350019e5d1e.csv?pretty=false HTTP/1.1" 200 788 "-" "Conquery (test client)" 19
INFO  [2023-01-26 18:10:39,249] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest EVENT_DATE_AGGREGATOR_RESTRICTION Test on 11 rows
INFO  [2023-01-26 18:10:39,249] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast EVENT_DATE_AGGREGATOR_RESTRICTION Test
INFO  [2023-01-26 18:10:39,249] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=EVENT_DATE_AGGREGATOR_RESTRICTION Test, name=EVENT_DATE_AGGREGATOR_RESTRICTION Test]
INFO  [2023-01-26 18:10:39,249] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=EVENT_DATE_AGGREGATOR_RESTRICTION Test, name=EVENT_DATE_AGGREGATOR_RESTRICTION Test]
INFO  [2023-01-26 18:10:39,249] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_EVENT_DATE_AGGREGATOR_RESTRICTION Test_47c687b3-2240-4b7d-a51d-032405ce6d91
INFO  [2023-01-26 18:10:39,249] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_EVENT_DATE_AGGREGATOR_RESTRICTION Test_a1b58a14-4249-4ea8-a67c-baa6918fd71b
INFO  [2023-01-26 18:10:39,252] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow EVENT_DATE_AGGREGATOR_RESTRICTION Test
INFO  [2023-01-26 18:10:39,253] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_EVENT_DATE_AGGREGATOR_RESTRICTION Test_47c687b3-2240-4b7d-a51d-032405ce6d91
INFO  [2023-01-26 18:10:39,257] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of EVENT_DATE_AGGREGATOR_RESTRICTION$20Test
INFO  [2023-01-26 18:10:39,257] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:39,260] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_EVENT_DATE_AGGREGATOR_RESTRICTION Test_a1b58a14-4249-4ea8-a67c-baa6918fd71b
INFO  [2023-01-26 18:10:39,385] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test EVENT_DATE_AGGREGATOR_RESTRICTION Test
INFO  [2023-01-26 18:10:39,385] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test EXISTS_AGGREGATOR & NUMBER Test
INFO  [2023-01-26 18:10:39,386] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:39,386] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:39,387] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=EXISTS_AGGREGATOR & NUMBER Test, name=EXISTS_AGGREGATOR & NUMBER Test]
INFO  [2023-01-26 18:10:39,387] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=EXISTS_AGGREGATOR & NUMBER Test, name=EXISTS_AGGREGATOR & NUMBER Test]
INFO  [2023-01-26 18:10:39,387] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:39,387] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:39,389] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker EXISTS_AGGREGATOR$20&$20NUMBER$20Test.worker_EXISTS_AGGREGATOR$20&$20NUMBER$20Test_25abbb48-5bdc-4f35-9d78-269dd70372a0 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:39,389] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:39,389] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker EXISTS_AGGREGATOR$20&$20NUMBER$20Test.worker_EXISTS_AGGREGATOR$20&$20NUMBER$20Test_25abbb48-5bdc-4f35-9d78-269dd70372a0 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:39,389] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:39,389] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker EXISTS_AGGREGATOR$20&$20NUMBER$20Test.worker_EXISTS_AGGREGATOR$20&$20NUMBER$20Test_856b0672-086b-4a7d-a7a5-d48a49e6cab9 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:39,389] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker EXISTS_AGGREGATOR$20&$20NUMBER$20Test.worker_EXISTS_AGGREGATOR$20&$20NUMBER$20Test_856b0672-086b-4a7d-a7a5-d48a49e6cab9 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:39,389] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:39,493] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:39,500] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:39,500] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table EXISTS_AGGREGATOR$20&$20NUMBER$20Test.table
INFO  [2023-01-26 18:10:39,500] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table EXISTS_AGGREGATOR$20&$20NUMBER$20Test.table
INFO  [2023-01-26 18:10:39,613] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:39,722] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:39,722] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:39,722] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 210 B in total
INFO  [2023-01-26 18:10:39,722] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_EXISTS_AGGREGATOR & NUMBER Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000365008sINFO  [2023-01-26 18:10:39,759] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=5, sum=7, min=1, average=1.400000, max=2}
INFO  [2023-01-26 18:10:39,759] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=7, nullLines=0), minParser=DateParser(super=Parser(lines=7, nullLines=0), subType=IntegerParser(super=Parser(lines=7, nullLines=0), minValue=16251, maxValue=16251), dateReader=com.bakdata.conquery.util.DateReader@731b8c17), maxParser=DateParser(super=Parser(lines=7, nullLines=0), subType=IntegerParser(super=Parser(lines=7, nullLines=0), minValue=16616, maxValue=16616), dateReader=com.bakdata.conquery.util.DateReader@60d735e3), dateReader=com.bakdata.conquery.util.DateReader@754f1f1a, onlyQuarters=false, maxValue=16616, minValue=16251, anyOpen=false)
INFO  [2023-01-26 18:10:39,759] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with RealParser(super=Parser(lines=7, nullLines=2), requiredPrecision=4.9E-324, floatULP=2.384185791015625E-7)
INFO  [2023-01-26 18:10:39,762] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_EXISTS_AGGREGATOR & NUMBER Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:39,762] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:39,762] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_EXISTS_AGGREGATOR & NUMBER Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:39,780] com.bakdata.conquery.models.jobs.ImportJob: Importing table into EXISTS_AGGREGATOR$20&$20NUMBER$20Test.table
INFO  [2023-01-26 18:10:39,780] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:10:39 +0000] "POST /admin/datasets/EXISTS_AGGREGATOR%20&%20NUMBER%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_EXISTS_AGGREGATOR+%26+NUMBER+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:10:39,781] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:39,781] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:39,781] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:39,782] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:39,783] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[EXISTS_AGGREGATOR$20&$20NUMBER$20Test.table.table], containing 7 entries.
INFO  [2023-01-26 18:10:39,783] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[EXISTS_AGGREGATOR$20&$20NUMBER$20Test.table.table], containing 7 entries.
WARN  [2023-01-26 18:10:39,783] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:39,784] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received EXISTS_AGGREGATOR$20&$20NUMBER$20Test.table.table.0
INFO  [2023-01-26 18:10:39,784] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received EXISTS_AGGREGATOR$20&$20NUMBER$20Test.table.table.1
INFO  [2023-01-26 18:10:39,888] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:39,895] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:39,905] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:39,905] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:39,905] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:40,011] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: EXISTS_AGGREGATOR & NUMBER Test QUERY INIT
INFO  [2023-01-26 18:10:40,022] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[EXISTS_AGGREGATOR$20&$20NUMBER$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:40,022] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[6ccdc67a-b7e6-425f-b45d-e17da71b42a0] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_EXISTS_AGGREGATOR & NUMBER Test))]]
INFO  [2023-01-26 18:10:40,026] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery EXISTS_AGGREGATOR$20&$20NUMBER$20Test.6ccdc67a-b7e6-425f-b45d-e17da71b42a0
INFO  [2023-01-26 18:10:40,026] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery EXISTS_AGGREGATOR$20&$20NUMBER$20Test.6ccdc67a-b7e6-425f-b45d-e17da71b42a0
127.0.0.1 - - [26/Jan/2023:18:10:40 +0000] "POST /api/datasets/EXISTS_AGGREGATOR$20&$20NUMBER$20Test/queries HTTP/1.1" 201 1487 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:10:40,032] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[EXISTS_AGGREGATOR$20&$20NUMBER$20Test.6ccdc67a-b7e6-425f-b45d-e17da71b42a0] with 1 results within PT0.00565S
INFO  [2023-01-26 18:10:40,032] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=EXISTS_AGGREGATOR$20&$20NUMBER$20Test.6ccdc67a-b7e6-425f-b45d-e17da71b42a0, workerId=EXISTS_AGGREGATOR$20&$20NUMBER$20Test.worker_EXISTS_AGGREGATOR$20&$20NUMBER$20Test_25abbb48-5bdc-4f35-9d78-269dd70372a0, startTime=2023-01-26T18:10:40.026554, finishTime=2023-01-26T18:10:40.032204) of size 1
INFO  [2023-01-26 18:10:40,038] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[EXISTS_AGGREGATOR$20&$20NUMBER$20Test.6ccdc67a-b7e6-425f-b45d-e17da71b42a0] with 2 results within PT0.011869S
INFO  [2023-01-26 18:10:40,038] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=EXISTS_AGGREGATOR$20&$20NUMBER$20Test.6ccdc67a-b7e6-425f-b45d-e17da71b42a0, workerId=EXISTS_AGGREGATOR$20&$20NUMBER$20Test.worker_EXISTS_AGGREGATOR$20&$20NUMBER$20Test_856b0672-086b-4a7d-a7a5-d48a49e6cab9, startTime=2023-01-26T18:10:40.026541, finishTime=2023-01-26T18:10:40.038410) of size 2
INFO  [2023-01-26 18:10:40,038] com.bakdata.conquery.models.execution.ManagedExecution: DONE 6ccdc67a-b7e6-425f-b45d-e17da71b42a0 ManagedQuery within PT0.016038S
127.0.0.1 - - [26/Jan/2023:18:10:40 +0000] "GET /api/datasets/EXISTS_AGGREGATOR$20&$20NUMBER$20Test/queries/EXISTS_AGGREGATOR$20&$20NUMBER$20Test.6ccdc67a-b7e6-425f-b45d-e17da71b42a0 HTTP/1.1" 200 1827 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:10:40,048] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=EXISTS_AGGREGATOR & NUMBER Test], queryId=6ccdc67a-b7e6-425f-b45d-e17da71b42a0, label=concept	@§$, creationTime=2023-01-26T18:10:40.022744, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@21eeae44[Count = 0], startTime=2023-01-26T18:10:40.022937, finishTime=2023-01-26T18:10:40.038975, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@3093b13a), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_EXISTS_AGGREGATOR & NUMBER Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=3, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@2dfdec3a, com.bakdata.conquery.models.query.ColumnDescriptor@5571c9af, com.bakdata.conquery.models.query.ColumnDescriptor@1b9d1cb]) download on dataset Dataset[label=null, name=EXISTS_AGGREGATOR & NUMBER Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:40,048] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=EXISTS_AGGREGATOR & NUMBER Test], queryId=6ccdc67a-b7e6-425f-b45d-e17da71b42a0, label=concept	@§$, creationTime=2023-01-26T18:10:40.022744, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@21eeae44[Count = 0], startTime=2023-01-26T18:10:40.022937, finishTime=2023-01-26T18:10:40.038975, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@3093b13a), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_EXISTS_AGGREGATOR & NUMBER Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=3, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@2dfdec3a, com.bakdata.conquery.models.query.ColumnDescriptor@5571c9af, com.bakdata.conquery.models.query.ColumnDescriptor@1b9d1cb]) on dataset Dataset[label=null, name=EXISTS_AGGREGATOR & NUMBER Test]
127.0.0.1 - - [26/Jan/2023:18:10:40 +0000] "GET /api/datasets/EXISTS_AGGREGATOR%20&%20NUMBER%20Test/result/EXISTS_AGGREGATOR$20&$20NUMBER$20Test.6ccdc67a-b7e6-425f-b45d-e17da71b42a0.csv?pretty=false HTTP/1.1" 200 114 "-" "Conquery (test client)" 30
INFO  [2023-01-26 18:10:40,076] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest EXISTS_AGGREGATOR & NUMBER Test on 4 rows
INFO  [2023-01-26 18:10:40,077] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast EXISTS_AGGREGATOR & NUMBER Test
INFO  [2023-01-26 18:10:40,077] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=EXISTS_AGGREGATOR & NUMBER Test, name=EXISTS_AGGREGATOR & NUMBER Test]
INFO  [2023-01-26 18:10:40,077] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=EXISTS_AGGREGATOR & NUMBER Test, name=EXISTS_AGGREGATOR & NUMBER Test]
INFO  [2023-01-26 18:10:40,077] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_EXISTS_AGGREGATOR & NUMBER Test_25abbb48-5bdc-4f35-9d78-269dd70372a0
INFO  [2023-01-26 18:10:40,077] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_EXISTS_AGGREGATOR & NUMBER Test_856b0672-086b-4a7d-a7a5-d48a49e6cab9
INFO  [2023-01-26 18:10:40,094] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_EXISTS_AGGREGATOR & NUMBER Test_25abbb48-5bdc-4f35-9d78-269dd70372a0
INFO  [2023-01-26 18:10:40,094] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_EXISTS_AGGREGATOR & NUMBER Test_856b0672-086b-4a7d-a7a5-d48a49e6cab9
INFO  [2023-01-26 18:10:40,094] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow EXISTS_AGGREGATOR & NUMBER Test
INFO  [2023-01-26 18:10:40,184] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of EXISTS_AGGREGATOR$20&$20NUMBER$20Test
INFO  [2023-01-26 18:10:40,184] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:40,211] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test EXISTS_AGGREGATOR & NUMBER Test
INFO  [2023-01-26 18:10:40,211] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test EXISTS_AGGREGATOR & NUMBER Test
INFO  [2023-01-26 18:10:40,211] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:40,211] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:40,216] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=EXISTS_AGGREGATOR & NUMBER Test[1], name=EXISTS_AGGREGATOR & NUMBER Test[1]]
INFO  [2023-01-26 18:10:40,216] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=EXISTS_AGGREGATOR & NUMBER Test[1], name=EXISTS_AGGREGATOR & NUMBER Test[1]]
INFO  [2023-01-26 18:10:40,216] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:40,216] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:40,219] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker EXISTS_AGGREGATOR$20&$20NUMBER$20Test[1].worker_EXISTS_AGGREGATOR$20&$20NUMBER$20Test[1]_cd41d78a-dc31-4ce1-8fe8-fa6701e92606 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:40,219] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker EXISTS_AGGREGATOR$20&$20NUMBER$20Test[1].worker_EXISTS_AGGREGATOR$20&$20NUMBER$20Test[1]_cd41d78a-dc31-4ce1-8fe8-fa6701e92606 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:40,219] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:40,219] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker EXISTS_AGGREGATOR$20&$20NUMBER$20Test[1].worker_EXISTS_AGGREGATOR$20&$20NUMBER$20Test[1]_b3a016af-ccdb-4100-91bd-b7fad51d7aa0 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:40,219] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker EXISTS_AGGREGATOR$20&$20NUMBER$20Test[1].worker_EXISTS_AGGREGATOR$20&$20NUMBER$20Test[1]_b3a016af-ccdb-4100-91bd-b7fad51d7aa0 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:40,219] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:40,222] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:40,323] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:40,330] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:40,330] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table EXISTS_AGGREGATOR$20&$20NUMBER$20Test[1].table
INFO  [2023-01-26 18:10:40,330] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table EXISTS_AGGREGATOR$20&$20NUMBER$20Test[1].table
INFO  [2023-01-26 18:10:40,440] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:40,550] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:40,550] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:40,550] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 78 B in total
INFO  [2023-01-26 18:10:40,550] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_EXISTS_AGGREGATOR & NUMBER Test[1]/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000291214sINFO  [2023-01-26 18:10:40,580] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=3, sum=4, min=1, average=1.333333, max=2}
INFO  [2023-01-26 18:10:40,580] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=4, nullLines=0), subType=IntegerParser(super=Parser(lines=4, nullLines=0), minValue=18262, maxValue=18262), dateReader=com.bakdata.conquery.util.DateReader@51b5ae42)
INFO  [2023-01-26 18:10:40,580] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with StringParser(super=Parser(lines=4, nullLines=0), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:40,583] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_EXISTS_AGGREGATOR & NUMBER Test[1]/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:40,583] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:40,583] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_EXISTS_AGGREGATOR & NUMBER Test[1]/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:40,599] com.bakdata.conquery.models.jobs.ImportJob: Importing table into EXISTS_AGGREGATOR$20&$20NUMBER$20Test[1].table
127.0.0.1 - - [26/Jan/2023:18:10:40 +0000] "POST /admin/datasets/EXISTS_AGGREGATOR%20&%20NUMBER%20Test%5B1%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_EXISTS_AGGREGATOR+%26+NUMBER+Test%5B1%5D%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:10:40,600] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:40,600] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:40,601] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:40,601] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:40,602] com.bakdata.conquery.models.jobs.ImportJob: Start sending 1 Buckets
INFO  [2023-01-26 18:10:40,602] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[EXISTS_AGGREGATOR$20&$20NUMBER$20Test[1].table.table], containing 4 entries.
INFO  [2023-01-26 18:10:40,602] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[EXISTS_AGGREGATOR$20&$20NUMBER$20Test[1].table.table], containing 4 entries.
WARN  [2023-01-26 18:10:40,603] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:40,603] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received EXISTS_AGGREGATOR$20&$20NUMBER$20Test[1].table.table.0
INFO  [2023-01-26 18:10:40,709] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:40,714] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:40,725] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:40,725] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:40,831] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: EXISTS_AGGREGATOR & NUMBER Test QUERY INIT
INFO  [2023-01-26 18:10:40,840] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[EXISTS_AGGREGATOR$20&$20NUMBER$20Test[1]] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:40,841] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[a4c1673a-ba0d-44cf-88dc-9fa78cf6d685] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_EXISTS_AGGREGATOR & NUMBER Test[1]))]]
INFO  [2023-01-26 18:10:40,844] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ArrayConceptQuery EXISTS_AGGREGATOR$20&$20NUMBER$20Test[1].a4c1673a-ba0d-44cf-88dc-9fa78cf6d685
INFO  [2023-01-26 18:10:40,844] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ArrayConceptQuery EXISTS_AGGREGATOR$20&$20NUMBER$20Test[1].a4c1673a-ba0d-44cf-88dc-9fa78cf6d685
WARN  [2023-01-26 18:10:40,844] com.bakdata.conquery.models.query.QueryExecutor: Entities for query are empty
INFO  [2023-01-26 18:10:40,844] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[EXISTS_AGGREGATOR$20&$20NUMBER$20Test[1].a4c1673a-ba0d-44cf-88dc-9fa78cf6d685] with 0 results within PT0.000259S
INFO  [2023-01-26 18:10:40,845] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=EXISTS_AGGREGATOR$20&$20NUMBER$20Test[1].a4c1673a-ba0d-44cf-88dc-9fa78cf6d685, workerId=EXISTS_AGGREGATOR$20&$20NUMBER$20Test[1].worker_EXISTS_AGGREGATOR$20&$20NUMBER$20Test[1]_cd41d78a-dc31-4ce1-8fe8-fa6701e92606, startTime=2023-01-26T18:10:40.844363, finishTime=2023-01-26T18:10:40.844622) of size 0
127.0.0.1 - - [26/Jan/2023:18:10:40 +0000] "POST /api/datasets/EXISTS_AGGREGATOR$20&$20NUMBER$20Test%5B1%5D/queries HTTP/1.1" 201 3513 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:10:40,845] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[EXISTS_AGGREGATOR$20&$20NUMBER$20Test[1].a4c1673a-ba0d-44cf-88dc-9fa78cf6d685] with 3 results within PT0.001542S
INFO  [2023-01-26 18:10:40,846] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=EXISTS_AGGREGATOR$20&$20NUMBER$20Test[1].a4c1673a-ba0d-44cf-88dc-9fa78cf6d685, workerId=EXISTS_AGGREGATOR$20&$20NUMBER$20Test[1].worker_EXISTS_AGGREGATOR$20&$20NUMBER$20Test[1]_b3a016af-ccdb-4100-91bd-b7fad51d7aa0, startTime=2023-01-26T18:10:40.844349, finishTime=2023-01-26T18:10:40.845891) of size 3
INFO  [2023-01-26 18:10:40,846] com.bakdata.conquery.models.execution.ManagedExecution: DONE a4c1673a-ba0d-44cf-88dc-9fa78cf6d685 ManagedQuery within PT0.005111S
127.0.0.1 - - [26/Jan/2023:18:10:40 +0000] "GET /api/datasets/EXISTS_AGGREGATOR$20&$20NUMBER$20Test%5B1%5D/queries/EXISTS_AGGREGATOR$20&$20NUMBER$20Test%5B1%5D.a4c1673a-ba0d-44cf-88dc-9fa78cf6d685 HTTP/1.1" 200 4176 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:10:40,874] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=EXISTS_AGGREGATOR & NUMBER Test[1]], queryId=a4c1673a-ba0d-44cf-88dc-9fa78cf6d685, label=concept---1 concept---2	@§$, creationTime=2023-01-26T18:10:40.841074, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@10fd9739[Count = 0], startTime=2023-01-26T18:10:40.841248, finishTime=2023-01-26T18:10:40.846359, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@17464492), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_EXISTS_AGGREGATOR & NUMBER Test[1])), query=com.bakdata.conquery.apiv1.query.ArrayConceptQuery@1, lastResultCount=3, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@35c98053, com.bakdata.conquery.models.query.ColumnDescriptor@5aa42531, com.bakdata.conquery.models.query.ColumnDescriptor@261c2503, com.bakdata.conquery.models.query.ColumnDescriptor@35b9786, com.bakdata.conquery.models.query.ColumnDescriptor@7ae944a6, com.bakdata.conquery.models.query.ColumnDescriptor@19f6b67, com.bakdata.conquery.models.query.ColumnDescriptor@466c726a, com.bakdata.conquery.models.query.ColumnDescriptor@19543a86]) download on dataset Dataset[label=null, name=EXISTS_AGGREGATOR & NUMBER Test[1]] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:40,875] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=EXISTS_AGGREGATOR & NUMBER Test[1]], queryId=a4c1673a-ba0d-44cf-88dc-9fa78cf6d685, label=concept---1 concept---2	@§$, creationTime=2023-01-26T18:10:40.841074, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@10fd9739[Count = 0], startTime=2023-01-26T18:10:40.841248, finishTime=2023-01-26T18:10:40.846359, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@17464492), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_EXISTS_AGGREGATOR & NUMBER Test[1])), query=com.bakdata.conquery.apiv1.query.ArrayConceptQuery@1, lastResultCount=3, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@35c98053, com.bakdata.conquery.models.query.ColumnDescriptor@5aa42531, com.bakdata.conquery.models.query.ColumnDescriptor@261c2503, com.bakdata.conquery.models.query.ColumnDescriptor@35b9786, com.bakdata.conquery.models.query.ColumnDescriptor@7ae944a6, com.bakdata.conquery.models.query.ColumnDescriptor@19f6b67, com.bakdata.conquery.models.query.ColumnDescriptor@466c726a, com.bakdata.conquery.models.query.ColumnDescriptor@19543a86]) on dataset Dataset[label=null, name=EXISTS_AGGREGATOR & NUMBER Test[1]]
127.0.0.1 - - [26/Jan/2023:18:10:40 +0000] "GET /api/datasets/EXISTS_AGGREGATOR%20&%20NUMBER%20Test%5B1%5D/result/EXISTS_AGGREGATOR$20&$20NUMBER$20Test%5B1%5D.a4c1673a-ba0d-44cf-88dc-9fa78cf6d685.csv?pretty=false HTTP/1.1" 200 222 "-" "Conquery (test client)" 13
INFO  [2023-01-26 18:10:40,886] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest EXISTS_AGGREGATOR & NUMBER Test on 4 rows
INFO  [2023-01-26 18:10:40,886] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast EXISTS_AGGREGATOR & NUMBER Test[1]
INFO  [2023-01-26 18:10:40,886] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=EXISTS_AGGREGATOR & NUMBER Test[1], name=EXISTS_AGGREGATOR & NUMBER Test[1]]
INFO  [2023-01-26 18:10:40,886] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=EXISTS_AGGREGATOR & NUMBER Test[1], name=EXISTS_AGGREGATOR & NUMBER Test[1]]
INFO  [2023-01-26 18:10:40,886] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_EXISTS_AGGREGATOR & NUMBER Test[1]_cd41d78a-dc31-4ce1-8fe8-fa6701e92606
INFO  [2023-01-26 18:10:40,886] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_EXISTS_AGGREGATOR & NUMBER Test[1]_b3a016af-ccdb-4100-91bd-b7fad51d7aa0
INFO  [2023-01-26 18:10:40,916] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow EXISTS_AGGREGATOR & NUMBER Test[1]
INFO  [2023-01-26 18:10:40,918] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_EXISTS_AGGREGATOR & NUMBER Test[1]_cd41d78a-dc31-4ce1-8fe8-fa6701e92606
INFO  [2023-01-26 18:10:40,919] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_EXISTS_AGGREGATOR & NUMBER Test[1]_b3a016af-ccdb-4100-91bd-b7fad51d7aa0
INFO  [2023-01-26 18:10:41,003] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of EXISTS_AGGREGATOR$20&$20NUMBER$20Test[1]
INFO  [2023-01-26 18:10:41,003] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:41,031] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test EXISTS_AGGREGATOR & NUMBER Test
INFO  [2023-01-26 18:10:41,031] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test EXISTS_AGGREGATOR & NUMBER Test
INFO  [2023-01-26 18:10:41,031] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:41,032] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:41,032] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=EXISTS_AGGREGATOR & NUMBER Test[2], name=EXISTS_AGGREGATOR & NUMBER Test[2]]
INFO  [2023-01-26 18:10:41,032] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:41,039] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=EXISTS_AGGREGATOR & NUMBER Test[2], name=EXISTS_AGGREGATOR & NUMBER Test[2]]
INFO  [2023-01-26 18:10:41,039] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:41,046] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker EXISTS_AGGREGATOR$20&$20NUMBER$20Test[2].worker_EXISTS_AGGREGATOR$20&$20NUMBER$20Test[2]_254b91f4-6328-490e-86d1-c42aa5225e09 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:41,046] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker EXISTS_AGGREGATOR$20&$20NUMBER$20Test[2].worker_EXISTS_AGGREGATOR$20&$20NUMBER$20Test[2]_254b91f4-6328-490e-86d1-c42aa5225e09 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:41,046] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:41,046] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker EXISTS_AGGREGATOR$20&$20NUMBER$20Test[2].worker_EXISTS_AGGREGATOR$20&$20NUMBER$20Test[2]_e14ebb13-ae05-4b92-b4d0-7fd3103027df are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:41,046] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker EXISTS_AGGREGATOR$20&$20NUMBER$20Test[2].worker_EXISTS_AGGREGATOR$20&$20NUMBER$20Test[2]_e14ebb13-ae05-4b92-b4d0-7fd3103027df are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:41,046] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:41,050] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:41,151] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:41,157] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:41,158] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table EXISTS_AGGREGATOR$20&$20NUMBER$20Test[2].table
INFO  [2023-01-26 18:10:41,158] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table EXISTS_AGGREGATOR$20&$20NUMBER$20Test[2].table
INFO  [2023-01-26 18:10:41,271] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:41,379] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:41,380] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:41,380] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 210 B in total
INFO  [2023-01-26 18:10:41,380] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_EXISTS_AGGREGATOR & NUMBER Test[2]/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000349053sINFO  [2023-01-26 18:10:41,415] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=5, sum=7, min=1, average=1.400000, max=2}
INFO  [2023-01-26 18:10:41,415] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateRangeParser(super=Parser(lines=7, nullLines=0), minParser=DateParser(super=Parser(lines=7, nullLines=0), subType=IntegerParser(super=Parser(lines=7, nullLines=0), minValue=16251, maxValue=16251), dateReader=com.bakdata.conquery.util.DateReader@2eb45fbf), maxParser=DateParser(super=Parser(lines=7, nullLines=0), subType=IntegerParser(super=Parser(lines=7, nullLines=0), minValue=16616, maxValue=16616), dateReader=com.bakdata.conquery.util.DateReader@6e867d98), dateReader=com.bakdata.conquery.util.DateReader@7008d748, onlyQuarters=false, maxValue=16616, minValue=16251, anyOpen=false)
INFO  [2023-01-26 18:10:41,415] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with RealParser(super=Parser(lines=7, nullLines=2), requiredPrecision=4.9E-324, floatULP=2.384185791015625E-7)
INFO  [2023-01-26 18:10:41,418] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_EXISTS_AGGREGATOR & NUMBER Test[2]/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:41,418] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:41,418] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_EXISTS_AGGREGATOR & NUMBER Test[2]/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:41,433] com.bakdata.conquery.models.jobs.ImportJob: Importing table into EXISTS_AGGREGATOR$20&$20NUMBER$20Test[2].table
INFO  [2023-01-26 18:10:41,434] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:10:41 +0000] "POST /admin/datasets/EXISTS_AGGREGATOR%20&%20NUMBER%20Test%5B2%5D/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_EXISTS_AGGREGATOR+%26+NUMBER+Test%5B2%5D%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:10:41,435] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:41,435] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:41,435] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:41,436] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:41,436] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[EXISTS_AGGREGATOR$20&$20NUMBER$20Test[2].table.table], containing 7 entries.
INFO  [2023-01-26 18:10:41,436] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[EXISTS_AGGREGATOR$20&$20NUMBER$20Test[2].table.table], containing 7 entries.
WARN  [2023-01-26 18:10:41,437] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:41,437] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received EXISTS_AGGREGATOR$20&$20NUMBER$20Test[2].table.table.0
INFO  [2023-01-26 18:10:41,437] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received EXISTS_AGGREGATOR$20&$20NUMBER$20Test[2].table.table.1
INFO  [2023-01-26 18:10:41,542] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:41,547] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:41,564] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:41,565] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:41,565] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:41,675] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: EXISTS_AGGREGATOR & NUMBER Test QUERY INIT
INFO  [2023-01-26 18:10:41,690] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[EXISTS_AGGREGATOR$20&$20NUMBER$20Test[2]] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:41,690] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[920b70b5-c92e-46f6-8cbd-580b26d76a4f] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_EXISTS_AGGREGATOR & NUMBER Test[2]))]]
INFO  [2023-01-26 18:10:41,695] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery EXISTS_AGGREGATOR$20&$20NUMBER$20Test[2].920b70b5-c92e-46f6-8cbd-580b26d76a4f
INFO  [2023-01-26 18:10:41,695] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery EXISTS_AGGREGATOR$20&$20NUMBER$20Test[2].920b70b5-c92e-46f6-8cbd-580b26d76a4f
INFO  [2023-01-26 18:10:41,696] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[EXISTS_AGGREGATOR$20&$20NUMBER$20Test[2].920b70b5-c92e-46f6-8cbd-580b26d76a4f] with 1 results within PT0.001013S
INFO  [2023-01-26 18:10:41,696] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[EXISTS_AGGREGATOR$20&$20NUMBER$20Test[2].920b70b5-c92e-46f6-8cbd-580b26d76a4f] with 2 results within PT0.001061S
127.0.0.1 - - [26/Jan/2023:18:10:41 +0000] "POST /api/datasets/EXISTS_AGGREGATOR$20&$20NUMBER$20Test%5B2%5D/queries HTTP/1.1" 201 2212 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:10:41,696] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=EXISTS_AGGREGATOR$20&$20NUMBER$20Test[2].920b70b5-c92e-46f6-8cbd-580b26d76a4f, workerId=EXISTS_AGGREGATOR$20&$20NUMBER$20Test[2].worker_EXISTS_AGGREGATOR$20&$20NUMBER$20Test[2]_254b91f4-6328-490e-86d1-c42aa5225e09, startTime=2023-01-26T18:10:41.695331, finishTime=2023-01-26T18:10:41.696344) of size 1
INFO  [2023-01-26 18:10:41,696] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=EXISTS_AGGREGATOR$20&$20NUMBER$20Test[2].920b70b5-c92e-46f6-8cbd-580b26d76a4f, workerId=EXISTS_AGGREGATOR$20&$20NUMBER$20Test[2].worker_EXISTS_AGGREGATOR$20&$20NUMBER$20Test[2]_e14ebb13-ae05-4b92-b4d0-7fd3103027df, startTime=2023-01-26T18:10:41.695304, finishTime=2023-01-26T18:10:41.696365) of size 2
INFO  [2023-01-26 18:10:41,697] com.bakdata.conquery.models.execution.ManagedExecution: DONE 920b70b5-c92e-46f6-8cbd-580b26d76a4f ManagedQuery within PT0.006157S
127.0.0.1 - - [26/Jan/2023:18:10:41 +0000] "GET /api/datasets/EXISTS_AGGREGATOR$20&$20NUMBER$20Test%5B2%5D/queries/EXISTS_AGGREGATOR$20&$20NUMBER$20Test%5B2%5D.920b70b5-c92e-46f6-8cbd-580b26d76a4f HTTP/1.1" 200 2875 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:10:41,723] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=EXISTS_AGGREGATOR & NUMBER Test[2]], queryId=920b70b5-c92e-46f6-8cbd-580b26d76a4f, label=concept	@§$, creationTime=2023-01-26T18:10:41.690608, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@77f83318[Count = 0], startTime=2023-01-26T18:10:41.690826, finishTime=2023-01-26T18:10:41.696983, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2713a26f), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_EXISTS_AGGREGATOR & NUMBER Test[2])), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=3, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@44c3c3ef, com.bakdata.conquery.models.query.ColumnDescriptor@506cb4cc, com.bakdata.conquery.models.query.ColumnDescriptor@66ba3d2a, com.bakdata.conquery.models.query.ColumnDescriptor@5c80eb48]) download on dataset Dataset[label=null, name=EXISTS_AGGREGATOR & NUMBER Test[2]] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:41,723] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=EXISTS_AGGREGATOR & NUMBER Test[2]], queryId=920b70b5-c92e-46f6-8cbd-580b26d76a4f, label=concept	@§$, creationTime=2023-01-26T18:10:41.690608, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@77f83318[Count = 0], startTime=2023-01-26T18:10:41.690826, finishTime=2023-01-26T18:10:41.696983, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2713a26f), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_EXISTS_AGGREGATOR & NUMBER Test[2])), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=3, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@44c3c3ef, com.bakdata.conquery.models.query.ColumnDescriptor@506cb4cc, com.bakdata.conquery.models.query.ColumnDescriptor@66ba3d2a, com.bakdata.conquery.models.query.ColumnDescriptor@5c80eb48]) on dataset Dataset[label=null, name=EXISTS_AGGREGATOR & NUMBER Test[2]]
INFO  [2023-01-26 18:10:41,739] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest EXISTS_AGGREGATOR & NUMBER Test on 4 rows
127.0.0.1 - - [26/Jan/2023:18:10:41 +0000] "GET /api/datasets/EXISTS_AGGREGATOR%20&%20NUMBER%20Test%5B2%5D/result/EXISTS_AGGREGATOR$20&$20NUMBER$20Test%5B2%5D.920b70b5-c92e-46f6-8cbd-580b26d76a4f.csv?pretty=false HTTP/1.1" 200 139 "-" "Conquery (test client)" 17
INFO  [2023-01-26 18:10:41,739] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast EXISTS_AGGREGATOR & NUMBER Test[2]
INFO  [2023-01-26 18:10:41,740] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=EXISTS_AGGREGATOR & NUMBER Test[2], name=EXISTS_AGGREGATOR & NUMBER Test[2]]
INFO  [2023-01-26 18:10:41,740] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=EXISTS_AGGREGATOR & NUMBER Test[2], name=EXISTS_AGGREGATOR & NUMBER Test[2]]
INFO  [2023-01-26 18:10:41,740] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_EXISTS_AGGREGATOR & NUMBER Test[2]_e14ebb13-ae05-4b92-b4d0-7fd3103027df
INFO  [2023-01-26 18:10:41,740] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_EXISTS_AGGREGATOR & NUMBER Test[2]_254b91f4-6328-490e-86d1-c42aa5225e09
INFO  [2023-01-26 18:10:41,745] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_EXISTS_AGGREGATOR & NUMBER Test[2]_254b91f4-6328-490e-86d1-c42aa5225e09
INFO  [2023-01-26 18:10:41,746] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_EXISTS_AGGREGATOR & NUMBER Test[2]_e14ebb13-ae05-4b92-b4d0-7fd3103027df
INFO  [2023-01-26 18:10:41,838] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow EXISTS_AGGREGATOR & NUMBER Test[2]
INFO  [2023-01-26 18:10:41,938] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of EXISTS_AGGREGATOR$20&$20NUMBER$20Test[2]
INFO  [2023-01-26 18:10:41,938] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:41,943] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test EXISTS_AGGREGATOR & NUMBER Test
INFO  [2023-01-26 18:10:41,944] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test FIRST_AGGREGATOR Test
INFO  [2023-01-26 18:10:41,944] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:41,944] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:41,945] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=FIRST_AGGREGATOR Test, name=FIRST_AGGREGATOR Test]
INFO  [2023-01-26 18:10:41,945] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=FIRST_AGGREGATOR Test, name=FIRST_AGGREGATOR Test]
INFO  [2023-01-26 18:10:41,945] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:41,945] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:41,946] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker FIRST_AGGREGATOR$20Test.worker_FIRST_AGGREGATOR$20Test_e10a1c75-1233-4ab1-baed-165420aca244 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:41,946] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker FIRST_AGGREGATOR$20Test.worker_FIRST_AGGREGATOR$20Test_e10a1c75-1233-4ab1-baed-165420aca244 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:41,946] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:41,946] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker FIRST_AGGREGATOR$20Test.worker_FIRST_AGGREGATOR$20Test_83083889-fb1b-4859-a7de-7af4b9818e74 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:41,946] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker FIRST_AGGREGATOR$20Test.worker_FIRST_AGGREGATOR$20Test_83083889-fb1b-4859-a7de-7af4b9818e74 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:41,946] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:41,946] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:42,050] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:42,057] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:42,057] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table FIRST_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:42,057] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table FIRST_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:42,168] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:42,283] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:42,283] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:42,284] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 161 B in total
INFO  [2023-01-26 18:10:42,284] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_FIRST_AGGREGATOR Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000282366sINFO  [2023-01-26 18:10:42,312] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=6, sum=10, min=1, average=1.666667, max=2}
INFO  [2023-01-26 18:10:42,312] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with StringParser(super=Parser(lines=10, nullLines=2), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:42,312] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=10, nullLines=2), subType=IntegerParser(super=Parser(lines=10, nullLines=2), minValue=14805, maxValue=15341), dateReader=com.bakdata.conquery.util.DateReader@508a4abd)
INFO  [2023-01-26 18:10:42,316] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_FIRST_AGGREGATOR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:42,316] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:42,316] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_FIRST_AGGREGATOR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:42,331] com.bakdata.conquery.models.jobs.ImportJob: Importing table into FIRST_AGGREGATOR$20Test.table
127.0.0.1 - - [26/Jan/2023:18:10:42 +0000] "POST /admin/datasets/FIRST_AGGREGATOR%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_FIRST_AGGREGATOR+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:10:42,332] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:42,332] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:42,333] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:42,333] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:42,335] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:42,335] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[FIRST_AGGREGATOR$20Test.table.table], containing 10 entries.
INFO  [2023-01-26 18:10:42,335] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[FIRST_AGGREGATOR$20Test.table.table], containing 10 entries.
WARN  [2023-01-26 18:10:42,336] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:42,336] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received FIRST_AGGREGATOR$20Test.table.table.0
INFO  [2023-01-26 18:10:42,337] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received FIRST_AGGREGATOR$20Test.table.table.1
INFO  [2023-01-26 18:10:42,461] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:42,466] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:42,476] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:42,476] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:42,476] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:42,581] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: FIRST_AGGREGATOR Test QUERY INIT
INFO  [2023-01-26 18:10:42,592] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[FIRST_AGGREGATOR$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:42,592] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[8b506cbe-7d0e-479a-8175-9a8c73dcd3f8] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_FIRST_AGGREGATOR Test))]]
INFO  [2023-01-26 18:10:42,595] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery FIRST_AGGREGATOR$20Test.8b506cbe-7d0e-479a-8175-9a8c73dcd3f8
INFO  [2023-01-26 18:10:42,595] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery FIRST_AGGREGATOR$20Test.8b506cbe-7d0e-479a-8175-9a8c73dcd3f8
INFO  [2023-01-26 18:10:42,596] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[FIRST_AGGREGATOR$20Test.8b506cbe-7d0e-479a-8175-9a8c73dcd3f8] with 3 results within PT0.000894S
INFO  [2023-01-26 18:10:42,596] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[FIRST_AGGREGATOR$20Test.8b506cbe-7d0e-479a-8175-9a8c73dcd3f8] with 2 results within PT0.00105S
127.0.0.1 - - [26/Jan/2023:18:10:42 +0000] "POST /api/datasets/FIRST_AGGREGATOR$20Test/queries HTTP/1.1" 201 1313 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:10:42,596] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=FIRST_AGGREGATOR$20Test.8b506cbe-7d0e-479a-8175-9a8c73dcd3f8, workerId=FIRST_AGGREGATOR$20Test.worker_FIRST_AGGREGATOR$20Test_e10a1c75-1233-4ab1-baed-165420aca244, startTime=2023-01-26T18:10:42.595318, finishTime=2023-01-26T18:10:42.596212) of size 3
INFO  [2023-01-26 18:10:42,596] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=FIRST_AGGREGATOR$20Test.8b506cbe-7d0e-479a-8175-9a8c73dcd3f8, workerId=FIRST_AGGREGATOR$20Test.worker_FIRST_AGGREGATOR$20Test_83083889-fb1b-4859-a7de-7af4b9818e74, startTime=2023-01-26T18:10:42.595339, finishTime=2023-01-26T18:10:42.596389) of size 2
INFO  [2023-01-26 18:10:42,596] com.bakdata.conquery.models.execution.ManagedExecution: DONE 8b506cbe-7d0e-479a-8175-9a8c73dcd3f8 ManagedQuery within PT0.003806S
127.0.0.1 - - [26/Jan/2023:18:10:42 +0000] "GET /api/datasets/FIRST_AGGREGATOR$20Test/queries/FIRST_AGGREGATOR$20Test.8b506cbe-7d0e-479a-8175-9a8c73dcd3f8 HTTP/1.1" 200 1596 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:10:42,625] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=FIRST_AGGREGATOR Test], queryId=8b506cbe-7d0e-479a-8175-9a8c73dcd3f8, label=concept	@§$, creationTime=2023-01-26T18:10:42.592800, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@76e29c00[Count = 0], startTime=2023-01-26T18:10:42.592965, finishTime=2023-01-26T18:10:42.596771, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@43d9032f), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_FIRST_AGGREGATOR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=5, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@581ca371, com.bakdata.conquery.models.query.ColumnDescriptor@2d8ca30b, com.bakdata.conquery.models.query.ColumnDescriptor@4fec2826]) download on dataset Dataset[label=null, name=FIRST_AGGREGATOR Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:42,625] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=FIRST_AGGREGATOR Test], queryId=8b506cbe-7d0e-479a-8175-9a8c73dcd3f8, label=concept	@§$, creationTime=2023-01-26T18:10:42.592800, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@76e29c00[Count = 0], startTime=2023-01-26T18:10:42.592965, finishTime=2023-01-26T18:10:42.596771, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@43d9032f), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_FIRST_AGGREGATOR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=5, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@581ca371, com.bakdata.conquery.models.query.ColumnDescriptor@2d8ca30b, com.bakdata.conquery.models.query.ColumnDescriptor@4fec2826]) on dataset Dataset[label=null, name=FIRST_AGGREGATOR Test]
INFO  [2023-01-26 18:10:42,644] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest FIRST_AGGREGATOR Test on 6 rows
127.0.0.1 - - [26/Jan/2023:18:10:42 +0000] "GET /api/datasets/FIRST_AGGREGATOR%20Test/result/FIRST_AGGREGATOR$20Test.8b506cbe-7d0e-479a-8175-9a8c73dcd3f8.csv?pretty=false HTTP/1.1" 200 169 "-" "Conquery (test client)" 21
INFO  [2023-01-26 18:10:42,645] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast FIRST_AGGREGATOR Test
INFO  [2023-01-26 18:10:42,645] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=FIRST_AGGREGATOR Test, name=FIRST_AGGREGATOR Test]
INFO  [2023-01-26 18:10:42,645] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=FIRST_AGGREGATOR Test, name=FIRST_AGGREGATOR Test]
INFO  [2023-01-26 18:10:42,645] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_FIRST_AGGREGATOR Test_e10a1c75-1233-4ab1-baed-165420aca244
INFO  [2023-01-26 18:10:42,645] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_FIRST_AGGREGATOR Test_83083889-fb1b-4859-a7de-7af4b9818e74
INFO  [2023-01-26 18:10:42,660] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow FIRST_AGGREGATOR Test
INFO  [2023-01-26 18:10:42,660] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_FIRST_AGGREGATOR Test_83083889-fb1b-4859-a7de-7af4b9818e74
INFO  [2023-01-26 18:10:42,660] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_FIRST_AGGREGATOR Test_e10a1c75-1233-4ab1-baed-165420aca244
INFO  [2023-01-26 18:10:42,743] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of FIRST_AGGREGATOR$20Test
INFO  [2023-01-26 18:10:42,743] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:42,792] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test FIRST_AGGREGATOR Test
INFO  [2023-01-26 18:10:42,792] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test LAST_AGGREGATOR Test
INFO  [2023-01-26 18:10:42,792] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:42,792] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:42,793] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=LAST_AGGREGATOR Test, name=LAST_AGGREGATOR Test]
INFO  [2023-01-26 18:10:42,793] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=LAST_AGGREGATOR Test, name=LAST_AGGREGATOR Test]
INFO  [2023-01-26 18:10:42,793] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:42,793] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:42,794] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker LAST_AGGREGATOR$20Test.worker_LAST_AGGREGATOR$20Test_6dcb2b2f-7230-4029-9236-b0100af9e387 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:42,794] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker LAST_AGGREGATOR$20Test.worker_LAST_AGGREGATOR$20Test_6dcb2b2f-7230-4029-9236-b0100af9e387 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:42,794] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:42,794] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker LAST_AGGREGATOR$20Test.worker_LAST_AGGREGATOR$20Test_674f5284-cf66-4b2a-828e-1e9d060c988f are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:42,794] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker LAST_AGGREGATOR$20Test.worker_LAST_AGGREGATOR$20Test_674f5284-cf66-4b2a-828e-1e9d060c988f are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:42,794] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:42,799] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:42,898] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:42,905] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:42,905] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table LAST_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:42,905] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table LAST_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:43,023] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:43,136] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:43,136] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:43,136] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 161 B in total
INFO  [2023-01-26 18:10:43,136] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_LAST_AGGREGATOR Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000446089sINFO  [2023-01-26 18:10:43,181] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=6, sum=10, min=1, average=1.666667, max=2}
INFO  [2023-01-26 18:10:43,182] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=10, nullLines=2), subType=IntegerParser(super=Parser(lines=10, nullLines=2), minValue=14805, maxValue=15341), dateReader=com.bakdata.conquery.util.DateReader@7273225a)
INFO  [2023-01-26 18:10:43,182] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with StringParser(super=Parser(lines=10, nullLines=2), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:43,185] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_LAST_AGGREGATOR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:43,185] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:43,185] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_LAST_AGGREGATOR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:43,201] com.bakdata.conquery.models.jobs.ImportJob: Importing table into LAST_AGGREGATOR$20Test.table
127.0.0.1 - - [26/Jan/2023:18:10:43 +0000] "POST /admin/datasets/LAST_AGGREGATOR%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_LAST_AGGREGATOR+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:10:43,202] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:43,202] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:43,203] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:43,203] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:43,205] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:43,205] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[LAST_AGGREGATOR$20Test.table.table], containing 10 entries.
INFO  [2023-01-26 18:10:43,205] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[LAST_AGGREGATOR$20Test.table.table], containing 10 entries.
WARN  [2023-01-26 18:10:43,206] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:43,206] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received LAST_AGGREGATOR$20Test.table.table.0
INFO  [2023-01-26 18:10:43,206] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received LAST_AGGREGATOR$20Test.table.table.1
INFO  [2023-01-26 18:10:43,312] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:43,318] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:43,328] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:43,328] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:43,329] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:43,433] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: LAST_AGGREGATOR Test QUERY INIT
INFO  [2023-01-26 18:10:43,443] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[LAST_AGGREGATOR$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:43,443] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[54e15c32-efea-4dc0-86fc-5b062e564a2b] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_LAST_AGGREGATOR Test))]]
INFO  [2023-01-26 18:10:43,445] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery LAST_AGGREGATOR$20Test.54e15c32-efea-4dc0-86fc-5b062e564a2b
INFO  [2023-01-26 18:10:43,445] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery LAST_AGGREGATOR$20Test.54e15c32-efea-4dc0-86fc-5b062e564a2b
INFO  [2023-01-26 18:10:43,446] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[LAST_AGGREGATOR$20Test.54e15c32-efea-4dc0-86fc-5b062e564a2b] with 3 results within PT0.000885S
127.0.0.1 - - [26/Jan/2023:18:10:43 +0000] "POST /api/datasets/LAST_AGGREGATOR$20Test/queries HTTP/1.1" 201 1310 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:10:43,446] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[LAST_AGGREGATOR$20Test.54e15c32-efea-4dc0-86fc-5b062e564a2b] with 2 results within PT0.001172S
INFO  [2023-01-26 18:10:43,446] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=LAST_AGGREGATOR$20Test.54e15c32-efea-4dc0-86fc-5b062e564a2b, workerId=LAST_AGGREGATOR$20Test.worker_LAST_AGGREGATOR$20Test_674f5284-cf66-4b2a-828e-1e9d060c988f, startTime=2023-01-26T18:10:43.445245, finishTime=2023-01-26T18:10:43.446130) of size 3
INFO  [2023-01-26 18:10:43,446] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=LAST_AGGREGATOR$20Test.54e15c32-efea-4dc0-86fc-5b062e564a2b, workerId=LAST_AGGREGATOR$20Test.worker_LAST_AGGREGATOR$20Test_6dcb2b2f-7230-4029-9236-b0100af9e387, startTime=2023-01-26T18:10:43.445342, finishTime=2023-01-26T18:10:43.446514) of size 2
INFO  [2023-01-26 18:10:43,446] com.bakdata.conquery.models.execution.ManagedExecution: DONE 54e15c32-efea-4dc0-86fc-5b062e564a2b ManagedQuery within PT0.003184S
127.0.0.1 - - [26/Jan/2023:18:10:43 +0000] "GET /api/datasets/LAST_AGGREGATOR$20Test/queries/LAST_AGGREGATOR$20Test.54e15c32-efea-4dc0-86fc-5b062e564a2b HTTP/1.1" 200 1589 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:10:43,461] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=LAST_AGGREGATOR Test], queryId=54e15c32-efea-4dc0-86fc-5b062e564a2b, label=concept	@§$, creationTime=2023-01-26T18:10:43.443609, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@538eef38[Count = 0], startTime=2023-01-26T18:10:43.443733, finishTime=2023-01-26T18:10:43.446917, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@672e0fbd), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_LAST_AGGREGATOR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=5, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@5e4c53ca, com.bakdata.conquery.models.query.ColumnDescriptor@5c76f3e9, com.bakdata.conquery.models.query.ColumnDescriptor@78a52070]) download on dataset Dataset[label=null, name=LAST_AGGREGATOR Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:43,461] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=LAST_AGGREGATOR Test], queryId=54e15c32-efea-4dc0-86fc-5b062e564a2b, label=concept	@§$, creationTime=2023-01-26T18:10:43.443609, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@538eef38[Count = 0], startTime=2023-01-26T18:10:43.443733, finishTime=2023-01-26T18:10:43.446917, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@672e0fbd), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_LAST_AGGREGATOR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=5, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@5e4c53ca, com.bakdata.conquery.models.query.ColumnDescriptor@5c76f3e9, com.bakdata.conquery.models.query.ColumnDescriptor@78a52070]) on dataset Dataset[label=null, name=LAST_AGGREGATOR Test]
127.0.0.1 - - [26/Jan/2023:18:10:43 +0000] "GET /api/datasets/LAST_AGGREGATOR%20Test/result/LAST_AGGREGATOR$20Test.54e15c32-efea-4dc0-86fc-5b062e564a2b.csv?pretty=false HTTP/1.1" 200 169 "-" "Conquery (test client)" 12
INFO  [2023-01-26 18:10:43,472] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest LAST_AGGREGATOR Test on 6 rows
INFO  [2023-01-26 18:10:43,473] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast LAST_AGGREGATOR Test
INFO  [2023-01-26 18:10:43,473] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=LAST_AGGREGATOR Test, name=LAST_AGGREGATOR Test]
INFO  [2023-01-26 18:10:43,473] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=LAST_AGGREGATOR Test, name=LAST_AGGREGATOR Test]
INFO  [2023-01-26 18:10:43,473] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_LAST_AGGREGATOR Test_674f5284-cf66-4b2a-828e-1e9d060c988f
INFO  [2023-01-26 18:10:43,473] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_LAST_AGGREGATOR Test_6dcb2b2f-7230-4029-9236-b0100af9e387
INFO  [2023-01-26 18:10:43,493] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow LAST_AGGREGATOR Test
INFO  [2023-01-26 18:10:43,494] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_LAST_AGGREGATOR Test_6dcb2b2f-7230-4029-9236-b0100af9e387
INFO  [2023-01-26 18:10:43,494] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_LAST_AGGREGATOR Test_674f5284-cf66-4b2a-828e-1e9d060c988f
INFO  [2023-01-26 18:10:43,506] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of LAST_AGGREGATOR$20Test
INFO  [2023-01-26 18:10:43,506] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:43,634] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test LAST_AGGREGATOR Test
INFO  [2023-01-26 18:10:43,634] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test MULTI_SELECT_AGGREGATOR Test
INFO  [2023-01-26 18:10:43,634] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:43,634] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:43,635] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=MULTI_SELECT_AGGREGATOR Test, name=MULTI_SELECT_AGGREGATOR Test]
INFO  [2023-01-26 18:10:43,635] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:43,635] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=MULTI_SELECT_AGGREGATOR Test, name=MULTI_SELECT_AGGREGATOR Test]
INFO  [2023-01-26 18:10:43,635] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:43,636] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:43,636] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker MULTI_SELECT_AGGREGATOR$20Test.worker_MULTI_SELECT_AGGREGATOR$20Test_f3c1b2bb-9310-4599-8823-dc688cb0f3dc are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:43,636] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker MULTI_SELECT_AGGREGATOR$20Test.worker_MULTI_SELECT_AGGREGATOR$20Test_f3c1b2bb-9310-4599-8823-dc688cb0f3dc are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:43,636] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:43,636] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker MULTI_SELECT_AGGREGATOR$20Test.worker_MULTI_SELECT_AGGREGATOR$20Test_305b7ba7-4691-4d1e-a6c2-96f630e75474 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:43,636] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker MULTI_SELECT_AGGREGATOR$20Test.worker_MULTI_SELECT_AGGREGATOR$20Test_305b7ba7-4691-4d1e-a6c2-96f630e75474 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:43,636] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:43,740] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:43,747] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:43,747] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table MULTI_SELECT_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:43,747] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table MULTI_SELECT_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:43,869] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:43,980] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:43,980] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:43,980] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 166 B in total
INFO  [2023-01-26 18:10:43,980] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTI_SELECT_AGGREGATOR Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000249728sINFO  [2023-01-26 18:10:44,005] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=6, sum=9, min=1, average=1.500000, max=2}
INFO  [2023-01-26 18:10:44,006] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with StringParser(super=Parser(lines=9, nullLines=1), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:44,006] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=9, nullLines=0), subType=IntegerParser(super=Parser(lines=9, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@2c9988a5)
INFO  [2023-01-26 18:10:44,008] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTI_SELECT_AGGREGATOR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:44,008] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:44,008] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_MULTI_SELECT_AGGREGATOR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:44,023] com.bakdata.conquery.models.jobs.ImportJob: Importing table into MULTI_SELECT_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:44,023] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:10:44 +0000] "POST /admin/datasets/MULTI_SELECT_AGGREGATOR%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_MULTI_SELECT_AGGREGATOR+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:10:44,024] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:44,024] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:44,024] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:44,025] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:44,026] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[MULTI_SELECT_AGGREGATOR$20Test.table.table], containing 9 entries.
INFO  [2023-01-26 18:10:44,026] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[MULTI_SELECT_AGGREGATOR$20Test.table.table], containing 9 entries.
WARN  [2023-01-26 18:10:44,026] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:44,027] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTI_SELECT_AGGREGATOR$20Test.table.table.0
INFO  [2023-01-26 18:10:44,027] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received MULTI_SELECT_AGGREGATOR$20Test.table.table.1
INFO  [2023-01-26 18:10:44,132] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:44,137] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:44,147] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:44,148] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:44,148] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:44,253] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: MULTI_SELECT_AGGREGATOR Test QUERY INIT
INFO  [2023-01-26 18:10:44,263] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[MULTI_SELECT_AGGREGATOR$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:44,263] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[c098e056-8724-4f24-b67d-3f76a6f6f963] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_MULTI_SELECT_AGGREGATOR Test))]]
INFO  [2023-01-26 18:10:44,265] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery MULTI_SELECT_AGGREGATOR$20Test.c098e056-8724-4f24-b67d-3f76a6f6f963
INFO  [2023-01-26 18:10:44,265] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery MULTI_SELECT_AGGREGATOR$20Test.c098e056-8724-4f24-b67d-3f76a6f6f963
127.0.0.1 - - [26/Jan/2023:18:10:44 +0000] "POST /api/datasets/MULTI_SELECT_AGGREGATOR$20Test/queries HTTP/1.1" 201 1350 "-" "Conquery (test client)" 5
INFO  [2023-01-26 18:10:44,279] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[MULTI_SELECT_AGGREGATOR$20Test.c098e056-8724-4f24-b67d-3f76a6f6f963] with 3 results within PT0.014266S
INFO  [2023-01-26 18:10:44,280] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[MULTI_SELECT_AGGREGATOR$20Test.c098e056-8724-4f24-b67d-3f76a6f6f963] with 3 results within PT0.014288S
INFO  [2023-01-26 18:10:44,281] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=MULTI_SELECT_AGGREGATOR$20Test.c098e056-8724-4f24-b67d-3f76a6f6f963, workerId=MULTI_SELECT_AGGREGATOR$20Test.worker_MULTI_SELECT_AGGREGATOR$20Test_f3c1b2bb-9310-4599-8823-dc688cb0f3dc, startTime=2023-01-26T18:10:44.265713, finishTime=2023-01-26T18:10:44.279979) of size 3
INFO  [2023-01-26 18:10:44,281] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=MULTI_SELECT_AGGREGATOR$20Test.c098e056-8724-4f24-b67d-3f76a6f6f963, workerId=MULTI_SELECT_AGGREGATOR$20Test.worker_MULTI_SELECT_AGGREGATOR$20Test_305b7ba7-4691-4d1e-a6c2-96f630e75474, startTime=2023-01-26T18:10:44.265715, finishTime=2023-01-26T18:10:44.280003) of size 3
INFO  [2023-01-26 18:10:44,281] com.bakdata.conquery.models.execution.ManagedExecution: DONE c098e056-8724-4f24-b67d-3f76a6f6f963 ManagedQuery within PT0.017967S
127.0.0.1 - - [26/Jan/2023:18:10:44 +0000] "GET /api/datasets/MULTI_SELECT_AGGREGATOR$20Test/queries/MULTI_SELECT_AGGREGATOR$20Test.c098e056-8724-4f24-b67d-3f76a6f6f963 HTTP/1.1" 200 1662 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:10:44,292] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=MULTI_SELECT_AGGREGATOR Test], queryId=c098e056-8724-4f24-b67d-3f76a6f6f963, label=concept	@§$, creationTime=2023-01-26T18:10:44.263655, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@5637182[Count = 0], startTime=2023-01-26T18:10:44.263792, finishTime=2023-01-26T18:10:44.281759, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@15f69b4e), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_MULTI_SELECT_AGGREGATOR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=6, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@1527406d, com.bakdata.conquery.models.query.ColumnDescriptor@394c37c7, com.bakdata.conquery.models.query.ColumnDescriptor@27bdbe0d]) download on dataset Dataset[label=null, name=MULTI_SELECT_AGGREGATOR Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:44,292] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=MULTI_SELECT_AGGREGATOR Test], queryId=c098e056-8724-4f24-b67d-3f76a6f6f963, label=concept	@§$, creationTime=2023-01-26T18:10:44.263655, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@5637182[Count = 0], startTime=2023-01-26T18:10:44.263792, finishTime=2023-01-26T18:10:44.281759, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@15f69b4e), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_MULTI_SELECT_AGGREGATOR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=6, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@1527406d, com.bakdata.conquery.models.query.ColumnDescriptor@394c37c7, com.bakdata.conquery.models.query.ColumnDescriptor@27bdbe0d]) on dataset Dataset[label=null, name=MULTI_SELECT_AGGREGATOR Test]
127.0.0.1 - - [26/Jan/2023:18:10:44 +0000] "GET /api/datasets/MULTI_SELECT_AGGREGATOR%20Test/result/MULTI_SELECT_AGGREGATOR$20Test.c098e056-8724-4f24-b67d-3f76a6f6f963.csv?pretty=false HTTP/1.1" 200 224 "-" "Conquery (test client)" 14
INFO  [2023-01-26 18:10:44,305] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest MULTI_SELECT_AGGREGATOR Test on 7 rows
INFO  [2023-01-26 18:10:44,305] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast MULTI_SELECT_AGGREGATOR Test
INFO  [2023-01-26 18:10:44,305] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=MULTI_SELECT_AGGREGATOR Test, name=MULTI_SELECT_AGGREGATOR Test]
INFO  [2023-01-26 18:10:44,305] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=MULTI_SELECT_AGGREGATOR Test, name=MULTI_SELECT_AGGREGATOR Test]
INFO  [2023-01-26 18:10:44,306] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_MULTI_SELECT_AGGREGATOR Test_f3c1b2bb-9310-4599-8823-dc688cb0f3dc
INFO  [2023-01-26 18:10:44,306] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_MULTI_SELECT_AGGREGATOR Test_305b7ba7-4691-4d1e-a6c2-96f630e75474
INFO  [2023-01-26 18:10:44,335] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow MULTI_SELECT_AGGREGATOR Test
INFO  [2023-01-26 18:10:44,336] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_MULTI_SELECT_AGGREGATOR Test_305b7ba7-4691-4d1e-a6c2-96f630e75474
INFO  [2023-01-26 18:10:44,336] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_MULTI_SELECT_AGGREGATOR Test_f3c1b2bb-9310-4599-8823-dc688cb0f3dc
INFO  [2023-01-26 18:10:44,427] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of MULTI_SELECT_AGGREGATOR$20Test
INFO  [2023-01-26 18:10:44,427] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:44,453] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test MULTI_SELECT_AGGREGATOR Test
INFO  [2023-01-26 18:10:44,454] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test PREFIX_AGGREGATOR Test
INFO  [2023-01-26 18:10:44,454] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:44,454] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:44,466] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=PREFIX_AGGREGATOR Test, name=PREFIX_AGGREGATOR Test]
INFO  [2023-01-26 18:10:44,466] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=PREFIX_AGGREGATOR Test, name=PREFIX_AGGREGATOR Test]
INFO  [2023-01-26 18:10:44,466] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:44,466] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:44,468] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker PREFIX_AGGREGATOR$20Test.worker_PREFIX_AGGREGATOR$20Test_d6c9030d-7fb9-4a13-a136-1a1923aedf96 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:44,468] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker PREFIX_AGGREGATOR$20Test.worker_PREFIX_AGGREGATOR$20Test_d6c9030d-7fb9-4a13-a136-1a1923aedf96 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:44,468] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:44,468] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker PREFIX_AGGREGATOR$20Test.worker_PREFIX_AGGREGATOR$20Test_f09bbde6-6477-491a-8bd1-9ee8b5019423 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:44,468] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker PREFIX_AGGREGATOR$20Test.worker_PREFIX_AGGREGATOR$20Test_f09bbde6-6477-491a-8bd1-9ee8b5019423 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:44,468] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:44,473] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:44,573] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:44,579] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:44,579] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table PREFIX_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:44,579] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table PREFIX_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:44,695] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:44,806] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:44,806] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:44,806] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 100 B in total
INFO  [2023-01-26 18:10:44,806] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_PREFIX_AGGREGATOR Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.00025008sINFO  [2023-01-26 18:10:44,831] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=5, min=1, average=1.250000, max=2}
INFO  [2023-01-26 18:10:44,831] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with StringParser(super=Parser(lines=5, nullLines=1), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:44,831] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=5, nullLines=0), subType=IntegerParser(super=Parser(lines=5, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@32ff15fc)
INFO  [2023-01-26 18:10:44,835] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_PREFIX_AGGREGATOR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:44,835] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:44,835] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_PREFIX_AGGREGATOR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:44,860] com.bakdata.conquery.models.jobs.ImportJob: Importing table into PREFIX_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:44,861] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:10:44 +0000] "POST /admin/datasets/PREFIX_AGGREGATOR%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_PREFIX_AGGREGATOR+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 16
INFO  [2023-01-26 18:10:44,861] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:44,862] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:44,862] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:44,863] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:44,864] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[PREFIX_AGGREGATOR$20Test.table.table], containing 5 entries.
INFO  [2023-01-26 18:10:44,864] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[PREFIX_AGGREGATOR$20Test.table.table], containing 5 entries.
WARN  [2023-01-26 18:10:44,864] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:44,864] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received PREFIX_AGGREGATOR$20Test.table.table.0
INFO  [2023-01-26 18:10:44,865] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received PREFIX_AGGREGATOR$20Test.table.table.1
INFO  [2023-01-26 18:10:44,969] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:44,975] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:44,984] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:44,984] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:44,984] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:45,090] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: PREFIX_AGGREGATOR Test QUERY INIT
INFO  [2023-01-26 18:10:45,098] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[PREFIX_AGGREGATOR$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:45,098] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[3a5ceb7b-eddc-41bf-ac61-09dc6af01672] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_PREFIX_AGGREGATOR Test))]]
INFO  [2023-01-26 18:10:45,100] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery PREFIX_AGGREGATOR$20Test.3a5ceb7b-eddc-41bf-ac61-09dc6af01672
INFO  [2023-01-26 18:10:45,100] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery PREFIX_AGGREGATOR$20Test.3a5ceb7b-eddc-41bf-ac61-09dc6af01672
127.0.0.1 - - [26/Jan/2023:18:10:45 +0000] "POST /api/datasets/PREFIX_AGGREGATOR$20Test/queries HTTP/1.1" 201 1320 "-" "Conquery (test client)" 4
INFO  [2023-01-26 18:10:45,101] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[PREFIX_AGGREGATOR$20Test.3a5ceb7b-eddc-41bf-ac61-09dc6af01672] with 1 results within PT0.000808S
INFO  [2023-01-26 18:10:45,101] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[PREFIX_AGGREGATOR$20Test.3a5ceb7b-eddc-41bf-ac61-09dc6af01672] with 3 results within PT0.001093S
INFO  [2023-01-26 18:10:45,101] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=PREFIX_AGGREGATOR$20Test.3a5ceb7b-eddc-41bf-ac61-09dc6af01672, workerId=PREFIX_AGGREGATOR$20Test.worker_PREFIX_AGGREGATOR$20Test_f09bbde6-6477-491a-8bd1-9ee8b5019423, startTime=2023-01-26T18:10:45.100240, finishTime=2023-01-26T18:10:45.101048) of size 1
INFO  [2023-01-26 18:10:45,102] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=PREFIX_AGGREGATOR$20Test.3a5ceb7b-eddc-41bf-ac61-09dc6af01672, workerId=PREFIX_AGGREGATOR$20Test.worker_PREFIX_AGGREGATOR$20Test_d6c9030d-7fb9-4a13-a136-1a1923aedf96, startTime=2023-01-26T18:10:45.100214, finishTime=2023-01-26T18:10:45.101307) of size 3
INFO  [2023-01-26 18:10:45,102] com.bakdata.conquery.models.execution.ManagedExecution: DONE 3a5ceb7b-eddc-41bf-ac61-09dc6af01672 ManagedQuery within PT0.003983S
127.0.0.1 - - [26/Jan/2023:18:10:45 +0000] "GET /api/datasets/PREFIX_AGGREGATOR$20Test/queries/PREFIX_AGGREGATOR$20Test.3a5ceb7b-eddc-41bf-ac61-09dc6af01672 HTTP/1.1" 200 1606 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:10:45,122] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=PREFIX_AGGREGATOR Test], queryId=3a5ceb7b-eddc-41bf-ac61-09dc6af01672, label=concept	@§$, creationTime=2023-01-26T18:10:45.098223, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@778793ba[Count = 0], startTime=2023-01-26T18:10:45.098347, finishTime=2023-01-26T18:10:45.102330, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2d76ef3f), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_PREFIX_AGGREGATOR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@661e7b62, com.bakdata.conquery.models.query.ColumnDescriptor@446f7aa1, com.bakdata.conquery.models.query.ColumnDescriptor@fbe3bd5]) download on dataset Dataset[label=null, name=PREFIX_AGGREGATOR Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:45,122] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=PREFIX_AGGREGATOR Test], queryId=3a5ceb7b-eddc-41bf-ac61-09dc6af01672, label=concept	@§$, creationTime=2023-01-26T18:10:45.098223, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@778793ba[Count = 0], startTime=2023-01-26T18:10:45.098347, finishTime=2023-01-26T18:10:45.102330, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@2d76ef3f), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_PREFIX_AGGREGATOR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@661e7b62, com.bakdata.conquery.models.query.ColumnDescriptor@446f7aa1, com.bakdata.conquery.models.query.ColumnDescriptor@fbe3bd5]) on dataset Dataset[label=null, name=PREFIX_AGGREGATOR Test]
127.0.0.1 - - [26/Jan/2023:18:10:45 +0000] "GET /api/datasets/PREFIX_AGGREGATOR%20Test/result/PREFIX_AGGREGATOR$20Test.3a5ceb7b-eddc-41bf-ac61-09dc6af01672.csv?pretty=false HTTP/1.1" 200 151 "-" "Conquery (test client)" 20
INFO  [2023-01-26 18:10:45,141] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest PREFIX_AGGREGATOR Test on 5 rows
INFO  [2023-01-26 18:10:45,141] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast PREFIX_AGGREGATOR Test
INFO  [2023-01-26 18:10:45,142] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=PREFIX_AGGREGATOR Test, name=PREFIX_AGGREGATOR Test]
INFO  [2023-01-26 18:10:45,142] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=PREFIX_AGGREGATOR Test, name=PREFIX_AGGREGATOR Test]
INFO  [2023-01-26 18:10:45,142] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_PREFIX_AGGREGATOR Test_f09bbde6-6477-491a-8bd1-9ee8b5019423
INFO  [2023-01-26 18:10:45,142] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_PREFIX_AGGREGATOR Test_d6c9030d-7fb9-4a13-a136-1a1923aedf96
INFO  [2023-01-26 18:10:45,166] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow PREFIX_AGGREGATOR Test
INFO  [2023-01-26 18:10:45,181] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_PREFIX_AGGREGATOR Test_d6c9030d-7fb9-4a13-a136-1a1923aedf96
INFO  [2023-01-26 18:10:45,181] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_PREFIX_AGGREGATOR Test_f09bbde6-6477-491a-8bd1-9ee8b5019423
INFO  [2023-01-26 18:10:45,265] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of PREFIX_AGGREGATOR$20Test
INFO  [2023-01-26 18:10:45,265] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:45,289] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test PREFIX_AGGREGATOR Test
INFO  [2023-01-26 18:10:45,290] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test QUARTER_AGGREGATOR
INFO  [2023-01-26 18:10:45,290] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:45,290] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:45,291] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=QUARTER_AGGREGATOR, name=QUARTER_AGGREGATOR]
INFO  [2023-01-26 18:10:45,291] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=QUARTER_AGGREGATOR, name=QUARTER_AGGREGATOR]
INFO  [2023-01-26 18:10:45,291] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:45,291] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:45,296] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker QUARTER_AGGREGATOR.worker_QUARTER_AGGREGATOR_81f067de-d3aa-4376-86dd-dfe2be3ea95e are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:45,296] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker QUARTER_AGGREGATOR.worker_QUARTER_AGGREGATOR_81f067de-d3aa-4376-86dd-dfe2be3ea95e are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:45,296] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:45,296] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker QUARTER_AGGREGATOR.worker_QUARTER_AGGREGATOR_d9e64817-95c6-42e5-8db1-a5142f55f423 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:45,296] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker QUARTER_AGGREGATOR.worker_QUARTER_AGGREGATOR_d9e64817-95c6-42e5-8db1-a5142f55f423 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:45,296] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:45,297] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:45,403] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:45,410] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:45,410] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table QUARTER_AGGREGATOR.table
INFO  [2023-01-26 18:10:45,410] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table QUARTER_AGGREGATOR.table
INFO  [2023-01-26 18:10:45,529] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:45,639] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:45,640] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:45,640] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 51 B in total
INFO  [2023-01-26 18:10:45,640] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_QUARTER_AGGREGATOR/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000359581sINFO  [2023-01-26 18:10:45,676] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=3, sum=4, min=1, average=1.333333, max=2}
INFO  [2023-01-26 18:10:45,676] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=4, nullLines=1), subType=IntegerParser(super=Parser(lines=4, nullLines=1), minValue=16452, maxValue=16679), dateReader=com.bakdata.conquery.util.DateReader@4612ab34)
INFO  [2023-01-26 18:10:45,678] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_QUARTER_AGGREGATOR/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:45,678] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:45,678] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_QUARTER_AGGREGATOR/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:45,691] com.bakdata.conquery.models.jobs.ImportJob: Importing table into QUARTER_AGGREGATOR.table
127.0.0.1 - - [26/Jan/2023:18:10:45 +0000] "POST /admin/datasets/QUARTER_AGGREGATOR/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_QUARTER_AGGREGATOR%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:10:45,692] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:45,693] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:45,693] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:45,693] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:45,694] com.bakdata.conquery.models.jobs.ImportJob: Start sending 1 Buckets
INFO  [2023-01-26 18:10:45,694] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[QUARTER_AGGREGATOR.table.table], containing 4 entries.
INFO  [2023-01-26 18:10:45,694] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[QUARTER_AGGREGATOR.table.table], containing 4 entries.
WARN  [2023-01-26 18:10:45,695] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:45,696] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received QUARTER_AGGREGATOR.table.table.0
INFO  [2023-01-26 18:10:45,801] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:45,806] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:45,817] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:45,817] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:45,923] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: QUARTER_AGGREGATOR QUERY INIT
INFO  [2023-01-26 18:10:45,941] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[QUARTER_AGGREGATOR] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:45,941] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[f28fcaa0-219c-4c4e-aade-86656f12e067] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_QUARTER_AGGREGATOR))]]
INFO  [2023-01-26 18:10:45,943] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery QUARTER_AGGREGATOR.f28fcaa0-219c-4c4e-aade-86656f12e067
WARN  [2023-01-26 18:10:45,944] com.bakdata.conquery.models.query.QueryExecutor: Entities for query are empty
INFO  [2023-01-26 18:10:45,944] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[QUARTER_AGGREGATOR.f28fcaa0-219c-4c4e-aade-86656f12e067] with 0 results within PT0.000246S
INFO  [2023-01-26 18:10:45,944] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery QUARTER_AGGREGATOR.f28fcaa0-219c-4c4e-aade-86656f12e067
INFO  [2023-01-26 18:10:45,944] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=QUARTER_AGGREGATOR.f28fcaa0-219c-4c4e-aade-86656f12e067, workerId=QUARTER_AGGREGATOR.worker_QUARTER_AGGREGATOR_81f067de-d3aa-4376-86dd-dfe2be3ea95e, startTime=2023-01-26T18:10:45.943888, finishTime=2023-01-26T18:10:45.944134) of size 0
127.0.0.1 - - [26/Jan/2023:18:10:45 +0000] "POST /api/datasets/QUARTER_AGGREGATOR/queries HTTP/1.1" 201 1289 "-" "Conquery (test client)" 5
INFO  [2023-01-26 18:10:45,949] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[QUARTER_AGGREGATOR.f28fcaa0-219c-4c4e-aade-86656f12e067] with 2 results within PT0.004883S
INFO  [2023-01-26 18:10:45,949] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=QUARTER_AGGREGATOR.f28fcaa0-219c-4c4e-aade-86656f12e067, workerId=QUARTER_AGGREGATOR.worker_QUARTER_AGGREGATOR_d9e64817-95c6-42e5-8db1-a5142f55f423, startTime=2023-01-26T18:10:45.944422, finishTime=2023-01-26T18:10:45.949305) of size 2
INFO  [2023-01-26 18:10:45,949] com.bakdata.conquery.models.execution.ManagedExecution: DONE f28fcaa0-219c-4c4e-aade-86656f12e067 ManagedQuery within PT0.008077S
127.0.0.1 - - [26/Jan/2023:18:10:45 +0000] "GET /api/datasets/QUARTER_AGGREGATOR/queries/QUARTER_AGGREGATOR.f28fcaa0-219c-4c4e-aade-86656f12e067 HTTP/1.1" 200 1552 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:10:45,969] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=QUARTER_AGGREGATOR], queryId=f28fcaa0-219c-4c4e-aade-86656f12e067, label=concept	@§$, creationTime=2023-01-26T18:10:45.941639, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@7acf2710[Count = 0], startTime=2023-01-26T18:10:45.941790, finishTime=2023-01-26T18:10:45.949867, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@234d717c), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_QUARTER_AGGREGATOR)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@4d8a43aa, com.bakdata.conquery.models.query.ColumnDescriptor@44cbadd0, com.bakdata.conquery.models.query.ColumnDescriptor@47bff5fe]) download on dataset Dataset[label=null, name=QUARTER_AGGREGATOR] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:45,970] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=QUARTER_AGGREGATOR], queryId=f28fcaa0-219c-4c4e-aade-86656f12e067, label=concept	@§$, creationTime=2023-01-26T18:10:45.941639, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@7acf2710[Count = 0], startTime=2023-01-26T18:10:45.941790, finishTime=2023-01-26T18:10:45.949867, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@234d717c), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_QUARTER_AGGREGATOR)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=2, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@4d8a43aa, com.bakdata.conquery.models.query.ColumnDescriptor@44cbadd0, com.bakdata.conquery.models.query.ColumnDescriptor@47bff5fe]) on dataset Dataset[label=null, name=QUARTER_AGGREGATOR]
127.0.0.1 - - [26/Jan/2023:18:10:45 +0000] "GET /api/datasets/QUARTER_AGGREGATOR/result/QUARTER_AGGREGATOR.f28fcaa0-219c-4c4e-aade-86656f12e067.csv?pretty=false HTTP/1.1" 200 122 "-" "Conquery (test client)" 26
INFO  [2023-01-26 18:10:45,994] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest QUARTER_AGGREGATOR on 3 rows
INFO  [2023-01-26 18:10:45,994] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast QUARTER_AGGREGATOR
INFO  [2023-01-26 18:10:45,994] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=QUARTER_AGGREGATOR, name=QUARTER_AGGREGATOR]
INFO  [2023-01-26 18:10:45,994] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=QUARTER_AGGREGATOR, name=QUARTER_AGGREGATOR]
INFO  [2023-01-26 18:10:45,994] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_QUARTER_AGGREGATOR_81f067de-d3aa-4376-86dd-dfe2be3ea95e
INFO  [2023-01-26 18:10:45,995] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_QUARTER_AGGREGATOR_d9e64817-95c6-42e5-8db1-a5142f55f423
INFO  [2023-01-26 18:10:45,996] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_QUARTER_AGGREGATOR_81f067de-d3aa-4376-86dd-dfe2be3ea95e
INFO  [2023-01-26 18:10:45,996] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_QUARTER_AGGREGATOR_d9e64817-95c6-42e5-8db1-a5142f55f423
INFO  [2023-01-26 18:10:46,093] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow QUARTER_AGGREGATOR
INFO  [2023-01-26 18:10:46,096] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of QUARTER_AGGREGATOR
INFO  [2023-01-26 18:10:46,096] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:46,122] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test QUARTER_AGGREGATOR
INFO  [2023-01-26 18:10:46,123] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test RANDOM_AGGREGATOR Test
INFO  [2023-01-26 18:10:46,123] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:46,123] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:46,124] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=RANDOM_AGGREGATOR Test, name=RANDOM_AGGREGATOR Test]
INFO  [2023-01-26 18:10:46,124] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=RANDOM_AGGREGATOR Test, name=RANDOM_AGGREGATOR Test]
INFO  [2023-01-26 18:10:46,124] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:46,124] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:46,126] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker RANDOM_AGGREGATOR$20Test.worker_RANDOM_AGGREGATOR$20Test_b61cb345-cf7d-4e3a-9d63-5719d74e27ab are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:46,126] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker RANDOM_AGGREGATOR$20Test.worker_RANDOM_AGGREGATOR$20Test_b61cb345-cf7d-4e3a-9d63-5719d74e27ab are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:46,126] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:46,126] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker RANDOM_AGGREGATOR$20Test.worker_RANDOM_AGGREGATOR$20Test_ccb68fe3-385f-4d5c-afc3-49762d322bef are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:46,126] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker RANDOM_AGGREGATOR$20Test.worker_RANDOM_AGGREGATOR$20Test_ccb68fe3-385f-4d5c-afc3-49762d322bef are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:46,126] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:46,126] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:46,230] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:46,236] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:46,236] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table RANDOM_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:46,236] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table RANDOM_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:46,346] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:46,454] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:46,454] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:46,455] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 111 B in total
INFO  [2023-01-26 18:10:46,455] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_RANDOM_AGGREGATOR Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000423312sINFO  [2023-01-26 18:10:46,498] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=5, sum=7, min=1, average=1.400000, max=2}
INFO  [2023-01-26 18:10:46,498] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with StringParser(super=Parser(lines=7, nullLines=1), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:46,498] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=7, nullLines=2), subType=IntegerParser(super=Parser(lines=7, nullLines=2), minValue=14805, maxValue=15340), dateReader=com.bakdata.conquery.util.DateReader@30a27ebc)
INFO  [2023-01-26 18:10:46,501] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_RANDOM_AGGREGATOR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:46,501] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:46,501] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_RANDOM_AGGREGATOR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:46,516] com.bakdata.conquery.models.jobs.ImportJob: Importing table into RANDOM_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:46,517] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:10:46 +0000] "POST /admin/datasets/RANDOM_AGGREGATOR%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_RANDOM_AGGREGATOR+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:10:46,517] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:46,518] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:46,518] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:46,519] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:46,520] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[RANDOM_AGGREGATOR$20Test.table.table], containing 7 entries.
WARN  [2023-01-26 18:10:46,520] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:46,520] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received RANDOM_AGGREGATOR$20Test.table.table.0
INFO  [2023-01-26 18:10:46,521] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[RANDOM_AGGREGATOR$20Test.table.table], containing 7 entries.
INFO  [2023-01-26 18:10:46,521] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received RANDOM_AGGREGATOR$20Test.table.table.1
INFO  [2023-01-26 18:10:46,625] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:46,631] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:46,649] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:46,649] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:46,649] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:46,755] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: RANDOM_AGGREGATOR Test QUERY INIT
INFO  [2023-01-26 18:10:46,763] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[RANDOM_AGGREGATOR$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:46,763] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[1a52a383-bb0b-4bc3-9242-531ff8080eee] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_RANDOM_AGGREGATOR Test))]]
INFO  [2023-01-26 18:10:46,764] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery RANDOM_AGGREGATOR$20Test.1a52a383-bb0b-4bc3-9242-531ff8080eee
INFO  [2023-01-26 18:10:46,764] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery RANDOM_AGGREGATOR$20Test.1a52a383-bb0b-4bc3-9242-531ff8080eee
127.0.0.1 - - [26/Jan/2023:18:10:46 +0000] "POST /api/datasets/RANDOM_AGGREGATOR$20Test/queries HTTP/1.1" 201 1319 "-" "Conquery (test client)" 4
INFO  [2023-01-26 18:10:46,765] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[RANDOM_AGGREGATOR$20Test.1a52a383-bb0b-4bc3-9242-531ff8080eee] with 2 results within PT0.000748S
INFO  [2023-01-26 18:10:46,765] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[RANDOM_AGGREGATOR$20Test.1a52a383-bb0b-4bc3-9242-531ff8080eee] with 2 results within PT0.000914S
INFO  [2023-01-26 18:10:46,765] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=RANDOM_AGGREGATOR$20Test.1a52a383-bb0b-4bc3-9242-531ff8080eee, workerId=RANDOM_AGGREGATOR$20Test.worker_RANDOM_AGGREGATOR$20Test_b61cb345-cf7d-4e3a-9d63-5719d74e27ab, startTime=2023-01-26T18:10:46.764805, finishTime=2023-01-26T18:10:46.765553) of size 2
INFO  [2023-01-26 18:10:46,766] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=RANDOM_AGGREGATOR$20Test.1a52a383-bb0b-4bc3-9242-531ff8080eee, workerId=RANDOM_AGGREGATOR$20Test.worker_RANDOM_AGGREGATOR$20Test_ccb68fe3-385f-4d5c-afc3-49762d322bef, startTime=2023-01-26T18:10:46.764702, finishTime=2023-01-26T18:10:46.765616) of size 2
INFO  [2023-01-26 18:10:46,766] com.bakdata.conquery.models.execution.ManagedExecution: DONE 1a52a383-bb0b-4bc3-9242-531ff8080eee ManagedQuery within PT0.002781S
127.0.0.1 - - [26/Jan/2023:18:10:46 +0000] "GET /api/datasets/RANDOM_AGGREGATOR$20Test/queries/RANDOM_AGGREGATOR$20Test.1a52a383-bb0b-4bc3-9242-531ff8080eee HTTP/1.1" 200 1606 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:10:46,786] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=RANDOM_AGGREGATOR Test], queryId=1a52a383-bb0b-4bc3-9242-531ff8080eee, label=concept	@§$, creationTime=2023-01-26T18:10:46.763194, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@4e744000[Count = 0], startTime=2023-01-26T18:10:46.763310, finishTime=2023-01-26T18:10:46.766091, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@23ba1bd1), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_RANDOM_AGGREGATOR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@40547932, com.bakdata.conquery.models.query.ColumnDescriptor@50aa6311, com.bakdata.conquery.models.query.ColumnDescriptor@3cb24d44]) download on dataset Dataset[label=null, name=RANDOM_AGGREGATOR Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:46,786] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=RANDOM_AGGREGATOR Test], queryId=1a52a383-bb0b-4bc3-9242-531ff8080eee, label=concept	@§$, creationTime=2023-01-26T18:10:46.763194, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@4e744000[Count = 0], startTime=2023-01-26T18:10:46.763310, finishTime=2023-01-26T18:10:46.766091, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@23ba1bd1), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_RANDOM_AGGREGATOR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@40547932, com.bakdata.conquery.models.query.ColumnDescriptor@50aa6311, com.bakdata.conquery.models.query.ColumnDescriptor@3cb24d44]) on dataset Dataset[label=null, name=RANDOM_AGGREGATOR Test]
127.0.0.1 - - [26/Jan/2023:18:10:46 +0000] "GET /api/datasets/RANDOM_AGGREGATOR%20Test/result/RANDOM_AGGREGATOR$20Test.1a52a383-bb0b-4bc3-9242-531ff8080eee.csv?pretty=false HTTP/1.1" 200 141 "-" "Conquery (test client)" 14
INFO  [2023-01-26 18:10:46,800] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest RANDOM_AGGREGATOR Test on 5 rows
INFO  [2023-01-26 18:10:46,800] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast RANDOM_AGGREGATOR Test
INFO  [2023-01-26 18:10:46,800] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=RANDOM_AGGREGATOR Test, name=RANDOM_AGGREGATOR Test]
INFO  [2023-01-26 18:10:46,800] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=RANDOM_AGGREGATOR Test, name=RANDOM_AGGREGATOR Test]
INFO  [2023-01-26 18:10:46,800] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_RANDOM_AGGREGATOR Test_b61cb345-cf7d-4e3a-9d63-5719d74e27ab
INFO  [2023-01-26 18:10:46,800] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_RANDOM_AGGREGATOR Test_ccb68fe3-385f-4d5c-afc3-49762d322bef
INFO  [2023-01-26 18:10:46,824] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow RANDOM_AGGREGATOR Test
INFO  [2023-01-26 18:10:46,825] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_RANDOM_AGGREGATOR Test_b61cb345-cf7d-4e3a-9d63-5719d74e27ab
INFO  [2023-01-26 18:10:46,825] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_RANDOM_AGGREGATOR Test_ccb68fe3-385f-4d5c-afc3-49762d322bef
INFO  [2023-01-26 18:10:46,921] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of RANDOM_AGGREGATOR$20Test
INFO  [2023-01-26 18:10:46,921] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:46,955] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test RANDOM_AGGREGATOR Test
INFO  [2023-01-26 18:10:46,955] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test SELECT_AGGREGATOR Test
INFO  [2023-01-26 18:10:46,955] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:46,955] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:46,956] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SELECT_AGGREGATOR Test, name=SELECT_AGGREGATOR Test]
INFO  [2023-01-26 18:10:46,956] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SELECT_AGGREGATOR Test, name=SELECT_AGGREGATOR Test]
INFO  [2023-01-26 18:10:46,956] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:46,956] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:46,957] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:46,957] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SELECT_AGGREGATOR$20Test.worker_SELECT_AGGREGATOR$20Test_dd108513-4775-4820-b55f-9e29f9231cce are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:46,957] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SELECT_AGGREGATOR$20Test.worker_SELECT_AGGREGATOR$20Test_dd108513-4775-4820-b55f-9e29f9231cce are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:46,957] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:46,958] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SELECT_AGGREGATOR$20Test.worker_SELECT_AGGREGATOR$20Test_5b611186-607c-4cdd-9730-5fbc39ab1d03 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:46,958] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SELECT_AGGREGATOR$20Test.worker_SELECT_AGGREGATOR$20Test_5b611186-607c-4cdd-9730-5fbc39ab1d03 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:46,958] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:47,062] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:47,068] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:47,069] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SELECT_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:47,069] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SELECT_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:47,181] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:47,288] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:47,289] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:47,289] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 98 B in total
INFO  [2023-01-26 18:10:47,289] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SELECT_AGGREGATOR Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000421019sINFO  [2023-01-26 18:10:47,331] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=5, min=1, average=1.250000, max=2}
INFO  [2023-01-26 18:10:47,332] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with StringParser(super=Parser(lines=5, nullLines=1), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:47,332] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=5, nullLines=0), subType=IntegerParser(super=Parser(lines=5, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@5ba8eb00)
INFO  [2023-01-26 18:10:47,335] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SELECT_AGGREGATOR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:47,335] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:47,335] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SELECT_AGGREGATOR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:47,353] com.bakdata.conquery.models.jobs.ImportJob: Importing table into SELECT_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:47,353] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:10:47 +0000] "POST /admin/datasets/SELECT_AGGREGATOR%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_SELECT_AGGREGATOR+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 9
INFO  [2023-01-26 18:10:47,354] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:47,354] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:47,354] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:47,356] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:47,356] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SELECT_AGGREGATOR$20Test.table.table], containing 5 entries.
INFO  [2023-01-26 18:10:47,356] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SELECT_AGGREGATOR$20Test.table.table], containing 5 entries.
WARN  [2023-01-26 18:10:47,357] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:47,357] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SELECT_AGGREGATOR$20Test.table.table.0
INFO  [2023-01-26 18:10:47,357] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SELECT_AGGREGATOR$20Test.table.table.1
INFO  [2023-01-26 18:10:47,463] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:47,468] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:47,480] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:47,480] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:47,481] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:47,586] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: SELECT_AGGREGATOR Test QUERY INIT
INFO  [2023-01-26 18:10:47,596] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[SELECT_AGGREGATOR$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:47,596] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[3a5fc78f-4c00-4d20-95a3-534efa77eebb] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_SELECT_AGGREGATOR Test))]]
INFO  [2023-01-26 18:10:47,598] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SELECT_AGGREGATOR$20Test.3a5fc78f-4c00-4d20-95a3-534efa77eebb
INFO  [2023-01-26 18:10:47,599] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SELECT_AGGREGATOR$20Test.3a5fc78f-4c00-4d20-95a3-534efa77eebb
127.0.0.1 - - [26/Jan/2023:18:10:47 +0000] "POST /api/datasets/SELECT_AGGREGATOR$20Test/queries HTTP/1.1" 201 1321 "-" "Conquery (test client)" 4
INFO  [2023-01-26 18:10:47,600] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SELECT_AGGREGATOR$20Test.3a5fc78f-4c00-4d20-95a3-534efa77eebb] with 1 results within PT0.000942S
INFO  [2023-01-26 18:10:47,600] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SELECT_AGGREGATOR$20Test.3a5fc78f-4c00-4d20-95a3-534efa77eebb] with 3 results within PT0.001126S
INFO  [2023-01-26 18:10:47,600] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SELECT_AGGREGATOR$20Test.3a5fc78f-4c00-4d20-95a3-534efa77eebb, workerId=SELECT_AGGREGATOR$20Test.worker_SELECT_AGGREGATOR$20Test_dd108513-4775-4820-b55f-9e29f9231cce, startTime=2023-01-26T18:10:47.599104, finishTime=2023-01-26T18:10:47.600046) of size 1
INFO  [2023-01-26 18:10:47,600] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SELECT_AGGREGATOR$20Test.3a5fc78f-4c00-4d20-95a3-534efa77eebb, workerId=SELECT_AGGREGATOR$20Test.worker_SELECT_AGGREGATOR$20Test_5b611186-607c-4cdd-9730-5fbc39ab1d03, startTime=2023-01-26T18:10:47.598999, finishTime=2023-01-26T18:10:47.600125) of size 3
INFO  [2023-01-26 18:10:47,600] com.bakdata.conquery.models.execution.ManagedExecution: DONE 3a5fc78f-4c00-4d20-95a3-534efa77eebb ManagedQuery within PT0.003636S
127.0.0.1 - - [26/Jan/2023:18:10:47 +0000] "GET /api/datasets/SELECT_AGGREGATOR$20Test/queries/SELECT_AGGREGATOR$20Test.3a5fc78f-4c00-4d20-95a3-534efa77eebb HTTP/1.1" 200 1608 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:10:47,623] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SELECT_AGGREGATOR Test], queryId=3a5fc78f-4c00-4d20-95a3-534efa77eebb, label=concept	@§$, creationTime=2023-01-26T18:10:47.596859, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@5f1cc00c[Count = 0], startTime=2023-01-26T18:10:47.596981, finishTime=2023-01-26T18:10:47.600617, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@6d141684), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SELECT_AGGREGATOR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@12d8914b, com.bakdata.conquery.models.query.ColumnDescriptor@7b27d43d, com.bakdata.conquery.models.query.ColumnDescriptor@428277f5]) download on dataset Dataset[label=null, name=SELECT_AGGREGATOR Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:47,623] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SELECT_AGGREGATOR Test], queryId=3a5fc78f-4c00-4d20-95a3-534efa77eebb, label=concept	@§$, creationTime=2023-01-26T18:10:47.596859, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@5f1cc00c[Count = 0], startTime=2023-01-26T18:10:47.596981, finishTime=2023-01-26T18:10:47.600617, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@6d141684), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SELECT_AGGREGATOR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@12d8914b, com.bakdata.conquery.models.query.ColumnDescriptor@7b27d43d, com.bakdata.conquery.models.query.ColumnDescriptor@428277f5]) on dataset Dataset[label=null, name=SELECT_AGGREGATOR Test]
127.0.0.1 - - [26/Jan/2023:18:10:47 +0000] "GET /api/datasets/SELECT_AGGREGATOR%20Test/result/SELECT_AGGREGATOR$20Test.3a5fc78f-4c00-4d20-95a3-534efa77eebb.csv?pretty=false HTTP/1.1" 200 140 "-" "Conquery (test client)" 29
INFO  [2023-01-26 18:10:47,651] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest SELECT_AGGREGATOR Test on 5 rows
INFO  [2023-01-26 18:10:47,651] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast SELECT_AGGREGATOR Test
INFO  [2023-01-26 18:10:47,652] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SELECT_AGGREGATOR Test, name=SELECT_AGGREGATOR Test]
INFO  [2023-01-26 18:10:47,652] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SELECT_AGGREGATOR Test, name=SELECT_AGGREGATOR Test]
INFO  [2023-01-26 18:10:47,652] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SELECT_AGGREGATOR Test_dd108513-4775-4820-b55f-9e29f9231cce
INFO  [2023-01-26 18:10:47,652] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SELECT_AGGREGATOR Test_5b611186-607c-4cdd-9730-5fbc39ab1d03
INFO  [2023-01-26 18:10:47,656] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow SELECT_AGGREGATOR Test
INFO  [2023-01-26 18:10:47,657] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SELECT_AGGREGATOR Test_dd108513-4775-4820-b55f-9e29f9231cce
INFO  [2023-01-26 18:10:47,657] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SELECT_AGGREGATOR Test_5b611186-607c-4cdd-9730-5fbc39ab1d03
INFO  [2023-01-26 18:10:47,657] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of SELECT_AGGREGATOR$20Test
INFO  [2023-01-26 18:10:47,657] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:47,785] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test SELECT_AGGREGATOR Test
INFO  [2023-01-26 18:10:47,786] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test SUM_AGGREGATOR Test
INFO  [2023-01-26 18:10:47,786] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:47,786] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:47,789] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SUM_AGGREGATOR Test, name=SUM_AGGREGATOR Test]
INFO  [2023-01-26 18:10:47,789] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SUM_AGGREGATOR Test, name=SUM_AGGREGATOR Test]
INFO  [2023-01-26 18:10:47,789] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:47,789] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:47,790] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:47,792] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SUM_AGGREGATOR$20Test.worker_SUM_AGGREGATOR$20Test_fb937434-fa4f-4bdf-af2a-a904e7aef598 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:47,792] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SUM_AGGREGATOR$20Test.worker_SUM_AGGREGATOR$20Test_fb937434-fa4f-4bdf-af2a-a904e7aef598 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:47,792] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:47,792] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SUM_AGGREGATOR$20Test.worker_SUM_AGGREGATOR$20Test_462207f3-15cc-426a-9630-7a51e3cef5e4 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:47,792] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SUM_AGGREGATOR$20Test.worker_SUM_AGGREGATOR$20Test_462207f3-15cc-426a-9630-7a51e3cef5e4 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:47,792] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:47,895] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:47,902] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:47,902] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SUM_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:47,902] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SUM_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:48,020] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:48,133] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:48,133] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:48,133] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 91 B in total
INFO  [2023-01-26 18:10:48,133] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SUM_AGGREGATOR Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000273715sINFO  [2023-01-26 18:10:48,161] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=5, min=1, average=1.250000, max=2}
INFO  [2023-01-26 18:10:48,161] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with IntegerParser(super=Parser(lines=5, nullLines=1), minValue=-1, maxValue=1)
INFO  [2023-01-26 18:10:48,161] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=5, nullLines=0), subType=IntegerParser(super=Parser(lines=5, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@3b149c70)
INFO  [2023-01-26 18:10:48,164] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SUM_AGGREGATOR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:48,164] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:48,164] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SUM_AGGREGATOR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:48,181] com.bakdata.conquery.models.jobs.ImportJob: Importing table into SUM_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:48,182] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:48,182] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:48,183] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:48,184] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:48,184] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SUM_AGGREGATOR$20Test.table.table], containing 5 entries.
WARN  [2023-01-26 18:10:48,185] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:48,185] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SUM_AGGREGATOR$20Test.table.table.0
INFO  [2023-01-26 18:10:48,185] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SUM_AGGREGATOR$20Test.table.table], containing 5 entries.
INFO  [2023-01-26 18:10:48,185] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SUM_AGGREGATOR$20Test.table.table.1
INFO  [2023-01-26 18:10:48,185] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:10:48 +0000] "POST /admin/datasets/SUM_AGGREGATOR%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_SUM_AGGREGATOR+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 11
INFO  [2023-01-26 18:10:48,290] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:48,295] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:48,305] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:48,306] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:48,306] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:48,411] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: SUM_AGGREGATOR Test QUERY INIT
INFO  [2023-01-26 18:10:48,432] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[SUM_AGGREGATOR$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:48,432] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[15f31b5a-d13a-4a10-b069-e0bb6e9f5c48] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_SUM_AGGREGATOR Test))]]
INFO  [2023-01-26 18:10:48,434] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SUM_AGGREGATOR$20Test.15f31b5a-d13a-4a10-b069-e0bb6e9f5c48
INFO  [2023-01-26 18:10:48,434] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SUM_AGGREGATOR$20Test.15f31b5a-d13a-4a10-b069-e0bb6e9f5c48
127.0.0.1 - - [26/Jan/2023:18:10:48 +0000] "POST /api/datasets/SUM_AGGREGATOR$20Test/queries HTTP/1.1" 201 1306 "-" "Conquery (test client)" 5
INFO  [2023-01-26 18:10:48,435] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SUM_AGGREGATOR$20Test.15f31b5a-d13a-4a10-b069-e0bb6e9f5c48] with 1 results within PT0.000936S
INFO  [2023-01-26 18:10:48,435] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SUM_AGGREGATOR$20Test.15f31b5a-d13a-4a10-b069-e0bb6e9f5c48] with 3 results within PT0.001166S
INFO  [2023-01-26 18:10:48,435] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SUM_AGGREGATOR$20Test.15f31b5a-d13a-4a10-b069-e0bb6e9f5c48, workerId=SUM_AGGREGATOR$20Test.worker_SUM_AGGREGATOR$20Test_462207f3-15cc-426a-9630-7a51e3cef5e4, startTime=2023-01-26T18:10:48.434343, finishTime=2023-01-26T18:10:48.435279) of size 1
INFO  [2023-01-26 18:10:48,435] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SUM_AGGREGATOR$20Test.15f31b5a-d13a-4a10-b069-e0bb6e9f5c48, workerId=SUM_AGGREGATOR$20Test.worker_SUM_AGGREGATOR$20Test_fb937434-fa4f-4bdf-af2a-a904e7aef598, startTime=2023-01-26T18:10:48.434253, finishTime=2023-01-26T18:10:48.435419) of size 3
INFO  [2023-01-26 18:10:48,435] com.bakdata.conquery.models.execution.ManagedExecution: DONE 15f31b5a-d13a-4a10-b069-e0bb6e9f5c48 ManagedQuery within PT0.003414S
127.0.0.1 - - [26/Jan/2023:18:10:48 +0000] "GET /api/datasets/SUM_AGGREGATOR$20Test/queries/SUM_AGGREGATOR$20Test.15f31b5a-d13a-4a10-b069-e0bb6e9f5c48 HTTP/1.1" 200 1581 "-" "Conquery (test client)" 3
INFO  [2023-01-26 18:10:48,464] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SUM_AGGREGATOR Test], queryId=15f31b5a-d13a-4a10-b069-e0bb6e9f5c48, label=concept	@§$, creationTime=2023-01-26T18:10:48.432273, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@d66645c[Count = 0], startTime=2023-01-26T18:10:48.432415, finishTime=2023-01-26T18:10:48.435829, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@27513fce), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SUM_AGGREGATOR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@22b2dea7, com.bakdata.conquery.models.query.ColumnDescriptor@5797ba52, com.bakdata.conquery.models.query.ColumnDescriptor@69ed7078]) download on dataset Dataset[label=null, name=SUM_AGGREGATOR Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:48,464] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SUM_AGGREGATOR Test], queryId=15f31b5a-d13a-4a10-b069-e0bb6e9f5c48, label=concept	@§$, creationTime=2023-01-26T18:10:48.432273, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@d66645c[Count = 0], startTime=2023-01-26T18:10:48.432415, finishTime=2023-01-26T18:10:48.435829, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@27513fce), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SUM_AGGREGATOR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@22b2dea7, com.bakdata.conquery.models.query.ColumnDescriptor@5797ba52, com.bakdata.conquery.models.query.ColumnDescriptor@69ed7078]) on dataset Dataset[label=null, name=SUM_AGGREGATOR Test]
127.0.0.1 - - [26/Jan/2023:18:10:48 +0000] "GET /api/datasets/SUM_AGGREGATOR%20Test/result/SUM_AGGREGATOR$20Test.15f31b5a-d13a-4a10-b069-e0bb6e9f5c48.csv?pretty=false HTTP/1.1" 200 142 "-" "Conquery (test client)" 31
INFO  [2023-01-26 18:10:48,493] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest SUM_AGGREGATOR Test on 5 rows
INFO  [2023-01-26 18:10:48,494] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast SUM_AGGREGATOR Test
INFO  [2023-01-26 18:10:48,494] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SUM_AGGREGATOR Test, name=SUM_AGGREGATOR Test]
INFO  [2023-01-26 18:10:48,494] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SUM_AGGREGATOR Test, name=SUM_AGGREGATOR Test]
INFO  [2023-01-26 18:10:48,494] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SUM_AGGREGATOR Test_462207f3-15cc-426a-9630-7a51e3cef5e4
INFO  [2023-01-26 18:10:48,494] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SUM_AGGREGATOR Test_fb937434-fa4f-4bdf-af2a-a904e7aef598
INFO  [2023-01-26 18:10:48,592] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SUM_AGGREGATOR Test_462207f3-15cc-426a-9630-7a51e3cef5e4
INFO  [2023-01-26 18:10:48,592] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow SUM_AGGREGATOR Test
INFO  [2023-01-26 18:10:48,592] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SUM_AGGREGATOR Test_fb937434-fa4f-4bdf-af2a-a904e7aef598
INFO  [2023-01-26 18:10:48,693] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of SUM_AGGREGATOR$20Test
INFO  [2023-01-26 18:10:48,693] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:48,712] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test SUM_AGGREGATOR Test
INFO  [2023-01-26 18:10:48,712] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test SUM_DIFF_AGGREGATOR Test
INFO  [2023-01-26 18:10:48,712] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:48,712] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:48,713] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SUM_DIFF_AGGREGATOR Test, name=SUM_DIFF_AGGREGATOR Test]
INFO  [2023-01-26 18:10:48,713] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:48,713] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=SUM_DIFF_AGGREGATOR Test, name=SUM_DIFF_AGGREGATOR Test]
INFO  [2023-01-26 18:10:48,713] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:48,714] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SUM_DIFF_AGGREGATOR$20Test.worker_SUM_DIFF_AGGREGATOR$20Test_3a815531-baca-4e57-be66-6c24160b0e1e are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:48,714] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SUM_DIFF_AGGREGATOR$20Test.worker_SUM_DIFF_AGGREGATOR$20Test_3a815531-baca-4e57-be66-6c24160b0e1e are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:48,714] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:48,714] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker SUM_DIFF_AGGREGATOR$20Test.worker_SUM_DIFF_AGGREGATOR$20Test_9572de06-866a-466e-a51a-8f5a4cc59526 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:48,714] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker SUM_DIFF_AGGREGATOR$20Test.worker_SUM_DIFF_AGGREGATOR$20Test_9572de06-866a-466e-a51a-8f5a4cc59526 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:48,714] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:48,719] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:48,819] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:48,825] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:48,825] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SUM_DIFF_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:48,825] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table SUM_DIFF_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:48,937] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:49,045] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:49,046] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:49,046] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 103 B in total
INFO  [2023-01-26 18:10:49,052] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SUM_DIFF_AGGREGATOR Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000385962sINFO  [2023-01-26 18:10:49,085] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=4, sum=5, min=1, average=1.250000, max=2}
INFO  [2023-01-26 18:10:49,085] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[sum] with IntegerParser(super=Parser(lines=5, nullLines=1), minValue=-1, maxValue=1)
INFO  [2023-01-26 18:10:49,085] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[sub] with IntegerParser(super=Parser(lines=5, nullLines=2), minValue=-1, maxValue=1)
INFO  [2023-01-26 18:10:49,085] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=5, nullLines=0), subType=IntegerParser(super=Parser(lines=5, nullLines=0), minValue=14805, maxValue=16019), dateReader=com.bakdata.conquery.util.DateReader@710e3e1b)
INFO  [2023-01-26 18:10:49,088] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SUM_DIFF_AGGREGATOR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:49,088] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:49,088] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_SUM_DIFF_AGGREGATOR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:49,103] com.bakdata.conquery.models.jobs.ImportJob: Importing table into SUM_DIFF_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:49,104] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:10:49 +0000] "POST /admin/datasets/SUM_DIFF_AGGREGATOR%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_SUM_DIFF_AGGREGATOR+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 7
INFO  [2023-01-26 18:10:49,104] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:49,104] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:49,104] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:49,105] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:49,105] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SUM_DIFF_AGGREGATOR$20Test.table.table], containing 5 entries.
WARN  [2023-01-26 18:10:49,106] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:49,106] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SUM_DIFF_AGGREGATOR$20Test.table.table.0
INFO  [2023-01-26 18:10:49,106] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[SUM_DIFF_AGGREGATOR$20Test.table.table], containing 5 entries.
INFO  [2023-01-26 18:10:49,106] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received SUM_DIFF_AGGREGATOR$20Test.table.table.1
INFO  [2023-01-26 18:10:49,211] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:49,217] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:49,234] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:49,234] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:49,235] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:49,340] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: SUM_DIFF_AGGREGATOR Test QUERY INIT
INFO  [2023-01-26 18:10:49,354] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[SUM_DIFF_AGGREGATOR$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:49,354] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[f69b41af-d789-4d10-b03c-d3541db8b591] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_SUM_DIFF_AGGREGATOR Test))]]
INFO  [2023-01-26 18:10:49,356] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SUM_DIFF_AGGREGATOR$20Test.f69b41af-d789-4d10-b03c-d3541db8b591
INFO  [2023-01-26 18:10:49,356] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery SUM_DIFF_AGGREGATOR$20Test.f69b41af-d789-4d10-b03c-d3541db8b591
INFO  [2023-01-26 18:10:49,356] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SUM_DIFF_AGGREGATOR$20Test.f69b41af-d789-4d10-b03c-d3541db8b591] with 1 results within PT0.000472S
127.0.0.1 - - [26/Jan/2023:18:10:49 +0000] "POST /api/datasets/SUM_DIFF_AGGREGATOR$20Test/queries HTTP/1.1" 201 1331 "-" "Conquery (test client)" 4
INFO  [2023-01-26 18:10:49,357] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SUM_DIFF_AGGREGATOR$20Test.f69b41af-d789-4d10-b03c-d3541db8b591, workerId=SUM_DIFF_AGGREGATOR$20Test.worker_SUM_DIFF_AGGREGATOR$20Test_3a815531-baca-4e57-be66-6c24160b0e1e, startTime=2023-01-26T18:10:49.356464, finishTime=2023-01-26T18:10:49.356936) of size 1
INFO  [2023-01-26 18:10:49,357] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[SUM_DIFF_AGGREGATOR$20Test.f69b41af-d789-4d10-b03c-d3541db8b591] with 3 results within PT0.001017S
INFO  [2023-01-26 18:10:49,357] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=SUM_DIFF_AGGREGATOR$20Test.f69b41af-d789-4d10-b03c-d3541db8b591, workerId=SUM_DIFF_AGGREGATOR$20Test.worker_SUM_DIFF_AGGREGATOR$20Test_9572de06-866a-466e-a51a-8f5a4cc59526, startTime=2023-01-26T18:10:49.356483, finishTime=2023-01-26T18:10:49.357500) of size 3
INFO  [2023-01-26 18:10:49,357] com.bakdata.conquery.models.execution.ManagedExecution: DONE f69b41af-d789-4d10-b03c-d3541db8b591 ManagedQuery within PT0.003173S
127.0.0.1 - - [26/Jan/2023:18:10:49 +0000] "GET /api/datasets/SUM_DIFF_AGGREGATOR$20Test/queries/SUM_DIFF_AGGREGATOR$20Test.f69b41af-d789-4d10-b03c-d3541db8b591 HTTP/1.1" 200 1626 "-" "Conquery (test client)" 2
INFO  [2023-01-26 18:10:49,384] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SUM_DIFF_AGGREGATOR Test], queryId=f69b41af-d789-4d10-b03c-d3541db8b591, label=concept	@§$, creationTime=2023-01-26T18:10:49.354627, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@69fa0ee9[Count = 0], startTime=2023-01-26T18:10:49.354755, finishTime=2023-01-26T18:10:49.357928, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@aa14083), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SUM_DIFF_AGGREGATOR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@23bf79c3, com.bakdata.conquery.models.query.ColumnDescriptor@739b4653, com.bakdata.conquery.models.query.ColumnDescriptor@4a2f838f]) download on dataset Dataset[label=null, name=SUM_DIFF_AGGREGATOR Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:49,384] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=SUM_DIFF_AGGREGATOR Test], queryId=f69b41af-d789-4d10-b03c-d3541db8b591, label=concept	@§$, creationTime=2023-01-26T18:10:49.354627, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@69fa0ee9[Count = 0], startTime=2023-01-26T18:10:49.354755, finishTime=2023-01-26T18:10:49.357928, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@aa14083), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_SUM_DIFF_AGGREGATOR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=4, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@23bf79c3, com.bakdata.conquery.models.query.ColumnDescriptor@739b4653, com.bakdata.conquery.models.query.ColumnDescriptor@4a2f838f]) on dataset Dataset[label=null, name=SUM_DIFF_AGGREGATOR Test]
127.0.0.1 - - [26/Jan/2023:18:10:49 +0000] "GET /api/datasets/SUM_DIFF_AGGREGATOR%20Test/result/SUM_DIFF_AGGREGATOR$20Test.f69b41af-d789-4d10-b03c-d3541db8b591.csv?pretty=false HTTP/1.1" 200 142 "-" "Conquery (test client)" 24
INFO  [2023-01-26 18:10:49,407] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest SUM_DIFF_AGGREGATOR Test on 5 rows
INFO  [2023-01-26 18:10:49,407] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast SUM_DIFF_AGGREGATOR Test
INFO  [2023-01-26 18:10:49,408] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SUM_DIFF_AGGREGATOR Test, name=SUM_DIFF_AGGREGATOR Test]
INFO  [2023-01-26 18:10:49,408] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=SUM_DIFF_AGGREGATOR Test, name=SUM_DIFF_AGGREGATOR Test]
INFO  [2023-01-26 18:10:49,408] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SUM_DIFF_AGGREGATOR Test_3a815531-baca-4e57-be66-6c24160b0e1e
INFO  [2023-01-26 18:10:49,408] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_SUM_DIFF_AGGREGATOR Test_9572de06-866a-466e-a51a-8f5a4cc59526
INFO  [2023-01-26 18:10:49,413] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow SUM_DIFF_AGGREGATOR Test
INFO  [2023-01-26 18:10:49,414] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SUM_DIFF_AGGREGATOR Test_3a815531-baca-4e57-be66-6c24160b0e1e
INFO  [2023-01-26 18:10:49,414] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_SUM_DIFF_AGGREGATOR Test_9572de06-866a-466e-a51a-8f5a4cc59526
INFO  [2023-01-26 18:10:49,521] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of SUM_DIFF_AGGREGATOR$20Test
INFO  [2023-01-26 18:10:49,521] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:49,540] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test SUM_DIFF_AGGREGATOR Test
INFO  [2023-01-26 18:10:49,540] com.bakdata.conquery.integration.IntegrationTest$Wrapper: STARTING integration test VALUES_AGGREGATOR Test
INFO  [2023-01-26 18:10:49,540] com.bakdata.conquery.util.support.TestConquery: Setting up dataset
INFO  [2023-01-26 18:10:49,540] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.NamespaceStorage
INFO  [2023-01-26 18:10:49,542] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=VALUES_AGGREGATOR Test, name=VALUES_AGGREGATOR Test]
INFO  [2023-01-26 18:10:49,542] com.bakdata.conquery.models.messages.network.specific.AddWorker: creating a new worker for Dataset[label=VALUES_AGGREGATOR Test, name=VALUES_AGGREGATOR Test]
INFO  [2023-01-26 18:10:49,542] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:49,542] com.bakdata.conquery.io.storage.NamespacedStorage: Done reading null / com.bakdata.conquery.io.storage.WorkerStorage
INFO  [2023-01-26 18:10:49,547] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:49,548] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker VALUES_AGGREGATOR$20Test.worker_VALUES_AGGREGATOR$20Test_8cd89d08-8cd4-41c6-98a3-36efb1e23262 are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:49,548] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker VALUES_AGGREGATOR$20Test.worker_VALUES_AGGREGATOR$20Test_8cd89d08-8cd4-41c6-98a3-36efb1e23262 are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:49,548] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:49,548] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Imports of worker VALUES_AGGREGATOR$20Test.worker_VALUES_AGGREGATOR$20Test_55b49fe9-2937-4780-86b0-cdbbbce454eb are consistent with the manager: 0 Imports
INFO  [2023-01-26 18:10:49,548] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Buckets of worker VALUES_AGGREGATOR$20Test.worker_VALUES_AGGREGATOR$20Test_55b49fe9-2937-4780-86b0-cdbbbce454eb are consistent with the manager: 0 Buckets
INFO  [2023-01-26 18:10:49,548] com.bakdata.conquery.models.messages.namespaces.specific.ReportConsistency: Consistency check was successful
INFO  [2023-01-26 18:10:49,647] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:49,654] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:49,655] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table VALUES_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:49,655] com.bakdata.conquery.models.messages.namespaces.specific.UpdateTable: Received update of Table VALUES_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:49,772] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:49,883] com.bakdata.conquery.commands.PreprocessorCommand: Preprocessing from command line config.
INFO  [2023-01-26 18:10:49,883] com.bakdata.conquery.commands.PreprocessorCommand: DOES NOT EXIST
INFO  [2023-01-26 18:10:49,883] com.bakdata.conquery.commands.PreprocessorCommand: Required to preprocess 235 B in total
INFO  [2023-01-26 18:10:49,883] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING START in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_VALUES_AGGREGATOR Test/table.import.json, tag=Optional.empty)
██████████████████████████████████████████████████▌ 100%	est. time remaining: 0.000363174sINFO  [2023-01-26 18:10:49,920] com.bakdata.conquery.models.preproc.Preprocessed: Statistics = IntSummaryStatistics{count=5, sum=13, min=1, average=2.600000, max=4}
INFO  [2023-01-26 18:10:49,920] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[value] with StringParser(super=Parser(lines=13, nullLines=1), encoding=null, prefix=, suffix=)
INFO  [2023-01-26 18:10:49,920] com.bakdata.conquery.models.preproc.PPColumn: Compute best Subtype for  Column[datum] with DateParser(super=Parser(lines=13, nullLines=0), subType=IntegerParser(super=Parser(lines=13, nullLines=0), minValue=14805, maxValue=15343), dateReader=com.bakdata.conquery.util.DateReader@527af918)
INFO  [2023-01-26 18:10:49,924] com.bakdata.conquery.models.preproc.Preprocessor: PREPROCESSING DONE in PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_VALUES_AGGREGATOR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:49,924] com.bakdata.conquery.commands.PreprocessorCommand: Successfully Preprocess 1 Jobs:
INFO  [2023-01-26 18:10:49,924] com.bakdata.conquery.commands.PreprocessorCommand: 	Succeeded Preprocessing for PreprocessingJob(descriptionFile=/tmp/conqueryIntegrationTest11721327024597521698/tmp_VALUES_AGGREGATOR Test/table.import.json, tag=Optional.empty)
INFO  [2023-01-26 18:10:49,942] com.bakdata.conquery.models.jobs.ImportJob: Importing table into VALUES_AGGREGATOR$20Test.table
INFO  [2023-01-26 18:10:49,943] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
127.0.0.1 - - [26/Jan/2023:18:10:49 +0000] "POST /admin/datasets/VALUES_AGGREGATOR%20Test/imports?file=%2Ftmp%2FconqueryIntegrationTest11721327024597521698%2Ftmp_VALUES_AGGREGATOR+Test%2Ftable.cqpp HTTP/1.1" 204 0 "-" "Conquery (test client)" 8
INFO  [2023-01-26 18:10:49,943] com.bakdata.conquery.models.jobs.ImportJob: Importing Dictionaries
INFO  [2023-01-26 18:10:49,944] com.bakdata.conquery.models.jobs.ImportJob: Remapping Dictionaries []
WARN  [2023-01-26 18:10:49,944] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: Max cannot be decreased.
INFO  [2023-01-26 18:10:49,945] com.bakdata.conquery.models.jobs.ImportJob: Start sending 2 Buckets
INFO  [2023-01-26 18:10:49,945] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[VALUES_AGGREGATOR$20Test.table.table], containing 13 entries.
INFO  [2023-01-26 18:10:49,945] com.bakdata.conquery.models.messages.namespaces.specific.AddImport: Received Import[VALUES_AGGREGATOR$20Test.table.table], containing 13 entries.
WARN  [2023-01-26 18:10:49,946] com.bakdata.conquery.util.progressreporter.ProgressReporterImpl: One or more Children are not done yet
INFO  [2023-01-26 18:10:49,946] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received VALUES_AGGREGATOR$20Test.table.table.0
INFO  [2023-01-26 18:10:49,946] com.bakdata.conquery.models.messages.namespaces.specific.ImportBucket: Received VALUES_AGGREGATOR$20Test.table.table.1
INFO  [2023-01-26 18:10:50,052] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:50,057] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:50,073] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:50,073] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:50,073] com.bakdata.conquery.models.messages.namespaces.specific.UpdateMatchingStatsMessage: BEGIN update Matching stats for 1 Concepts
INFO  [2023-01-26 18:10:50,200] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: VALUES_AGGREGATOR Test QUERY INIT
INFO  [2023-01-26 18:10:50,209] com.bakdata.conquery.apiv1.QueryProcessor: Query posted on Dataset[VALUES_AGGREGATOR$20Test] by User[{user.SUPERUSER@SUPERUSER].
INFO  [2023-01-26 18:10:50,209] com.bakdata.conquery.models.query.ExecutionManager: Executing Query[92dfb53a-39c9-47ee-88ad-304a4e7d71ca] in Datasets[[Namespace(storage=NamespacedStorage(pathName=dataset_VALUES_AGGREGATOR Test))]]
INFO  [2023-01-26 18:10:50,211] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery VALUES_AGGREGATOR$20Test.92dfb53a-39c9-47ee-88ad-304a4e7d71ca
INFO  [2023-01-26 18:10:50,211] com.bakdata.conquery.models.messages.namespaces.specific.ExecuteQuery: Started ConceptQuery VALUES_AGGREGATOR$20Test.92dfb53a-39c9-47ee-88ad-304a4e7d71ca
127.0.0.1 - - [26/Jan/2023:18:10:50 +0000] "POST /api/datasets/VALUES_AGGREGATOR$20Test/queries HTTP/1.1" 201 1326 "-" "Conquery (test client)" 5
INFO  [2023-01-26 18:10:50,223] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[VALUES_AGGREGATOR$20Test.92dfb53a-39c9-47ee-88ad-304a4e7d71ca] with 2 results within PT0.012291S
INFO  [2023-01-26 18:10:50,224] com.bakdata.conquery.models.query.results.ShardResult: FINISHED Query[VALUES_AGGREGATOR$20Test.92dfb53a-39c9-47ee-88ad-304a4e7d71ca] with 3 results within PT0.012561S
INFO  [2023-01-26 18:10:50,224] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=VALUES_AGGREGATOR$20Test.92dfb53a-39c9-47ee-88ad-304a4e7d71ca, workerId=VALUES_AGGREGATOR$20Test.worker_VALUES_AGGREGATOR$20Test_8cd89d08-8cd4-41c6-98a3-36efb1e23262, startTime=2023-01-26T18:10:50.211630, finishTime=2023-01-26T18:10:50.223921) of size 2
INFO  [2023-01-26 18:10:50,225] com.bakdata.conquery.models.messages.namespaces.specific.CollectQueryResult: Received ShardResult(queryId=VALUES_AGGREGATOR$20Test.92dfb53a-39c9-47ee-88ad-304a4e7d71ca, workerId=VALUES_AGGREGATOR$20Test.worker_VALUES_AGGREGATOR$20Test_55b49fe9-2937-4780-86b0-cdbbbce454eb, startTime=2023-01-26T18:10:50.211635, finishTime=2023-01-26T18:10:50.224196) of size 3
INFO  [2023-01-26 18:10:50,226] com.bakdata.conquery.models.execution.ManagedExecution: DONE 92dfb53a-39c9-47ee-88ad-304a4e7d71ca ManagedQuery within PT0.016591S
127.0.0.1 - - [26/Jan/2023:18:10:50 +0000] "GET /api/datasets/VALUES_AGGREGATOR$20Test/queries/VALUES_AGGREGATOR$20Test.92dfb53a-39c9-47ee-88ad-304a4e7d71ca HTTP/1.1" 200 1614 "-" "Conquery (test client)" 6
INFO  [2023-01-26 18:10:50,237] com.bakdata.conquery.resources.api.ResultCsvResource: Result for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=VALUES_AGGREGATOR Test], queryId=92dfb53a-39c9-47ee-88ad-304a4e7d71ca, label=concept	@§$, creationTime=2023-01-26T18:10:50.209265, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@3b961cca[Count = 0], startTime=2023-01-26T18:10:50.209422, finishTime=2023-01-26T18:10:50.226013, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@3e49d462), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_VALUES_AGGREGATOR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=5, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@4c8ef776, com.bakdata.conquery.models.query.ColumnDescriptor@312ba7c5, com.bakdata.conquery.models.query.ColumnDescriptor@3a509d66]) download on dataset Dataset[label=null, name=VALUES_AGGREGATOR Test] by subject user.SUPERUSER@SUPERUSER (SUPERUSER@SUPERUSER).
INFO  [2023-01-26 18:10:50,237] com.bakdata.conquery.io.result.csv.ResultCsvProcessor: Downloading results for ManagedQuery(super=ManagedExecution(dataset=Dataset[label=null, name=VALUES_AGGREGATOR Test], queryId=92dfb53a-39c9-47ee-88ad-304a4e7d71ca, label=concept	@§$, creationTime=2023-01-26T18:10:50.209265, owner=User[user.SUPERUSER@SUPERUSER], tags=[], shared=false, machineGenerated=false, state=DONE, execution=java.util.concurrent.CountDownLatch@3b961cca[Count = 0], startTime=2023-01-26T18:10:50.209422, finishTime=2023-01-26T18:10:50.226013, error=null, progress=null, initialized=true, executionManager=com.bakdata.conquery.models.query.ExecutionManager@3e49d462), namespace=Namespace(storage=NamespacedStorage(pathName=dataset_VALUES_AGGREGATOR Test)), query=com.bakdata.conquery.apiv1.query.ConceptQuery@1, lastResultCount=5, involvedWorkers=2, executingThreads=0, config=Configuration{server=DefaultServerFactory{applicationConnectors=[io.dropwizard.jetty.HttpConnectorFactory@1e7146a6], adminConnectors=[io.dropwizard.jetty.HttpConnectorFactory@7738e1d7], adminMaxThreads=64, adminMinThreads=1, applicationContextPath='/', adminContextPath='/'}, logging=DefaultLoggingFactory{level=INFO, loggers={}, appenders=[io.dropwizard.logging.ConsoleAppenderFactory@3509728d]}, metrics=MetricsFactory{frequency=1 minute, reporters=[], reportOnStop=false}, admin=AdminFactory[healthChecks=HealthCheckConfiguration[minThreads=1, maxThreads=4, workQueueSize=1], tasks=TaskConfiguration[printStackTraceOnError=false]]}, columnDescriptions=[com.bakdata.conquery.models.query.ColumnDescriptor@4c8ef776, com.bakdata.conquery.models.query.ColumnDescriptor@312ba7c5, com.bakdata.conquery.models.query.ColumnDescriptor@3a509d66]) on dataset Dataset[label=null, name=VALUES_AGGREGATOR Test]
127.0.0.1 - - [26/Jan/2023:18:10:50 +0000] "GET /api/datasets/VALUES_AGGREGATOR%20Test/result/VALUES_AGGREGATOR$20Test.92dfb53a-39c9-47ee-88ad-304a4e7d71ca.csv?pretty=false HTTP/1.1" 200 195 "-" "Conquery (test client)" 17
INFO  [2023-01-26 18:10:50,252] com.bakdata.conquery.integration.json.AbstractQueryEngineTest: INTEGRATION TEST SUCCESSFUL QueryTest VALUES_AGGREGATOR Test on 6 rows
INFO  [2023-01-26 18:10:50,252] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast VALUES_AGGREGATOR Test
INFO  [2023-01-26 18:10:50,253] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=VALUES_AGGREGATOR Test, name=VALUES_AGGREGATOR Test]
INFO  [2023-01-26 18:10:50,253] com.bakdata.conquery.models.messages.network.specific.RemoveWorker: removing worker for Dataset[label=VALUES_AGGREGATOR Test, name=VALUES_AGGREGATOR Test]
INFO  [2023-01-26 18:10:50,253] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_VALUES_AGGREGATOR Test_8cd89d08-8cd4-41c6-98a3-36efb1e23262
INFO  [2023-01-26 18:10:50,253] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast worker_VALUES_AGGREGATOR Test_55b49fe9-2937-4780-86b0-cdbbbce454eb
INFO  [2023-01-26 18:10:50,351] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow VALUES_AGGREGATOR Test
INFO  [2023-01-26 18:10:50,351] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_VALUES_AGGREGATOR Test_8cd89d08-8cd4-41c6-98a3-36efb1e23262
INFO  [2023-01-26 18:10:50,351] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow worker_VALUES_AGGREGATOR Test_55b49fe9-2937-4780-86b0-cdbbbce454eb
INFO  [2023-01-26 18:10:50,451] com.bakdata.conquery.models.worker.Namespace: Removing namespace storage of VALUES_AGGREGATOR$20Test
INFO  [2023-01-26 18:10:50,452] com.bakdata.conquery.util.support.TestConquery: Waiting for jobs to finish
INFO  [2023-01-26 18:10:50,478] com.bakdata.conquery.integration.IntegrationTest$Wrapper: SUCCESS integration test VALUES_AGGREGATOR Test
[INFO] Tests run: 172, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 171.678 s - in com.bakdata.conquery.integration.ConqueryIntegrationTests
[INFO] Running com.bakdata.conquery.tasks.PermissionCleanupTaskTest
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 s - in com.bakdata.conquery.tasks.PermissionCleanupTaskTest
[INFO] Running com.bakdata.conquery.tasks.IsUUIDTestTest
INFO  [2023-01-26 18:10:50,489] com.bakdata.conquery.tasks.IsUUIDTestTest: 77ee4225-2d6c-485b-b189-9c6005bdb9e8
INFO  [2023-01-26 18:10:50,491] com.bakdata.conquery.tasks.IsUUIDTestTest: 6aad4a97-f526-4b2b-8b62-2f78184e9d73
INFO  [2023-01-26 18:10:50,492] com.bakdata.conquery.tasks.IsUUIDTestTest: 2ac2d469-45b2-422f-a423-01bf763cb4eb
INFO  [2023-01-26 18:10:50,492] com.bakdata.conquery.tasks.IsUUIDTestTest: 6cca31a7-c6b4-4abd-899b-98f94b407cf4
INFO  [2023-01-26 18:10:50,493] com.bakdata.conquery.tasks.IsUUIDTestTest: adbe1b7f-7193-4db4-80d7-fb3f861c9b3d
INFO  [2023-01-26 18:10:50,494] com.bakdata.conquery.tasks.IsUUIDTestTest: e1a797a6-b6df-40f1-a67b-e1ff151428d1
INFO  [2023-01-26 18:10:50,494] com.bakdata.conquery.tasks.IsUUIDTestTest: 9426d5a5-4e7a-4027-942a-5e87863d45ea
INFO  [2023-01-26 18:10:50,495] com.bakdata.conquery.tasks.IsUUIDTestTest: 2ed69d11-a775-4ef7-8cd4-849c231e9fce
INFO  [2023-01-26 18:10:50,495] com.bakdata.conquery.tasks.IsUUIDTestTest: 7ddc554f-3702-4e86-96a9-2a66fb6bc121
INFO  [2023-01-26 18:10:50,496] com.bakdata.conquery.tasks.IsUUIDTestTest: b72bbdfe-4ea5-4b6e-8235-285b464df6c0
INFO  [2023-01-26 18:10:50,496] com.bakdata.conquery.tasks.IsUUIDTestTest: 5a7e0f88-ea65-4a6d-a899-65854fcc1d80
INFO  [2023-01-26 18:10:50,496] com.bakdata.conquery.tasks.IsUUIDTestTest: 93012bd1-0b82-42db-b2d9-a68ff9b3dbf8
INFO  [2023-01-26 18:10:50,497] com.bakdata.conquery.tasks.IsUUIDTestTest: 6f6c7f6d-5e07-480d-bd41-a6064f164a2c
INFO  [2023-01-26 18:10:50,497] com.bakdata.conquery.tasks.IsUUIDTestTest: a60212d4-47ee-4c58-9217-0c5ab503546d
INFO  [2023-01-26 18:10:50,498] com.bakdata.conquery.tasks.IsUUIDTestTest: 2b5fbe46-29a5-4b99-bca0-75ec4d4500db
INFO  [2023-01-26 18:10:50,499] com.bakdata.conquery.tasks.IsUUIDTestTest: a2a8b147-9fe5-40f1-a951-63b45d83e185
INFO  [2023-01-26 18:10:50,499] com.bakdata.conquery.tasks.IsUUIDTestTest: 6bd96d1a-9261-4ee3-be34-2b9817b40c1d
INFO  [2023-01-26 18:10:50,500] com.bakdata.conquery.tasks.IsUUIDTestTest: 6645d863-e788-4005-84d0-f9261aacd770
INFO  [2023-01-26 18:10:50,500] com.bakdata.conquery.tasks.IsUUIDTestTest: 15251bb0-85d8-4edc-bb22-7e98b9e2b4e5
INFO  [2023-01-26 18:10:50,501] com.bakdata.conquery.tasks.IsUUIDTestTest: b47d169e-6167-413b-b989-313b28b0ade2
INFO  [2023-01-26 18:10:50,501] com.bakdata.conquery.tasks.IsUUIDTestTest: fdb8bda8-225c-4aaa-acc1-efd0d53d450b
INFO  [2023-01-26 18:10:50,501] com.bakdata.conquery.tasks.IsUUIDTestTest: 8a879dbe-f53e-4616-a676-3b2515aa0284
INFO  [2023-01-26 18:10:50,502] com.bakdata.conquery.tasks.IsUUIDTestTest: f6c5e5f6-fd16-438a-888a-65b4b6905c4c
INFO  [2023-01-26 18:10:50,502] com.bakdata.conquery.tasks.IsUUIDTestTest: 56c4598b-d580-41b4-990f-4432319dea55
INFO  [2023-01-26 18:10:50,502] com.bakdata.conquery.tasks.IsUUIDTestTest: 1fc1a528-27ff-420b-8068-1df0737ce190
INFO  [2023-01-26 18:10:50,503] com.bakdata.conquery.tasks.IsUUIDTestTest: 19801ec2-72cb-47bd-8369-ae39aee90b75
INFO  [2023-01-26 18:10:50,503] com.bakdata.conquery.tasks.IsUUIDTestTest: cf693dc5-a01c-479f-85cc-d753c6d1f7ac
INFO  [2023-01-26 18:10:50,503] com.bakdata.conquery.tasks.IsUUIDTestTest: 8b3019cc-c8d8-43cb-9d28-5fcc5f58b2c8
INFO  [2023-01-26 18:10:50,504] com.bakdata.conquery.tasks.IsUUIDTestTest: c3b34e7c-eae2-4402-8501-f198e2dd4408
INFO  [2023-01-26 18:10:50,504] com.bakdata.conquery.tasks.IsUUIDTestTest: 099dc83c-8e61-4f2a-bfe0-d2d893821970
INFO  [2023-01-26 18:10:50,504] com.bakdata.conquery.tasks.IsUUIDTestTest: 0744eb41-0447-4365-a0f1-35bd0960253a
INFO  [2023-01-26 18:10:50,505] com.bakdata.conquery.tasks.IsUUIDTestTest: d596fdfe-d9ce-49e6-92ce-9c1c5888a0f5
INFO  [2023-01-26 18:10:50,505] com.bakdata.conquery.tasks.IsUUIDTestTest: 0530377a-284d-4f55-bfa1-0b85611f29c7
INFO  [2023-01-26 18:10:50,505] com.bakdata.conquery.tasks.IsUUIDTestTest: 74a56d3f-e858-41d2-aa77-105def80e6d6
INFO  [2023-01-26 18:10:50,505] com.bakdata.conquery.tasks.IsUUIDTestTest: 8b6d4e38-c905-424b-a73f-2cdffd3c6b60
INFO  [2023-01-26 18:10:50,506] com.bakdata.conquery.tasks.IsUUIDTestTest: cc591a23-3ec3-4bc7-bf5d-62609222f37e
INFO  [2023-01-26 18:10:50,506] com.bakdata.conquery.tasks.IsUUIDTestTest: 856066bb-1db6-4fa7-be32-11a426d3afac
INFO  [2023-01-26 18:10:50,506] com.bakdata.conquery.tasks.IsUUIDTestTest: 5cf17dc7-d520-4055-be80-615b25e38272
INFO  [2023-01-26 18:10:50,506] com.bakdata.conquery.tasks.IsUUIDTestTest: e198c794-c96f-484f-b43c-baffd33a8e97
INFO  [2023-01-26 18:10:50,506] com.bakdata.conquery.tasks.IsUUIDTestTest: 819b02d5-1dfa-443c-8d7f-294a95e60c92
INFO  [2023-01-26 18:10:50,507] com.bakdata.conquery.tasks.IsUUIDTestTest: ab87145a-afc1-4e92-a712-54d9191f002c
INFO  [2023-01-26 18:10:50,507] com.bakdata.conquery.tasks.IsUUIDTestTest: 0b68164a-07b5-42f1-85b6-41b2b32ed430
INFO  [2023-01-26 18:10:50,507] com.bakdata.conquery.tasks.IsUUIDTestTest: b8c754c0-6803-4689-aa84-2eced13452ea
INFO  [2023-01-26 18:10:50,507] com.bakdata.conquery.tasks.IsUUIDTestTest: d5471a70-6a09-4cde-b031-18c71777d4db
INFO  [2023-01-26 18:10:50,508] com.bakdata.conquery.tasks.IsUUIDTestTest: 24563235-35cd-4b1c-a4e4-b43bf3a5a673
INFO  [2023-01-26 18:10:50,508] com.bakdata.conquery.tasks.IsUUIDTestTest: 3eb438b9-e955-40a8-96f3-43df11178dfe
INFO  [2023-01-26 18:10:50,508] com.bakdata.conquery.tasks.IsUUIDTestTest: 8e08705e-ac67-4510-b5ab-a7215a708786
INFO  [2023-01-26 18:10:50,508] com.bakdata.conquery.tasks.IsUUIDTestTest: 26c1e7da-8d23-4ea7-a215-3398efb3fc48
INFO  [2023-01-26 18:10:50,508] com.bakdata.conquery.tasks.IsUUIDTestTest: 613b95df-0171-4fd6-a6da-8c01e644647d
INFO  [2023-01-26 18:10:50,509] com.bakdata.conquery.tasks.IsUUIDTestTest: 22603bce-2545-4d85-8eea-8d0994eaf5aa
[INFO] Tests run: 51, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.01 s - in com.bakdata.conquery.tasks.IsUUIDTestTest
[INFO] Running com.bakdata.conquery.tasks.QueryCleanupTaskTest
INFO  [2023-01-26 18:10:50,517] com.bakdata.conquery.tasks.QueryCleanupTask: Starting deletion of queries older than PT720H of 1
INFO  [2023-01-26 18:10:50,518] com.bakdata.conquery.tasks.QueryCleanupTask: No queries to delete
INFO  [2023-01-26 18:10:50,518] com.bakdata.conquery.tasks.QueryCleanupTask: Starting deletion of queries older than PT720H of 2
INFO  [2023-01-26 18:10:50,518] com.bakdata.conquery.tasks.QueryCleanupTask: Deleting 1 Executions
INFO  [2023-01-26 18:10:50,518] com.bakdata.conquery.tasks.QueryCleanupTask: No queries to delete
INFO  [2023-01-26 18:10:50,519] com.bakdata.conquery.tasks.QueryCleanupTask: Starting deletion of queries older than PT720H of 2
INFO  [2023-01-26 18:10:50,519] com.bakdata.conquery.tasks.QueryCleanupTask: Deleting 1 Executions
INFO  [2023-01-26 18:10:50,519] com.bakdata.conquery.tasks.QueryCleanupTask: No queries to delete
INFO  [2023-01-26 18:10:50,519] com.bakdata.conquery.tasks.QueryCleanupTask: Starting deletion of queries older than PT720H of 2
INFO  [2023-01-26 18:10:50,519] com.bakdata.conquery.tasks.QueryCleanupTask: Deleting 1 Executions
INFO  [2023-01-26 18:10:50,519] com.bakdata.conquery.tasks.QueryCleanupTask: No queries to delete
INFO  [2023-01-26 18:10:50,519] com.bakdata.conquery.tasks.QueryCleanupTask: Starting deletion of queries older than PT720H of 2
INFO  [2023-01-26 18:10:50,519] com.bakdata.conquery.tasks.QueryCleanupTask: No queries to delete
INFO  [2023-01-26 18:10:50,520] com.bakdata.conquery.tasks.QueryCleanupTask: Starting deletion of queries older than PT720H of 2
INFO  [2023-01-26 18:10:50,520] com.bakdata.conquery.tasks.QueryCleanupTask: No queries to delete
INFO  [2023-01-26 18:10:50,520] com.bakdata.conquery.tasks.QueryCleanupTask: Starting deletion of queries older than PT720H of 2
INFO  [2023-01-26 18:10:50,520] com.bakdata.conquery.tasks.QueryCleanupTask: Deleting 1 Executions
INFO  [2023-01-26 18:10:50,520] com.bakdata.conquery.tasks.QueryCleanupTask: Deleting 1 Executions
INFO  [2023-01-26 18:10:50,520] com.bakdata.conquery.tasks.QueryCleanupTask: No queries to delete
INFO  [2023-01-26 18:10:50,520] com.bakdata.conquery.tasks.QueryCleanupTask: Starting deletion of queries older than PT720H of 1
INFO  [2023-01-26 18:10:50,520] com.bakdata.conquery.tasks.QueryCleanupTask: Deleting 1 Executions
INFO  [2023-01-26 18:10:50,520] com.bakdata.conquery.tasks.QueryCleanupTask: No queries to delete
INFO  [2023-01-26 18:10:50,521] com.bakdata.conquery.tasks.QueryCleanupTask: Starting deletion of queries older than PT719H of 1
INFO  [2023-01-26 18:10:50,521] com.bakdata.conquery.tasks.QueryCleanupTask: Deleting 1 Executions
INFO  [2023-01-26 18:10:50,521] com.bakdata.conquery.tasks.QueryCleanupTask: No queries to delete
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.005 s - in com.bakdata.conquery.tasks.QueryCleanupTaskTest
[INFO] Running com.bakdata.conquery.io.storage.xodus.stores.SerializingStoreDumpTest
INFO  [2023-01-26 18:10:50,543] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/1674756650524-0
INFO  [2023-01-26 18:10:50,544] com.bakdata.conquery.io.storage.xodus.stores.SerializingStoreDumpTest: This test will throw some warnings from the SerializingStore.
WARN  [2023-01-26 18:10:50,559] com.bakdata.conquery.io.storage.xodus.stores.SerializingStore: Could not parse value for key [user.testU2]
WARN  [2023-01-26 18:10:50,560] com.bakdata.conquery.io.storage.xodus.stores.SerializingStore: Could not parse key [:)
Vnot a valid conquery Id]
WARN  [2023-01-26 18:10:50,560] com.bakdata.conquery.io.storage.xodus.stores.SerializingStore: Removing 2 unreadable elements from the store AUTH_USER.
WARN  [2023-01-26 18:10:50,564] com.bakdata.conquery.io.storage.xodus.stores.SerializingStore: Removing 0 unreadable elements from the store AUTH_USER.
INFO  [2023-01-26 18:10:50,596] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/1674756650577-0
INFO  [2023-01-26 18:10:50,611] com.bakdata.conquery.io.storage.xodus.stores.SerializingStore: Dumping value of key :)
Vnot a valid conquery Id to /tmp/1674756650577-0/20230126-AUTH_USER-____Vnot a valid conquery Id.json (because it cannot be deserialized anymore).
WARN  [2023-01-26 18:10:50,611] com.bakdata.conquery.io.storage.xodus.stores.SerializingStore: Could not parse key [:)
Vnot a valid conquery Id]
INFO  [2023-01-26 18:10:50,637] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/1674756650619-0
INFO  [2023-01-26 18:10:50,654] com.bakdata.conquery.io.storage.xodus.stores.SerializingStore: Dumping value of key user.testU2 to /tmp/1674756650619-0/20230126-AUTH_USER-user.testU2.json (because it cannot be deserialized anymore).
WARN  [2023-01-26 18:10:50,654] com.bakdata.conquery.io.storage.xodus.stores.SerializingStore: Could not parse value for key [user.testU2]
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.137 s - in com.bakdata.conquery.io.storage.xodus.stores.SerializingStoreDumpTest
[INFO] Running com.bakdata.conquery.io.storage.xodus.stores.BigStoreTest
INFO  [2023-01-26 18:10:50,681] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/BigStoreTest16335864562938686813
INFO  [2023-01-26 18:10:50,725] jetbrains.exodus.env.EnvironmentImpl: Exodus environment created: /tmp/BigStoreTest16527962583240148331
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.405 s - in com.bakdata.conquery.io.storage.xodus.stores.BigStoreTest
[INFO] Running com.bakdata.conquery.io.jackson.SerializationBlockTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 s - in com.bakdata.conquery.io.jackson.SerializationBlockTest
[INFO] Running com.bakdata.conquery.io.jackson.JacksonTest
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.03 s - in com.bakdata.conquery.io.jackson.JacksonTest
[INFO] Running com.bakdata.conquery.io.jackson.serializer.RangeSerializerTest
[INFO] Tests run: 100, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.389 s - in com.bakdata.conquery.io.jackson.serializer.RangeSerializerTest
[INFO] Running com.bakdata.conquery.io.jackson.serializer.ClassToInstanceMapDeserializerTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.003 s - in com.bakdata.conquery.io.jackson.serializer.ClassToInstanceMapDeserializerTest
[INFO] Running com.bakdata.conquery.io.jackson.serializer.IdRefrenceTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.055 s - in com.bakdata.conquery.io.jackson.serializer.IdRefrenceTest
[INFO] Running com.bakdata.conquery.io.cps.CPSBaseTest
[INFO] Tests run: 188, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.008 s - in com.bakdata.conquery.io.cps.CPSBaseTest
[INFO] Running com.bakdata.conquery.io.result.csv.CsvResultGenerationTest
INFO  [2023-01-26 18:10:54,592] com.bakdata.conquery.io.result.csv.CsvResultGenerationTest: Wrote and than read this csv data: id1,id2,BOOLEAN,INTEGER,NUMERIC,CATEGORICAL,RESOLUTION,DATE,DATE_RANGE,STRING,MONEY,LIST[BOOLEAN],LIST[DATE_RANGE],LIST[STRING]
1,1,Ja,2.345.634,"123.423,34",CAT1,Tag,17.06.1985,12.12.1970 - 19.06.1971,test_string,"45,21","Ja, Nein","12.12.1970 - 19.06.1971, 02.01.1970 - 03.01.1970","fizz, buzz"
2,2,Nein,,,,,,,,,,19.05.1973 - +∞,
2,2,Ja,,,,,,,,,"Nein, Nein",,
3,3,Nein,,,,,,,,,Nein,,
3,3,Ja,,,,,,,,,,,
3,3,Ja,,,,,,,,"0,04","Ja, Nein, Ja, Nein",,

[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.006 s - in com.bakdata.conquery.io.result.csv.CsvResultGenerationTest
[INFO] Running com.bakdata.conquery.io.result.arrow.ArrowResultGenerationTest
INFO  [2023-01-26 18:10:54,601] org.apache.arrow.memory.BaseAllocator: Debug mode enabled.
INFO  [2023-01-26 18:10:54,604] org.apache.arrow.memory.DefaultAllocationManagerOption: allocation manager type not specified, using netty as the default type
INFO  [2023-01-26 18:10:54,604] org.apache.arrow.memory.CheckAllocator: Using DefaultAllocationManager at memory-netty/5.0.0/arrow-memory-netty-5.0.0.jar!/org/apache/arrow/memory/DefaultAllocationManagerFactory.class
INFO  [2023-01-26 18:10:54,827] com.bakdata.conquery.io.result.arrow.ArrowResultGenerationTest: Reading the produced arrow data.
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.288 s - in com.bakdata.conquery.io.result.arrow.ArrowResultGenerationTest
[INFO] Running com.bakdata.conquery.io.result.excel.ExcelResultRenderTest
[ERROR] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.606 s <<< FAILURE! - in com.bakdata.conquery.io.result.excel.ExcelResultRenderTest
[ERROR] writeAndRead  Time elapsed: 0.606 s  <<< ERROR!
java.lang.AbstractMethodError: Receiver class org.apache.poi.xssf.streaming.SXSSFRow does not define or inherit an implementation of the resolved method 'java.util.Iterator iterator()' of interface org.apache.poi.ss.usermodel.Row.
	at org.apache.poi.xssf.streaming.AutoSizeColumnTracker.updateColumnWidths(AutoSizeColumnTracker.java:323)
	at org.apache.poi.xssf.streaming.SXSSFSheet.flushOneRow(SXSSFSheet.java:1806)
	at org.apache.poi.xssf.streaming.SXSSFSheet.flushRows(SXSSFSheet.java:1775)
	at org.apache.poi.xssf.streaming.SXSSFSheet.flushRows(SXSSFSheet.java:1788)
	at org.apache.poi.xssf.streaming.SXSSFSheet.dispose(SXSSFSheet.java:1831)
	at org.apache.poi.xssf.streaming.SXSSFWorkbook.dispose(SXSSFWorkbook.java:1030)
	at com.bakdata.conquery.io.result.excel.ExcelRenderer.renderToStream(ExcelRenderer.java:94)
	at com.bakdata.conquery.io.result.excel.ExcelResultRenderTest.writeAndRead(ExcelResultRenderTest.java:86)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:688)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$6(TestMethodTestDescriptor.java:210)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:206)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:131)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:65)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:129)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:127)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:126)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:84)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:38)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:143)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:129)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:127)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:126)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:84)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:38)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:143)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:129)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:127)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:126)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:84)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:32)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:51)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:220)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$6(DefaultLauncher.java:188)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:202)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:181)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:128)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:150)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)

[INFO] Running com.bakdata.conquery.io.result.ResultNameTest
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 s - in com.bakdata.conquery.io.result.ResultNameTest
INFO  [2023-01-26 18:10:55,506] org.eclipse.jetty.server.AbstractConnector: Stopped application@57d52a0e{HTTP/1.1, (http/1.1)}{0.0.0.0:44991}
INFO  [2023-01-26 18:10:55,507] org.eclipse.jetty.server.AbstractConnector: Stopped admin@7a1d627e{HTTP/1.1, (http/1.1)}{0.0.0.0:45301}
INFO  [2023-01-26 18:10:55,514] org.eclipse.jetty.server.handler.ContextHandler: Stopped i.d.j.MutableServletContextHandler@186ab4fa{/,null,STOPPED}
INFO  [2023-01-26 18:10:55,518] org.eclipse.jetty.server.handler.ContextHandler: Stopped i.d.j.MutableServletContextHandler@1873e5f9{/,null,STOPPED}
INFO  [2023-01-26 18:10:55,519] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast shard-node0
INFO  [2023-01-26 18:10:55,582] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow shard-node0
INFO  [2023-01-26 18:10:55,691] com.bakdata.conquery.commands.ShardNode: Disconnected from ManagerNode
INFO  [2023-01-26 18:10:55,692] com.bakdata.conquery.commands.ManagerNode: Client 'null' disconnected 
INFO  [2023-01-26 18:10:55,696] com.bakdata.conquery.commands.ShardNode: Connection was closed by ManagerNode
INFO  [2023-01-26 18:10:55,702] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast shard-node1
INFO  [2023-01-26 18:10:55,783] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow shard-node1
INFO  [2023-01-26 18:10:55,882] com.bakdata.conquery.commands.ShardNode: Connection was closed by ManagerNode
INFO  [2023-01-26 18:10:55,883] com.bakdata.conquery.commands.ShardNode: Disconnected from ManagerNode
INFO  [2023-01-26 18:10:55,883] com.bakdata.conquery.commands.ManagerNode: Client 'null' disconnected 
INFO  [2023-01-26 18:10:55,883] com.bakdata.conquery.models.auth.apitoken.TokenStorage: Closing the environment.
INFO  [2023-01-26 18:10:55,898] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast ManagerNode
INFO  [2023-01-26 18:10:55,983] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow ManagerNode
INFO  [2023-01-26 18:10:55,984] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/manager/meta/executions:EXECUTIONS}
INFO  [2023-01-26 18:10:55,984] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/manager/meta/executions
INFO  [2023-01-26 18:10:55,996] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/manager/meta/formConfigs:FORM_CONFIG}
INFO  [2023-01-26 18:10:55,996] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/manager/meta/formConfigs
INFO  [2023-01-26 18:10:56,006] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/manager/meta/users:AUTH_USER}
INFO  [2023-01-26 18:10:56,006] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/manager/meta/users
INFO  [2023-01-26 18:10:56,016] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/manager/meta/roles:AUTH_ROLE}
INFO  [2023-01-26 18:10:56,016] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/manager/meta/roles
INFO  [2023-01-26 18:10:56,027] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/manager/meta/groups:AUTH_GROUP}
INFO  [2023-01-26 18:10:56,027] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/ApiTokenRealmTest/manager/meta/groups
INFO  [2023-01-26 18:10:56,041] org.eclipse.jetty.server.AbstractConnector: Stopped application@d390378{HTTP/1.1, (http/1.1)}{0.0.0.0:39407}
INFO  [2023-01-26 18:10:56,042] org.eclipse.jetty.server.AbstractConnector: Stopped admin@2ccf2ca4{HTTP/1.1, (http/1.1)}{0.0.0.0:41661}
INFO  [2023-01-26 18:10:56,048] org.eclipse.jetty.server.handler.ContextHandler: Stopped i.d.j.MutableServletContextHandler@688f89f2{/,null,STOPPED}
INFO  [2023-01-26 18:10:56,052] org.eclipse.jetty.server.handler.ContextHandler: Stopped i.d.j.MutableServletContextHandler@22ff5887{/,null,STOPPED}
INFO  [2023-01-26 18:10:56,052] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast shard-node1
INFO  [2023-01-26 18:10:56,083] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow shard-node1
INFO  [2023-01-26 18:10:56,100] com.bakdata.conquery.commands.ShardNode: Connection was closed by ManagerNode
INFO  [2023-01-26 18:10:56,100] com.bakdata.conquery.commands.ShardNode: Disconnected from ManagerNode
INFO  [2023-01-26 18:10:56,100] com.bakdata.conquery.commands.ManagerNode: Client 'null' disconnected 
INFO  [2023-01-26 18:10:56,102] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast shard-node0
INFO  [2023-01-26 18:10:56,183] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow shard-node0
INFO  [2023-01-26 18:10:56,283] com.bakdata.conquery.commands.ShardNode: Connection was closed by ManagerNode
INFO  [2023-01-26 18:10:56,283] com.bakdata.conquery.commands.ShardNode: Disconnected from ManagerNode
INFO  [2023-01-26 18:10:56,283] com.bakdata.conquery.commands.ManagerNode: Client 'null' disconnected 
INFO  [2023-01-26 18:10:56,283] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast ManagerNode
INFO  [2023-01-26 18:10:56,292] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow ManagerNode
INFO  [2023-01-26 18:10:56,385] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/executions:EXECUTIONS}
INFO  [2023-01-26 18:10:56,385] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/executions
INFO  [2023-01-26 18:10:56,397] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/formConfigs:FORM_CONFIG}
INFO  [2023-01-26 18:10:56,397] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/formConfigs
INFO  [2023-01-26 18:10:56,408] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/users:AUTH_USER}
INFO  [2023-01-26 18:10:56,408] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/users
INFO  [2023-01-26 18:10:56,422] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/roles:AUTH_ROLE}
INFO  [2023-01-26 18:10:56,422] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/roles
INFO  [2023-01-26 18:10:56,433] com.bakdata.conquery.models.config.XodusStoreFactory: Closed XodusStore: XodusStore[/tmp/conqueryIntegrationTest12910953884258704183/manager/meta/groups:AUTH_GROUP}
INFO  [2023-01-26 18:10:56,433] com.bakdata.conquery.models.config.XodusStoreFactory: Closed last XodusStore in Environment. Closing Environment as well: /tmp/conqueryIntegrationTest12910953884258704183/manager/meta/groups
INFO  [2023-01-26 18:10:56,446] org.eclipse.jetty.server.AbstractConnector: Stopped application@31f36816{HTTP/1.1, (http/1.1)}{0.0.0.0:37893}
INFO  [2023-01-26 18:10:56,446] org.eclipse.jetty.server.AbstractConnector: Stopped admin@6e10a039{HTTP/1.1, (http/1.1)}{0.0.0.0:37395}
INFO  [2023-01-26 18:10:56,450] org.eclipse.jetty.server.handler.ContextHandler: Stopped i.d.j.MutableServletContextHandler@3904195{/,null,STOPPED}
INFO  [2023-01-26 18:10:56,452] org.eclipse.jetty.server.handler.ContextHandler: Stopped i.d.j.MutableServletContextHandler@72d630c5{/,null,STOPPED}
INFO  [2023-01-26 18:10:56,453] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast shard-node1
INFO  [2023-01-26 18:10:56,497] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow shard-node1
INFO  [2023-01-26 18:10:56,500] com.bakdata.conquery.commands.ShardNode: Connection was closed by ManagerNode
INFO  [2023-01-26 18:10:56,500] com.bakdata.conquery.commands.ShardNode: Disconnected from ManagerNode
INFO  [2023-01-26 18:10:56,500] com.bakdata.conquery.commands.ManagerNode: Client 'null' disconnected 
INFO  [2023-01-26 18:10:56,501] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast shard-node0
INFO  [2023-01-26 18:10:56,585] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow shard-node0
INFO  [2023-01-26 18:10:56,601] com.bakdata.conquery.commands.ShardNode: Connection was closed by ManagerNode
INFO  [2023-01-26 18:10:56,601] com.bakdata.conquery.commands.ShardNode: Disconnected from ManagerNode
INFO  [2023-01-26 18:10:56,601] com.bakdata.conquery.commands.ManagerNode: Client 'null' disconnected 
INFO  [2023-01-26 18:10:56,601] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast ManagerNode
INFO  [2023-01-26 18:10:56,666] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow ManagerNode
INFO  [2023-01-26 18:10:56,703] org.eclipse.jetty.server.AbstractConnector: Stopped application@58fbfd4d{HTTP/1.1, (http/1.1)}{0.0.0.0:45505}
INFO  [2023-01-26 18:10:56,703] org.eclipse.jetty.server.AbstractConnector: Stopped admin@449d3375{HTTP/1.1, (http/1.1)}{0.0.0.0:35531}
INFO  [2023-01-26 18:10:56,708] org.eclipse.jetty.server.handler.ContextHandler: Stopped i.d.j.MutableServletContextHandler@37215f46{/,null,STOPPED}
INFO  [2023-01-26 18:10:56,712] org.eclipse.jetty.server.handler.ContextHandler: Stopped i.d.j.MutableServletContextHandler@34365908{/,null,STOPPED}
INFO  [2023-01-26 18:10:56,712] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast shard-node1
INFO  [2023-01-26 18:10:56,789] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow shard-node1
INFO  [2023-01-26 18:10:56,884] com.bakdata.conquery.commands.ShardNode: Connection was closed by ManagerNode
INFO  [2023-01-26 18:10:56,884] com.bakdata.conquery.commands.ShardNode: Disconnected from ManagerNode
INFO  [2023-01-26 18:10:56,884] com.bakdata.conquery.commands.ManagerNode: Client 'null' disconnected 
INFO  [2023-01-26 18:10:56,892] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast shard-node0
INFO  [2023-01-26 18:10:56,899] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow shard-node0
INFO  [2023-01-26 18:10:56,983] com.bakdata.conquery.commands.ShardNode: Connection was closed by ManagerNode
INFO  [2023-01-26 18:10:56,983] com.bakdata.conquery.commands.ShardNode: Disconnected from ManagerNode
INFO  [2023-01-26 18:10:56,983] com.bakdata.conquery.commands.ManagerNode: Client 'null' disconnected 
INFO  [2023-01-26 18:10:56,987] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager fast ManagerNode
INFO  [2023-01-26 18:10:57,077] com.bakdata.conquery.models.jobs.JobExecutor: Closing Job Manager slow ManagerNode
[INFO] 
[INFO] Results:
[INFO] 
[ERROR] Errors: 
[ERROR]   ExcelResultRenderTest.writeAndRead:86 » AbstractMethod Receiver class org.apac...
[INFO] 
[ERROR] Tests run: 1665, Failures: 0, Errors: 1, Skipped: 0
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary for Conquery Parent 0.0.0-SNAPSHOT:
[INFO] 
[INFO] Conquery Parent .................................... SUCCESS [  0.181 s]
[INFO] backend ............................................ FAILURE [03:33 min]
[INFO] executable ......................................... SKIPPED
[INFO] autodoc ............................................ SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  03:33 min
[INFO] Finished at: 2023-01-26T18:10:57Z
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.22.2:test (default-test) on project backend: There are test failures.
[ERROR] 
[ERROR] Please refer to /home/gabsko/breaking-updates/backend/target/surefire-reports for the individual test results.
[ERROR] Please refer to dump files (if any exist) [date].dump, [date]-jvmRun[N].dump and [date].dumpstream.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <args> -rf :backend
