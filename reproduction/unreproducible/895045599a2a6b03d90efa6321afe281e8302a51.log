[INFO] Scanning for projects...
[INFO] Inspecting build with total of 1 modules...
[INFO] Installing Nexus Staging features:
[INFO]   ... total of 1 executions of maven-deploy-plugin replaced with nexus-staging-maven-plugin
[INFO] 
[INFO] --------------< com.snowflake:snowflake-kafka-connector >---------------
[INFO] Building Snowflake Kafka Connector 1.5.5
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ snowflake-kafka-connector ---
[INFO] Deleting /home/gabsko/breaking-updates/target
[INFO] 
[INFO] --- jacoco-maven-plugin:0.8.2:prepare-agent (pre-unit-test) @ snowflake-kafka-connector ---
[INFO] argLine set to -javaagent:/home/gabsko/.m2/repository/org/jacoco/org.jacoco.agent/0.8.2/org.jacoco.agent-0.8.2-runtime.jar=destfile=/home/gabsko/breaking-updates/target/jacoco-ut.exec
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ snowflake-kafka-connector ---
[WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent!
[INFO] skip non existing resourceDirectory /home/gabsko/breaking-updates/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ snowflake-kafka-connector ---
[INFO] Changes detected - recompiling the module!
[WARNING] File encoding has not been set, using platform encoding UTF-8, i.e. build is platform dependent!
[INFO] Compiling 39 source files to /home/gabsko/breaking-updates/target/classes
[WARNING] /home/gabsko/breaking-updates/src/main/java/com/snowflake/kafka/connector/records/AvroConverterConfig.java: Some input files use or override a deprecated API.
[WARNING] /home/gabsko/breaking-updates/src/main/java/com/snowflake/kafka/connector/records/AvroConverterConfig.java: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ snowflake-kafka-connector ---
[WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent!
[INFO] Copying 4 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ snowflake-kafka-connector ---
[INFO] Changes detected - recompiling the module!
[WARNING] File encoding has not been set, using platform encoding UTF-8, i.e. build is platform dependent!
[INFO] Compiling 28 source files to /home/gabsko/breaking-updates/target/test-classes
[WARNING] /home/gabsko/breaking-updates/src/test/java/com/snowflake/kafka/connector/internal/InternalStageIT.java: Some input files use or override a deprecated API.
[WARNING] /home/gabsko/breaking-updates/src/test/java/com/snowflake/kafka/connector/internal/InternalStageIT.java: Recompile with -Xlint:deprecation for details.
[WARNING] /home/gabsko/breaking-updates/src/test/java/com/snowflake/kafka/connector/internal/ConnectionServiceIT.java: Some input files use unchecked or unsafe operations.
[WARNING] /home/gabsko/breaking-updates/src/test/java/com/snowflake/kafka/connector/internal/ConnectionServiceIT.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.22.0:test (default-test) @ snowflake-kafka-connector ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running com.snowflake.kafka.connector.ConnectorConfigTest
12-02-2023 00:57:26 main ERROR Utils:585 - 
[SF_KAFKA_CONNECTOR] Invalid snowflake.topic2table.map config format: $@#$#@%^$12312
12-02-2023 00:57:26 main ERROR Utils:453 - 
[SF_KAFKA_CONNECTOR] snowflake.url.name cannot be empty.
12-02-2023 00:57:26 main ERROR Utils:370 - 
[SF_KAFKA_CONNECTOR] buffer.count.records is empty
12-02-2023 00:57:26 main ERROR Utils:413 - 
[SF_KAFKA_CONNECTOR] buffer.size.bytes is empty
12-02-2023 00:57:26 main ERROR Utils:474 - 
[SF_KAFKA_CONNECTOR] Kafka provider config error:Unsupported provider name: Something_which_is_not_supported. Supported are: unknown,self_hosted,confluent
12-02-2023 00:57:26 main ERROR Utils:385 - 
[SF_KAFKA_CONNECTOR] buffer.count.records should be an integer
12-02-2023 00:57:26 main ERROR Utils:398 - 
[SF_KAFKA_CONNECTOR] buffer.size.bytes is too low at 0. It must be 1 or greater.
12-02-2023 00:57:26 main ERROR Utils:407 - 
[SF_KAFKA_CONNECTOR] buffer.size.bytes should be an integer
12-02-2023 00:57:26 main ERROR Utils:440 - 
[SF_KAFKA_CONNECTOR] snowflake.private.key cannot be empty.
12-02-2023 00:57:26 main ERROR Utils:461 - 
[SF_KAFKA_CONNECTOR] Proxy settings error: 
12-02-2023 00:57:26 main ERROR Utils:334 - 
[SF_KAFKA_CONNECTOR] name is empty or invalid. It should match Snowflake object identifier syntax. Please see the documentation.
12-02-2023 00:57:26 main ERROR Utils:461 - 
[SF_KAFKA_CONNECTOR] Proxy settings error: 
12-02-2023 00:57:26 main ERROR Utils:447 - 
[SF_KAFKA_CONNECTOR] snowflake.user.name cannot be empty.
12-02-2023 00:57:26 main ERROR Utils:345 - 
[SF_KAFKA_CONNECTOR] buffer.flush.time is empty
12-02-2023 00:57:26 main ERROR Utils:361 - 
[SF_KAFKA_CONNECTOR] buffer.flush.time should be an integer
12-02-2023 00:57:26 main ERROR Utils:485 - 
[SF_KAFKA_CONNECTOR] Kafka config:behavior.on.null.values error:Invalid value invalid for configuration behavior.on.null.values: String must be one of: default, ignore
12-02-2023 00:57:26 main ERROR Utils:377 - 
[SF_KAFKA_CONNECTOR] buffer.count.records is -1, it should not be negative
12-02-2023 00:57:26 main ERROR Utils:434 - 
[SF_KAFKA_CONNECTOR] snowflake.schema.name cannot be empty.
12-02-2023 00:57:26 main ERROR Utils:597 - 
[SF_KAFKA_CONNECTOR] table name !@#@!#!@ should have at least 2 characters, start with _a-zA-Z, and only contains _$a-zA-z0-9
12-02-2023 00:57:26 main ERROR Utils:426 - 
[SF_KAFKA_CONNECTOR] snowflake.database.name cannot be empty.
12-02-2023 00:57:26 main ERROR Utils:607 - 
[SF_KAFKA_CONNECTOR] topic name topic1 is duplicated
12-02-2023 00:57:26 main ERROR Utils:497 - 
[SF_KAFKA_CONNECTOR] Kafka config:jmx should either be true or false
12-02-2023 00:57:26 main ERROR Utils:352 - 
[SF_KAFKA_CONNECTOR] buffer.flush.time is 9, it should be greater than 10
12-02-2023 00:57:26 main ERROR Utils:613 - 
[SF_KAFKA_CONNECTOR] table name table1 is duplicated
[INFO] Tests run: 32, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.162 s - in com.snowflake.kafka.connector.ConnectorConfigTest
[INFO] Running com.snowflake.kafka.connector.UtilsTest
12-02-2023 00:57:26 main INFO  Utils:198 - 
[SF_KAFKA_CONNECTOR] invalid JDBC_LOG_DIR /dummy_dir_not_exist defaulting to /tmp
12-02-2023 00:57:26 main INFO  Utils:195 - 
[SF_KAFKA_CONNECTOR] jdbc tracing directory = /usr
12-02-2023 00:57:26 main INFO  Utils:195 - 
[SF_KAFKA_CONNECTOR] jdbc tracing directory = /tmp
12-02-2023 00:57:26 main ERROR Utils:585 - 
[SF_KAFKA_CONNECTOR] Invalid snowflake.topic2table.map config format: adsadas
12-02-2023 00:57:26 main ERROR Utils:597 - 
[SF_KAFKA_CONNECTOR] table name @123 should have at least 2 characters, start with _a-zA-Z, and only contains _$a-zA-z0-9
12-02-2023 00:57:26 main INFO  Utils:100 - 
[SF_KAFKA_CONNECTOR] Current Snowflake Kafka Connector Version: 1.5.5
12-02-2023 00:57:27 main WARN  Utils:130 - 
[SF_KAFKA_CONNECTOR] Connector update is available, please upgrade Snowflake Kafka Connector (1.5.5 -> 1.8.2) 
12-02-2023 00:57:27 main ERROR Utils:585 - 
[SF_KAFKA_CONNECTOR] Invalid snowflake.topic2table.map config format: 12321
12-02-2023 00:57:27 main ERROR SnowflakeSinkTask:317 - 
[SF_KAFKA_CONNECTOR] Invalid Input, Topic2Table Map disabled
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.516 s - in com.snowflake.kafka.connector.UtilsTest
[INFO] Running com.snowflake.kafka.connector.records.RecordContentTest
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.146 s - in com.snowflake.kafka.connector.records.RecordContentTest
[INFO] Running com.snowflake.kafka.connector.records.MetaColumnTest
{"content":{"name":"test"},"meta":{"topic":"test","offset":0,"partition":0,"key":"test"}}
12-02-2023 00:57:27 main ERROR SnowflakeConverter:42 - 
[SF_KAFKA_CONNECTOR] Failed to parse JSON record
[SF_KAFKA_CONNECTOR] net.snowflake.client.jdbc.internal.fasterxml.jackson.core.JsonParseException: Unexpected character ('a' (code 97)): Expected space separating root-level values
[SF_KAFKA_CONNECTOR]  at [Source: (byte[])"123adsada"; line: 1, column: 5]
Config test success
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.377 s - in com.snowflake.kafka.connector.records.MetaColumnTest
[INFO] Running com.snowflake.kafka.connector.records.ValueSchemaTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 s - in com.snowflake.kafka.connector.records.ValueSchemaTest
[INFO] Running com.snowflake.kafka.connector.records.HeaderTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 s - in com.snowflake.kafka.connector.records.HeaderTest
[INFO] Running com.snowflake.kafka.connector.records.ConverterTest
{
  "type" : "record",
  "name" : "MyRecord",
  "fields" : [ {
    "name" : "bytesDecimal",
    "type" : {
      "type" : "bytes",
      "logicalType" : "decimal",
      "precision" : 20,
      "scale" : 4
    }
  } ]
}
12-02-2023 00:57:27 main INFO  AvroDataConfig:361 - AvroDataConfig values: 
	connect.meta.data = true
	enhanced.avro.schema.support = false
	schemas.cache.config = 100

12-02-2023 00:57:27 main INFO  AvroConverterConfig:179 - AvroConverterConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

12-02-2023 00:57:27 main INFO  KafkaAvroSerializerConfig:179 - KafkaAvroSerializerConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

12-02-2023 00:57:27 main INFO  KafkaAvroDeserializerConfig:179 - KafkaAvroDeserializerConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	specific.avro.reader = false
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

12-02-2023 00:57:27 main INFO  AvroDataConfig:361 - AvroDataConfig values: 
	connect.meta.data = true
	enhanced.avro.schema.support = false
	schemas.cache.config = 1000

0000000001060dbba0
12-02-2023 00:57:27 main ERROR SnowflakeConverter:42 - 
[SF_KAFKA_CONNECTOR] Failed to parse JSON record
[SF_KAFKA_CONNECTOR] net.snowflake.client.jdbc.internal.fasterxml.jackson.core.JsonParseException: Unrecognized token 'fasfas': was expecting (JSON String, Number, Array, Object or token 'null', 'true' or 'false')
[SF_KAFKA_CONNECTOR]  at [Source: (byte[])"fasfas"; line: 1, column: 7]
12-02-2023 00:57:27 main ERROR SnowflakeConverter:138 - 
[SF_KAFKA_CONNECTOR] failed to parse AVRO record
[SF_KAFKA_CONNECTOR] 
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Exception: Invalid input record
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Error Code: 0010
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Detail: Input record value can't be parsed
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Message: unknown bytes
12-02-2023 00:57:27 main ERROR SnowflakeConverter:138 - 
[SF_KAFKA_CONNECTOR] failed to parse AVRO record
[SF_KAFKA_CONNECTOR] null
12-02-2023 00:57:27 main ERROR SnowflakeConverter:138 - 
[SF_KAFKA_CONNECTOR] failed to parse AVRO record
[SF_KAFKA_CONNECTOR] 
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Exception: Invalid input record
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Error Code: 0010
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Detail: Input record value can't be parsed
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Message: Failed to parse AVRO record
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] java.io.EOFException
12-02-2023 00:57:27 main ERROR SnowflakeConverter:86 - 
[SF_KAFKA_CONNECTOR] Failed to parse AVRO record
[SF_KAFKA_CONNECTOR] 
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Exception: Invalid input record
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Error Code: 0010
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Detail: Input record value can't be parsed
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Message: Failed to parse AVRO record
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Not an Avro data file.
12-02-2023 00:57:27 main INFO  AvroConverterConfig:179 - AvroConverterConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

12-02-2023 00:57:27 main INFO  AvroConverterConfig:179 - AvroConverterConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

12-02-2023 00:57:27 main INFO  KafkaAvroSerializerConfig:179 - KafkaAvroSerializerConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

12-02-2023 00:57:27 main INFO  KafkaAvroDeserializerConfig:179 - KafkaAvroDeserializerConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	specific.avro.reader = false
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

12-02-2023 00:57:27 main INFO  AvroDataConfig:361 - AvroDataConfig values: 
	connect.meta.data = true
	enhanced.avro.schema.support = false
	schemas.cache.config = 1000

Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-1,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-4,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-3,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-4,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-1,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-3,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-4,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-1,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-4,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-3,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-1,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-4,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-3,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-1,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-4,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-1,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-3,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-4,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-1,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-4,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-3,5,main]
12-02-2023 00:57:27 main INFO  AvroConverterConfig:179 - AvroConverterConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

12-02-2023 00:57:27 main INFO  KafkaAvroSerializerConfig:179 - KafkaAvroSerializerConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

12-02-2023 00:57:27 main INFO  KafkaAvroDeserializerConfig:179 - KafkaAvroDeserializerConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	specific.avro.reader = false
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

12-02-2023 00:57:27 main INFO  AvroDataConfig:361 - AvroDataConfig values: 
	connect.meta.data = true
	enhanced.avro.schema.support = false
	schemas.cache.config = 1000

12-02-2023 00:57:27 main ERROR SnowflakeConverter:138 - 
[SF_KAFKA_CONNECTOR] failed to parse AVRO record
[SF_KAFKA_CONNECTOR] null
[INFO] Tests run: 13, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.158 s - in com.snowflake.kafka.connector.records.ConverterTest
[INFO] Running com.snowflake.kafka.connector.records.ProcessRecordTest
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.027 s - in com.snowflake.kafka.connector.records.ProcessRecordTest
[INFO] Running com.snowflake.kafka.connector.SecurityTest
[ERROR] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.005 s <<< FAILURE! - in com.snowflake.kafka.connector.SecurityTest
[ERROR] testRSAPasswordOutput(com.snowflake.kafka.connector.SecurityTest)  Time elapsed: 0.004 s  <<< ERROR!
java.lang.RuntimeException: java.io.FileNotFoundException: profile.json (No such file or directory)
	at com.snowflake.kafka.connector.SecurityTest.testRSAPasswordOutput(SecurityTest.java:19)
Caused by: java.io.FileNotFoundException: profile.json (No such file or directory)
	at com.snowflake.kafka.connector.SecurityTest.testRSAPasswordOutput(SecurityTest.java:19)

[INFO] Running com.snowflake.kafka.connector.internal.FIPSTest
[ERROR] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.001 s <<< FAILURE! - in com.snowflake.kafka.connector.internal.FIPSTest
[ERROR] testFips(com.snowflake.kafka.connector.internal.FIPSTest)  Time elapsed: 0.001 s  <<< ERROR!
java.lang.NullPointerException
	at com.snowflake.kafka.connector.internal.FIPSTest.testFips(FIPSTest.java:20)

[INFO] Running com.snowflake.kafka.connector.internal.InternalUtilsTest
12-02-2023 00:57:27 main DEBUG InternalUtils:104 - 
[SF_KAFKA_CONNECTOR] converted date: 2019-07-18T23:32:38Z
[ERROR] Tests run: 6, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 0.115 s <<< FAILURE! - in com.snowflake.kafka.connector.internal.InternalUtilsTest
[ERROR] testCreateProperties(com.snowflake.kafka.connector.internal.InternalUtilsTest)  Time elapsed: 0.001 s  <<< ERROR!
java.lang.NullPointerException
	at com.snowflake.kafka.connector.internal.InternalUtilsTest.testCreateProperties(InternalUtilsTest.java:80)

[ERROR] testPrivateKey(com.snowflake.kafka.connector.internal.InternalUtilsTest)  Time elapsed: 0.112 s  <<< ERROR!
java.lang.NullPointerException
	at com.snowflake.kafka.connector.internal.InternalUtilsTest.testPrivateKey(InternalUtilsTest.java:21)

[INFO] Running com.snowflake.kafka.connector.internal.FileNameUtilsTest
12-02-2023 00:57:28 main DEBUG FileNameUtils:43 - 
[SF_KAFKA_CONNECTOR] generated file name: TEST_CONNECTOR/test_topic/123/456_789_1676163448069.json.gz
12-02-2023 00:57:28 main DEBUG FileNameUtils:74 - 
[SF_KAFKA_CONNECTOR] generated broken data file name: TEST_CONNECTOR/test_topic/123/456_key_1676163448075.gz
12-02-2023 00:57:28 main DEBUG FileNameUtils:74 - 
[SF_KAFKA_CONNECTOR] generated broken data file name: TEST_CONNECTOR/test_topic/123/456_value_1676163448075.gz
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.011 s - in com.snowflake.kafka.connector.internal.FileNameUtilsTest
[INFO] Running com.snowflake.kafka.connector.internal.TelemetryUnitTest
12-02-2023 00:57:28 main DEBUG SnowflakeTelemetryBasicInfo:274 - 
[SF_KAFKA_CONNECTOR] Registering metrics for pipe:pipe, existing:[]
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.077 s - in com.snowflake.kafka.connector.internal.TelemetryUnitTest
[INFO] Running com.snowflake.kafka.connector.internal.LoggingTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 s - in com.snowflake.kafka.connector.internal.LoggingTest
[INFO] Running com.snowflake.kafka.connector.internal.SnowflakeURLTest
12-02-2023 00:57:28 main DEBUG SnowflakeURL:75 - 
[SF_KAFKA_CONNECTOR] parsed Snowflake URL: http://account.snowflake.com:80
12-02-2023 00:57:28 main DEBUG SnowflakeURL:75 - 
[SF_KAFKA_CONNECTOR] parsed Snowflake URL: https://account.snowflake.com:443
12-02-2023 00:57:28 main DEBUG SnowflakeURL:75 - 
[SF_KAFKA_CONNECTOR] parsed Snowflake URL:  account.snowflake.com:80
12-02-2023 00:57:28 main DEBUG SnowflakeURL:75 - 
[SF_KAFKA_CONNECTOR] parsed Snowflake URL: account.snowflake.com
12-02-2023 00:57:28 main DEBUG SnowflakeURL:75 - 
[SF_KAFKA_CONNECTOR] parsed Snowflake URL: http://account.snowflake.com 
12-02-2023 00:57:28 main DEBUG SnowflakeURL:75 - 
[SF_KAFKA_CONNECTOR] parsed Snowflake URL: https://account.snowflake.com
12-02-2023 00:57:28 main DEBUG SnowflakeURL:75 - 
[SF_KAFKA_CONNECTOR] parsed Snowflake URL: https://account.region.aws.privatelink.snowflake.com:443
12-02-2023 00:57:28 main INFO  SnowflakeURL:32 - 
[SF_KAFKA_CONNECTOR] enabling JDBC tracing
12-02-2023 00:57:28 main DEBUG SnowflakeURL:75 - 
[SF_KAFKA_CONNECTOR] parsed Snowflake URL: https://account.region.aws.privatelink.snowflake.com:443
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 s - in com.snowflake.kafka.connector.internal.SnowflakeURLTest
[INFO] 
[INFO] Results:
[INFO] 
[ERROR] Errors: 
[ERROR]   SecurityTest.testRSAPasswordOutput:19 » Runtime java.io.FileNotFoundException:...
[ERROR]   FIPSTest.testFips:20 » NullPointer
[ERROR]   InternalUtilsTest.testCreateProperties:80 » NullPointer
[ERROR]   InternalUtilsTest.testPrivateKey:21 » NullPointer
[INFO] 
[ERROR] Tests run: 100, Failures: 0, Errors: 4, Skipped: 0
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  5.834 s
[INFO] Finished at: 2023-02-12T00:57:28Z
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.22.0:test (default-test) on project snowflake-kafka-connector: There are test failures.
[ERROR] 
[ERROR] Please refer to /home/gabsko/breaking-updates/target/surefire-reports for the individual test results.
[ERROR] Please refer to dump files (if any exist) [date]-jvmRun[N].dump, [date].dumpstream and [date]-jvmRun[N].dumpstream.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
