[INFO] Scanning for projects...
[INFO] 
[INFO] --------< com.github.splunk.kafka.connect:splunk-kafka-connect >--------
[INFO] Building splunk-kafka-connect v2.0.5
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ splunk-kafka-connect ---
[INFO] Deleting /home/gabsko/breaking-updates/target
[INFO] 
[INFO] --- maven-checkstyle-plugin:2.17:check (validate) @ splunk-kafka-connect ---
[INFO] 
[INFO] --- jacoco-maven-plugin:0.8.6:prepare-agent (pre-unit-test) @ splunk-kafka-connect ---
[INFO] surefireArgLine set to -javaagent:/home/gabsko/.m2/repository/org/jacoco/org.jacoco.agent/0.8.6/org.jacoco.agent-0.8.6-runtime.jar=destfile=/home/gabsko/breaking-updates/target/coverage-reports/jacoco-ut.exec,excludes=**/*com/splunk/hecclient/examples/**/*
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ splunk-kafka-connect ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 1 resource
[INFO] 
[INFO] --- maven-compiler-plugin:3.7.0:compile (default-compile) @ splunk-kafka-connect ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 38 source files to /home/gabsko/breaking-updates/target/classes
[WARNING] bootstrap class path not set in conjunction with -source 8
[WARNING] No processor claimed any of these annotations: com.fasterxml.jackson.annotation.JsonIgnore,com.fasterxml.jackson.annotation.JsonInclude,com.fasterxml.jackson.databind.annotation.JsonSerialize,com.fasterxml.jackson.annotation.JsonIgnoreProperties
[WARNING] /home/gabsko/breaking-updates/src/main/java/com/splunk/hecclient/DoubleSerializer.java:[29,64] ROUND_HALF_UP in java.math.BigDecimal has been deprecated
[WARNING] /home/gabsko/breaking-updates/src/main/java/com/splunk/hecclient/DoubleSerializer.java:[29,41] setScale(int,int) in java.math.BigDecimal has been deprecated
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ splunk-kafka-connect ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 3 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.7.0:testCompile (default-testCompile) @ splunk-kafka-connect ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 35 source files to /home/gabsko/breaking-updates/target/test-classes
[WARNING] bootstrap class path not set in conjunction with -source 8
[WARNING] No processor claimed any of these annotations: org.junit.jupiter.api.Test,org.junit.Test,com.fasterxml.jackson.databind.annotation.JsonSerialize
[WARNING] /home/gabsko/breaking-updates/src/test/java/com/splunk/hecclient/HecAckPollResponseTest.java:[35,48] Long(long) in java.lang.Long has been deprecated
[WARNING] /home/gabsko/breaking-updates/src/test/java/com/splunk/hecclient/JsonEventTest.java:[175,29] Double(double) in java.lang.Double has been deprecated
[INFO] 
[INFO] --- maven-surefire-plugin:2.22.2:test (default-test) @ splunk-kafka-connect ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running com.splunk.kafka.connect.SplunkSinkConnecterTest
[main] INFO com.splunk.kafka.connect.SplunkSinkConnector - kafka-connect-splunk starts
[main] INFO com.splunk.kafka.connect.SplunkSinkConnector - kafka-connect-splunk discovered 10 tasks
[main] INFO com.splunk.kafka.connect.SplunkSinkConnector - kafka-connect-splunk stops
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.023 s - in com.splunk.kafka.connect.SplunkSinkConnecterTest
[INFO] Running com.splunk.kafka.connect.SplunkSinkRecordTest
[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = false
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 1
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = true
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = 
	splunk.hec.ssl.validate.certs = false
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = false
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = index-1
	splunk.sources = kafka-connect
	splunk.sourcetypes = kafka-data

ConnectHeaders(headers=[ConnectHeader(key=splunk.header.index, value=splunk.header.index, schema=Schema{STRING}), ConnectHeader(key=splunk.header.host, value=splunk.header.host, schema=Schema{STRING}), ConnectHeader(key=splunk.header.source, value=splunk.header.source, schema=Schema{STRING}), ConnectHeader(key=splunk.header.sourcetype, value=splunk.header.sourcetype, schema=Schema{STRING})])
[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = false
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 1
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = true
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = 
	splunk.hec.ssl.validate.certs = false
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = false
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = index-1
	splunk.sources = kafka-connect
	splunk.sourcetypes = kafka-data

[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.019 s - in com.splunk.kafka.connect.SplunkSinkRecordTest
[INFO] Running StructEventTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.375 s - in StructEventTest
[INFO] Running KafkaRecordTrackerTest
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 1
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.025 s - in KafkaRecordTrackerTest
[INFO] Running SplunkSinkConnectorConfigTest
[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = false
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 1
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = true
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = 
	splunk.hec.ssl.validate.certs = false
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = false
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = index-1
	splunk.sources = kafka-connect
	splunk.sourcetypes = kafka-data

[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = true
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = ni=hao,hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 1
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = false
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = 
	splunk.hec.ssl.validate.certs = true
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = true
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = 
	splunk.sources = 
	splunk.sourcetypes = 

[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = true
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = ni=hao,hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 1
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = false
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = ./src/test/resources/keystoretest.jks
	splunk.hec.ssl.validate.certs = true
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = true
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = i1,i2
	splunk.sources = s1,s2,s3
	splunk.sourcetypes = e1,e2,e3

[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = true
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = ni=hao,hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 1
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = false
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = ./src/test/resources/keystoretest.jks
	splunk.hec.ssl.validate.certs = true
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = true
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = 
	splunk.sources = 
	splunk.sourcetypes = 

[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = true
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = i1,i2
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 1
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = false
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = ./src/test/resources/keystoretest.jks
	splunk.hec.ssl.validate.certs = true
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = true
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = 
	splunk.sources = 
	splunk.sourcetypes = 

[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = false
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 1
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = true
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = 
	splunk.hec.ssl.validate.certs = false
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = false
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = index-1
	splunk.sources = kafka-connect
	splunk.sourcetypes = kafka-data

[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = false
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 1
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = true
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = 
	splunk.hec.ssl.validate.certs = false
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = false
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = index-1
	splunk.sources = kafka-connect
	splunk.sourcetypes = kafka-data

[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = false
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 1
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = true
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = 
	splunk.hec.ssl.validate.certs = false
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = false
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = index-1
	splunk.sources = kafka-connect
	splunk.sourcetypes = kafka-data

[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = true
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = ni=hao,hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 1
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = false
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = ./src/test/resources/keystoretest.jks
	splunk.hec.ssl.validate.certs = true
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = true
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = 
	splunk.sources = 
	splunk.sourcetypes = 

[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = true
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = 
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 1
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = false
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = ./src/test/resources/keystoretest.jks
	splunk.hec.ssl.validate.certs = true
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = true
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = 
	splunk.sources = 
	splunk.sourcetypes = 

[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = true
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = null
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 1
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = false
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = ./src/test/resources/keystoretest.jks
	splunk.hec.ssl.validate.certs = true
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = true
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = 
	splunk.sources = 
	splunk.sourcetypes = 

[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = true
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = ni=hao,hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 1
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = false
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = ./src/test/resources/keystoretest.jks
	splunk.hec.ssl.validate.certs = true
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = true
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = 
	splunk.sources = 
	splunk.sourcetypes = 

[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = true
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = ni=hao,hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 1
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = false
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = ./src/test/resources/keystoretest.jks
	splunk.hec.ssl.validate.certs = false
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = true
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = 
	splunk.sources = 
	splunk.sourcetypes = 

[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = false
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 1
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = true
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = ./src/test/resources/keystoretest.jks
	splunk.hec.ssl.validate.certs = true
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = false
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = index-1
	splunk.sources = kafka-connect
	splunk.sourcetypes = kafka-data

[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = false
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 1
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = true
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = ./src/test/resources/keystoretest.jks
	splunk.hec.ssl.validate.certs = true
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = false
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = index-1
	splunk.sources = kafka-connect
	splunk.sourcetypes = kafka-data

[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = true
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = ni=hao,hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 1
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = false
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = ./src/test/resources/keystoretest.jks
	splunk.hec.ssl.validate.certs = true
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = true
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = i1
	splunk.sources = s1
	splunk.sourcetypes = e1

[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = true
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = ni=hao,hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 1
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = false
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = ./src/test/resources/keystoretest.jks
	splunk.hec.ssl.validate.certs = true
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = true
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = 
	splunk.sources = s1
	splunk.sourcetypes = e1

[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = true
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = ni=hao,hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 1
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = false
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = ./src/test/resources/keystoretest.jks
	splunk.hec.ssl.validate.certs = true
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = true
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = 
	splunk.sources = 
	splunk.sourcetypes = e1

[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = true
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = ni=hao,hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 1
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = false
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = ./src/test/resources/keystoretest.jks
	splunk.hec.ssl.validate.certs = true
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = true
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = i1
	splunk.sources = s1,s2,s3
	splunk.sourcetypes = e1,e2,e3

[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = true
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = ni=hao,hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 1
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = false
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = ./src/test/resources/keystoretest.jks
	splunk.hec.ssl.validate.certs = true
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = true
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = i1,i2,i3
	splunk.sources = s1,s2,s3
	splunk.sourcetypes = e1,e2,e3

[INFO] Tests run: 16, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.08 s - in SplunkSinkConnectorConfigTest
[INFO] Running SplunkSinkTaskTest
[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = true
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = ni=hao,hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 100
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = false
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = ./src/test/resources/keystoretest.jks
	splunk.hec.ssl.validate.certs = true
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = true
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = 
	splunk.sources = 
	splunk.sourcetypes = 

[main] INFO com.splunk.kafka.connect.SplunkSinkTask - kafka-connect-splunk task starts with config=splunkURI:https://dummy:8088, raw:false, ack:true, indexes:, sourcetypes:, sources:, headerSupport:false, headerCustom:, httpKeepAlive:true, validateCertificates:true, trustStorePath:./src/test/resources/keystoretest.jks, socketTimeout:1, eventBatchTimeout:1, ackPollInterval:1, ackPollThreads:1, maxHttpConnectionPerChannel:1, flushWindow:30, totalHecChannels:1, enrichment:ni=hao,hello=world, maxBatchSize:100, numberOfThreads:1, lineBreaker:, maxOutstandingEvents:1000000, maxRetries:-1, useRecordTimestamp:true, hecEventFormatted:false, trackData:true, headerSupport:false, headerCustom:, headerIndex:splunk.header.index, headerSource:splunk.header.source, headerSourcetype:splunk.header.sourcetype, headerHost:splunk.header.host, enableCompression:false, lbPollInterval:120
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - purge offsets for closed partitions=[mytopic-1] leaving offsets={}
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - kafka-connect-splunk task ends with config=splunkURI:https://dummy:8088, raw:false, ack:true, indexes:, sourcetypes:, sources:, headerSupport:false, headerCustom:, httpKeepAlive:true, validateCertificates:true, trustStorePath:./src/test/resources/keystoretest.jks, socketTimeout:1, eventBatchTimeout:1, ackPollInterval:1, ackPollThreads:1, maxHttpConnectionPerChannel:1, flushWindow:30, totalHecChannels:1, enrichment:ni=hao,hello=world, maxBatchSize:100, numberOfThreads:1, lineBreaker:, maxOutstandingEvents:1000000, maxRetries:-1, useRecordTimestamp:true, hecEventFormatted:false, trackData:true, headerSupport:false, headerCustom:, headerIndex:splunk.header.index, headerSource:splunk.header.source, headerSourcetype:splunk.header.sourcetype, headerHost:splunk.header.host, enableCompression:false, lbPollInterval:120
[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = true
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = ni=hao,hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 100
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = false
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = ./src/test/resources/keystoretest.jks
	splunk.hec.ssl.validate.certs = true
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = true
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = 
	splunk.sources = 
	splunk.sourcetypes = 

[main] INFO com.splunk.kafka.connect.SplunkSinkTask - kafka-connect-splunk task starts with config=splunkURI:https://dummy:8088, raw:false, ack:true, indexes:, sourcetypes:, sources:, headerSupport:false, headerCustom:, httpKeepAlive:true, validateCertificates:true, trustStorePath:./src/test/resources/keystoretest.jks, socketTimeout:1, eventBatchTimeout:1, ackPollInterval:1, ackPollThreads:1, maxHttpConnectionPerChannel:1, flushWindow:30, totalHecChannels:1, enrichment:ni=hao,hello=world, maxBatchSize:100, numberOfThreads:1, lineBreaker:, maxOutstandingEvents:1000000, maxRetries:-1, useRecordTimestamp:true, hecEventFormatted:false, trackData:true, headerSupport:false, headerCustom:, headerIndex:splunk.header.index, headerSource:splunk.header.source, headerSourcetype:splunk.header.sourcetype, headerHost:splunk.header.host, enableCompression:false, lbPollInterval:120
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 1
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 2
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 3
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 4
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 5
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 6
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 7
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 8
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 9
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 10
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - kafka-connect-splunk task ends with config=splunkURI:https://dummy:8088, raw:false, ack:true, indexes:, sourcetypes:, sources:, headerSupport:false, headerCustom:, httpKeepAlive:true, validateCertificates:true, trustStorePath:./src/test/resources/keystoretest.jks, socketTimeout:1, eventBatchTimeout:1, ackPollInterval:1, ackPollThreads:1, maxHttpConnectionPerChannel:1, flushWindow:30, totalHecChannels:1, enrichment:ni=hao,hello=world, maxBatchSize:100, numberOfThreads:1, lineBreaker:, maxOutstandingEvents:1000000, maxRetries:-1, useRecordTimestamp:true, hecEventFormatted:false, trackData:true, headerSupport:false, headerCustom:, headerIndex:splunk.header.index, headerSource:splunk.header.source, headerSourcetype:splunk.header.sourcetype, headerHost:splunk.header.host, enableCompression:false, lbPollInterval:120
[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = true
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = ni=hao,hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 100
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = true
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = ./src/test/resources/keystoretest.jks
	splunk.hec.ssl.validate.certs = true
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = true
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = 
	splunk.sources = 
	splunk.sourcetypes = 

[main] INFO com.splunk.kafka.connect.SplunkSinkTask - kafka-connect-splunk task starts with config=splunkURI:https://dummy:8088, raw:true, ack:true, indexes:, sourcetypes:, sources:, headerSupport:false, headerCustom:, httpKeepAlive:true, validateCertificates:true, trustStorePath:./src/test/resources/keystoretest.jks, socketTimeout:1, eventBatchTimeout:1, ackPollInterval:1, ackPollThreads:1, maxHttpConnectionPerChannel:1, flushWindow:30, totalHecChannels:1, enrichment:ni=hao,hello=world, maxBatchSize:100, numberOfThreads:1, lineBreaker:, maxOutstandingEvents:1000000, maxRetries:-1, useRecordTimestamp:true, hecEventFormatted:false, trackData:true, headerSupport:false, headerCustom:, headerIndex:splunk.header.index, headerSource:splunk.header.source, headerSourcetype:splunk.header.sourcetype, headerHost:splunk.header.host, enableCompression:false, lbPollInterval:120
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - purge offsets for closed partitions=[mytopic-1] leaving offsets={}
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - kafka-connect-splunk task ends with config=splunkURI:https://dummy:8088, raw:true, ack:true, indexes:, sourcetypes:, sources:, headerSupport:false, headerCustom:, httpKeepAlive:true, validateCertificates:true, trustStorePath:./src/test/resources/keystoretest.jks, socketTimeout:1, eventBatchTimeout:1, ackPollInterval:1, ackPollThreads:1, maxHttpConnectionPerChannel:1, flushWindow:30, totalHecChannels:1, enrichment:ni=hao,hello=world, maxBatchSize:100, numberOfThreads:1, lineBreaker:, maxOutstandingEvents:1000000, maxRetries:-1, useRecordTimestamp:true, hecEventFormatted:false, trackData:true, headerSupport:false, headerCustom:, headerIndex:splunk.header.index, headerSource:splunk.header.source, headerSourcetype:splunk.header.sourcetype, headerHost:splunk.header.host, enableCompression:false, lbPollInterval:120
[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = true
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = ni=hao,hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 6
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = false
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = ./src/test/resources/keystoretest.jks
	splunk.hec.ssl.validate.certs = true
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = true
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = 
	splunk.sources = 
	splunk.sourcetypes = 

[main] INFO com.splunk.kafka.connect.SplunkSinkTask - kafka-connect-splunk task starts with config=splunkURI:https://dummy:8088, raw:false, ack:true, indexes:, sourcetypes:, sources:, headerSupport:false, headerCustom:, httpKeepAlive:true, validateCertificates:true, trustStorePath:./src/test/resources/keystoretest.jks, socketTimeout:1, eventBatchTimeout:1, ackPollInterval:1, ackPollThreads:1, maxHttpConnectionPerChannel:1, flushWindow:30, totalHecChannels:1, enrichment:ni=hao,hello=world, maxBatchSize:6, numberOfThreads:1, lineBreaker:, maxOutstandingEvents:1000000, maxRetries:-1, useRecordTimestamp:true, hecEventFormatted:false, trackData:true, headerSupport:false, headerCustom:, headerIndex:splunk.header.index, headerSource:splunk.header.source, headerSourcetype:splunk.header.sourcetype, headerHost:splunk.header.host, enableCompression:false, lbPollInterval:120
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - kafka-connect-splunk task ends with config=splunkURI:https://dummy:8088, raw:false, ack:true, indexes:, sourcetypes:, sources:, headerSupport:false, headerCustom:, httpKeepAlive:true, validateCertificates:true, trustStorePath:./src/test/resources/keystoretest.jks, socketTimeout:1, eventBatchTimeout:1, ackPollInterval:1, ackPollThreads:1, maxHttpConnectionPerChannel:1, flushWindow:30, totalHecChannels:1, enrichment:ni=hao,hello=world, maxBatchSize:6, numberOfThreads:1, lineBreaker:, maxOutstandingEvents:1000000, maxRetries:-1, useRecordTimestamp:true, hecEventFormatted:false, trackData:true, headerSupport:false, headerCustom:, headerIndex:splunk.header.index, headerSource:splunk.header.source, headerSourcetype:splunk.header.sourcetype, headerHost:splunk.header.host, enableCompression:false, lbPollInterval:120
[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = true
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = ni=hao,hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 100
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = false
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = ./src/test/resources/keystoretest.jks
	splunk.hec.ssl.validate.certs = true
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = true
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = i1
	splunk.sources = e1
	splunk.sourcetypes = s1

[main] INFO com.splunk.kafka.connect.SplunkSinkTask - kafka-connect-splunk task starts with config=splunkURI:https://dummy:8088, raw:false, ack:true, indexes:i1, sourcetypes:s1, sources:e1, headerSupport:false, headerCustom:, httpKeepAlive:true, validateCertificates:true, trustStorePath:./src/test/resources/keystoretest.jks, socketTimeout:1, eventBatchTimeout:1, ackPollInterval:1, ackPollThreads:1, maxHttpConnectionPerChannel:1, flushWindow:30, totalHecChannels:1, enrichment:ni=hao,hello=world, maxBatchSize:100, numberOfThreads:1, lineBreaker:, maxOutstandingEvents:1000000, maxRetries:-1, useRecordTimestamp:true, hecEventFormatted:false, trackData:true, headerSupport:false, headerCustom:, headerIndex:splunk.header.index, headerSource:splunk.header.source, headerSourcetype:splunk.header.sourcetype, headerHost:splunk.header.host, enableCompression:false, lbPollInterval:120
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - purge offsets for closed partitions=[mytopic-1] leaving offsets={}
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - kafka-connect-splunk task ends with config=splunkURI:https://dummy:8088, raw:false, ack:true, indexes:i1, sourcetypes:s1, sources:e1, headerSupport:false, headerCustom:, httpKeepAlive:true, validateCertificates:true, trustStorePath:./src/test/resources/keystoretest.jks, socketTimeout:1, eventBatchTimeout:1, ackPollInterval:1, ackPollThreads:1, maxHttpConnectionPerChannel:1, flushWindow:30, totalHecChannels:1, enrichment:ni=hao,hello=world, maxBatchSize:100, numberOfThreads:1, lineBreaker:, maxOutstandingEvents:1000000, maxRetries:-1, useRecordTimestamp:true, hecEventFormatted:false, trackData:true, headerSupport:false, headerCustom:, headerIndex:splunk.header.index, headerSource:splunk.header.source, headerSourcetype:splunk.header.sourcetype, headerHost:splunk.header.host, enableCompression:false, lbPollInterval:120
[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = true
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = ni=hao,hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 100
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = false
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = ./src/test/resources/keystoretest.jks
	splunk.hec.ssl.validate.certs = true
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = true
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = 
	splunk.sources = 
	splunk.sourcetypes = 

[main] INFO com.splunk.kafka.connect.SplunkSinkTask - kafka-connect-splunk task starts with config=splunkURI:https://dummy:8088, raw:false, ack:true, indexes:, sourcetypes:, sources:, headerSupport:false, headerCustom:, httpKeepAlive:true, validateCertificates:true, trustStorePath:./src/test/resources/keystoretest.jks, socketTimeout:1, eventBatchTimeout:1, ackPollInterval:1, ackPollThreads:1, maxHttpConnectionPerChannel:1, flushWindow:30, totalHecChannels:1, enrichment:ni=hao,hello=world, maxBatchSize:100, numberOfThreads:1, lineBreaker:, maxOutstandingEvents:1000000, maxRetries:-1, useRecordTimestamp:true, hecEventFormatted:false, trackData:true, headerSupport:false, headerCustom:, headerIndex:splunk.header.index, headerSource:splunk.header.source, headerSourcetype:splunk.header.sourcetype, headerHost:splunk.header.host, enableCompression:false, lbPollInterval:120
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - purge offsets for closed partitions=[mytopic-1] leaving offsets={}
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - kafka-connect-splunk task ends with config=splunkURI:https://dummy:8088, raw:false, ack:true, indexes:, sourcetypes:, sources:, headerSupport:false, headerCustom:, httpKeepAlive:true, validateCertificates:true, trustStorePath:./src/test/resources/keystoretest.jks, socketTimeout:1, eventBatchTimeout:1, ackPollInterval:1, ackPollThreads:1, maxHttpConnectionPerChannel:1, flushWindow:30, totalHecChannels:1, enrichment:ni=hao,hello=world, maxBatchSize:100, numberOfThreads:1, lineBreaker:, maxOutstandingEvents:1000000, maxRetries:-1, useRecordTimestamp:true, hecEventFormatted:false, trackData:true, headerSupport:false, headerCustom:, headerIndex:splunk.header.index, headerSource:splunk.header.source, headerSourcetype:splunk.header.sourcetype, headerHost:splunk.header.host, enableCompression:false, lbPollInterval:120
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - kafka-connect-splunk task ends with config=null
[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = true
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = ni=hao,hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 1
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = false
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = ./src/test/resources/keystoretest.jks
	splunk.hec.ssl.validate.certs = true
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = true
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = 
	splunk.sources = 
	splunk.sourcetypes = 

[main] INFO com.splunk.kafka.connect.SplunkSinkTask - kafka-connect-splunk task starts with config=splunkURI:https://dummy:8088, raw:false, ack:true, indexes:, sourcetypes:, sources:, headerSupport:false, headerCustom:, httpKeepAlive:true, validateCertificates:true, trustStorePath:./src/test/resources/keystoretest.jks, socketTimeout:1, eventBatchTimeout:1, ackPollInterval:1, ackPollThreads:1, maxHttpConnectionPerChannel:1, flushWindow:30, totalHecChannels:1, enrichment:ni=hao,hello=world, maxBatchSize:1, numberOfThreads:1, lineBreaker:, maxOutstandingEvents:1000000, maxRetries:-1, useRecordTimestamp:true, hecEventFormatted:false, trackData:true, headerSupport:false, headerCustom:, headerIndex:splunk.header.index, headerSource:splunk.header.source, headerSourcetype:splunk.header.sourcetype, headerHost:splunk.header.host, enableCompression:false, lbPollInterval:120
[main] INFO com.splunk.hecclient.HecAckPoller - HecAckPoller stopped with 0 outstanding un-ACKed events
[main] INFO com.splunk.hecclient.LoadBalancer - LoadBalancer stopped
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - kafka-connect-splunk task ends with config=splunkURI:https://dummy:8088, raw:false, ack:true, indexes:, sourcetypes:, sources:, headerSupport:false, headerCustom:, httpKeepAlive:true, validateCertificates:true, trustStorePath:./src/test/resources/keystoretest.jks, socketTimeout:1, eventBatchTimeout:1, ackPollInterval:1, ackPollThreads:1, maxHttpConnectionPerChannel:1, flushWindow:30, totalHecChannels:1, enrichment:ni=hao,hello=world, maxBatchSize:1, numberOfThreads:1, lineBreaker:, maxOutstandingEvents:1000000, maxRetries:-1, useRecordTimestamp:true, hecEventFormatted:false, trackData:true, headerSupport:false, headerCustom:, headerIndex:splunk.header.index, headerSource:splunk.header.source, headerSourcetype:splunk.header.sourcetype, headerHost:splunk.header.host, enableCompression:false, lbPollInterval:120
[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = true
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = ni=hao,hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 100
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000
	splunk.hec.max.retries = -1
	splunk.hec.raw = false
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = ./src/test/resources/keystoretest.jks
	splunk.hec.ssl.validate.certs = true
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = true
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = 
	splunk.sources = 
	splunk.sourcetypes = 

[main] INFO com.splunk.kafka.connect.SplunkSinkTask - kafka-connect-splunk task starts with config=splunkURI:https://dummy:8088, raw:false, ack:true, indexes:, sourcetypes:, sources:, headerSupport:false, headerCustom:, httpKeepAlive:true, validateCertificates:true, trustStorePath:./src/test/resources/keystoretest.jks, socketTimeout:1, eventBatchTimeout:1, ackPollInterval:1, ackPollThreads:1, maxHttpConnectionPerChannel:1, flushWindow:30, totalHecChannels:1, enrichment:ni=hao,hello=world, maxBatchSize:100, numberOfThreads:1, lineBreaker:, maxOutstandingEvents:1000, maxRetries:-1, useRecordTimestamp:true, hecEventFormatted:false, trackData:true, headerSupport:false, headerCustom:, headerIndex:splunk.header.index, headerSource:splunk.header.source, headerSourcetype:splunk.header.sourcetype, headerHost:splunk.header.host, enableCompression:false, lbPollInterval:120
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 1
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 2
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 3
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 4
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 5
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 6
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 7
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 8
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 9
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 10
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - attempting to resend batch 0750a57b-c574-42e2-8827-95790dfebeea with 0 events, this is attempt 1 out of -1 for this batch 
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 1
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - attempting to resend batch 5b0578c7-6595-4057-bd5e-1515cbdc6227 with 0 events, this is attempt 1 out of -1 for this batch 
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 2
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - attempting to resend batch 0eb8f683-3ed5-4d76-8a95-67549d323ad5 with 0 events, this is attempt 1 out of -1 for this batch 
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 3
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - attempting to resend batch 17d41c53-1498-47ff-821a-95967d80abc7 with 0 events, this is attempt 1 out of -1 for this batch 
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 4
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - attempting to resend batch cd6967c2-9e59-4ccc-8d1f-7c240c9298c6 with 0 events, this is attempt 1 out of -1 for this batch 
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 5
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - attempting to resend batch 7f1e7353-1d45-4371-ac6c-0a195e5c0541 with 0 events, this is attempt 1 out of -1 for this batch 
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 6
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - attempting to resend batch aa892969-2027-48b9-a9f5-7334cca997ff with 0 events, this is attempt 1 out of -1 for this batch 
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 7
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - attempting to resend batch e6e81592-ea02-476a-8feb-ed78e0f65fcf with 0 events, this is attempt 1 out of -1 for this batch 
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 8
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - attempting to resend batch a9d772ac-1a4b-4b28-8e0a-559f68b0fce2 with 0 events, this is attempt 1 out of -1 for this batch 
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 9
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - attempting to resend batch e0f753a1-5b4b-4e4f-b4a4-a45eb372cee0 with 0 events, this is attempt 1 out of -1 for this batch 
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 10
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - handled 10 failed batches with 0 events
[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = true
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = ni=hao,hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 6
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = false
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = ./src/test/resources/keystoretest.jks
	splunk.hec.ssl.validate.certs = true
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = true
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = 
	splunk.sources = 
	splunk.sourcetypes = 

[main] INFO com.splunk.kafka.connect.SplunkSinkTask - kafka-connect-splunk task starts with config=splunkURI:https://dummy:8088, raw:false, ack:true, indexes:, sourcetypes:, sources:, headerSupport:false, headerCustom:, httpKeepAlive:true, validateCertificates:true, trustStorePath:./src/test/resources/keystoretest.jks, socketTimeout:1, eventBatchTimeout:1, ackPollInterval:1, ackPollThreads:1, maxHttpConnectionPerChannel:1, flushWindow:30, totalHecChannels:1, enrichment:ni=hao,hello=world, maxBatchSize:6, numberOfThreads:1, lineBreaker:, maxOutstandingEvents:1000000, maxRetries:-1, useRecordTimestamp:true, hecEventFormatted:false, trackData:true, headerSupport:false, headerCustom:, headerIndex:splunk.header.index, headerSource:splunk.header.source, headerSourcetype:splunk.header.sourcetype, headerHost:splunk.header.host, enableCompression:false, lbPollInterval:120
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - Ignoring Null/Empty event for topicPartitionOffset=(mytopic, 1, 0)
com.splunk.hecclient.HecEmptyEventException: Empty event
	at com.splunk.hecclient.Event.checkEventData(Event.java:351)
	at com.splunk.hecclient.Event.<init>(Event.java:86)
	at com.splunk.hecclient.JsonEvent.<init>(JsonEvent.java:48)
	at com.splunk.kafka.connect.SplunkSinkTask.createHECEventNonFormatted(SplunkSinkTask.java:474)
	at com.splunk.kafka.connect.SplunkSinkTask.createHecEventFrom(SplunkSinkTask.java:411)
	at com.splunk.kafka.connect.SplunkSinkTask.sendEvents(SplunkSinkTask.java:274)
	at com.splunk.kafka.connect.SplunkSinkTask.handleEvent(SplunkSinkTask.java:267)
	at com.splunk.kafka.connect.SplunkSinkTask.put(SplunkSinkTask.java:105)
	at com.splunk.kafka.connect.SplunkSinkTaskTest.putWithEmptyEvent(SplunkSinkTaskTest.java:219)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:39)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
	at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133)
	at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:79)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:70)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:220)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$6(DefaultLauncher.java:188)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:202)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:181)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:128)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:150)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - Ignoring Null/Empty event for topicPartitionOffset=(mytopic, 1, 1)
com.splunk.hecclient.HecEmptyEventException: Empty event
	at com.splunk.hecclient.Event.checkEventData(Event.java:351)
	at com.splunk.hecclient.Event.<init>(Event.java:86)
	at com.splunk.hecclient.JsonEvent.<init>(JsonEvent.java:48)
	at com.splunk.kafka.connect.SplunkSinkTask.createHECEventNonFormatted(SplunkSinkTask.java:474)
	at com.splunk.kafka.connect.SplunkSinkTask.createHecEventFrom(SplunkSinkTask.java:411)
	at com.splunk.kafka.connect.SplunkSinkTask.sendEvents(SplunkSinkTask.java:274)
	at com.splunk.kafka.connect.SplunkSinkTask.handleEvent(SplunkSinkTask.java:267)
	at com.splunk.kafka.connect.SplunkSinkTask.put(SplunkSinkTask.java:105)
	at com.splunk.kafka.connect.SplunkSinkTaskTest.putWithEmptyEvent(SplunkSinkTaskTest.java:219)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:39)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
	at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133)
	at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:79)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:70)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:220)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$6(DefaultLauncher.java:188)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:202)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:181)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:128)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:150)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - Ignoring Null/Empty event for topicPartitionOffset=(mytopic, 1, 2)
com.splunk.hecclient.HecEmptyEventException: Empty event
	at com.splunk.hecclient.Event.checkEventData(Event.java:351)
	at com.splunk.hecclient.Event.<init>(Event.java:86)
	at com.splunk.hecclient.JsonEvent.<init>(JsonEvent.java:48)
	at com.splunk.kafka.connect.SplunkSinkTask.createHECEventNonFormatted(SplunkSinkTask.java:474)
	at com.splunk.kafka.connect.SplunkSinkTask.createHecEventFrom(SplunkSinkTask.java:411)
	at com.splunk.kafka.connect.SplunkSinkTask.sendEvents(SplunkSinkTask.java:274)
	at com.splunk.kafka.connect.SplunkSinkTask.handleEvent(SplunkSinkTask.java:267)
	at com.splunk.kafka.connect.SplunkSinkTask.put(SplunkSinkTask.java:105)
	at com.splunk.kafka.connect.SplunkSinkTaskTest.putWithEmptyEvent(SplunkSinkTaskTest.java:219)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:39)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
	at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133)
	at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:79)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:70)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:220)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$6(DefaultLauncher.java:188)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:202)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:181)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:128)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:150)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - Ignoring Null/Empty event for topicPartitionOffset=(mytopic, 1, 3)
com.splunk.hecclient.HecEmptyEventException: Empty event
	at com.splunk.hecclient.Event.checkEventData(Event.java:351)
	at com.splunk.hecclient.Event.<init>(Event.java:86)
	at com.splunk.hecclient.JsonEvent.<init>(JsonEvent.java:48)
	at com.splunk.kafka.connect.SplunkSinkTask.createHECEventNonFormatted(SplunkSinkTask.java:474)
	at com.splunk.kafka.connect.SplunkSinkTask.createHecEventFrom(SplunkSinkTask.java:411)
	at com.splunk.kafka.connect.SplunkSinkTask.sendEvents(SplunkSinkTask.java:274)
	at com.splunk.kafka.connect.SplunkSinkTask.handleEvent(SplunkSinkTask.java:267)
	at com.splunk.kafka.connect.SplunkSinkTask.put(SplunkSinkTask.java:105)
	at com.splunk.kafka.connect.SplunkSinkTaskTest.putWithEmptyEvent(SplunkSinkTaskTest.java:219)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:39)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
	at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133)
	at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:79)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:70)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:220)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$6(DefaultLauncher.java:188)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:202)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:181)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:128)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:150)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - Ignoring Null/Empty event for topicPartitionOffset=(mytopic, 1, 4)
com.splunk.hecclient.HecEmptyEventException: Empty event
	at com.splunk.hecclient.Event.checkEventData(Event.java:351)
	at com.splunk.hecclient.Event.<init>(Event.java:86)
	at com.splunk.hecclient.JsonEvent.<init>(JsonEvent.java:48)
	at com.splunk.kafka.connect.SplunkSinkTask.createHECEventNonFormatted(SplunkSinkTask.java:474)
	at com.splunk.kafka.connect.SplunkSinkTask.createHecEventFrom(SplunkSinkTask.java:411)
	at com.splunk.kafka.connect.SplunkSinkTask.sendEvents(SplunkSinkTask.java:274)
	at com.splunk.kafka.connect.SplunkSinkTask.handleEvent(SplunkSinkTask.java:267)
	at com.splunk.kafka.connect.SplunkSinkTask.put(SplunkSinkTask.java:105)
	at com.splunk.kafka.connect.SplunkSinkTaskTest.putWithEmptyEvent(SplunkSinkTaskTest.java:219)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:39)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
	at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133)
	at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:79)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:70)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:220)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$6(DefaultLauncher.java:188)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:202)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:181)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:128)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:150)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - Ignoring Null/Empty event for topicPartitionOffset=(mytopic, 1, 5)
com.splunk.hecclient.HecEmptyEventException: Empty event
	at com.splunk.hecclient.Event.checkEventData(Event.java:351)
	at com.splunk.hecclient.Event.<init>(Event.java:86)
	at com.splunk.hecclient.JsonEvent.<init>(JsonEvent.java:48)
	at com.splunk.kafka.connect.SplunkSinkTask.createHECEventNonFormatted(SplunkSinkTask.java:474)
	at com.splunk.kafka.connect.SplunkSinkTask.createHecEventFrom(SplunkSinkTask.java:411)
	at com.splunk.kafka.connect.SplunkSinkTask.sendEvents(SplunkSinkTask.java:274)
	at com.splunk.kafka.connect.SplunkSinkTask.handleEvent(SplunkSinkTask.java:267)
	at com.splunk.kafka.connect.SplunkSinkTask.put(SplunkSinkTask.java:105)
	at com.splunk.kafka.connect.SplunkSinkTaskTest.putWithEmptyEvent(SplunkSinkTaskTest.java:219)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:39)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
	at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133)
	at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:79)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:70)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:220)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$6(DefaultLauncher.java:188)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:202)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:181)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:128)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:150)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - Ignoring Null/Empty event for topicPartitionOffset=(mytopic, 1, 6)
com.splunk.hecclient.HecEmptyEventException: Empty event
	at com.splunk.hecclient.Event.checkEventData(Event.java:351)
	at com.splunk.hecclient.Event.<init>(Event.java:86)
	at com.splunk.hecclient.JsonEvent.<init>(JsonEvent.java:48)
	at com.splunk.kafka.connect.SplunkSinkTask.createHECEventNonFormatted(SplunkSinkTask.java:474)
	at com.splunk.kafka.connect.SplunkSinkTask.createHecEventFrom(SplunkSinkTask.java:411)
	at com.splunk.kafka.connect.SplunkSinkTask.sendEvents(SplunkSinkTask.java:274)
	at com.splunk.kafka.connect.SplunkSinkTask.handleEvent(SplunkSinkTask.java:267)
	at com.splunk.kafka.connect.SplunkSinkTask.put(SplunkSinkTask.java:105)
	at com.splunk.kafka.connect.SplunkSinkTaskTest.putWithEmptyEvent(SplunkSinkTaskTest.java:219)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:39)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
	at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133)
	at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:79)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:70)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:220)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$6(DefaultLauncher.java:188)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:202)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:181)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:128)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:150)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - Ignoring Null/Empty event for topicPartitionOffset=(mytopic, 1, 7)
com.splunk.hecclient.HecEmptyEventException: Empty event
	at com.splunk.hecclient.Event.checkEventData(Event.java:351)
	at com.splunk.hecclient.Event.<init>(Event.java:86)
	at com.splunk.hecclient.JsonEvent.<init>(JsonEvent.java:48)
	at com.splunk.kafka.connect.SplunkSinkTask.createHECEventNonFormatted(SplunkSinkTask.java:474)
	at com.splunk.kafka.connect.SplunkSinkTask.createHecEventFrom(SplunkSinkTask.java:411)
	at com.splunk.kafka.connect.SplunkSinkTask.sendEvents(SplunkSinkTask.java:274)
	at com.splunk.kafka.connect.SplunkSinkTask.handleEvent(SplunkSinkTask.java:267)
	at com.splunk.kafka.connect.SplunkSinkTask.put(SplunkSinkTask.java:105)
	at com.splunk.kafka.connect.SplunkSinkTaskTest.putWithEmptyEvent(SplunkSinkTaskTest.java:219)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:39)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
	at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133)
	at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:79)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:70)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:220)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$6(DefaultLauncher.java:188)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:202)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:181)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:128)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:150)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - Ignoring Null/Empty event for topicPartitionOffset=(mytopic, 1, 8)
com.splunk.hecclient.HecEmptyEventException: Empty event
	at com.splunk.hecclient.Event.checkEventData(Event.java:351)
	at com.splunk.hecclient.Event.<init>(Event.java:86)
	at com.splunk.hecclient.JsonEvent.<init>(JsonEvent.java:48)
	at com.splunk.kafka.connect.SplunkSinkTask.createHECEventNonFormatted(SplunkSinkTask.java:474)
	at com.splunk.kafka.connect.SplunkSinkTask.createHecEventFrom(SplunkSinkTask.java:411)
	at com.splunk.kafka.connect.SplunkSinkTask.sendEvents(SplunkSinkTask.java:274)
	at com.splunk.kafka.connect.SplunkSinkTask.handleEvent(SplunkSinkTask.java:267)
	at com.splunk.kafka.connect.SplunkSinkTask.put(SplunkSinkTask.java:105)
	at com.splunk.kafka.connect.SplunkSinkTaskTest.putWithEmptyEvent(SplunkSinkTaskTest.java:219)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:39)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
	at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133)
	at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:79)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:70)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:220)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$6(DefaultLauncher.java:188)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:202)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:181)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:128)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:150)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - Ignoring Null/Empty event for topicPartitionOffset=(mytopic, 1, 9)
com.splunk.hecclient.HecEmptyEventException: Empty event
	at com.splunk.hecclient.Event.checkEventData(Event.java:351)
	at com.splunk.hecclient.Event.<init>(Event.java:86)
	at com.splunk.hecclient.JsonEvent.<init>(JsonEvent.java:48)
	at com.splunk.kafka.connect.SplunkSinkTask.createHECEventNonFormatted(SplunkSinkTask.java:474)
	at com.splunk.kafka.connect.SplunkSinkTask.createHecEventFrom(SplunkSinkTask.java:411)
	at com.splunk.kafka.connect.SplunkSinkTask.sendEvents(SplunkSinkTask.java:274)
	at com.splunk.kafka.connect.SplunkSinkTask.handleEvent(SplunkSinkTask.java:267)
	at com.splunk.kafka.connect.SplunkSinkTask.put(SplunkSinkTask.java:105)
	at com.splunk.kafka.connect.SplunkSinkTaskTest.putWithEmptyEvent(SplunkSinkTaskTest.java:219)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:39)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
	at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133)
	at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:79)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:70)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:220)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$6(DefaultLauncher.java:188)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:202)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:181)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:128)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:150)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - kafka-connect-splunk task ends with config=splunkURI:https://dummy:8088, raw:false, ack:true, indexes:, sourcetypes:, sources:, headerSupport:false, headerCustom:, httpKeepAlive:true, validateCertificates:true, trustStorePath:./src/test/resources/keystoretest.jks, socketTimeout:1, eventBatchTimeout:1, ackPollInterval:1, ackPollThreads:1, maxHttpConnectionPerChannel:1, flushWindow:30, totalHecChannels:1, enrichment:ni=hao,hello=world, maxBatchSize:6, numberOfThreads:1, lineBreaker:, maxOutstandingEvents:1000000, maxRetries:-1, useRecordTimestamp:true, hecEventFormatted:false, trackData:true, headerSupport:false, headerCustom:, headerIndex:splunk.header.index, headerSource:splunk.header.source, headerSourcetype:splunk.header.sourcetype, headerHost:splunk.header.host, enableCompression:false, lbPollInterval:120
[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = true
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = ni=hao,hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 100
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = true
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = ./src/test/resources/keystoretest.jks
	splunk.hec.ssl.validate.certs = true
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = true
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = i1
	splunk.sources = e1
	splunk.sourcetypes = s1

[main] INFO com.splunk.kafka.connect.SplunkSinkTask - kafka-connect-splunk task starts with config=splunkURI:https://dummy:8088, raw:true, ack:true, indexes:i1, sourcetypes:s1, sources:e1, headerSupport:false, headerCustom:, httpKeepAlive:true, validateCertificates:true, trustStorePath:./src/test/resources/keystoretest.jks, socketTimeout:1, eventBatchTimeout:1, ackPollInterval:1, ackPollThreads:1, maxHttpConnectionPerChannel:1, flushWindow:30, totalHecChannels:1, enrichment:ni=hao,hello=world, maxBatchSize:100, numberOfThreads:1, lineBreaker:, maxOutstandingEvents:1000000, maxRetries:-1, useRecordTimestamp:true, hecEventFormatted:false, trackData:true, headerSupport:false, headerCustom:, headerIndex:splunk.header.index, headerSource:splunk.header.source, headerSourcetype:splunk.header.sourcetype, headerHost:splunk.header.host, enableCompression:false, lbPollInterval:120
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - purge offsets for closed partitions=[mytopic-1] leaving offsets={}
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - kafka-connect-splunk task ends with config=splunkURI:https://dummy:8088, raw:true, ack:true, indexes:i1, sourcetypes:s1, sources:e1, headerSupport:false, headerCustom:, httpKeepAlive:true, validateCertificates:true, trustStorePath:./src/test/resources/keystoretest.jks, socketTimeout:1, eventBatchTimeout:1, ackPollInterval:1, ackPollThreads:1, maxHttpConnectionPerChannel:1, flushWindow:30, totalHecChannels:1, enrichment:ni=hao,hello=world, maxBatchSize:100, numberOfThreads:1, lineBreaker:, maxOutstandingEvents:1000000, maxRetries:-1, useRecordTimestamp:true, hecEventFormatted:false, trackData:true, headerSupport:false, headerCustom:, headerIndex:splunk.header.index, headerSource:splunk.header.source, headerSourcetype:splunk.header.sourcetype, headerHost:splunk.header.host, enableCompression:false, lbPollInterval:120
[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = true
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = ni=hao,hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 100
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000
	splunk.hec.max.retries = -1
	splunk.hec.raw = false
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = ./src/test/resources/keystoretest.jks
	splunk.hec.ssl.validate.certs = true
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = true
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = 
	splunk.sources = 
	splunk.sourcetypes = 

[main] INFO com.splunk.kafka.connect.SplunkSinkTask - kafka-connect-splunk task starts with config=splunkURI:https://dummy:8088, raw:false, ack:true, indexes:, sourcetypes:, sources:, headerSupport:false, headerCustom:, httpKeepAlive:true, validateCertificates:true, trustStorePath:./src/test/resources/keystoretest.jks, socketTimeout:1, eventBatchTimeout:1, ackPollInterval:1, ackPollThreads:1, maxHttpConnectionPerChannel:1, flushWindow:30, totalHecChannels:1, enrichment:ni=hao,hello=world, maxBatchSize:100, numberOfThreads:1, lineBreaker:, maxOutstandingEvents:1000, maxRetries:-1, useRecordTimestamp:true, hecEventFormatted:false, trackData:true, headerSupport:false, headerCustom:, headerIndex:splunk.header.index, headerSource:splunk.header.source, headerSourcetype:splunk.header.sourcetype, headerHost:splunk.header.host, enableCompression:false, lbPollInterval:120
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 1
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 2
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 3
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 4
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 5
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 6
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 7
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 8
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 9
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 10
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - attempting to resend batch 87bc184a-1531-4fa3-845f-62321adeafe9 with 0 events, this is attempt 1 out of -1 for this batch 
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 1
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - attempting to resend batch d9ca457b-458f-4ab6-92fc-9b1562defc0a with 0 events, this is attempt 1 out of -1 for this batch 
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 2
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - attempting to resend batch 23b3ca18-be4c-462f-b4f3-3f0b7df9dd00 with 0 events, this is attempt 1 out of -1 for this batch 
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 3
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - attempting to resend batch cc6969df-da50-44ee-a9ab-fb765f92d84e with 0 events, this is attempt 1 out of -1 for this batch 
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 4
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - attempting to resend batch cdc8096b-ff4c-47ec-8d9e-de9257e7f162 with 0 events, this is attempt 1 out of -1 for this batch 
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 5
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - attempting to resend batch 281c52fd-4ef6-4d14-ba74-6d5e1dceb398 with 0 events, this is attempt 1 out of -1 for this batch 
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 6
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - attempting to resend batch 9ce6c0a3-04fe-45ca-ad13-fbb0707e1972 with 0 events, this is attempt 1 out of -1 for this batch 
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 7
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - attempting to resend batch f1547b10-87a1-4a7d-a2d2-e86ebffe967b with 0 events, this is attempt 1 out of -1 for this batch 
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 8
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - attempting to resend batch 7b5bddf2-1e7b-4c77-a920-7d973ac81b8d with 0 events, this is attempt 1 out of -1 for this batch 
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 9
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - attempting to resend batch 43f31034-6c9b-4095-bd31-416a96fbff59 with 0 events, this is attempt 1 out of -1 for this batch 
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 10
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - handled 10 failed batches with 0 events
[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = true
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = ni=hao,hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 1
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = false
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = ./src/test/resources/keystoretest.jks
	splunk.hec.ssl.validate.certs = true
	splunk.hec.threads = 2
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = true
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = 
	splunk.sources = 
	splunk.sourcetypes = 

[main] INFO com.splunk.kafka.connect.SplunkSinkTask - kafka-connect-splunk task starts with config=splunkURI:https://dummy:8088, raw:false, ack:true, indexes:, sourcetypes:, sources:, headerSupport:false, headerCustom:, httpKeepAlive:true, validateCertificates:true, trustStorePath:./src/test/resources/keystoretest.jks, socketTimeout:1, eventBatchTimeout:1, ackPollInterval:1, ackPollThreads:1, maxHttpConnectionPerChannel:1, flushWindow:30, totalHecChannels:1, enrichment:ni=hao,hello=world, maxBatchSize:1, numberOfThreads:2, lineBreaker:, maxOutstandingEvents:1000000, maxRetries:-1, useRecordTimestamp:true, hecEventFormatted:false, trackData:true, headerSupport:false, headerCustom:, headerIndex:splunk.header.index, headerSource:splunk.header.source, headerSourcetype:splunk.header.sourcetype, headerHost:splunk.header.host, enableCompression:false, lbPollInterval:120
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - kafka-connect-splunk task ends with config=splunkURI:https://dummy:8088, raw:false, ack:true, indexes:, sourcetypes:, sources:, headerSupport:false, headerCustom:, httpKeepAlive:true, validateCertificates:true, trustStorePath:./src/test/resources/keystoretest.jks, socketTimeout:1, eventBatchTimeout:1, ackPollInterval:1, ackPollThreads:1, maxHttpConnectionPerChannel:1, flushWindow:30, totalHecChannels:1, enrichment:ni=hao,hello=world, maxBatchSize:1, numberOfThreads:2, lineBreaker:, maxOutstandingEvents:1000000, maxRetries:-1, useRecordTimestamp:true, hecEventFormatted:false, trackData:true, headerSupport:false, headerCustom:, headerIndex:splunk.header.index, headerSource:splunk.header.source, headerSourcetype:splunk.header.sourcetype, headerHost:splunk.header.host, enableCompression:false, lbPollInterval:120
[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = false
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = ni=hao,hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 1
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = false
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = ./src/test/resources/keystoretest.jks
	splunk.hec.ssl.validate.certs = true
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = true
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = 
	splunk.sources = 
	splunk.sourcetypes = 

[main] INFO com.splunk.kafka.connect.SplunkSinkTask - kafka-connect-splunk task starts with config=splunkURI:https://dummy:8088, raw:false, ack:false, indexes:, sourcetypes:, sources:, headerSupport:false, headerCustom:, httpKeepAlive:true, validateCertificates:true, trustStorePath:./src/test/resources/keystoretest.jks, socketTimeout:1, eventBatchTimeout:1, ackPollInterval:1, ackPollThreads:1, maxHttpConnectionPerChannel:1, flushWindow:30, totalHecChannels:1, enrichment:ni=hao,hello=world, maxBatchSize:1, numberOfThreads:1, lineBreaker:, maxOutstandingEvents:1000000, maxRetries:-1, useRecordTimestamp:true, hecEventFormatted:false, trackData:true, headerSupport:false, headerCustom:, headerIndex:splunk.header.index, headerSource:splunk.header.source, headerSourcetype:splunk.header.sourcetype, headerHost:splunk.header.host, enableCompression:false, lbPollInterval:120
[main] INFO com.splunk.hecclient.LoadBalancer - LoadBalancer stopped
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - kafka-connect-splunk task ends with config=splunkURI:https://dummy:8088, raw:false, ack:false, indexes:, sourcetypes:, sources:, headerSupport:false, headerCustom:, httpKeepAlive:true, validateCertificates:true, trustStorePath:./src/test/resources/keystoretest.jks, socketTimeout:1, eventBatchTimeout:1, ackPollInterval:1, ackPollThreads:1, maxHttpConnectionPerChannel:1, flushWindow:30, totalHecChannels:1, enrichment:ni=hao,hello=world, maxBatchSize:1, numberOfThreads:1, lineBreaker:, maxOutstandingEvents:1000000, maxRetries:-1, useRecordTimestamp:true, hecEventFormatted:false, trackData:true, headerSupport:false, headerCustom:, headerIndex:splunk.header.index, headerSource:splunk.header.source, headerSourcetype:splunk.header.sourcetype, headerHost:splunk.header.host, enableCompression:false, lbPollInterval:120
[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = true
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = ni=hao,hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 100
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000
	splunk.hec.max.retries = -1
	splunk.hec.raw = false
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = ./src/test/resources/keystoretest.jks
	splunk.hec.ssl.validate.certs = true
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = true
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = 
	splunk.sources = 
	splunk.sourcetypes = 

[main] INFO com.splunk.kafka.connect.SplunkSinkTask - kafka-connect-splunk task starts with config=splunkURI:https://dummy:8088, raw:false, ack:true, indexes:, sourcetypes:, sources:, headerSupport:false, headerCustom:, httpKeepAlive:true, validateCertificates:true, trustStorePath:./src/test/resources/keystoretest.jks, socketTimeout:1, eventBatchTimeout:1, ackPollInterval:1, ackPollThreads:1, maxHttpConnectionPerChannel:1, flushWindow:30, totalHecChannels:1, enrichment:ni=hao,hello=world, maxBatchSize:100, numberOfThreads:1, lineBreaker:, maxOutstandingEvents:1000, maxRetries:-1, useRecordTimestamp:true, hecEventFormatted:false, trackData:true, headerSupport:false, headerCustom:, headerIndex:splunk.header.index, headerSource:splunk.header.source, headerSourcetype:splunk.header.sourcetype, headerHost:splunk.header.host, enableCompression:false, lbPollInterval:120
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 1
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 2
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 3
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 4
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 5
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 6
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 7
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 8
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 9
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 10
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - attempting to resend batch 77d68191-13da-4eee-9e96-0078b2009cf3 with 0 events, this is attempt 1 out of -1 for this batch 
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 1
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - attempting to resend batch 7397c3d0-12f1-49b9-8d9a-aa07b3e2ad37 with 0 events, this is attempt 1 out of -1 for this batch 
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 2
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - attempting to resend batch 264b95f3-7956-43a9-bab2-46c9bd90081f with 0 events, this is attempt 1 out of -1 for this batch 
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 3
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - attempting to resend batch d44c5ec8-67ad-4c7f-8991-d62b7b1b4347 with 0 events, this is attempt 1 out of -1 for this batch 
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 4
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - attempting to resend batch 6c26df64-84b6-4dfb-852d-01c8d91c182e with 0 events, this is attempt 1 out of -1 for this batch 
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 5
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - attempting to resend batch b6738d2e-f15d-4aaa-94cf-977bdeeaf790 with 0 events, this is attempt 1 out of -1 for this batch 
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 6
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - attempting to resend batch 44fb3f34-7558-4560-a80d-28d54f251141 with 0 events, this is attempt 1 out of -1 for this batch 
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 7
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - attempting to resend batch 1f3dfe01-f7ec-4005-9009-120ae1770651 with 0 events, this is attempt 1 out of -1 for this batch 
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 8
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - attempting to resend batch 19058b27-aaf9-4262-8ea2-066465115e63 with 0 events, this is attempt 1 out of -1 for this batch 
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 9
[main] WARN com.splunk.kafka.connect.SplunkSinkTask - attempting to resend batch 93b0bdfb-c06f-49de-b0c8-2bf40d7e7513 with 0 events, this is attempt 1 out of -1 for this batch 
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - add 1 failed batches
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - total failed batches 10
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - handled 10 failed batches with 0 events
[main] INFO com.splunk.kafka.connect.SplunkSinkConnectorConfig - SplunkSinkConnectorConfig values: 
	splunk.flush.window = 30
	splunk.header.custom = 
	splunk.header.host = splunk.header.host
	splunk.header.index = splunk.header.index
	splunk.header.source = splunk.header.source
	splunk.header.sourcetype = splunk.header.sourcetype
	splunk.header.support = false
	splunk.hec.ack.enabled = true
	splunk.hec.ack.poll.interval = 1
	splunk.hec.ack.poll.threads = 1
	splunk.hec.backoff.threshhold.seconds = 60
	splunk.hec.enable.compression = false
	splunk.hec.event.timeout = 1
	splunk.hec.http.keepalive = true
	splunk.hec.json.event.enrichment = ni=hao,hello=world
	splunk.hec.json.event.formatted = false
	splunk.hec.lb.poll.interval = 120
	splunk.hec.max.batch.size = 100
	splunk.hec.max.http.connection.per.channel = 1
	splunk.hec.max.outstanding.events = 1000000
	splunk.hec.max.retries = -1
	splunk.hec.raw = false
	splunk.hec.raw.line.breaker = 
	splunk.hec.socket.timeout = 1
	splunk.hec.ssl.trust.store.password = [hidden]
	splunk.hec.ssl.trust.store.path = ./src/test/resources/keystoretest.jks
	splunk.hec.ssl.validate.certs = true
	splunk.hec.threads = 1
	splunk.hec.token = [hidden]
	splunk.hec.total.channels = 1
	splunk.hec.track.data = true
	splunk.hec.uri = https://dummy:8088
	splunk.hec.use.record.timestamp = true
	splunk.indexes = 
	splunk.sources = 
	splunk.sourcetypes = 

[main] INFO com.splunk.kafka.connect.SplunkSinkTask - kafka-connect-splunk task starts with config=splunkURI:https://dummy:8088, raw:false, ack:true, indexes:, sourcetypes:, sources:, headerSupport:false, headerCustom:, httpKeepAlive:true, validateCertificates:true, trustStorePath:./src/test/resources/keystoretest.jks, socketTimeout:1, eventBatchTimeout:1, ackPollInterval:1, ackPollThreads:1, maxHttpConnectionPerChannel:1, flushWindow:30, totalHecChannels:1, enrichment:ni=hao,hello=world, maxBatchSize:100, numberOfThreads:1, lineBreaker:, maxOutstandingEvents:1000000, maxRetries:-1, useRecordTimestamp:true, hecEventFormatted:false, trackData:true, headerSupport:false, headerCustom:, headerIndex:splunk.header.index, headerSource:splunk.header.source, headerSourcetype:splunk.header.sourcetype, headerHost:splunk.header.host, enableCompression:false, lbPollInterval:120
[main] INFO com.splunk.kafka.connect.SplunkSinkTask - kafka-connect-splunk task ends with config=splunkURI:https://dummy:8088, raw:false, ack:true, indexes:, sourcetypes:, sources:, headerSupport:false, headerCustom:, httpKeepAlive:true, validateCertificates:true, trustStorePath:./src/test/resources/keystoretest.jks, socketTimeout:1, eventBatchTimeout:1, ackPollInterval:1, ackPollThreads:1, maxHttpConnectionPerChannel:1, flushWindow:30, totalHecChannels:1, enrichment:ni=hao,hello=world, maxBatchSize:100, numberOfThreads:1, lineBreaker:, maxOutstandingEvents:1000000, maxRetries:-1, useRecordTimestamp:true, hecEventFormatted:false, trackData:true, headerSupport:false, headerCustom:, headerIndex:splunk.header.index, headerSource:splunk.header.source, headerSourcetype:splunk.header.sourcetype, headerHost:splunk.header.host, enableCompression:false, lbPollInterval:120
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.317 s - in SplunkSinkTaskTest
[INFO] Running VersionUtilsTest
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 s - in VersionUtilsTest
[INFO] Running DoubleSerializerTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 s - in DoubleSerializerTest
[INFO] Running HecChannelTest
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 s - in HecChannelTest
[INFO] Running HecAckPollerTest
[main] INFO com.splunk.hecclient.HecAckPoller - HecAckPoller stopped with 0 outstanding un-ACKed events
[Concurrent-HEC-worker] INFO com.splunk.hecclient.HecAckPoller - HecAckPoller stopped with 0 outstanding un-ACKed events
[Concurrent-HEC-worker] INFO com.splunk.hecclient.HecAckPoller - HecAckPoller stopped with 0 outstanding un-ACKed events
[Concurrent-HEC-worker] INFO com.splunk.hecclient.LoadBalancer - LoadBalancer stopped
[HEC-ACK-poller-scheduler] INFO com.splunk.hecclient.HecAckPoller - start polling 1 outstanding acks for 1 channels
[HEC-ACK-poller-scheduler] INFO com.splunk.hecclient.HecAckPoller - polling 1 acks for channel=010a102c-7636-4b77-b086-00bb057d33e8 on indexer=com.splunk.hecclient.IndexerMock@1f1ca7b9
[HEC-ACK-poller] INFO com.splunk.hecclient.HecAckPoller - no ackIds are ready for channel=010a102c-7636-4b77-b086-00bb057d33e8 on indexer=com.splunk.hecclient.IndexerMock@1f1ca7b9
[main] INFO com.splunk.hecclient.HecAckPoller - HecAckPoller stopped with 1 outstanding un-ACKed events
[main] INFO com.splunk.hecclient.HecAckPoller - HecAckPoller stopped with 0 outstanding un-ACKed events
[main] INFO com.splunk.hecclient.HecAckPoller - HecAckPoller stopped with 6 outstanding un-ACKed events
[HEC-ACK-poller-scheduler] INFO com.splunk.hecclient.HecAckPoller - start polling 1 outstanding acks for 1 channels
[HEC-ACK-poller-scheduler] INFO com.splunk.hecclient.HecAckPoller - polling 1 acks for channel=ab80c81a-4ec2-472e-9cb4-91c1a543e8ae on indexer=com.splunk.hecclient.IndexerMock@71f82821
[HEC-ACK-poller] INFO com.splunk.hecclient.HecAckPoller - polled 1 acks for channel=ab80c81a-4ec2-472e-9cb4-91c1a543e8ae on indexer=com.splunk.hecclient.IndexerMock@71f82821
[main] INFO com.splunk.hecclient.HecAckPoller - HecAckPoller stopped with 0 outstanding un-ACKed events
[HEC-ACK-poller-scheduler] INFO com.splunk.hecclient.HecAckPoller - start polling 1 outstanding acks for 1 channels
[HEC-ACK-poller-scheduler] INFO com.splunk.hecclient.HecAckPoller - polling 1 acks for channel=719bdb65-0d9c-44e2-84af-abf56088ae08 on indexer=com.splunk.hecclient.IndexerMock@6bd48e0b
[HEC-ACK-poller] INFO com.splunk.hecclient.HecAckPoller - polled 1 acks for channel=719bdb65-0d9c-44e2-84af-abf56088ae08 on indexer=com.splunk.hecclient.IndexerMock@6bd48e0b
[HEC-ACK-poller] WARN com.splunk.hecclient.HecAckPoller - event batch id=2 for channel=719bdb65-0d9c-44e2-84af-abf56088ae08 on host=com.splunk.hecclient.IndexerMock@6bd48e0b is not in map anymore
[main] INFO com.splunk.hecclient.HecAckPoller - HecAckPoller stopped with 1 outstanding un-ACKed events
[HEC-ACK-poller-scheduler] INFO com.splunk.hecclient.HecAckPoller - start polling 1 outstanding acks for 1 channels
[HEC-ACK-poller-scheduler] INFO com.splunk.hecclient.HecAckPoller - polling 1 acks for channel=3cf8830f-15ea-40bb-82e1-b0d728a02968 on indexer=com.splunk.hecclient.IndexerMock@5ffa67b9
[HEC-ACK-poller] INFO com.splunk.hecclient.HecAckPoller - polled 1 acks for channel=3cf8830f-15ea-40bb-82e1-b0d728a02968 on indexer=com.splunk.hecclient.IndexerMock@5ffa67b9
[main] INFO com.splunk.hecclient.HecAckPoller - HecAckPoller stopped with 0 outstanding un-ACKed events
[HEC-ACK-poller-scheduler] INFO com.splunk.hecclient.HecAckPoller - start polling 1 outstanding acks for 1 channels
[HEC-ACK-poller-scheduler] INFO com.splunk.hecclient.HecAckPoller - polling 1 acks for channel=a8f19679-ab6d-43bf-9062-751caa650ee0 on indexer=com.splunk.hecclient.IndexerMock@8885011
[HEC-ACK-poller] INFO com.splunk.hecclient.HecAckPoller - no ackIds are ready for channel=a8f19679-ab6d-43bf-9062-751caa650ee0 on indexer=com.splunk.hecclient.IndexerMock@8885011
[HEC-ACK-poller-scheduler] INFO com.splunk.hecclient.HecAckPoller - start polling 1 outstanding acks for 1 channels
[HEC-ACK-poller-scheduler] WARN com.splunk.hecclient.EventBatch - timed out event batch after 3 seconds not acked
[HEC-ACK-poller-scheduler] WARN com.splunk.hecclient.HecAckPoller - detected 1 event batches timedout
[main] INFO com.splunk.hecclient.HecAckPoller - HecAckPoller stopped with 0 outstanding un-ACKed events
[HEC-ACK-poller-scheduler] INFO com.splunk.hecclient.HecAckPoller - start polling 1 outstanding acks for 1 channels
[HEC-ACK-poller-scheduler] INFO com.splunk.hecclient.HecAckPoller - polling 1 acks for channel=10e0cde4-ae79-410d-9dbf-06ee2264c617 on indexer=com.splunk.hecclient.IndexerMock@5541d254
[HEC-ACK-poller] INFO com.splunk.hecclient.HecAckPoller - polled 1 acks for channel=10e0cde4-ae79-410d-9dbf-06ee2264c617 on indexer=com.splunk.hecclient.IndexerMock@5541d254
[main] INFO com.splunk.hecclient.HecAckPoller - Channel 10e0cde4-ae79-410d-9dbf-06ee2264c617 set to be not available
[main] INFO com.splunk.hecclient.HecAckPoller - Changed channel id from 10e0cde4-ae79-410d-9dbf-06ee2264c617 to 39003fb8-9c85-4b17-8e7d-8cde8a5e1230
[main] INFO com.splunk.hecclient.HecAckPoller - Channel 39003fb8-9c85-4b17-8e7d-8cde8a5e1230 is available
[main] INFO com.splunk.hecclient.HecAckPoller - HecAckPoller stopped with 0 outstanding un-ACKed events
[main] WARN com.splunk.hecclient.HecAckPoller - ackId=1 already exists for channel=930839fa-2716-4b2b-983d-b966c9feb44b index=com.splunk.hecclient.IndexerMock@47bcd95a data may be duplicated in Splunk
[main] INFO com.splunk.hecclient.HecAckPoller - HecAckPoller stopped with 1 outstanding un-ACKed events
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.569 s - in HecAckPollerTest
[INFO] Running ConcurrentHecTest
[Concurrent-HEC-worker] INFO com.splunk.hecclient.HecAckPoller - HecAckPoller stopped with 0 outstanding un-ACKed events
[Concurrent-HEC-worker] INFO com.splunk.hecclient.LoadBalancer - LoadBalancer stopped
[Concurrent-HEC-worker] ERROR com.splunk.hecclient.ConcurrentHec - sending batch to splunk encountered error
com.splunk.hecclient.HecException: mocked up
	at com.splunk.hecclient.LoadBalancerMock.send(LoadBalancerMock.java:36)
	at com.splunk.hecclient.Hec.send(Hec.java:234)
	at com.splunk.hecclient.ConcurrentHec.send(ConcurrentHec.java:97)
	at com.splunk.hecclient.ConcurrentHec.run(ConcurrentHec.java:89)
	at com.splunk.hecclient.ConcurrentHec.lambda$new$1(ConcurrentHec.java:51)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.098 s - in ConcurrentHecTest
[INFO] Running ResponsePollerTest
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.006 s - in ResponsePollerTest
[INFO] Running LoadBalancerTest
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.006 s - in LoadBalancerTest
[INFO] Running RawEventBatchTest
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.011 s - in RawEventBatchTest
[INFO] Running JsonEventTest
[INFO] Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.015 s - in JsonEventTest
[INFO] Running PostResponseTest
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 s - in PostResponseTest
[INFO] Running JsonEvenBatchTest
[Concurrent-HEC-worker] INFO com.splunk.hecclient.HecAckPoller - HecAckPoller stopped with 0 outstanding un-ACKed events
[Concurrent-HEC-worker] INFO com.splunk.hecclient.HecAckPoller - HecAckPoller stopped with 0 outstanding un-ACKed events
[main] WARN com.splunk.hecclient.EventBatch - timed out event batch after 1 seconds not acked
[INFO] Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.003 s - in JsonEvenBatchTest
[INFO] Running HecTest
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.018 s - in HecTest
[INFO] Running HecConfigTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 s - in HecConfigTest
[INFO] Running HttpClientBuilderTest
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.004 s - in HttpClientBuilderTest
[INFO] Running HecAckPollResponseTest
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 s - in HecAckPollResponseTest
[INFO] Running RawEventTest
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.003 s - in RawEventTest
[INFO] Running IndexerTest
[main] ERROR com.splunk.hecclient.Indexer - failed to post events resp={"text":"Server busy","code":1}, status=503
[main] WARN com.splunk.hecclient.Indexer - Still in Backpressure window 5:60000
[pool-13-thread-1] INFO com.splunk.hecclient.LoadBalancer - healthcheck failed for https://dummyhost:8088 indexer, removing this indexer and its channels from the loadbalancer
[pool-14-thread-1] INFO com.splunk.hecclient.LoadBalancer - healthcheck failed for https://dummyhost:8088 indexer, removing this indexer and its channels from the loadbalancer
[pool-16-thread-1] INFO com.splunk.hecclient.LoadBalancer - healthcheck failed for https://dummyhost:8088 indexer, removing this indexer and its channels from the loadbalancer
[pool-15-thread-1] INFO com.splunk.hecclient.LoadBalancer - healthcheck failed for https://dummyhost:8088 indexer, removing this indexer and its channels from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost: Temporary failure in name resolution, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[main] WARN com.splunk.hecclient.Indexer - Still in Backpressure window 5005:10000
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost: Temporary failure in name resolution, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[main] INFO com.splunk.hecclient.Indexer - Clearing Backpressure
[main] ERROR com.splunk.hecclient.Indexer - failed to post events resp={"text":"Server busy","code":1}, status=503
[main] WARN com.splunk.hecclient.Indexer - Still in Backpressure window 1:60000
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-16-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-14-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-13-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[pool-15-thread-1] ERROR com.splunk.hecclient.LoadBalancer - encountered exception when checking health of indexer dummyhost, this means indexer and its channels are removed from the loadbalancer
[main] INFO com.splunk.hecclient.Indexer - Clearing Backpressure
[main] ERROR com.splunk.hecclient.Indexer - encountered io exception
java.io.IOException: mocked up
	at com.splunk.hecclient.CloseableHttpClientMock.doExecute(CloseableHttpClientMock.java:43)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at com.splunk.hecclient.Indexer.executeHttpRequest(Indexer.java:151)
	at com.splunk.hecclient.Indexer.send(Indexer.java:131)
	at com.splunk.hecclient.IndexerTest.assertFailure(IndexerTest.java:189)
	at com.splunk.hecclient.IndexerTest.sendWithIOError(IndexerTest.java:165)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:39)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
	at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133)
	at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:79)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:70)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:220)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$6(DefaultLauncher.java:188)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:202)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:181)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:128)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:150)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
[main] ERROR com.splunk.hecclient.Indexer - failed to process http response
java.io.IOException: mocked up
	at com.splunk.hecclient.HttpEntityMock.getContent(HttpEntityMock.java:54)
	at org.apache.http.util.EntityUtils.toString(EntityUtils.java:201)
	at org.apache.http.util.EntityUtils.toString(EntityUtils.java:270)
	at org.apache.http.util.EntityUtils.toString(EntityUtils.java:290)
	at com.splunk.hecclient.Indexer.readAndCloseResponse(Indexer.java:165)
	at com.splunk.hecclient.Indexer.executeHttpRequest(Indexer.java:158)
	at com.splunk.hecclient.Indexer.send(Indexer.java:131)
	at com.splunk.hecclient.IndexerTest.assertFailure(IndexerTest.java:189)
	at com.splunk.hecclient.IndexerTest.sendWithReadError(IndexerTest.java:181)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:115)
	at org.junit.vintage.engine.execution.RunnerExecutor.execute(RunnerExecutor.java:39)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183)
	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195)
	at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133)
	at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484)
	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474)
	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)
	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)
	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497)
	at org.junit.vintage.engine.VintageTestEngine.executeAllChildren(VintageTestEngine.java:79)
	at org.junit.vintage.engine.VintageTestEngine.execute(VintageTestEngine.java:70)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:220)
	at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$6(DefaultLauncher.java:188)
	at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:202)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:181)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:128)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:150)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
[INFO] Tests run: 12, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 13.521 s - in IndexerTest
[INFO] 
[INFO] Results:
[INFO] 
[INFO] Tests run: 142, Failures: 0, Errors: 0, Skipped: 0
[INFO] 
[INFO] 
[INFO] --- jacoco-maven-plugin:0.8.6:report (post-unit-test) @ splunk-kafka-connect ---
[INFO] Loading execution data file /home/gabsko/breaking-updates/target/coverage-reports/jacoco-ut.exec
[INFO] Analyzed bundle 'splunk-kafka-connect' with 36 classes
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  43.447 s
[INFO] Finished at: 2023-02-07T14:27:15Z
[INFO] ------------------------------------------------------------------------
