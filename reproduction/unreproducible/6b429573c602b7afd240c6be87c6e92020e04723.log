[INFO] Scanning for projects...
[INFO] Inspecting build with total of 1 modules...
[INFO] Installing Nexus Staging features:
[INFO]   ... total of 1 executions of maven-deploy-plugin replaced with nexus-staging-maven-plugin
[INFO] 
[INFO] --------------< com.snowflake:snowflake-kafka-connector >---------------
[INFO] Building Snowflake Kafka Connector 1.6.1
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-surefire-plugin/2.22.0/maven-surefire-plugin-2.22.0.pom
[INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-surefire-plugin/2.22.0/maven-surefire-plugin-2.22.0.pom (5.0 kB at 28 kB/s)
[INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-surefire-plugin/2.22.0/maven-surefire-plugin-2.22.0.jar
[INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/plugins/maven-surefire-plugin/2.22.0/maven-surefire-plugin-2.22.0.jar (41 kB at 1.4 MB/s)
[INFO] Downloading from confluent: https://packages.confluent.io/maven/io/confluent/kafka-connect-avro-converter/5.5.1/kafka-connect-avro-converter-5.5.1.jar
[INFO] Downloading from confluent: https://packages.confluent.io/maven/io/confluent/common-utils/5.5.1/common-utils-5.5.1.jar
[INFO] Downloading from confluent: https://packages.confluent.io/maven/io/confluent/kafka-connect-avro-data/5.5.1/kafka-connect-avro-data-5.5.1.jar
[INFO] Downloading from confluent: https://packages.confluent.io/maven/org/mockito/mockito-core/2.20.1/mockito-core-2.20.1.jar
[INFO] Downloading from confluent: https://packages.confluent.io/maven/net/bytebuddy/byte-buddy/1.8.13/byte-buddy-1.8.13.jar
[INFO] Downloaded from confluent: https://packages.confluent.io/maven/io/confluent/common-utils/5.5.1/common-utils-5.5.1.jar (18 kB at 207 kB/s)
[INFO] Downloading from confluent: https://packages.confluent.io/maven/net/bytebuddy/byte-buddy-agent/1.8.13/byte-buddy-agent-1.8.13.jar
[INFO] Downloaded from confluent: https://packages.confluent.io/maven/io/confluent/kafka-connect-avro-converter/5.5.1/kafka-connect-avro-converter-5.5.1.jar (8.5 kB at 83 kB/s)
[INFO] Downloading from confluent: https://packages.confluent.io/maven/org/apache/kafka/connect-json/0.9.0.0/connect-json-0.9.0.0.jar
[INFO] Downloaded from confluent: https://packages.confluent.io/maven/io/confluent/kafka-connect-avro-data/5.5.1/kafka-connect-avro-data-5.5.1.jar (43 kB at 373 kB/s)
[INFO] Downloading from cloudera-repo: https://repository.cloudera.com/content/repositories/releases/org/mockito/mockito-core/2.20.1/mockito-core-2.20.1.jar
[INFO] Downloading from cloudera-repo: https://repository.cloudera.com/content/repositories/releases/net/bytebuddy/byte-buddy/1.8.13/byte-buddy-1.8.13.jar
[INFO] Downloading from cloudera-repo: https://repository.cloudera.com/content/repositories/releases/net/bytebuddy/byte-buddy-agent/1.8.13/byte-buddy-agent-1.8.13.jar
[INFO] Downloading from cloudera-repo: https://repository.cloudera.com/content/repositories/releases/org/apache/kafka/connect-json/0.9.0.0/connect-json-0.9.0.0.jar
[INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/mockito/mockito-core/2.20.1/mockito-core-2.20.1.jar
[INFO] Downloading from central: https://repo.maven.apache.org/maven2/net/bytebuddy/byte-buddy/1.8.13/byte-buddy-1.8.13.jar
[INFO] Downloading from central: https://repo.maven.apache.org/maven2/net/bytebuddy/byte-buddy-agent/1.8.13/byte-buddy-agent-1.8.13.jar
[INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/apache/kafka/connect-json/0.9.0.0/connect-json-0.9.0.0.jar
[INFO] Downloaded from central: https://repo.maven.apache.org/maven2/net/bytebuddy/byte-buddy-agent/1.8.13/byte-buddy-agent-1.8.13.jar (42 kB at 1.5 MB/s)
[INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/mockito/mockito-core/2.20.1/mockito-core-2.20.1.jar (561 kB at 11 MB/s)
[INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/kafka/connect-json/0.9.0.0/connect-json-0.9.0.0.jar (35 kB at 293 kB/s)
[INFO] Downloaded from central: https://repo.maven.apache.org/maven2/net/bytebuddy/byte-buddy/1.8.13/byte-buddy-1.8.13.jar (3.0 MB at 23 MB/s)
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ snowflake-kafka-connector ---
[INFO] Deleting /home/gabsko/breaking-updates/target
[INFO] 
[INFO] --- jacoco-maven-plugin:0.8.2:prepare-agent (pre-unit-test) @ snowflake-kafka-connector ---
[INFO] argLine set to -javaagent:/home/gabsko/.m2/repository/org/jacoco/org.jacoco.agent/0.8.2/org.jacoco.agent-0.8.2-runtime.jar=destfile=/home/gabsko/breaking-updates/target/jacoco-ut.exec
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ snowflake-kafka-connector ---
[WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent!
[INFO] skip non existing resourceDirectory /home/gabsko/breaking-updates/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ snowflake-kafka-connector ---
[INFO] Changes detected - recompiling the module!
[WARNING] File encoding has not been set, using platform encoding UTF-8, i.e. build is platform dependent!
[INFO] Compiling 39 source files to /home/gabsko/breaking-updates/target/classes
[WARNING] /home/gabsko/breaking-updates/src/main/java/com/snowflake/kafka/connector/records/AvroConverterConfig.java: Some input files use or override a deprecated API.
[WARNING] /home/gabsko/breaking-updates/src/main/java/com/snowflake/kafka/connector/records/AvroConverterConfig.java: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ snowflake-kafka-connector ---
[WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent!
[INFO] Copying 4 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ snowflake-kafka-connector ---
[INFO] Changes detected - recompiling the module!
[WARNING] File encoding has not been set, using platform encoding UTF-8, i.e. build is platform dependent!
[INFO] Compiling 28 source files to /home/gabsko/breaking-updates/target/test-classes
[WARNING] /home/gabsko/breaking-updates/src/test/java/com/snowflake/kafka/connector/internal/InternalStageIT.java: Some input files use or override a deprecated API.
[WARNING] /home/gabsko/breaking-updates/src/test/java/com/snowflake/kafka/connector/internal/InternalStageIT.java: Recompile with -Xlint:deprecation for details.
[WARNING] /home/gabsko/breaking-updates/src/test/java/com/snowflake/kafka/connector/internal/ConnectionServiceIT.java: Some input files use unchecked or unsafe operations.
[WARNING] /home/gabsko/breaking-updates/src/test/java/com/snowflake/kafka/connector/internal/ConnectionServiceIT.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.22.0:test (default-test) @ snowflake-kafka-connector ---
[INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.22.0/surefire-junit4-2.22.0.pom
[INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.22.0/surefire-junit4-2.22.0.pom (3.1 kB at 237 kB/s)
[INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-providers/2.22.0/surefire-providers-2.22.0.pom
[INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-providers/2.22.0/surefire-providers-2.22.0.pom (2.5 kB at 249 kB/s)
[INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.22.0/surefire-junit4-2.22.0.jar
[INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/maven/surefire/surefire-junit4/2.22.0/surefire-junit4-2.22.0.jar (85 kB at 4.4 MB/s)
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running com.snowflake.kafka.connector.ConnectorConfigTest
07-02-2023 14:13:27 main ERROR Utils:598 - 
[SF_KAFKA_CONNECTOR] Invalid snowflake.topic2table.map config format: $@#$#@%^$12312
07-02-2023 14:13:27 main ERROR Utils:454 - 
[SF_KAFKA_CONNECTOR] snowflake.url.name cannot be empty.
07-02-2023 14:13:27 main ERROR Utils:371 - 
[SF_KAFKA_CONNECTOR] buffer.count.records is empty
07-02-2023 14:13:27 main ERROR Utils:414 - 
[SF_KAFKA_CONNECTOR] buffer.size.bytes is empty
07-02-2023 14:13:27 main ERROR Utils:475 - 
[SF_KAFKA_CONNECTOR] Kafka provider config error:Unsupported provider name: Something_which_is_not_supported. Supported are: unknown,self_hosted,confluent
07-02-2023 14:13:27 main ERROR Utils:386 - 
[SF_KAFKA_CONNECTOR] buffer.count.records should be an integer
07-02-2023 14:13:27 main ERROR Utils:399 - 
[SF_KAFKA_CONNECTOR] buffer.size.bytes is too low at 0. It must be 1 or greater.
07-02-2023 14:13:27 main ERROR Utils:408 - 
[SF_KAFKA_CONNECTOR] buffer.size.bytes should be an integer
07-02-2023 14:13:27 main ERROR Utils:441 - 
[SF_KAFKA_CONNECTOR] snowflake.private.key cannot be empty.
07-02-2023 14:13:27 main ERROR Utils:462 - 
[SF_KAFKA_CONNECTOR] Proxy settings error: 
07-02-2023 14:13:27 main ERROR Utils:335 - 
[SF_KAFKA_CONNECTOR] name is empty or invalid. It should match Snowflake object identifier syntax. Please see the documentation.
07-02-2023 14:13:27 main ERROR Utils:462 - 
[SF_KAFKA_CONNECTOR] Proxy settings error: 
07-02-2023 14:13:27 main ERROR Utils:448 - 
[SF_KAFKA_CONNECTOR] snowflake.user.name cannot be empty.
07-02-2023 14:13:27 main ERROR Utils:346 - 
[SF_KAFKA_CONNECTOR] buffer.flush.time is empty
07-02-2023 14:13:27 main ERROR Utils:362 - 
[SF_KAFKA_CONNECTOR] buffer.flush.time should be an integer
07-02-2023 14:13:27 main ERROR Utils:509 - 
[SF_KAFKA_CONNECTOR] Delivery Guarantee config:delivery.guarantee error:Unsupported Delivery Guarantee Type: INVALID. Supported are: at_least_once,exactly_once
07-02-2023 14:13:27 main ERROR Utils:486 - 
[SF_KAFKA_CONNECTOR] Kafka config:behavior.on.null.values error:Invalid value invalid for configuration behavior.on.null.values: String must be one of: default, ignore
07-02-2023 14:13:27 main ERROR Utils:378 - 
[SF_KAFKA_CONNECTOR] buffer.count.records is -1, it should not be negative
07-02-2023 14:13:27 main ERROR Utils:435 - 
[SF_KAFKA_CONNECTOR] snowflake.schema.name cannot be empty.
07-02-2023 14:13:27 main ERROR Utils:610 - 
[SF_KAFKA_CONNECTOR] table name !@#@!#!@ should have at least 2 characters, start with _a-zA-Z, and only contains _$a-zA-z0-9
07-02-2023 14:13:27 main ERROR Utils:427 - 
[SF_KAFKA_CONNECTOR] snowflake.database.name cannot be empty.
07-02-2023 14:13:27 main ERROR Utils:620 - 
[SF_KAFKA_CONNECTOR] topic name topic1 is duplicated
07-02-2023 14:13:27 main ERROR Utils:498 - 
[SF_KAFKA_CONNECTOR] Kafka config:jmx should either be true or false
07-02-2023 14:13:27 main ERROR Utils:353 - 
[SF_KAFKA_CONNECTOR] buffer.flush.time is 9, it should be greater than 10
07-02-2023 14:13:27 main ERROR Utils:626 - 
[SF_KAFKA_CONNECTOR] table name table1 is duplicated
[INFO] Tests run: 34, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.198 s - in com.snowflake.kafka.connector.ConnectorConfigTest
[INFO] Running com.snowflake.kafka.connector.UtilsTest
07-02-2023 14:13:27 main INFO  Utils:199 - 
[SF_KAFKA_CONNECTOR] invalid JDBC_LOG_DIR /dummy_dir_not_exist defaulting to /tmp
07-02-2023 14:13:27 main INFO  Utils:196 - 
[SF_KAFKA_CONNECTOR] jdbc tracing directory = /usr
07-02-2023 14:13:27 main INFO  Utils:196 - 
[SF_KAFKA_CONNECTOR] jdbc tracing directory = /tmp
07-02-2023 14:13:27 main ERROR Utils:598 - 
[SF_KAFKA_CONNECTOR] Invalid snowflake.topic2table.map config format: adsadas
07-02-2023 14:13:27 main ERROR Utils:610 - 
[SF_KAFKA_CONNECTOR] table name @123 should have at least 2 characters, start with _a-zA-Z, and only contains _$a-zA-z0-9
07-02-2023 14:13:27 main INFO  Utils:101 - 
[SF_KAFKA_CONNECTOR] Current Snowflake Kafka Connector Version: 1.6.1
07-02-2023 14:13:27 main WARN  Utils:131 - 
[SF_KAFKA_CONNECTOR] Connector update is available, please upgrade Snowflake Kafka Connector (1.6.1 -> 1.8.2) 
07-02-2023 14:13:27 main ERROR Utils:598 - 
[SF_KAFKA_CONNECTOR] Invalid snowflake.topic2table.map config format: 12321
07-02-2023 14:13:27 main ERROR SnowflakeSinkTask:346 - 
[SF_KAFKA_CONNECTOR] Invalid Input, Topic2Table Map disabled
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.512 s - in com.snowflake.kafka.connector.UtilsTest
[INFO] Running com.snowflake.kafka.connector.records.RecordContentTest
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.083 s - in com.snowflake.kafka.connector.records.RecordContentTest
[INFO] Running com.snowflake.kafka.connector.records.MetaColumnTest
{"content":{"name":"test"},"meta":{"topic":"test","offset":0,"partition":0,"key":"test"}}
07-02-2023 14:13:27 main ERROR SnowflakeConverter:42 - 
[SF_KAFKA_CONNECTOR] Failed to parse JSON record
[SF_KAFKA_CONNECTOR] net.snowflake.client.jdbc.internal.fasterxml.jackson.core.JsonParseException: Unexpected character ('a' (code 97)): Expected space separating root-level values
[SF_KAFKA_CONNECTOR]  at [Source: (byte[])"123adsada"; line: 1, column: 5]
Config test success
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.368 s - in com.snowflake.kafka.connector.records.MetaColumnTest
[INFO] Running com.snowflake.kafka.connector.records.ValueSchemaTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 s - in com.snowflake.kafka.connector.records.ValueSchemaTest
[INFO] Running com.snowflake.kafka.connector.records.HeaderTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 s - in com.snowflake.kafka.connector.records.HeaderTest
[INFO] Running com.snowflake.kafka.connector.records.ConverterTest
{
  "type" : "record",
  "name" : "MyRecord",
  "fields" : [ {
    "name" : "bytesDecimal",
    "type" : {
      "type" : "bytes",
      "logicalType" : "decimal",
      "precision" : 20,
      "scale" : 4
    }
  } ]
}
07-02-2023 14:13:28 main INFO  AvroDataConfig:372 - AvroDataConfig values: 
	connect.meta.data = true
	enhanced.avro.schema.support = false
	schemas.cache.config = 100

07-02-2023 14:13:28 main INFO  AvroConverterConfig:179 - AvroConverterConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

07-02-2023 14:13:28 main INFO  KafkaAvroSerializerConfig:179 - KafkaAvroSerializerConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

07-02-2023 14:13:28 main INFO  KafkaAvroDeserializerConfig:179 - KafkaAvroDeserializerConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	specific.avro.reader = false
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

07-02-2023 14:13:28 main INFO  AvroDataConfig:372 - AvroDataConfig values: 
	connect.meta.data = true
	enhanced.avro.schema.support = false
	schemas.cache.config = 1000

0000000001060dbba0
07-02-2023 14:13:28 main ERROR SnowflakeConverter:42 - 
[SF_KAFKA_CONNECTOR] Failed to parse JSON record
[SF_KAFKA_CONNECTOR] net.snowflake.client.jdbc.internal.fasterxml.jackson.core.JsonParseException: Unrecognized token 'fasfas': was expecting (JSON String, Number, Array, Object or token 'null', 'true' or 'false')
[SF_KAFKA_CONNECTOR]  at [Source: (byte[])"fasfas"; line: 1, column: 7]
07-02-2023 14:13:28 main ERROR SnowflakeConverter:176 - 
[SF_KAFKA_CONNECTOR] failed to parse AVRO record
[SF_KAFKA_CONNECTOR] 
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Exception: Invalid input record
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Error Code: 0010
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Detail: Input record value can't be parsed
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Message: unknown bytes
07-02-2023 14:13:28 main ERROR SnowflakeConverter:176 - 
[SF_KAFKA_CONNECTOR] failed to parse AVRO record
[SF_KAFKA_CONNECTOR] null
07-02-2023 14:13:28 main ERROR SnowflakeConverter:176 - 
[SF_KAFKA_CONNECTOR] failed to parse AVRO record
[SF_KAFKA_CONNECTOR] 
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Exception: Invalid input record
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Error Code: 0010
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Detail: Input record value can't be parsed
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Message: Failed to parse AVRO record
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] java.io.EOFException
07-02-2023 14:13:28 main ERROR SnowflakeConverter:86 - 
[SF_KAFKA_CONNECTOR] Failed to parse AVRO record
[SF_KAFKA_CONNECTOR] 
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Exception: Invalid input record
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Error Code: 0010
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Detail: Input record value can't be parsed
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Message: Failed to parse AVRO record
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Not an Avro data file.
07-02-2023 14:13:28 main INFO  AvroConverterConfig:179 - AvroConverterConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

07-02-2023 14:13:28 main INFO  AvroConverterConfig:179 - AvroConverterConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

07-02-2023 14:13:28 main INFO  AvroConverterConfig:179 - AvroConverterConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

07-02-2023 14:13:28 main INFO  KafkaAvroSerializerConfig:179 - KafkaAvroSerializerConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

07-02-2023 14:13:28 main INFO  KafkaAvroDeserializerConfig:179 - KafkaAvroDeserializerConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	specific.avro.reader = false
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

07-02-2023 14:13:28 main INFO  AvroDataConfig:372 - AvroDataConfig values: 
	connect.meta.data = true
	enhanced.avro.schema.support = false
	schemas.cache.config = 1000

Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-3,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-1,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-4,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-3,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-1,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-4,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-3,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-4,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-1,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-3,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-4,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-1,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-3,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-4,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-1,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-3,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-4,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-1,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-3,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-4,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-3,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-1,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-4,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-3,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-4,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-1,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-3,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
07-02-2023 14:13:28 main INFO  AvroConverterConfig:179 - AvroConverterConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

07-02-2023 14:13:28 main INFO  KafkaAvroSerializerConfig:179 - KafkaAvroSerializerConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

07-02-2023 14:13:28 main INFO  KafkaAvroDeserializerConfig:179 - KafkaAvroDeserializerConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	specific.avro.reader = false
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

07-02-2023 14:13:28 main INFO  AvroDataConfig:372 - AvroDataConfig values: 
	connect.meta.data = true
	enhanced.avro.schema.support = false
	schemas.cache.config = 1000

07-02-2023 14:13:28 main ERROR SnowflakeConverter:176 - 
[SF_KAFKA_CONNECTOR] failed to parse AVRO record
[SF_KAFKA_CONNECTOR] null
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.163 s - in com.snowflake.kafka.connector.records.ConverterTest
[INFO] Running com.snowflake.kafka.connector.records.ProcessRecordTest
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.025 s - in com.snowflake.kafka.connector.records.ProcessRecordTest
[INFO] Running com.snowflake.kafka.connector.SecurityTest
[ERROR] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.002 s <<< FAILURE! - in com.snowflake.kafka.connector.SecurityTest
[ERROR] testRSAPasswordOutput(com.snowflake.kafka.connector.SecurityTest)  Time elapsed: 0.002 s  <<< ERROR!
java.lang.RuntimeException: java.io.FileNotFoundException: profile.json (No such file or directory)
	at com.snowflake.kafka.connector.SecurityTest.testRSAPasswordOutput(SecurityTest.java:19)
Caused by: java.io.FileNotFoundException: profile.json (No such file or directory)
	at com.snowflake.kafka.connector.SecurityTest.testRSAPasswordOutput(SecurityTest.java:19)

[INFO] Running com.snowflake.kafka.connector.internal.FIPSTest
[ERROR] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0 s <<< FAILURE! - in com.snowflake.kafka.connector.internal.FIPSTest
[ERROR] testFips(com.snowflake.kafka.connector.internal.FIPSTest)  Time elapsed: 0 s  <<< ERROR!
java.lang.NullPointerException
	at com.snowflake.kafka.connector.internal.FIPSTest.testFips(FIPSTest.java:20)

[INFO] Running com.snowflake.kafka.connector.internal.InternalUtilsTest
07-02-2023 14:13:28 main DEBUG InternalUtils:104 - 
[SF_KAFKA_CONNECTOR] converted date: 2019-07-18T23:32:38Z
[ERROR] Tests run: 6, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 0.121 s <<< FAILURE! - in com.snowflake.kafka.connector.internal.InternalUtilsTest
[ERROR] testCreateProperties(com.snowflake.kafka.connector.internal.InternalUtilsTest)  Time elapsed: 0 s  <<< ERROR!
java.lang.NullPointerException
	at com.snowflake.kafka.connector.internal.InternalUtilsTest.testCreateProperties(InternalUtilsTest.java:80)

[ERROR] testPrivateKey(com.snowflake.kafka.connector.internal.InternalUtilsTest)  Time elapsed: 0.12 s  <<< ERROR!
java.lang.NullPointerException
	at com.snowflake.kafka.connector.internal.InternalUtilsTest.testPrivateKey(InternalUtilsTest.java:21)

[INFO] Running com.snowflake.kafka.connector.internal.FileNameUtilsTest
07-02-2023 14:13:28 main DEBUG FileNameUtils:43 - 
[SF_KAFKA_CONNECTOR] generated file name: TEST_CONNECTOR/test_topic/123/456_789_1675779208676.json.gz
07-02-2023 14:13:28 main DEBUG FileNameUtils:74 - 
[SF_KAFKA_CONNECTOR] generated broken data file name: TEST_CONNECTOR/test_topic/123/456_key_1675779208682.gz
07-02-2023 14:13:28 main DEBUG FileNameUtils:74 - 
[SF_KAFKA_CONNECTOR] generated broken data file name: TEST_CONNECTOR/test_topic/123/456_value_1675779208682.gz
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.012 s - in com.snowflake.kafka.connector.internal.FileNameUtilsTest
[INFO] Running com.snowflake.kafka.connector.internal.TelemetryUnitTest
07-02-2023 14:13:28 main DEBUG SnowflakeTelemetryBasicInfo:274 - 
[SF_KAFKA_CONNECTOR] Registering metrics for pipe:pipe, existing:[]
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.085 s - in com.snowflake.kafka.connector.internal.TelemetryUnitTest
[INFO] Running com.snowflake.kafka.connector.internal.LoggingTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 s - in com.snowflake.kafka.connector.internal.LoggingTest
[INFO] Running com.snowflake.kafka.connector.internal.SnowflakeURLTest
07-02-2023 14:13:28 main DEBUG SnowflakeURL:75 - 
[SF_KAFKA_CONNECTOR] parsed Snowflake URL: http://account.snowflake.com:80
07-02-2023 14:13:28 main DEBUG SnowflakeURL:75 - 
[SF_KAFKA_CONNECTOR] parsed Snowflake URL: https://account.snowflake.com:443
07-02-2023 14:13:28 main DEBUG SnowflakeURL:75 - 
[SF_KAFKA_CONNECTOR] parsed Snowflake URL:  account.snowflake.com:80
07-02-2023 14:13:28 main DEBUG SnowflakeURL:75 - 
[SF_KAFKA_CONNECTOR] parsed Snowflake URL: account.snowflake.com
07-02-2023 14:13:28 main DEBUG SnowflakeURL:75 - 
[SF_KAFKA_CONNECTOR] parsed Snowflake URL: http://account.snowflake.com 
07-02-2023 14:13:28 main DEBUG SnowflakeURL:75 - 
[SF_KAFKA_CONNECTOR] parsed Snowflake URL: https://account.snowflake.com
07-02-2023 14:13:28 main DEBUG SnowflakeURL:75 - 
[SF_KAFKA_CONNECTOR] parsed Snowflake URL: https://account.region.aws.privatelink.snowflake.com:443
07-02-2023 14:13:28 main DEBUG SnowflakeURL:75 - 
[SF_KAFKA_CONNECTOR] parsed Snowflake URL: http://org-account.snowflake.com:80
07-02-2023 14:13:28 main INFO  SnowflakeURL:32 - 
[SF_KAFKA_CONNECTOR] enabling JDBC tracing
07-02-2023 14:13:28 main DEBUG SnowflakeURL:75 - 
[SF_KAFKA_CONNECTOR] parsed Snowflake URL: https://account.region.aws.privatelink.snowflake.com:443
07-02-2023 14:13:28 main DEBUG SnowflakeURL:75 - 
[SF_KAFKA_CONNECTOR] parsed Snowflake URL: https://org-account.privatelink.snowflake.com:80
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.001 s - in com.snowflake.kafka.connector.internal.SnowflakeURLTest
[INFO] 
[INFO] Results:
[INFO] 
[ERROR] Errors: 
[ERROR]   SecurityTest.testRSAPasswordOutput:19 » Runtime java.io.FileNotFoundException:...
[ERROR]   FIPSTest.testFips:20 » NullPointer
[ERROR]   InternalUtilsTest.testCreateProperties:80 » NullPointer
[ERROR]   InternalUtilsTest.testPrivateKey:21 » NullPointer
[INFO] 
[ERROR] Tests run: 105, Failures: 0, Errors: 4, Skipped: 0
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  7.593 s
[INFO] Finished at: 2023-02-07T14:13:29Z
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.22.0:test (default-test) on project snowflake-kafka-connector: There are test failures.
[ERROR] 
[ERROR] Please refer to /home/gabsko/breaking-updates/target/surefire-reports for the individual test results.
[ERROR] Please refer to dump files (if any exist) [date]-jvmRun[N].dump, [date].dumpstream and [date]-jvmRun[N].dumpstream.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
