[INFO] Scanning for projects...
[INFO] Inspecting build with total of 1 modules...
[INFO] Installing Nexus Staging features:
[INFO]   ... total of 1 executions of maven-deploy-plugin replaced with nexus-staging-maven-plugin
[INFO] 
[INFO] --------------< com.snowflake:snowflake-kafka-connector >---------------
[INFO] Building Snowflake Kafka Connector 1.6.1
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] Downloading from confluent: https://packages.confluent.io/maven/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar
[INFO] Downloading from confluent: https://packages.confluent.io/maven/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar
[INFO] Downloading from cloudera-repo: https://repository.cloudera.com/content/repositories/releases/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar
[INFO] Downloading from cloudera-repo: https://repository.cloudera.com/content/repositories/releases/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar
[INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar
[INFO] Downloading from central: https://repo.maven.apache.org/maven2/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar
[INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/logging/log4j/log4j-api/2.13.2/log4j-api-2.13.2.jar (292 kB at 3.7 MB/s)
[INFO] Downloaded from central: https://repo.maven.apache.org/maven2/org/apache/logging/log4j/log4j-core/2.13.2/log4j-core-2.13.2.jar (1.7 MB at 13 MB/s)
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ snowflake-kafka-connector ---
[INFO] Deleting /home/gabsko/breaking-updates/target
[INFO] 
[INFO] --- jacoco-maven-plugin:0.8.2:prepare-agent (pre-unit-test) @ snowflake-kafka-connector ---
[INFO] argLine set to -javaagent:/home/gabsko/.m2/repository/org/jacoco/org.jacoco.agent/0.8.2/org.jacoco.agent-0.8.2-runtime.jar=destfile=/home/gabsko/breaking-updates/target/jacoco-ut.exec
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ snowflake-kafka-connector ---
[WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent!
[INFO] skip non existing resourceDirectory /home/gabsko/breaking-updates/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ snowflake-kafka-connector ---
[INFO] Changes detected - recompiling the module!
[WARNING] File encoding has not been set, using platform encoding UTF-8, i.e. build is platform dependent!
[INFO] Compiling 39 source files to /home/gabsko/breaking-updates/target/classes
[WARNING] /home/gabsko/breaking-updates/src/main/java/com/snowflake/kafka/connector/records/AvroConverterConfig.java: Some input files use or override a deprecated API.
[WARNING] /home/gabsko/breaking-updates/src/main/java/com/snowflake/kafka/connector/records/AvroConverterConfig.java: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ snowflake-kafka-connector ---
[WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent!
[INFO] Copying 4 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ snowflake-kafka-connector ---
[INFO] Changes detected - recompiling the module!
[WARNING] File encoding has not been set, using platform encoding UTF-8, i.e. build is platform dependent!
[INFO] Compiling 28 source files to /home/gabsko/breaking-updates/target/test-classes
[WARNING] /home/gabsko/breaking-updates/src/test/java/com/snowflake/kafka/connector/internal/InternalStageIT.java: Some input files use or override a deprecated API.
[WARNING] /home/gabsko/breaking-updates/src/test/java/com/snowflake/kafka/connector/internal/InternalStageIT.java: Recompile with -Xlint:deprecation for details.
[WARNING] /home/gabsko/breaking-updates/src/test/java/com/snowflake/kafka/connector/internal/ConnectionServiceIT.java: /home/gabsko/breaking-updates/src/test/java/com/snowflake/kafka/connector/internal/ConnectionServiceIT.java uses unchecked or unsafe operations.
[WARNING] /home/gabsko/breaking-updates/src/test/java/com/snowflake/kafka/connector/internal/ConnectionServiceIT.java: Recompile with -Xlint:unchecked for details.
[INFO] 
[INFO] --- maven-surefire-plugin:2.22.0:test (default-test) @ snowflake-kafka-connector ---
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running com.snowflake.kafka.connector.ConnectorConfigTest
09-02-2023 01:40:34 main ERROR Utils:598 - 
[SF_KAFKA_CONNECTOR] Invalid snowflake.topic2table.map config format: $@#$#@%^$12312
09-02-2023 01:40:34 main ERROR Utils:454 - 
[SF_KAFKA_CONNECTOR] snowflake.url.name cannot be empty.
09-02-2023 01:40:34 main ERROR Utils:371 - 
[SF_KAFKA_CONNECTOR] buffer.count.records is empty
09-02-2023 01:40:34 main ERROR Utils:414 - 
[SF_KAFKA_CONNECTOR] buffer.size.bytes is empty
09-02-2023 01:40:34 main ERROR Utils:475 - 
[SF_KAFKA_CONNECTOR] Kafka provider config error:Unsupported provider name: Something_which_is_not_supported. Supported are: unknown,self_hosted,confluent
09-02-2023 01:40:34 main ERROR Utils:386 - 
[SF_KAFKA_CONNECTOR] buffer.count.records should be an integer
09-02-2023 01:40:34 main ERROR Utils:399 - 
[SF_KAFKA_CONNECTOR] buffer.size.bytes is too low at 0. It must be 1 or greater.
09-02-2023 01:40:34 main ERROR Utils:408 - 
[SF_KAFKA_CONNECTOR] buffer.size.bytes should be an integer
09-02-2023 01:40:34 main ERROR Utils:441 - 
[SF_KAFKA_CONNECTOR] snowflake.private.key cannot be empty.
09-02-2023 01:40:34 main ERROR Utils:462 - 
[SF_KAFKA_CONNECTOR] Proxy settings error: 
09-02-2023 01:40:34 main ERROR Utils:335 - 
[SF_KAFKA_CONNECTOR] name is empty or invalid. It should match Snowflake object identifier syntax. Please see the documentation.
09-02-2023 01:40:34 main ERROR Utils:462 - 
[SF_KAFKA_CONNECTOR] Proxy settings error: 
09-02-2023 01:40:34 main ERROR Utils:448 - 
[SF_KAFKA_CONNECTOR] snowflake.user.name cannot be empty.
09-02-2023 01:40:34 main ERROR Utils:346 - 
[SF_KAFKA_CONNECTOR] buffer.flush.time is empty
09-02-2023 01:40:34 main ERROR Utils:362 - 
[SF_KAFKA_CONNECTOR] buffer.flush.time should be an integer
09-02-2023 01:40:34 main ERROR Utils:509 - 
[SF_KAFKA_CONNECTOR] Delivery Guarantee config:delivery.guarantee error:Unsupported Delivery Guarantee Type: INVALID. Supported are: at_least_once,exactly_once
09-02-2023 01:40:34 main ERROR Utils:486 - 
[SF_KAFKA_CONNECTOR] Kafka config:behavior.on.null.values error:Invalid value invalid for configuration behavior.on.null.values: String must be one of: default, ignore
09-02-2023 01:40:34 main ERROR Utils:378 - 
[SF_KAFKA_CONNECTOR] buffer.count.records is -1, it should not be negative
09-02-2023 01:40:34 main ERROR Utils:435 - 
[SF_KAFKA_CONNECTOR] snowflake.schema.name cannot be empty.
09-02-2023 01:40:34 main ERROR Utils:610 - 
[SF_KAFKA_CONNECTOR] table name !@#@!#!@ should have at least 2 characters, start with _a-zA-Z, and only contains _$a-zA-z0-9
09-02-2023 01:40:34 main ERROR Utils:427 - 
[SF_KAFKA_CONNECTOR] snowflake.database.name cannot be empty.
09-02-2023 01:40:34 main ERROR Utils:620 - 
[SF_KAFKA_CONNECTOR] topic name topic1 is duplicated
09-02-2023 01:40:34 main ERROR Utils:498 - 
[SF_KAFKA_CONNECTOR] Kafka config:jmx should either be true or false
09-02-2023 01:40:34 main ERROR Utils:353 - 
[SF_KAFKA_CONNECTOR] buffer.flush.time is 9, it should be greater than 10
09-02-2023 01:40:34 main ERROR Utils:626 - 
[SF_KAFKA_CONNECTOR] table name table1 is duplicated
[INFO] Tests run: 34, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.15 s - in com.snowflake.kafka.connector.ConnectorConfigTest
[INFO] Running com.snowflake.kafka.connector.UtilsTest
09-02-2023 01:40:34 main INFO  Utils:199 - 
[SF_KAFKA_CONNECTOR] invalid JDBC_LOG_DIR /dummy_dir_not_exist defaulting to /tmp
09-02-2023 01:40:34 main INFO  Utils:196 - 
[SF_KAFKA_CONNECTOR] jdbc tracing directory = /usr
09-02-2023 01:40:34 main INFO  Utils:196 - 
[SF_KAFKA_CONNECTOR] jdbc tracing directory = /tmp
09-02-2023 01:40:34 main ERROR Utils:598 - 
[SF_KAFKA_CONNECTOR] Invalid snowflake.topic2table.map config format: adsadas
09-02-2023 01:40:34 main ERROR Utils:610 - 
[SF_KAFKA_CONNECTOR] table name @123 should have at least 2 characters, start with _a-zA-Z, and only contains _$a-zA-z0-9
09-02-2023 01:40:34 main INFO  Utils:101 - 
[SF_KAFKA_CONNECTOR] Current Snowflake Kafka Connector Version: 1.6.1
09-02-2023 01:40:35 main WARN  Utils:131 - 
[SF_KAFKA_CONNECTOR] Connector update is available, please upgrade Snowflake Kafka Connector (1.6.1 -> 1.8.2) 
09-02-2023 01:40:35 main ERROR Utils:598 - 
[SF_KAFKA_CONNECTOR] Invalid snowflake.topic2table.map config format: 12321
09-02-2023 01:40:35 main ERROR SnowflakeSinkTask:327 - 
[SF_KAFKA_CONNECTOR] Invalid Input, Topic2Table Map disabled
[INFO] Tests run: 9, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.523 s - in com.snowflake.kafka.connector.UtilsTest
[INFO] Running com.snowflake.kafka.connector.records.RecordContentTest
[INFO] Tests run: 11, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.104 s - in com.snowflake.kafka.connector.records.RecordContentTest
[INFO] Running com.snowflake.kafka.connector.records.MetaColumnTest
{"content":{"name":"test"},"meta":{"topic":"test","offset":0,"partition":0,"key":"test"}}
09-02-2023 01:40:35 main ERROR SnowflakeConverter:42 - 
[SF_KAFKA_CONNECTOR] Failed to parse JSON record
[SF_KAFKA_CONNECTOR] net.snowflake.client.jdbc.internal.fasterxml.jackson.core.JsonParseException: Unexpected character ('a' (code 97)): Expected space separating root-level values
[SF_KAFKA_CONNECTOR]  at [Source: (byte[])"123adsada"; line: 1, column: 5]
Config test success
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.364 s - in com.snowflake.kafka.connector.records.MetaColumnTest
[INFO] Running com.snowflake.kafka.connector.records.ValueSchemaTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 s - in com.snowflake.kafka.connector.records.ValueSchemaTest
[INFO] Running com.snowflake.kafka.connector.records.HeaderTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.003 s - in com.snowflake.kafka.connector.records.HeaderTest
[INFO] Running com.snowflake.kafka.connector.records.ConverterTest
{
  "type" : "record",
  "name" : "MyRecord",
  "fields" : [ {
    "name" : "bytesDecimal",
    "type" : {
      "type" : "bytes",
      "logicalType" : "decimal",
      "precision" : 20,
      "scale" : 4
    }
  } ]
}
09-02-2023 01:40:35 main INFO  AvroDataConfig:372 - AvroDataConfig values: 
	connect.meta.data = true
	enhanced.avro.schema.support = false
	schemas.cache.config = 100

09-02-2023 01:40:35 main INFO  AvroConverterConfig:179 - AvroConverterConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

09-02-2023 01:40:35 main INFO  KafkaAvroSerializerConfig:179 - KafkaAvroSerializerConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

09-02-2023 01:40:35 main INFO  KafkaAvroDeserializerConfig:179 - KafkaAvroDeserializerConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	specific.avro.reader = false
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

09-02-2023 01:40:35 main INFO  AvroDataConfig:372 - AvroDataConfig values: 
	connect.meta.data = true
	enhanced.avro.schema.support = false
	schemas.cache.config = 1000

0000000001060dbba0
09-02-2023 01:40:35 main ERROR SnowflakeConverter:42 - 
[SF_KAFKA_CONNECTOR] Failed to parse JSON record
[SF_KAFKA_CONNECTOR] net.snowflake.client.jdbc.internal.fasterxml.jackson.core.JsonParseException: Unrecognized token 'fasfas': was expecting (JSON String, Number, Array, Object or token 'null', 'true' or 'false')
[SF_KAFKA_CONNECTOR]  at [Source: (byte[])"fasfas"; line: 1, column: 7]
09-02-2023 01:40:35 main ERROR SnowflakeConverter:176 - 
[SF_KAFKA_CONNECTOR] failed to parse AVRO record
[SF_KAFKA_CONNECTOR] 
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Exception: Invalid input record
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Error Code: 0010
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Detail: Input record value can't be parsed
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Message: unknown bytes
09-02-2023 01:40:35 main ERROR SnowflakeConverter:176 - 
[SF_KAFKA_CONNECTOR] failed to parse AVRO record
[SF_KAFKA_CONNECTOR] null
09-02-2023 01:40:35 main ERROR SnowflakeConverter:176 - 
[SF_KAFKA_CONNECTOR] failed to parse AVRO record
[SF_KAFKA_CONNECTOR] 
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Exception: Invalid input record
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Error Code: 0010
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Detail: Input record value can't be parsed
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Message: Failed to parse AVRO record
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] java.io.EOFException
09-02-2023 01:40:35 main ERROR SnowflakeConverter:86 - 
[SF_KAFKA_CONNECTOR] Failed to parse AVRO record
[SF_KAFKA_CONNECTOR] 
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Exception: Invalid input record
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Error Code: 0010
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Detail: Input record value can't be parsed
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Message: Failed to parse AVRO record
[SF_KAFKA_CONNECTOR] [SF_KAFKA_CONNECTOR] Not an Avro data file.
09-02-2023 01:40:35 main INFO  AvroConverterConfig:179 - AvroConverterConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

09-02-2023 01:40:35 main INFO  AvroConverterConfig:179 - AvroConverterConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

09-02-2023 01:40:35 main INFO  AvroConverterConfig:179 - AvroConverterConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

09-02-2023 01:40:35 main INFO  KafkaAvroSerializerConfig:179 - KafkaAvroSerializerConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

09-02-2023 01:40:35 main INFO  KafkaAvroDeserializerConfig:179 - KafkaAvroDeserializerConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	specific.avro.reader = false
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

09-02-2023 01:40:35 main INFO  AvroDataConfig:372 - AvroDataConfig values: 
	connect.meta.data = true
	enhanced.avro.schema.support = false
	schemas.cache.config = 1000

Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-3,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-1,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-4,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-3,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-4,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-1,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-3,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-4,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-4,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-3,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-3,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-4,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-1,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-3,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-4,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-3,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-1,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-4,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-3,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-4,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-1,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-3,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-4,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-4,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-3,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-1,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-4,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-3,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-4,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-3,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-4,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-1,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-5,5,main]
Record Service result:"1997-05-19T00:00:00.000Z" Thread :Thread[pool-1-thread-2,5,main]
09-02-2023 01:40:35 main INFO  AvroConverterConfig:179 - AvroConverterConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

09-02-2023 01:40:35 main INFO  KafkaAvroSerializerConfig:179 - KafkaAvroSerializerConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

09-02-2023 01:40:35 main INFO  KafkaAvroDeserializerConfig:179 - KafkaAvroDeserializerConfig values: 
	bearer.auth.token = [hidden]
	proxy.port = -1
	schema.reflection = false
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	specific.avro.reader = false
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	schema.registry.url = [http://fake-url]
	basic.auth.user.info = [hidden]
	proxy.host = 
	use.latest.version = false
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

09-02-2023 01:40:35 main INFO  AvroDataConfig:372 - AvroDataConfig values: 
	connect.meta.data = true
	enhanced.avro.schema.support = false
	schemas.cache.config = 1000

09-02-2023 01:40:35 main ERROR SnowflakeConverter:176 - 
[SF_KAFKA_CONNECTOR] failed to parse AVRO record
[SF_KAFKA_CONNECTOR] null
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.174 s - in com.snowflake.kafka.connector.records.ConverterTest
[INFO] Running com.snowflake.kafka.connector.records.ProcessRecordTest
[INFO] Tests run: 14, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.023 s - in com.snowflake.kafka.connector.records.ProcessRecordTest
[INFO] Running com.snowflake.kafka.connector.SecurityTest
[ERROR] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.001 s <<< FAILURE! - in com.snowflake.kafka.connector.SecurityTest
[ERROR] testRSAPasswordOutput(com.snowflake.kafka.connector.SecurityTest)  Time elapsed: 0.001 s  <<< ERROR!
java.lang.RuntimeException: java.io.FileNotFoundException: profile.json (No such file or directory)
	at com.snowflake.kafka.connector.SecurityTest.testRSAPasswordOutput(SecurityTest.java:19)
Caused by: java.io.FileNotFoundException: profile.json (No such file or directory)
	at com.snowflake.kafka.connector.SecurityTest.testRSAPasswordOutput(SecurityTest.java:19)

[INFO] Running com.snowflake.kafka.connector.internal.FIPSTest
[ERROR] Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0 s <<< FAILURE! - in com.snowflake.kafka.connector.internal.FIPSTest
[ERROR] testFips(com.snowflake.kafka.connector.internal.FIPSTest)  Time elapsed: 0 s  <<< ERROR!
java.lang.NullPointerException
	at com.snowflake.kafka.connector.internal.FIPSTest.testFips(FIPSTest.java:20)

[INFO] Running com.snowflake.kafka.connector.internal.InternalUtilsTest
09-02-2023 01:40:35 main DEBUG InternalUtils:104 - 
[SF_KAFKA_CONNECTOR] converted date: 2019-07-18T23:32:38Z
[ERROR] Tests run: 6, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 0.145 s <<< FAILURE! - in com.snowflake.kafka.connector.internal.InternalUtilsTest
[ERROR] testCreateProperties(com.snowflake.kafka.connector.internal.InternalUtilsTest)  Time elapsed: 0.002 s  <<< ERROR!
java.lang.NullPointerException
	at com.snowflake.kafka.connector.internal.InternalUtilsTest.testCreateProperties(InternalUtilsTest.java:80)

[ERROR] testPrivateKey(com.snowflake.kafka.connector.internal.InternalUtilsTest)  Time elapsed: 0.137 s  <<< ERROR!
java.lang.NullPointerException
	at com.snowflake.kafka.connector.internal.InternalUtilsTest.testPrivateKey(InternalUtilsTest.java:21)

[INFO] Running com.snowflake.kafka.connector.internal.FileNameUtilsTest
09-02-2023 01:40:35 main DEBUG FileNameUtils:43 - 
[SF_KAFKA_CONNECTOR] generated file name: TEST_CONNECTOR/test_topic/123/456_789_1675906835964.json.gz
09-02-2023 01:40:35 main DEBUG FileNameUtils:74 - 
[SF_KAFKA_CONNECTOR] generated broken data file name: TEST_CONNECTOR/test_topic/123/456_key_1675906835970.gz
09-02-2023 01:40:35 main DEBUG FileNameUtils:74 - 
[SF_KAFKA_CONNECTOR] generated broken data file name: TEST_CONNECTOR/test_topic/123/456_value_1675906835970.gz
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.009 s - in com.snowflake.kafka.connector.internal.FileNameUtilsTest
[INFO] Running com.snowflake.kafka.connector.internal.TelemetryUnitTest
09-02-2023 01:40:36 main DEBUG SnowflakeTelemetryBasicInfo:274 - 
[SF_KAFKA_CONNECTOR] Registering metrics for pipe:pipe, existing:[]
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.074 s - in com.snowflake.kafka.connector.internal.TelemetryUnitTest
[INFO] Running com.snowflake.kafka.connector.internal.LoggingTest
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0 s - in com.snowflake.kafka.connector.internal.LoggingTest
[INFO] Running com.snowflake.kafka.connector.internal.SnowflakeURLTest
09-02-2023 01:40:36 main DEBUG SnowflakeURL:75 - 
[SF_KAFKA_CONNECTOR] parsed Snowflake URL: http://account.snowflake.com:80
09-02-2023 01:40:36 main DEBUG SnowflakeURL:75 - 
[SF_KAFKA_CONNECTOR] parsed Snowflake URL: https://account.snowflake.com:443
09-02-2023 01:40:36 main DEBUG SnowflakeURL:75 - 
[SF_KAFKA_CONNECTOR] parsed Snowflake URL:  account.snowflake.com:80
09-02-2023 01:40:36 main DEBUG SnowflakeURL:75 - 
[SF_KAFKA_CONNECTOR] parsed Snowflake URL: account.snowflake.com
09-02-2023 01:40:36 main DEBUG SnowflakeURL:75 - 
[SF_KAFKA_CONNECTOR] parsed Snowflake URL: http://account.snowflake.com 
09-02-2023 01:40:36 main DEBUG SnowflakeURL:75 - 
[SF_KAFKA_CONNECTOR] parsed Snowflake URL: https://account.snowflake.com
09-02-2023 01:40:36 main DEBUG SnowflakeURL:75 - 
[SF_KAFKA_CONNECTOR] parsed Snowflake URL: https://account.region.aws.privatelink.snowflake.com:443
09-02-2023 01:40:36 main DEBUG SnowflakeURL:75 - 
[SF_KAFKA_CONNECTOR] parsed Snowflake URL: http://org-account.snowflake.com:80
09-02-2023 01:40:36 main INFO  SnowflakeURL:32 - 
[SF_KAFKA_CONNECTOR] enabling JDBC tracing
09-02-2023 01:40:36 main DEBUG SnowflakeURL:75 - 
[SF_KAFKA_CONNECTOR] parsed Snowflake URL: https://account.region.aws.privatelink.snowflake.com:443
09-02-2023 01:40:36 main DEBUG SnowflakeURL:75 - 
[SF_KAFKA_CONNECTOR] parsed Snowflake URL: https://org-account.privatelink.snowflake.com:80
[INFO] Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.002 s - in com.snowflake.kafka.connector.internal.SnowflakeURLTest
[INFO] 
[INFO] Results:
[INFO] 
[ERROR] Errors: 
[ERROR]   SecurityTest.testRSAPasswordOutput:19 » Runtime java.io.FileNotFoundException:...
[ERROR]   FIPSTest.testFips:20 » NullPointer
[ERROR]   InternalUtilsTest.testCreateProperties:80 » NullPointer
[ERROR]   InternalUtilsTest.testPrivateKey:21 » NullPointer
[INFO] 
[ERROR] Tests run: 105, Failures: 0, Errors: 4, Skipped: 0
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  7.392 s
[INFO] Finished at: 2023-02-09T01:40:36Z
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.22.0:test (default-test) on project snowflake-kafka-connector: There are test failures.
[ERROR] 
[ERROR] Please refer to /home/gabsko/breaking-updates/target/surefire-reports for the individual test results.
[ERROR] Please refer to dump files (if any exist) [date]-jvmRun[N].dump, [date].dumpstream and [date]-jvmRun[N].dumpstream.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
